WARNING:absl:Tensorflow library not found, tensorflow.io.gfile operations will use native shim calls. GCS paths (i.e. 'gs://...') cannot be accessed.
INFO:2025-02-21 14:13:08,034:jax._src.xla_bridge:945: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
seed: 1234
checkpoint: null
data_dir: ./data
output_dir: ./outputs/${now:%Y-%m-%d-%H-%M-%S}
checkpoint_dir: ./checkpoints
model:
  ssm_init:
    C_init: lecun_normal
    dt_min: 0.0015
    dt_max: 0.1
    conj_sym: true
    clip_eigs: false
  ssm:
    discretization: async
    d_model: 96
    d_ssm: 128
    ssm_block_size: 16
    num_stages: 2
    num_layers_per_stage: 3
    dropout: 0.23
    classification_mode: pool
    prenorm: true
    batchnorm: true
    bn_momentum: 0.95
    pooling_stride: 8
    pooling_mode: avgpool
    state_expansion_factor: 2
task:
  name: ssc-classification
training:
  num_epochs: 200
  per_device_batch_size: 32
  per_device_eval_batch_size: 64
  num_workers: 0
  time_jitter: 3
  spatial_jitter: 1.0
  noise: 100
  drop_event: 0.1
  max_drop_chunk: 0.02
  cut_mix: 0.3
  time_skew: 1.05
  pad_unit: 8192
optimizer:
  ssm_base_lr: 5.0e-06
  lr_factor: 5
  warmup_epochs: 20
  ssm_weight_decay: 0.0
  weight_decay: 0.05
  schedule: cosine
  accumulation_steps: 1
logging:
  log_dir: ${output_dir}
  interval: 1000
  wandb: false
  summary_metric: Performance/Validation accuracy
  project: ???
  entity: ???

[2025-02-21 14:13:08,034][jax._src.xla_bridge][INFO] - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
INFO:2025-02-21 14:13:08,045:jax._src.xla_bridge:945: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-02-21 14:13:08,045][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[*] Loading dataset...
[*] Generating Spiking Speech Commands Classification Dataset
[*] Creating model...
[*] Initializing model state...
[SequenceLayer] Layer 0: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (128,) and values: [-0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25]
SSM: 96 -> 128 -> 96 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (128,) and values: [-0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25]
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 2: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (128,) and values: [-0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25]
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 0: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (256,) and values: [-0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25]
SSM: 96 -> 256 -> 192 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (256,) and values: [-0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25]
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 2: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (256,) and values: [-0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
 -0.25 -0.25 -0.25 -0.25]
SSM: 192 -> 256 -> 192
[*] Model parameter count: 597731
[*] Using gradient accumulation with 1 steps
[*] Running training on 2 GPUs
[*] Logging to ./outputs/2025-02-21-14-13-07
[*] Number of model parameters: 597731
[*] Running training...
[SequenceLayer] Layer 0: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (128,) and values: Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace>
SSM: 96 -> 128 -> 96 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (128,) and values: Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace>
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 2: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (128,) and values: Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace>
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 0: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (256,) and values: Traced<ShapedArray(float32[256])>with<DynamicJaxprTrace>
SSM: 96 -> 256 -> 192 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (256,) and values: Traced<ShapedArray(float32[256])>with<DynamicJaxprTrace>
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 2: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (256,) and values: Traced<ShapedArray(float32[256])>with<DynamicJaxprTrace>
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 0: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (128,) and values: Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace>
SSM: 96 -> 128 -> 96 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (128,) and values: Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace>
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 2: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (128,) and values: Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace>
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 0: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (256,) and values: Traced<ShapedArray(float32[256])>with<DynamicJaxprTrace>
SSM: 96 -> 256 -> 192 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (256,) and values: Traced<ShapedArray(float32[256])>with<DynamicJaxprTrace>
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 2: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (256,) and values: Traced<ShapedArray(float32[256])>with<DynamicJaxprTrace>
SSM: 192 -> 256 -> 192
| epoch 1 | 1000/1179 batches | ms/batch 1157.21 | Performance/Training accuracy:  0.05 | Performance/Training loss:  3.53
-----------------------------------------------------------------------------------------
| end of epoch   1 | time per epoch: 1331.75s |
| Train Metrics | accuracy:  0.06 | loss:  3.49
[SequenceLayer] Layer 0: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (128,) and values: Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace>
SSM: 96 -> 128 -> 96 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (128,) and values: Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace>
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 2: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (128,) and values: Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace>
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 0: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (256,) and values: Traced<ShapedArray(float32[256])>with<DynamicJaxprTrace>
SSM: 96 -> 256 -> 192 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (256,) and values: Traced<ShapedArray(float32[256])>with<DynamicJaxprTrace>
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 2: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (256,) and values: Traced<ShapedArray(float32[256])>with<DynamicJaxprTrace>
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 0: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (128,) and values: Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace>
SSM: 96 -> 128 -> 96 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (128,) and values: Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace>
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 2: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (128,) and values: Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace>
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 0: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (256,) and values: Traced<ShapedArray(float32[256])>with<DynamicJaxprTrace>
SSM: 96 -> 256 -> 192 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (256,) and values: Traced<ShapedArray(float32[256])>with<DynamicJaxprTrace>
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 2: manual_lambda = -0.25
[S5SSM] Using manual lambda: -0.25, resulting in Lambda with shape (256,) and values: Traced<ShapedArray(float32[256])>with<DynamicJaxprTrace>
SSM: 192 -> 256 -> 192
| Eval  Metrics | accuracy:  0.15 | loss:  3.03
-----------------------------------------------------------------------------------------
[2025-02-21 14:38:03,772][absl][INFO] - Saving checkpoint at step: 1179
[2025-02-21 14:38:03,774][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 14:38:03,774][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 14:38:03,774][absl][INFO] - orbax-checkpoint version: 0.11.1
[2025-02-21 14:38:03,776][absl][INFO] - [thread=MainThread] Failed to get flag value for EXPERIMENTAL_ORBAX_USE_DISTRIBUTED_PROCESS_ID.
[2025-02-21 14:38:03,776][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_1179.
[2025-02-21 14:38:03,787][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 14:38:03,788][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_1179.orbax-checkpoint-tmp-0
[2025-02-21 14:38:03,794][absl][INFO] - Wrote Metadata={'item_handlers': None, 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1740166683790839500, 'commit_timestamp_nsecs': None, 'custom': {}}, json={"item_handlers": null, "metrics": {}, "performance_metrics": {}, "init_timestamp_nsecs": 1740166683790839500, "commit_timestamp_nsecs": null, "custom": {}} to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_1179.orbax-checkpoint-tmp-0/_CHECKPOINT_METADATA
[2025-02-21 14:38:03,794][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 14:38:03,821][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 14:38:03,847][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 175.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 51 milliseconds) (per-host)
[2025-02-21 14:38:04,090][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-21 14:38:04,090][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 294 milliseconds) (per-host)
[2025-02-21 14:38:04,093][absl][INFO] - Read Metadata={'item_handlers': None, 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1740166683790839500, 'commit_timestamp_nsecs': None, 'custom': {}} from /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_1179.orbax-checkpoint-tmp-0/_CHECKPOINT_METADATA
[2025-02-21 14:38:04,097][absl][INFO] - Updated Metadata={'item_handlers': 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler', 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1740166683790839500, 'commit_timestamp_nsecs': None, 'custom': {}} to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_1179.orbax-checkpoint-tmp-0/_CHECKPOINT_METADATA
[2025-02-21 14:38:04,097][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 14:38:04,131][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_1179.orbax-checkpoint-tmp-0 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_1179
[2025-02-21 14:38:04,138][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_1179`.
[2025-02-21 14:38:04,138][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
| epoch 2 | 1000/1179 batches | ms/batch 958.11 | Performance/Training accuracy:  0.15 | Performance/Training loss:  3.05
-----------------------------------------------------------------------------------------
| end of epoch   2 | time per epoch: 1128.45s |
| Train Metrics | accuracy:  0.15 | loss:  3.03
| Eval  Metrics | accuracy:  0.28 | loss:  2.62
-----------------------------------------------------------------------------------------
[2025-02-21 14:58:17,703][absl][INFO] - Saving checkpoint at step: 2358
[2025-02-21 14:58:17,704][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 14:58:17,705][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 14:58:17,706][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_2358.
[2025-02-21 14:58:17,714][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 14:58:17,715][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_2358.orbax-checkpoint-tmp-1
[2025-02-21 14:58:17,722][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 14:58:17,749][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 14:58:17,782][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 156.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 58 milliseconds) (per-host)
[2025-02-21 14:58:18,029][absl][INFO] - ChainedFuture completed 1/1 futures in 0.25 seconds.
[2025-02-21 14:58:18,029][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 29.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 305 milliseconds) (per-host)
[2025-02-21 14:58:18,035][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 14:58:18,066][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_2358.orbax-checkpoint-tmp-1 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_2358
[2025-02-21 14:58:18,072][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_2358`.
[2025-02-21 14:58:18,072][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 14:58:18,073][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_1179
| epoch 3 | 1000/1179 batches | ms/batch 946.01 | Performance/Training accuracy:  0.22 | Performance/Training loss:  2.82
-----------------------------------------------------------------------------------------
| end of epoch   3 | time per epoch: 1113.01s |
| Train Metrics | accuracy:  0.22 | loss:  2.80
| Eval  Metrics | accuracy:  0.34 | loss:  2.32
-----------------------------------------------------------------------------------------
[2025-02-21 15:18:17,471][absl][INFO] - Saving checkpoint at step: 3537
[2025-02-21 15:18:17,472][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 15:18:17,473][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 15:18:17,474][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_3537.
[2025-02-21 15:18:17,482][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 15:18:17,483][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_3537.orbax-checkpoint-tmp-2
[2025-02-21 15:18:17,490][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 15:18:17,517][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 15:18:17,533][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 219.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 41 milliseconds) (per-host)
[2025-02-21 15:18:17,769][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-21 15:18:17,769][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 278 milliseconds) (per-host)
[2025-02-21 15:18:17,775][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 15:18:17,808][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_3537.orbax-checkpoint-tmp-2 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_3537
[2025-02-21 15:18:17,815][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_3537`.
[2025-02-21 15:18:17,815][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 15:18:17,816][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_2358
| epoch 4 | 1000/1179 batches | ms/batch 930.88 | Performance/Training accuracy:  0.28 | Performance/Training loss:  2.59
-----------------------------------------------------------------------------------------
| end of epoch   4 | time per epoch: 1095.28s |
| Train Metrics | accuracy:  0.29 | loss:  2.57
| Eval  Metrics | accuracy:  0.45 | loss:  1.93
-----------------------------------------------------------------------------------------
[2025-02-21 15:38:07,192][absl][INFO] - Saving checkpoint at step: 4716
[2025-02-21 15:38:07,194][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 15:38:07,194][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 15:38:07,196][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_4716.
[2025-02-21 15:38:07,204][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 15:38:07,205][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_4716.orbax-checkpoint-tmp-3
[2025-02-21 15:38:07,213][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 15:38:07,239][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 15:38:07,270][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 162.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 56 milliseconds) (per-host)
[2025-02-21 15:38:07,510][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-21 15:38:07,510][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 296 milliseconds) (per-host)
[2025-02-21 15:38:07,518][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 15:38:07,557][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_4716.orbax-checkpoint-tmp-3 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_4716
[2025-02-21 15:38:07,564][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_4716`.
[2025-02-21 15:38:07,564][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 15:38:07,566][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_3537
| epoch 5 | 1000/1179 batches | ms/batch 895.31 | Performance/Training accuracy:  0.35 | Performance/Training loss:  2.37
-----------------------------------------------------------------------------------------
| end of epoch   5 | time per epoch: 1051.46s |
| Train Metrics | accuracy:  0.35 | loss:  2.35
| Eval  Metrics | accuracy:  0.51 | loss:  1.68
-----------------------------------------------------------------------------------------
[2025-02-21 15:57:09,899][absl][INFO] - Saving checkpoint at step: 5895
[2025-02-21 15:57:09,901][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 15:57:09,901][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 15:57:09,902][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_5895.
[2025-02-21 15:57:09,910][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 15:57:09,911][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_5895.orbax-checkpoint-tmp-4
[2025-02-21 15:57:09,919][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 15:57:09,945][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 15:57:09,974][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 167.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-21 15:57:10,213][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-21 15:57:10,213][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 294 milliseconds) (per-host)
[2025-02-21 15:57:10,219][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 15:57:10,252][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_5895.orbax-checkpoint-tmp-4 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_5895
[2025-02-21 15:57:10,258][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_5895`.
[2025-02-21 15:57:10,258][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 15:57:10,260][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_4716
| epoch 6 | 1000/1179 batches | ms/batch 887.54 | Performance/Training accuracy:  0.40 | Performance/Training loss:  2.18
-----------------------------------------------------------------------------------------
| end of epoch   6 | time per epoch: 1048.55s |
| Train Metrics | accuracy:  0.41 | loss:  2.17
| Eval  Metrics | accuracy:  0.55 | loss:  1.52
-----------------------------------------------------------------------------------------
[2025-02-21 16:16:10,004][absl][INFO] - Saving checkpoint at step: 7074
[2025-02-21 16:16:10,006][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 16:16:10,006][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 16:16:10,007][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_7074.
[2025-02-21 16:16:10,015][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 16:16:10,016][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_7074.orbax-checkpoint-tmp-5
[2025-02-21 16:16:10,024][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 16:16:10,050][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 16:16:10,418][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 23.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 393 milliseconds) (per-host)
[2025-02-21 16:16:10,643][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-21 16:16:10,643][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 14.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 618 milliseconds) (per-host)
[2025-02-21 16:16:10,650][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 16:16:10,694][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_7074.orbax-checkpoint-tmp-5 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_7074
[2025-02-21 16:16:10,701][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_7074`.
[2025-02-21 16:16:10,701][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 16:16:10,702][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_5895
| epoch 7 | 1000/1179 batches | ms/batch 892.93 | Performance/Training accuracy:  0.44 | Performance/Training loss:  2.04
-----------------------------------------------------------------------------------------
| end of epoch   7 | time per epoch: 1052.44s |
| Train Metrics | accuracy:  0.45 | loss:  2.03
| Eval  Metrics | accuracy:  0.59 | loss:  1.41
-----------------------------------------------------------------------------------------
[2025-02-21 16:35:15,457][absl][INFO] - Saving checkpoint at step: 8253
[2025-02-21 16:35:15,458][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 16:35:15,459][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 16:35:15,460][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_8253.
[2025-02-21 16:35:15,468][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 16:35:15,469][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_8253.orbax-checkpoint-tmp-6
[2025-02-21 16:35:15,477][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 16:35:15,504][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 16:35:15,532][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 168.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-21 16:35:15,752][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-21 16:35:15,752][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 274 milliseconds) (per-host)
[2025-02-21 16:35:15,758][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 16:35:15,791][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_8253.orbax-checkpoint-tmp-6 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_8253
[2025-02-21 16:35:15,797][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_8253`.
[2025-02-21 16:35:15,797][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 16:35:15,799][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_7074
| epoch 8 | 1000/1179 batches | ms/batch 921.50 | Performance/Training accuracy:  0.48 | Performance/Training loss:  1.92
-----------------------------------------------------------------------------------------
| end of epoch   8 | time per epoch: 1089.15s |
| Train Metrics | accuracy:  0.48 | loss:  1.91
| Eval  Metrics | accuracy:  0.63 | loss:  1.26
-----------------------------------------------------------------------------------------
[2025-02-21 16:54:57,753][absl][INFO] - Saving checkpoint at step: 9432
[2025-02-21 16:54:57,755][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 16:54:57,755][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 16:54:57,756][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_9432.
[2025-02-21 16:54:57,765][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 16:54:57,766][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_9432.orbax-checkpoint-tmp-7
[2025-02-21 16:54:57,774][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 16:54:57,801][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 16:54:57,830][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 166.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-21 16:54:58,073][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-21 16:54:58,073][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 298 milliseconds) (per-host)
[2025-02-21 16:54:58,079][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 16:54:58,115][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_9432.orbax-checkpoint-tmp-7 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_9432
[2025-02-21 16:54:58,121][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_9432`.
[2025-02-21 16:54:58,121][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 16:54:58,123][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_8253
| epoch 9 | 1000/1179 batches | ms/batch 935.21 | Performance/Training accuracy:  0.51 | Performance/Training loss:  1.82
-----------------------------------------------------------------------------------------
| end of epoch   9 | time per epoch: 1110.60s |
| Train Metrics | accuracy:  0.51 | loss:  1.82
| Eval  Metrics | accuracy:  0.64 | loss:  1.24
-----------------------------------------------------------------------------------------
[2025-02-21 17:15:04,026][absl][INFO] - Saving checkpoint at step: 10611
[2025-02-21 17:15:04,027][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 17:15:04,028][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 17:15:04,029][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_10611.
[2025-02-21 17:15:04,031][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 17:15:04,032][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_10611.orbax-checkpoint-tmp-8
[2025-02-21 17:15:04,040][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 17:15:04,066][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 17:15:04,095][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 168.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-21 17:15:04,334][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-21 17:15:04,334][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 293 milliseconds) (per-host)
[2025-02-21 17:15:04,340][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 17:15:04,373][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_10611.orbax-checkpoint-tmp-8 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_10611
[2025-02-21 17:15:04,379][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_10611`.
[2025-02-21 17:15:04,379][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 17:15:04,381][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_9432
| epoch 10 | 1000/1179 batches | ms/batch 938.74 | Performance/Training accuracy:  0.53 | Performance/Training loss:  1.74
-----------------------------------------------------------------------------------------
| end of epoch  10 | time per epoch: 1104.64s |
| Train Metrics | accuracy:  0.53 | loss:  1.75
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.0075367591343820095,
    "std": 0.12513898313045502,
    "var": 0.015659768134355545,
    "min": -0.30161941051483154,
    "max": 0.2641180455684662,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.8301088213920593,
    "std": 0.08069845288991928,
    "var": 0.006512240972369909,
    "min": 0.6692063808441162,
    "max": 1.0439759492874146,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.00022712167992722243,
    "std": 0.08995483070611954,
    "var": 0.008091872557997704,
    "min": -0.22741422057151794,
    "max": 0.2227664589881897,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.07547226548194885,
    "std": 0.06486915051937103,
    "var": 0.004208006430417299,
    "min": -0.06908956915140152,
    "max": 0.24194423854351044,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.8291664123535156,
    "std": 0.10049156844615936,
    "var": 0.01009855605661869,
    "min": 0.5900473594665527,
    "max": 1.1229053735733032,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00016319332644343376,
    "std": 0.08902809023857117,
    "var": 0.007926001213490963,
    "min": -0.23910267651081085,
    "max": 0.23548191785812378,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.07031532377004623,
    "std": 0.059857308864593506,
    "var": 0.003582897363230586,
    "min": -0.08793065696954727,
    "max": 0.24015918374061584,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.7985752820968628,
    "std": 0.10169214010238647,
    "var": 0.01034129224717617,
    "min": 0.5791966915130615,
    "max": 1.058882474899292,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0010557409841567278,
    "std": 0.08903545141220093,
    "var": 0.007927311584353447,
    "min": -0.2393803745508194,
    "max": 0.2448931634426117,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.05514216423034668,
    "std": 0.05271247774362564,
    "var": 0.0027786053251475096,
    "min": -0.06614115089178085,
    "max": 0.2646026313304901,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.9243699312210083,
    "std": 0.10324253886938095,
    "var": 0.010659022256731987,
    "min": 0.6884648203849792,
    "max": 1.2289445400238037,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0002893098280765116,
    "std": 0.06345415860414505,
    "var": 0.004026429727673531,
    "min": -0.19462844729423523,
    "max": 0.1676713526248932,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.0524357371032238,
    "std": 0.055902428925037384,
    "var": 0.0031250815372914076,
    "min": -0.10704486072063446,
    "max": 0.23660612106323242,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 1.0761997699737549,
    "std": 0.15004104375839233,
    "var": 0.022512316703796387,
    "min": 0.7940854430198669,
    "max": 1.62852942943573,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 3.166263923048973e-05,
    "std": 0.06262137740850449,
    "var": 0.003921437542885542,
    "min": -0.1799572855234146,
    "max": 0.1710701435804367,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.025578400120139122,
    "std": 0.04024474322795868,
    "var": 0.001619639340788126,
    "min": -0.08020419627428055,
    "max": 0.1470753252506256,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.1559524536132812,
    "std": 0.15917842090129852,
    "var": 0.025337766855955124,
    "min": 0.8746665120124817,
    "max": 1.7575438022613525,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0004354685952421278,
    "std": 0.06321319937705994,
    "var": 0.003995908424258232,
    "min": -0.18607795238494873,
    "max": 0.1864021122455597,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": 0.000605259498115629,
    "std": 0.09655911475419998,
    "var": 0.0093236630782485,
    "min": -0.5024762153625488,
    "max": 0.545323371887207,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0009035972179844975,
    "std": 0.0913718044757843,
    "var": 0.008348806761205196,
    "min": -0.2822761535644531,
    "max": 0.3728983402252197,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0013902091886848211,
    "std": 0.09328502416610718,
    "var": 0.008702095597982407,
    "min": -0.311332106590271,
    "max": 0.355729341506958,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0005170134827494621,
    "std": 0.07272035628557205,
    "var": 0.005288250744342804,
    "min": -0.2867622971534729,
    "max": 0.302286833524704,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 9.96671078610234e-05,
    "std": 0.07121522724628448,
    "var": 0.005071608349680901,
    "min": -0.3119249939918518,
    "max": 0.28768736124038696,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0004558814107440412,
    "std": 0.07434558868408203,
    "var": 0.005527266766875982,
    "min": -0.3113296329975128,
    "max": 0.3298836052417755,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.14322401583194733,
    "std": 0.048888374119997025,
    "var": 0.0023900731466710567,
    "min": -0.2622673213481903,
    "max": -0.016963625326752663,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.0356123186647892,
    "std": 0.12252018600702286,
    "var": 0.015011195093393326,
    "min": -0.49565982818603516,
    "max": 0.44606053829193115,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.016498461365699768,
    "std": 0.8790258765220642,
    "var": 0.7726864814758301,
    "min": -1.796836256980896,
    "max": 2.1511223316192627,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.13573023676872253,
    "std": 0.055692996829748154,
    "var": 0.0031017097644507885,
    "min": -0.2734834849834442,
    "max": 0.021774644032120705,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.08402278274297714,
    "std": 0.10054080933332443,
    "var": 0.010108455084264278,
    "min": -0.4858247935771942,
    "max": 0.2529483735561371,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.003483851905912161,
    "std": 0.8128824830055237,
    "var": 0.6607779860496521,
    "min": -1.8769152164459229,
    "max": 2.152268648147583,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.14127075672149658,
    "std": 0.0446089468896389,
    "var": 0.001989958342164755,
    "min": -0.2501063346862793,
    "max": 0.020769359543919563,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.07942645996809006,
    "std": 0.10000953078269958,
    "var": 0.01000190619379282,
    "min": -0.4423525035381317,
    "max": 0.26307523250579834,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.09543876349925995,
    "std": 0.7766222357749939,
    "var": 0.6031420826911926,
    "min": -1.420617938041687,
    "max": 1.8915084600448608,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.0671742781996727,
    "std": 0.04832317680120468,
    "var": 0.002335129538550973,
    "min": -0.1987847238779068,
    "max": 0.06445762515068054,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.05257028341293335,
    "std": 0.09299054741859436,
    "var": 0.00864724162966013,
    "min": -0.5322290062904358,
    "max": 0.2922738492488861,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0008925962611101568,
    "std": 0.03783036768436432,
    "var": 0.0014311366248875856,
    "min": -0.09890236705541611,
    "max": 0.09114392101764679,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.0003617486800067127,
    "std": 0.08166874945163727,
    "var": 0.006669784430414438,
    "min": -0.2867801785469055,
    "max": 0.2923688590526581,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.002990327775478363,
    "std": 0.12189539521932602,
    "var": 0.014858487993478775,
    "min": -0.6376949548721313,
    "max": 0.6427505612373352,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.0781489759683609,
    "std": 0.05108262225985527,
    "var": 0.00260943453758955,
    "min": -0.20595236122608185,
    "max": 0.0997210144996643,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.03619246557354927,
    "std": 0.10494165867567062,
    "var": 0.011012752540409565,
    "min": -0.6202694773674011,
    "max": 0.5484232306480408,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": -0.08419045060873032,
    "std": 0.9350878596305847,
    "var": 0.8743893504142761,
    "min": -3.0027272701263428,
    "max": 2.3079142570495605,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.029280543327331543,
    "std": 0.049326181411743164,
    "var": 0.0024330723099410534,
    "min": -0.19944573938846588,
    "max": 0.09010535478591919,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.01671482063829899,
    "std": 0.1097925454378128,
    "var": 0.012054403312504292,
    "min": -0.5362844467163086,
    "max": 0.4264672100543976,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.18276050686836243,
    "std": 0.9457248449325562,
    "var": 0.8943954706192017,
    "min": -2.240823268890381,
    "max": 2.8738203048706055,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.004035863094031811,
    "std": 0.03040926717221737,
    "var": 0.0009247235138900578,
    "min": -0.07612474262714386,
    "max": 0.048662666231393814,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0015416460810229182,
    "std": 0.09277185797691345,
    "var": 0.008606618270277977,
    "min": -0.40087226033210754,
    "max": 0.3008154034614563,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.00010641264088917524,
    "std": 0.1489207148551941,
    "var": 0.022177381440997124,
    "min": -0.7298678159713745,
    "max": 0.8742706775665283,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -3.5639350414276123,
    "std": 0.9984631538391113,
    "var": 0.9969286918640137,
    "min": -5.177742004394531,
    "max": -1.4286295175552368,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -3.500053882598877,
    "std": 0.9326859712600708,
    "var": 0.8699031472206116,
    "min": -5.123350620269775,
    "max": -1.716517448425293,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -3.689108371734619,
    "std": 0.9215961694717407,
    "var": 0.8493395447731018,
    "min": -5.112950801849365,
    "max": -1.7669215202331543,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -3.4861631393432617,
    "std": 0.9286905527114868,
    "var": 0.8624662160873413,
    "min": -5.162075042724609,
    "max": -1.797683596611023,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -3.5673625469207764,
    "std": 0.9070948958396912,
    "var": 0.8228211998939514,
    "min": -5.1818342208862305,
    "max": -1.6530144214630127,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -3.5297157764434814,
    "std": 0.8361460566520691,
    "var": 0.6991402506828308,
    "min": -5.050747871398926,
    "max": -1.9067144393920898,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.66 | loss:  1.14
-----------------------------------------------------------------------------------------
[2025-02-21 17:35:07,605][absl][INFO] - Saving checkpoint at step: 11790
[2025-02-21 17:35:07,606][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 17:35:07,606][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 17:35:07,607][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_11790.
[2025-02-21 17:35:07,615][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 17:35:07,616][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_11790.orbax-checkpoint-tmp-9
[2025-02-21 17:35:07,624][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 17:35:07,649][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 17:35:07,675][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 180.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 50 milliseconds) (per-host)
[2025-02-21 17:35:07,900][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-21 17:35:07,900][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 275 milliseconds) (per-host)
[2025-02-21 17:35:07,906][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 17:35:07,938][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_11790.orbax-checkpoint-tmp-9 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_11790
[2025-02-21 17:35:07,945][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_11790`.
[2025-02-21 17:35:07,945][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 17:35:07,947][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_10611
| epoch 11 | 1000/1179 batches | ms/batch 937.04 | Performance/Training accuracy:  0.55 | Performance/Training loss:  1.69
-----------------------------------------------------------------------------------------
| end of epoch  11 | time per epoch: 1104.03s |
| Train Metrics | accuracy:  0.55 | loss:  1.68
| Eval  Metrics | accuracy:  0.68 | loss:  1.09
-----------------------------------------------------------------------------------------
[2025-02-21 17:55:05,364][absl][INFO] - Saving checkpoint at step: 12969
[2025-02-21 17:55:05,366][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 17:55:05,366][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 17:55:05,367][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_12969.
[2025-02-21 17:55:05,370][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 17:55:05,371][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_12969.orbax-checkpoint-tmp-10
[2025-02-21 17:55:05,381][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 17:55:05,406][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 17:55:05,434][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 174.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 52 milliseconds) (per-host)
[2025-02-21 17:55:05,670][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-21 17:55:05,670][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 288 milliseconds) (per-host)
[2025-02-21 17:55:05,676][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 17:55:05,712][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_12969.orbax-checkpoint-tmp-10 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_12969
[2025-02-21 17:55:05,719][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_12969`.
[2025-02-21 17:55:05,719][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 17:55:05,721][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_11790
| epoch 12 | 1000/1179 batches | ms/batch 988.91 | Performance/Training accuracy:  0.56 | Performance/Training loss:  1.63
-----------------------------------------------------------------------------------------
| end of epoch  12 | time per epoch: 1169.56s |
| Train Metrics | accuracy:  0.56 | loss:  1.63
| Eval  Metrics | accuracy:  0.69 | loss:  1.04
-----------------------------------------------------------------------------------------
[2025-02-21 18:16:10,835][absl][INFO] - Saving checkpoint at step: 14148
[2025-02-21 18:16:10,836][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 18:16:10,837][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 18:16:10,838][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_14148.
[2025-02-21 18:16:10,853][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 18:16:10,854][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_14148.orbax-checkpoint-tmp-11
[2025-02-21 18:16:10,863][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 18:16:10,889][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 18:16:11,230][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 24.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 366 milliseconds) (per-host)
[2025-02-21 18:16:11,496][absl][INFO] - ChainedFuture completed 1/1 futures in 0.26 seconds.
[2025-02-21 18:16:11,496][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 14.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 632 milliseconds) (per-host)
[2025-02-21 18:16:11,504][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 18:16:11,540][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_14148.orbax-checkpoint-tmp-11 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_14148
[2025-02-21 18:16:11,547][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_14148`.
[2025-02-21 18:16:11,548][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 18:16:11,549][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_12969
| epoch 13 | 1000/1179 batches | ms/batch 994.52 | Performance/Training accuracy:  0.58 | Performance/Training loss:  1.57
-----------------------------------------------------------------------------------------
| end of epoch  13 | time per epoch: 1169.91s |
| Train Metrics | accuracy:  0.58 | loss:  1.57
| Eval  Metrics | accuracy:  0.70 | loss:  1.00
-----------------------------------------------------------------------------------------
[2025-02-21 18:37:15,155][absl][INFO] - Saving checkpoint at step: 15327
[2025-02-21 18:37:15,157][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 18:37:15,157][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 18:37:15,159][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_15327.
[2025-02-21 18:37:15,167][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 18:37:15,168][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_15327.orbax-checkpoint-tmp-12
[2025-02-21 18:37:15,175][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 18:37:15,202][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 18:37:15,236][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 151.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 60 milliseconds) (per-host)
[2025-02-21 18:37:15,466][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-21 18:37:15,466][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 289 milliseconds) (per-host)
[2025-02-21 18:37:15,472][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 18:37:15,508][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_15327.orbax-checkpoint-tmp-12 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_15327
[2025-02-21 18:37:15,516][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_15327`.
[2025-02-21 18:37:15,516][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 18:37:15,518][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_14148
| epoch 14 | 1000/1179 batches | ms/batch 1013.30 | Performance/Training accuracy:  0.59 | Performance/Training loss:  1.56
-----------------------------------------------------------------------------------------
| end of epoch  14 | time per epoch: 1193.36s |
| Train Metrics | accuracy:  0.58 | loss:  1.57
| Eval  Metrics | accuracy:  0.70 | loss:  1.03
-----------------------------------------------------------------------------------------
| epoch 15 | 1000/1179 batches | ms/batch 930.61 | Performance/Training accuracy:  0.60 | Performance/Training loss:  1.54
-----------------------------------------------------------------------------------------
| end of epoch  15 | time per epoch: 1095.42s |
| Train Metrics | accuracy:  0.59 | loss:  1.54
| Eval  Metrics | accuracy:  0.71 | loss:  1.01
-----------------------------------------------------------------------------------------
[2025-02-21 19:18:34,275][absl][INFO] - Saving checkpoint at step: 17685
[2025-02-21 19:18:34,277][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 19:18:34,277][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 19:18:34,278][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_17685.
[2025-02-21 19:18:34,281][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 19:18:34,282][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_17685.orbax-checkpoint-tmp-13
[2025-02-21 19:18:34,292][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 19:18:34,319][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 19:18:34,349][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 162.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 56 milliseconds) (per-host)
[2025-02-21 19:18:34,586][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-21 19:18:34,586][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 292 milliseconds) (per-host)
[2025-02-21 19:18:34,592][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 19:18:34,627][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_17685.orbax-checkpoint-tmp-13 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_17685
[2025-02-21 19:18:34,633][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_17685`.
[2025-02-21 19:18:34,633][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 19:18:34,635][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_15327
| epoch 16 | 1000/1179 batches | ms/batch 902.03 | Performance/Training accuracy:  0.60 | Performance/Training loss:  1.52
-----------------------------------------------------------------------------------------
| end of epoch  16 | time per epoch: 1064.82s |
| Train Metrics | accuracy:  0.60 | loss:  1.51
| Eval  Metrics | accuracy:  0.72 | loss:  0.95
-----------------------------------------------------------------------------------------
[2025-02-21 19:37:51,470][absl][INFO] - Saving checkpoint at step: 18864
[2025-02-21 19:37:51,472][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 19:37:51,473][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 19:37:51,475][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_18864.
[2025-02-21 19:37:51,484][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 19:37:51,486][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_18864.orbax-checkpoint-tmp-14
[2025-02-21 19:37:51,493][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 19:37:51,521][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 19:37:51,550][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 164.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 55 milliseconds) (per-host)
[2025-02-21 19:37:51,775][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-21 19:37:51,775][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 281 milliseconds) (per-host)
[2025-02-21 19:37:51,781][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 19:37:51,816][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_18864.orbax-checkpoint-tmp-14 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_18864
[2025-02-21 19:37:51,822][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_18864`.
[2025-02-21 19:37:51,822][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 19:37:51,824][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_17685
| epoch 17 | 1000/1179 batches | ms/batch 894.09 | Performance/Training accuracy:  0.61 | Performance/Training loss:  1.50
-----------------------------------------------------------------------------------------
| end of epoch  17 | time per epoch: 1057.24s |
| Train Metrics | accuracy:  0.61 | loss:  1.50
| Eval  Metrics | accuracy:  0.72 | loss:  0.99
-----------------------------------------------------------------------------------------
[2025-02-21 19:57:00,563][absl][INFO] - Saving checkpoint at step: 20043
[2025-02-21 19:57:00,565][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 19:57:00,565][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 19:57:00,566][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_20043.
[2025-02-21 19:57:00,574][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 19:57:00,575][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_20043.orbax-checkpoint-tmp-15
[2025-02-21 19:57:00,581][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 19:57:00,608][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 19:57:00,638][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 164.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 55 milliseconds) (per-host)
[2025-02-21 19:57:00,883][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-21 19:57:00,883][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 300 milliseconds) (per-host)
[2025-02-21 19:57:00,889][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 19:57:00,920][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_20043.orbax-checkpoint-tmp-15 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_20043
[2025-02-21 19:57:00,927][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_20043`.
[2025-02-21 19:57:00,927][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 19:57:00,929][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_18864
| epoch 18 | 1000/1179 batches | ms/batch 887.14 | Performance/Training accuracy:  0.61 | Performance/Training loss:  1.48
-----------------------------------------------------------------------------------------
| end of epoch  18 | time per epoch: 1051.47s |
| Train Metrics | accuracy:  0.61 | loss:  1.49
| Eval  Metrics | accuracy:  0.72 | loss:  0.94
-----------------------------------------------------------------------------------------
[2025-02-21 20:16:04,669][absl][INFO] - Saving checkpoint at step: 21222
[2025-02-21 20:16:04,671][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 20:16:04,671][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 20:16:04,672][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_21222.
[2025-02-21 20:16:04,680][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 20:16:04,681][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_21222.orbax-checkpoint-tmp-16
[2025-02-21 20:16:04,688][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 20:16:04,714][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 20:16:04,744][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 167.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-21 20:16:04,966][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-21 20:16:04,966][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 276 milliseconds) (per-host)
[2025-02-21 20:16:04,972][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 20:16:05,003][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_21222.orbax-checkpoint-tmp-16 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_21222
[2025-02-21 20:16:05,009][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_21222`.
[2025-02-21 20:16:05,009][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 20:16:05,010][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_20043
| epoch 19 | 1000/1179 batches | ms/batch 948.13 | Performance/Training accuracy:  0.61 | Performance/Training loss:  1.50
-----------------------------------------------------------------------------------------
| end of epoch  19 | time per epoch: 1164.39s |
| Train Metrics | accuracy:  0.61 | loss:  1.49
| Eval  Metrics | accuracy:  0.72 | loss:  0.93
-----------------------------------------------------------------------------------------
[2025-02-21 20:37:19,591][absl][INFO] - Saving checkpoint at step: 22401
[2025-02-21 20:37:19,592][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 20:37:19,592][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 20:37:19,594][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_22401.
[2025-02-21 20:37:19,602][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 20:37:19,603][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_22401.orbax-checkpoint-tmp-17
[2025-02-21 20:37:19,611][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 20:37:19,637][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 20:37:19,666][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 169.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 53 milliseconds) (per-host)
[2025-02-21 20:37:19,901][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-21 20:37:19,901][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 289 milliseconds) (per-host)
[2025-02-21 20:37:19,907][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 20:37:19,945][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_22401.orbax-checkpoint-tmp-17 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_22401
[2025-02-21 20:37:19,951][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_22401`.
[2025-02-21 20:37:19,952][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 20:37:19,953][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_21222
| epoch 20 | 1000/1179 batches | ms/batch 966.16 | Performance/Training accuracy:  0.62 | Performance/Training loss:  1.48
-----------------------------------------------------------------------------------------
| end of epoch  20 | time per epoch: 1128.57s |
| Train Metrics | accuracy:  0.62 | loss:  1.47
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.058284830302000046,
    "std": 0.32770487666130066,
    "var": 0.10739049315452576,
    "min": -0.47598129510879517,
    "max": 0.6719220280647278,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.48058271408081055,
    "std": 0.1100965216755867,
    "var": 0.012121244333684444,
    "min": 0.22397373616695404,
    "max": 0.8983928561210632,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.00027955026598647237,
    "std": 0.09285052120685577,
    "var": 0.008621218614280224,
    "min": -0.3058727979660034,
    "max": 0.3069641888141632,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.22651034593582153,
    "std": 0.15485617518424988,
    "var": 0.023980434983968735,
    "min": -0.061025913804769516,
    "max": 0.6835395097732544,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.5535544157028198,
    "std": 0.18540622293949127,
    "var": 0.03437546640634537,
    "min": 0.10684491693973541,
    "max": 1.0052478313446045,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00023363958462141454,
    "std": 0.09132658690214157,
    "var": 0.008340544998645782,
    "min": -0.28916943073272705,
    "max": 0.27211228013038635,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.21766214072704315,
    "std": 0.15194189548492432,
    "var": 0.023086339235305786,
    "min": -0.10668997466564178,
    "max": 0.6016323566436768,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.5259605050086975,
    "std": 0.2356039136648178,
    "var": 0.05550920218229294,
    "min": 0.10785778611898422,
    "max": 1.2427000999450684,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0011990059865638614,
    "std": 0.09202659130096436,
    "var": 0.00846889428794384,
    "min": -0.28190672397613525,
    "max": 0.29648083448410034,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.1328551173210144,
    "std": 0.13991160690784454,
    "var": 0.01957526057958603,
    "min": -0.15807007253170013,
    "max": 0.7611569166183472,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.7433025240898132,
    "std": 0.22754523158073425,
    "var": 0.051776837557554245,
    "min": 0.16409382224082947,
    "max": 1.6484043598175049,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0007660178816877306,
    "std": 0.06320375204086304,
    "var": 0.003994714468717575,
    "min": -0.25295010209083557,
    "max": 0.21087013185024261,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.12544122338294983,
    "std": 0.1756041944026947,
    "var": 0.030836831778287888,
    "min": -0.31024986505508423,
    "max": 0.8262459635734558,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.918071448802948,
    "std": 0.25757715106010437,
    "var": 0.06634598970413208,
    "min": 0.36352968215942383,
    "max": 1.8252921104431152,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 5.0024944357573986e-05,
    "std": 0.06084481254220009,
    "var": 0.00370209151878953,
    "min": -0.2173394411802292,
    "max": 0.2240142971277237,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.010955654084682465,
    "std": 0.08050360530614853,
    "var": 0.006480831187218428,
    "min": -0.27232596278190613,
    "max": 0.2233031541109085,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.0701994895935059,
    "std": 0.25390562415122986,
    "var": 0.06446807086467743,
    "min": 0.6807838082313538,
    "max": 2.4064080715179443,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0004861446504946798,
    "std": 0.06449953466653824,
    "var": 0.004160190001130104,
    "min": -0.21722687780857086,
    "max": 0.2290385365486145,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": 0.0012219519121572375,
    "std": 0.10372025519609451,
    "var": 0.010757891461253166,
    "min": -0.5511362552642822,
    "max": 0.536521315574646,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0012225080281496048,
    "std": 0.102415531873703,
    "var": 0.010488942265510559,
    "min": -0.4460464417934418,
    "max": 0.5229796171188354,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.002826729789376259,
    "std": 0.10635597258806229,
    "var": 0.01131159346550703,
    "min": -0.46260568499565125,
    "max": 0.40556514263153076,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0005259286845102906,
    "std": 0.09500245004892349,
    "var": 0.00902546476572752,
    "min": -0.7046226263046265,
    "max": 0.5274089574813843,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00044646134483627975,
    "std": 0.09288830310106277,
    "var": 0.008628237061202526,
    "min": -0.4693162143230438,
    "max": 0.5949607491493225,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.00033243742655031383,
    "std": 0.09759465605020523,
    "var": 0.00952471699565649,
    "min": -0.6128777265548706,
    "max": 0.4701682925224304,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.34675049781799316,
    "std": 0.11077702045440674,
    "var": 0.012271548621356487,
    "min": -0.5876055359840393,
    "max": -0.055993981659412384,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.06386690586805344,
    "std": 0.20804071426391602,
    "var": 0.043280940502882004,
    "min": -0.93752521276474,
    "max": 0.7814803719520569,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.5013986229896545,
    "std": 0.8301088213920593,
    "var": 0.6890807151794434,
    "min": -1.4427355527877808,
    "max": 2.52331805229187,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.297023743391037,
    "std": 0.09365539252758026,
    "var": 0.00877133198082447,
    "min": -0.4822954535484314,
    "max": -0.04373662918806076,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.14709454774856567,
    "std": 0.12277013063430786,
    "var": 0.015072504989802837,
    "min": -0.6254012584686279,
    "max": 0.30063197016716003,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.6923222541809082,
    "std": 0.5993822813034058,
    "var": 0.35925912857055664,
    "min": -0.8179327845573425,
    "max": 2.5477676391601562,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.30536267161369324,
    "std": 0.09072945266962051,
    "var": 0.008231833577156067,
    "min": -0.5048661828041077,
    "max": -0.08044672757387161,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.13988083600997925,
    "std": 0.1293342560529709,
    "var": 0.016727352514863014,
    "min": -0.7635205388069153,
    "max": 0.3122960925102234,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.5571733117103577,
    "std": 0.5802703499794006,
    "var": 0.3367137312889099,
    "min": -0.633686900138855,
    "max": 2.292048931121826,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.11249107122421265,
    "std": 0.08140985667705536,
    "var": 0.006627565249800682,
    "min": -0.3125677704811096,
    "max": 0.11730805784463882,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.0843736082315445,
    "std": 0.13377031683921814,
    "var": 0.017894497141242027,
    "min": -0.7218236923217773,
    "max": 0.47739800810813904,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0035060024820268154,
    "std": 0.015445802360773087,
    "var": 0.0002385728294029832,
    "min": -0.05157697945833206,
    "max": 0.03641417622566223,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.000994731206446886,
    "std": 0.09348813444375992,
    "var": 0.008740031160414219,
    "min": -0.5700132846832275,
    "max": 0.8512629866600037,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.017473334446549416,
    "std": 0.27140042185783386,
    "var": 0.07365819066762924,
    "min": -1.39732825756073,
    "max": 1.705085039138794,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.16430878639221191,
    "std": 0.09319524466991425,
    "var": 0.008685354143381119,
    "min": -0.40358081459999084,
    "max": 0.12137448787689209,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.06528845429420471,
    "std": 0.1392814815044403,
    "var": 0.019399330019950867,
    "min": -0.8397479057312012,
    "max": 0.5420083999633789,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": -0.006866353563964367,
    "std": 1.0046687126159668,
    "var": 1.009359359741211,
    "min": -2.2999167442321777,
    "max": 2.137174129486084,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.02713475190103054,
    "std": 0.10242565721273422,
    "var": 0.010491015389561653,
    "min": -0.3546559810638428,
    "max": 0.2708696126937866,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.035345155745744705,
    "std": 0.14350652694702148,
    "var": 0.020594125613570213,
    "min": -0.9131012558937073,
    "max": 0.5514129400253296,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.3299255073070526,
    "std": 0.9005088210105896,
    "var": 0.8109161853790283,
    "min": -2.2015511989593506,
    "max": 2.586498498916626,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.01343493815511465,
    "std": 0.08851755410432816,
    "var": 0.007835358381271362,
    "min": -0.18720228970050812,
    "max": 0.14890825748443604,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0017793705919757485,
    "std": 0.15106526017189026,
    "var": 0.022820714861154556,
    "min": -0.7800844311714172,
    "max": 0.6626919507980347,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.003780947532504797,
    "std": 0.2391165792942047,
    "var": 0.05717674270272255,
    "min": -1.3704416751861572,
    "max": 1.2857836484909058,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -2.1674623489379883,
    "std": 0.6325892806053162,
    "var": 0.4001691937446594,
    "min": -3.5222277641296387,
    "max": -0.33742809295654297,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.9916224479675293,
    "std": 0.6588714122772217,
    "var": 0.4341115355491638,
    "min": -3.230302572250366,
    "max": -0.8404523134231567,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -2.1936819553375244,
    "std": 0.6833073496818542,
    "var": 0.46690893173217773,
    "min": -3.773959159851074,
    "max": -0.891284167766571,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -2.291452646255493,
    "std": 0.650560736656189,
    "var": 0.42322927713394165,
    "min": -3.8889124393463135,
    "max": -0.6631802320480347,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -2.389056921005249,
    "std": 0.6281220316886902,
    "var": 0.3945372998714447,
    "min": -3.7885377407073975,
    "max": -0.7004278302192688,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -2.3630197048187256,
    "std": 0.6029185652732849,
    "var": 0.36351078748703003,
    "min": -3.464632272720337,
    "max": -0.9781919717788696,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.74 | loss:  0.88
-----------------------------------------------------------------------------------------
[2025-02-21 20:57:42,119][absl][INFO] - Saving checkpoint at step: 23580
[2025-02-21 20:57:42,120][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 20:57:42,120][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 20:57:42,122][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_23580.
[2025-02-21 20:57:42,130][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 20:57:42,131][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_23580.orbax-checkpoint-tmp-18
[2025-02-21 20:57:42,139][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 20:57:42,164][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 20:57:42,193][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 169.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 53 milliseconds) (per-host)
[2025-02-21 20:57:42,427][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-21 20:57:42,427][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 288 milliseconds) (per-host)
[2025-02-21 20:57:42,433][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 20:57:42,466][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_23580.orbax-checkpoint-tmp-18 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_23580
[2025-02-21 20:57:42,472][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_23580`.
[2025-02-21 20:57:42,472][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 20:57:42,474][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_22401
| epoch 21 | 1000/1179 batches | ms/batch 895.51 | Performance/Training accuracy:  0.63 | Performance/Training loss:  1.44
-----------------------------------------------------------------------------------------
| end of epoch  21 | time per epoch: 1055.98s |
| Train Metrics | accuracy:  0.62 | loss:  1.45
| Eval  Metrics | accuracy:  0.70 | loss:  0.98
-----------------------------------------------------------------------------------------
| epoch 22 | 1000/1179 batches | ms/batch 905.86 | Performance/Training accuracy:  0.63 | Performance/Training loss:  1.44
-----------------------------------------------------------------------------------------
| end of epoch  22 | time per epoch: 1072.88s |
| Train Metrics | accuracy:  0.63 | loss:  1.43
| Eval  Metrics | accuracy:  0.75 | loss:  0.87
-----------------------------------------------------------------------------------------
[2025-02-21 21:36:19,711][absl][INFO] - Saving checkpoint at step: 25938
[2025-02-21 21:36:19,713][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 21:36:19,713][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 21:36:19,714][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_25938.
[2025-02-21 21:36:19,722][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 21:36:19,723][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_25938.orbax-checkpoint-tmp-19
[2025-02-21 21:36:19,732][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 21:36:19,758][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 21:36:20,217][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 18.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 483 milliseconds) (per-host)
[2025-02-21 21:36:20,456][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-21 21:36:20,456][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 12.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 723 milliseconds) (per-host)
[2025-02-21 21:36:20,462][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 21:36:20,495][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_25938.orbax-checkpoint-tmp-19 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_25938
[2025-02-21 21:36:20,502][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_25938`.
[2025-02-21 21:36:20,502][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 21:36:20,504][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_23580
| epoch 23 | 1000/1179 batches | ms/batch 909.74 | Performance/Training accuracy:  0.63 | Performance/Training loss:  1.44
-----------------------------------------------------------------------------------------
| end of epoch  23 | time per epoch: 1073.30s |
| Train Metrics | accuracy:  0.63 | loss:  1.44
| Eval  Metrics | accuracy:  0.75 | loss:  0.85
-----------------------------------------------------------------------------------------
[2025-02-21 21:55:49,871][absl][INFO] - Saving checkpoint at step: 27117
[2025-02-21 21:55:49,872][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 21:55:49,873][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 21:55:49,874][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_27117.
[2025-02-21 21:55:49,882][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 21:55:49,883][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_27117.orbax-checkpoint-tmp-20
[2025-02-21 21:55:49,890][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 21:55:49,917][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 21:55:49,938][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 195.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 46 milliseconds) (per-host)
[2025-02-21 21:55:50,167][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-21 21:55:50,167][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 276 milliseconds) (per-host)
[2025-02-21 21:55:50,173][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 21:55:50,205][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_27117.orbax-checkpoint-tmp-20 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_27117
[2025-02-21 21:55:50,211][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_27117`.
[2025-02-21 21:55:50,211][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 21:55:50,212][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_25938
| epoch 24 | 1000/1179 batches | ms/batch 916.55 | Performance/Training accuracy:  0.64 | Performance/Training loss:  1.37
-----------------------------------------------------------------------------------------
| end of epoch  24 | time per epoch: 1081.51s |
| Train Metrics | accuracy:  0.64 | loss:  1.38
| Eval  Metrics | accuracy:  0.75 | loss:  0.86
-----------------------------------------------------------------------------------------
| epoch 25 | 1000/1179 batches | ms/batch 954.69 | Performance/Training accuracy:  0.64 | Performance/Training loss:  1.39
-----------------------------------------------------------------------------------------
| end of epoch  25 | time per epoch: 1123.56s |
| Train Metrics | accuracy:  0.64 | loss:  1.38
| Eval  Metrics | accuracy:  0.74 | loss:  0.89
-----------------------------------------------------------------------------------------
| epoch 26 | 1000/1179 batches | ms/batch 938.33 | Performance/Training accuracy:  0.65 | Performance/Training loss:  1.37
-----------------------------------------------------------------------------------------
| end of epoch  26 | time per epoch: 1107.33s |
| Train Metrics | accuracy:  0.65 | loss:  1.35
| Eval  Metrics | accuracy:  0.75 | loss:  0.86
-----------------------------------------------------------------------------------------
[2025-02-21 22:56:05,443][absl][INFO] - Saving checkpoint at step: 30654
[2025-02-21 22:56:05,445][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 22:56:05,445][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 22:56:05,446][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_30654.
[2025-02-21 22:56:05,454][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 22:56:05,455][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_30654.orbax-checkpoint-tmp-21
[2025-02-21 22:56:05,462][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 22:56:05,488][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 22:56:05,509][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 200.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 45 milliseconds) (per-host)
[2025-02-21 22:56:05,768][absl][INFO] - ChainedFuture completed 1/1 futures in 0.25 seconds.
[2025-02-21 22:56:05,768][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 29.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 304 milliseconds) (per-host)
[2025-02-21 22:56:05,774][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 22:56:05,805][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_30654.orbax-checkpoint-tmp-21 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_30654
[2025-02-21 22:56:05,811][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_30654`.
[2025-02-21 22:56:05,811][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 22:56:05,813][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_27117
| epoch 27 | 1000/1179 batches | ms/batch 942.32 | Performance/Training accuracy:  0.65 | Performance/Training loss:  1.35
-----------------------------------------------------------------------------------------
| end of epoch  27 | time per epoch: 1113.84s |
| Train Metrics | accuracy:  0.65 | loss:  1.36
| Eval  Metrics | accuracy:  0.75 | loss:  0.84
-----------------------------------------------------------------------------------------
| epoch 28 | 1000/1179 batches | ms/batch 961.72 | Performance/Training accuracy:  0.65 | Performance/Training loss:  1.36
-----------------------------------------------------------------------------------------
| end of epoch  28 | time per epoch: 1133.85s |
| Train Metrics | accuracy:  0.65 | loss:  1.35
| Eval  Metrics | accuracy:  0.75 | loss:  0.83
-----------------------------------------------------------------------------------------
| epoch 29 | 1000/1179 batches | ms/batch 964.90 | Performance/Training accuracy:  0.66 | Performance/Training loss:  1.35
-----------------------------------------------------------------------------------------
| end of epoch  29 | time per epoch: 1137.44s |
| Train Metrics | accuracy:  0.66 | loss:  1.34
| Eval  Metrics | accuracy:  0.77 | loss:  0.77
-----------------------------------------------------------------------------------------
[2025-02-21 23:57:42,203][absl][INFO] - Saving checkpoint at step: 34191
[2025-02-21 23:57:42,205][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-21 23:57:42,205][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-21 23:57:42,207][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_34191.
[2025-02-21 23:57:42,215][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-21 23:57:42,216][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_34191.orbax-checkpoint-tmp-22
[2025-02-21 23:57:42,225][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-21 23:57:42,252][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-21 23:57:42,285][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 154.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 59 milliseconds) (per-host)
[2025-02-21 23:57:42,522][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-21 23:57:42,522][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 296 milliseconds) (per-host)
[2025-02-21 23:57:42,528][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-21 23:57:42,560][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_34191.orbax-checkpoint-tmp-22 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_34191
[2025-02-21 23:57:42,566][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_34191`.
[2025-02-21 23:57:42,566][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-21 23:57:42,568][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_30654
| epoch 30 | 1000/1179 batches | ms/batch 982.36 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.28
-----------------------------------------------------------------------------------------
| end of epoch  30 | time per epoch: 1160.94s |
| Train Metrics | accuracy:  0.67 | loss:  1.29
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.08971233665943146,
    "std": 0.2694915235042572,
    "var": 0.07262568920850754,
    "min": -0.31867414712905884,
    "max": 0.6766173839569092,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.30211591720581055,
    "std": 0.10350427031517029,
    "var": 0.010713133029639721,
    "min": 0.1355719119310379,
    "max": 0.7235599160194397,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0002755667665041983,
    "std": 0.09717553853988647,
    "var": 0.009443085640668869,
    "min": -0.3510006368160248,
    "max": 0.37076514959335327,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.24897262454032898,
    "std": 0.1906367540359497,
    "var": 0.036342374980449677,
    "min": -0.08302377164363861,
    "max": 0.8157857656478882,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.4310028553009033,
    "std": 0.21544645726680756,
    "var": 0.046417176723480225,
    "min": 0.056114889681339264,
    "max": 1.0372717380523682,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": -7.212627679109573e-06,
    "std": 0.09635675698518753,
    "var": 0.009284624829888344,
    "min": -0.33351364731788635,
    "max": 0.32800865173339844,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.26278114318847656,
    "std": 0.20332911610603333,
    "var": 0.041342731565237045,
    "min": -0.03765467554330826,
    "max": 0.8222274780273438,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.42456114292144775,
    "std": 0.25570183992385864,
    "var": 0.0653834268450737,
    "min": 0.053174760192632675,
    "max": 1.5004892349243164,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0009400739218108356,
    "std": 0.09727606922388077,
    "var": 0.009462634101510048,
    "min": -0.34016144275665283,
    "max": 0.3443056046962738,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.14264419674873352,
    "std": 0.18492405116558075,
    "var": 0.03419690579175949,
    "min": -0.22933077812194824,
    "max": 0.9041718244552612,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6544209718704224,
    "std": 0.24427834153175354,
    "var": 0.05967190861701965,
    "min": 0.08220946043729782,
    "max": 1.4570205211639404,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0006257855566218495,
    "std": 0.06344267725944519,
    "var": 0.004024973139166832,
    "min": -0.4284067153930664,
    "max": 0.3712679445743561,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.14245548844337463,
    "std": 0.22167500853538513,
    "var": 0.04913980886340141,
    "min": -0.3957218825817108,
    "max": 0.9909797310829163,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.7862070798873901,
    "std": 0.2640921175479889,
    "var": 0.06974464654922485,
    "min": 0.16091996431350708,
    "max": 1.7146989107131958,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00010592515900498256,
    "std": 0.06030142679810524,
    "var": 0.003636262146756053,
    "min": -0.28612220287323,
    "max": 0.3066425025463104,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.017491457983851433,
    "std": 0.09236606955528259,
    "var": 0.00853149127215147,
    "min": -0.34339773654937744,
    "max": 0.21086092293262482,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.9973244071006775,
    "std": 0.2553701400756836,
    "var": 0.06521390378475189,
    "min": 0.6534261703491211,
    "max": 2.30456805229187,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0004813518316950649,
    "std": 0.06877123564481735,
    "var": 0.004729483276605606,
    "min": -0.2940867841243744,
    "max": 0.3776193857192993,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": 0.0007102589588612318,
    "std": 0.11432357132434845,
    "var": 0.01306987926363945,
    "min": -0.6527002453804016,
    "max": 0.7079256772994995,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00042626168578863144,
    "std": 0.1197090595960617,
    "var": 0.014330259524285793,
    "min": -0.6044800281524658,
    "max": 0.6783700585365295,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0028836806304752827,
    "std": 0.1222209557890892,
    "var": 0.014937961474061012,
    "min": -0.8363903760910034,
    "max": 0.7091954946517944,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0009733554325066507,
    "std": 0.10473199933767319,
    "var": 0.01096879132091999,
    "min": -0.7742375135421753,
    "max": 0.8944196701049805,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0009807390160858631,
    "std": 0.10547171533107758,
    "var": 0.011124283075332642,
    "min": -0.636581301689148,
    "max": 0.7729398608207703,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.000185184006113559,
    "std": 0.11309023201465607,
    "var": 0.012789401225745678,
    "min": -0.8106768727302551,
    "max": 0.6178165078163147,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.44031986594200134,
    "std": 0.16504056751728058,
    "var": 0.02723838947713375,
    "min": -0.8460994958877563,
    "max": -0.10694709420204163,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07760930061340332,
    "std": 0.2833540737628937,
    "var": 0.08028953522443771,
    "min": -1.1523003578186035,
    "max": 1.0351430177688599,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.795122504234314,
    "std": 0.7823399305343628,
    "var": 0.612055778503418,
    "min": -1.0865668058395386,
    "max": 3.273048162460327,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.324665367603302,
    "std": 0.11891814321279526,
    "var": 0.014141525141894817,
    "min": -0.5974341630935669,
    "max": -0.0323733389377594,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.17264246940612793,
    "std": 0.16148662567138672,
    "var": 0.026077929884195328,
    "min": -0.9252446889877319,
    "max": 0.3931816518306732,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.0005900859832764,
    "std": 0.7955390214920044,
    "var": 0.6328823566436768,
    "min": -0.7051441073417664,
    "max": 3.6972014904022217,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.30404132604599,
    "std": 0.12167173624038696,
    "var": 0.014804011210799217,
    "min": -0.5752299427986145,
    "max": 0.03292151167988777,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.16060596704483032,
    "std": 0.17469556629657745,
    "var": 0.030518541112542152,
    "min": -1.1241528987884521,
    "max": 0.5214561820030212,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.7785922288894653,
    "std": 0.698198139667511,
    "var": 0.48748064041137695,
    "min": -0.7102203965187073,
    "max": 3.3041412830352783,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.10934951156377792,
    "std": 0.0896976962685585,
    "var": 0.008045677095651627,
    "min": -0.4001808762550354,
    "max": 0.11513977497816086,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.09060980379581451,
    "std": 0.1581970602273941,
    "var": 0.025026312097907066,
    "min": -1.0334906578063965,
    "max": 0.46150103211402893,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.002257975749671459,
    "std": 0.009662008844316006,
    "var": 9.33544069994241e-05,
    "min": -0.03383267670869827,
    "max": 0.02009049616754055,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 2.8009837478748523e-05,
    "std": 0.10799616575241089,
    "var": 0.011663171462714672,
    "min": -0.8196828365325928,
    "max": 0.8320398926734924,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.029102014377713203,
    "std": 0.3476227819919586,
    "var": 0.1208416000008583,
    "min": -1.7582595348358154,
    "max": 1.8720120191574097,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.1813218891620636,
    "std": 0.1075153648853302,
    "var": 0.011559553444385529,
    "min": -0.4627946615219116,
    "max": 0.15495067834854126,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07492273300886154,
    "std": 0.15988141298294067,
    "var": 0.025562066584825516,
    "min": -0.9281516075134277,
    "max": 0.5688413381576538,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.07228700071573257,
    "std": 1.053922176361084,
    "var": 1.1107521057128906,
    "min": -2.4377942085266113,
    "max": 2.304833173751831,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.003439831081777811,
    "std": 0.1300932765007019,
    "var": 0.016924262046813965,
    "min": -0.34266629815101624,
    "max": 0.41911354660987854,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.04449089989066124,
    "std": 0.16301019489765167,
    "var": 0.026572324335575104,
    "min": -0.9445999264717102,
    "max": 0.5568147897720337,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.37019938230514526,
    "std": 0.8155490159988403,
    "var": 0.6651202440261841,
    "min": -2.058600425720215,
    "max": 2.208606481552124,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.01481693983078003,
    "std": 0.09345284104347229,
    "var": 0.008733433671295643,
    "min": -0.1863887906074524,
    "max": 0.15469880402088165,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0014486659783869982,
    "std": 0.18732798099517822,
    "var": 0.03509177267551422,
    "min": -0.83464115858078,
    "max": 0.7953901290893555,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.0025264318101108074,
    "std": 0.28698939085006714,
    "var": 0.08236292004585266,
    "min": -1.7592145204544067,
    "max": 1.4680330753326416,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.3684632778167725,
    "std": 0.5365276336669922,
    "var": 0.2878618836402893,
    "min": -2.734025239944458,
    "max": 0.17097234725952148,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.2588330507278442,
    "std": 0.5262917876243591,
    "var": 0.27698302268981934,
    "min": -2.659043788909912,
    "max": -0.21853534877300262,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.4742794036865234,
    "std": 0.6295952200889587,
    "var": 0.3963901400566101,
    "min": -3.3421120643615723,
    "max": -0.2879998981952667,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.7910823822021484,
    "std": 0.5909847021102905,
    "var": 0.34926292300224304,
    "min": -3.5664010047912598,
    "max": -0.21697643399238586,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.839242696762085,
    "std": 0.5226133465766907,
    "var": 0.27312469482421875,
    "min": -3.1264140605926514,
    "max": -0.28210172057151794,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.8654290437698364,
    "std": 0.6106959581375122,
    "var": 0.37294960021972656,
    "min": -3.16098952293396,
    "max": -0.605232834815979,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.77 | loss:  0.80
-----------------------------------------------------------------------------------------
| epoch 31 | 1000/1179 batches | ms/batch 1000.68 | Performance/Training accuracy:  0.66 | Performance/Training loss:  1.35
-----------------------------------------------------------------------------------------
| end of epoch  31 | time per epoch: 1179.82s |
| Train Metrics | accuracy:  0.66 | loss:  1.34
| Eval  Metrics | accuracy:  0.76 | loss:  0.83
-----------------------------------------------------------------------------------------
| epoch 32 | 1000/1179 batches | ms/batch 1005.10 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.30
-----------------------------------------------------------------------------------------
| end of epoch  32 | time per epoch: 1187.16s |
| Train Metrics | accuracy:  0.67 | loss:  1.30
| Eval  Metrics | accuracy:  0.77 | loss:  0.77
-----------------------------------------------------------------------------------------
| epoch 33 | 1000/1179 batches | ms/batch 1015.71 | Performance/Training accuracy:  0.66 | Performance/Training loss:  1.33
-----------------------------------------------------------------------------------------
| end of epoch  33 | time per epoch: 1196.15s |
| Train Metrics | accuracy:  0.66 | loss:  1.32
| Eval  Metrics | accuracy:  0.77 | loss:  0.78
-----------------------------------------------------------------------------------------
| epoch 34 | 1000/1179 batches | ms/batch 1081.01 | Performance/Training accuracy:  0.66 | Performance/Training loss:  1.33
-----------------------------------------------------------------------------------------
| end of epoch  34 | time per epoch: 1265.86s |
| Train Metrics | accuracy:  0.66 | loss:  1.33
| Eval  Metrics | accuracy:  0.78 | loss:  0.76
-----------------------------------------------------------------------------------------
[2025-02-22 01:46:44,193][absl][INFO] - Saving checkpoint at step: 40086
[2025-02-22 01:46:44,196][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-22 01:46:44,196][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-22 01:46:44,197][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_40086.
[2025-02-22 01:46:44,206][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-22 01:46:44,207][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_40086.orbax-checkpoint-tmp-23
[2025-02-22 01:46:44,217][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-22 01:46:44,243][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-22 01:46:44,272][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 167.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-22 01:46:44,505][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-22 01:46:44,505][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 288 milliseconds) (per-host)
[2025-02-22 01:46:44,511][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-22 01:46:44,544][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_40086.orbax-checkpoint-tmp-23 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_40086
[2025-02-22 01:46:44,550][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_40086`.
[2025-02-22 01:46:44,550][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-22 01:46:44,551][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_34191
| epoch 35 | 1000/1179 batches | ms/batch 1041.26 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.32
-----------------------------------------------------------------------------------------
| end of epoch  35 | time per epoch: 1229.17s |
| Train Metrics | accuracy:  0.67 | loss:  1.32
| Eval  Metrics | accuracy:  0.77 | loss:  0.84
-----------------------------------------------------------------------------------------
| epoch 36 | 1000/1179 batches | ms/batch 1078.92 | Performance/Training accuracy:  0.66 | Performance/Training loss:  1.33
-----------------------------------------------------------------------------------------
| end of epoch  36 | time per epoch: 1272.98s |
| Train Metrics | accuracy:  0.67 | loss:  1.31
| Eval  Metrics | accuracy:  0.77 | loss:  0.78
-----------------------------------------------------------------------------------------
| epoch 37 | 1000/1179 batches | ms/batch 1097.92 | Performance/Training accuracy:  0.66 | Performance/Training loss:  1.32
-----------------------------------------------------------------------------------------
| end of epoch  37 | time per epoch: 1287.55s |
| Train Metrics | accuracy:  0.67 | loss:  1.31
| Eval  Metrics | accuracy:  0.78 | loss:  0.75
-----------------------------------------------------------------------------------------
[2025-02-22 02:55:45,893][absl][INFO] - Saving checkpoint at step: 43623
[2025-02-22 02:55:45,895][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-22 02:55:45,896][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-22 02:55:45,897][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_43623.
[2025-02-22 02:55:45,913][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-22 02:55:45,914][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_43623.orbax-checkpoint-tmp-24
[2025-02-22 02:55:45,923][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-22 02:55:45,949][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-22 02:55:45,978][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 169.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 53 milliseconds) (per-host)
[2025-02-22 02:55:46,212][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-22 02:55:46,212][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 288 milliseconds) (per-host)
[2025-02-22 02:55:46,218][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-22 02:55:46,249][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_43623.orbax-checkpoint-tmp-24 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_43623
[2025-02-22 02:55:46,255][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_43623`.
[2025-02-22 02:55:46,255][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-22 02:55:46,257][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_40086
| epoch 38 | 1000/1179 batches | ms/batch 1137.29 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.30
-----------------------------------------------------------------------------------------
| end of epoch  38 | time per epoch: 1333.25s |
| Train Metrics | accuracy:  0.67 | loss:  1.30
| Eval  Metrics | accuracy:  0.77 | loss:  0.79
-----------------------------------------------------------------------------------------
| epoch 39 | 1000/1179 batches | ms/batch 1086.92 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.29
-----------------------------------------------------------------------------------------
| end of epoch  39 | time per epoch: 1282.08s |
| Train Metrics | accuracy:  0.67 | loss:  1.29
| Eval  Metrics | accuracy:  0.77 | loss:  0.79
-----------------------------------------------------------------------------------------
| epoch 40 | 1000/1179 batches | ms/batch 1126.05 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.24
-----------------------------------------------------------------------------------------
| end of epoch  40 | time per epoch: 1323.30s |
| Train Metrics | accuracy:  0.68 | loss:  1.25
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.12640872597694397,
    "std": 0.25194698572158813,
    "var": 0.0634772926568985,
    "min": -0.21265868842601776,
    "max": 0.9771082997322083,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.24748021364212036,
    "std": 0.10342401266098022,
    "var": 0.010696525685489178,
    "min": 0.08524283021688461,
    "max": 0.5470887422561646,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0002541812136769295,
    "std": 0.10088387131690979,
    "var": 0.010177555494010448,
    "min": -0.3505765497684479,
    "max": 0.3871440589427948,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.23941706120967865,
    "std": 0.17734089493751526,
    "var": 0.03144979476928711,
    "min": -0.0635450929403305,
    "max": 0.8114404678344727,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.38844120502471924,
    "std": 0.2318548560142517,
    "var": 0.053756676614284515,
    "min": 0.036074865609407425,
    "max": 1.1103440523147583,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0005835204501636326,
    "std": 0.10107598453760147,
    "var": 0.010216355323791504,
    "min": -0.4009645879268646,
    "max": 0.4351963400840759,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2578964829444885,
    "std": 0.19685658812522888,
    "var": 0.038752514868974686,
    "min": -0.03176314756274223,
    "max": 0.7882793545722961,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.4123525619506836,
    "std": 0.2822175621986389,
    "var": 0.0796467512845993,
    "min": 0.04700229689478874,
    "max": 1.8682538270950317,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0006230567814782262,
    "std": 0.10169348865747452,
    "var": 0.010341565124690533,
    "min": -0.45763668417930603,
    "max": 0.41043052077293396,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.14503370225429535,
    "std": 0.2091117799282074,
    "var": 0.04372773692011833,
    "min": -0.31476151943206787,
    "max": 0.9286622405052185,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6438349485397339,
    "std": 0.24921919405460358,
    "var": 0.062110207974910736,
    "min": 0.05529824271798134,
    "max": 1.6671333312988281,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.00045387737918645144,
    "std": 0.062032390385866165,
    "var": 0.0038480176590383053,
    "min": -0.5664508938789368,
    "max": 0.5233547687530518,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.1434725970029831,
    "std": 0.23675504326820374,
    "var": 0.056052953004837036,
    "min": -0.46762704849243164,
    "max": 1.0532780885696411,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.740087628364563,
    "std": 0.264132559299469,
    "var": 0.06976601481437683,
    "min": 0.11830519884824753,
    "max": 1.7035380601882935,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00010912961442954838,
    "std": 0.060103852301836014,
    "var": 0.00361247337423265,
    "min": -0.3609059453010559,
    "max": 0.36937132477760315,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.03194967284798622,
    "std": 0.09779123961925507,
    "var": 0.009563127532601357,
    "min": -0.32594895362854004,
    "max": 0.18223822116851807,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.9962539076805115,
    "std": 0.2505076825618744,
    "var": 0.06275410205125809,
    "min": 0.6151704788208008,
    "max": 2.1954832077026367,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00046496232971549034,
    "std": 0.07316018640995026,
    "var": 0.005352412816137075,
    "min": -0.3938159942626953,
    "max": 0.49210360646247864,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": 0.00044326213537715375,
    "std": 0.11573754251003265,
    "var": 0.013395178131759167,
    "min": -0.7747693061828613,
    "max": 0.6146028637886047,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.00048467572196386755,
    "std": 0.1215079128742218,
    "var": 0.014764172956347466,
    "min": -0.877749502658844,
    "max": 0.6488787531852722,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.001835953677073121,
    "std": 0.1222849115729332,
    "var": 0.014953600242733955,
    "min": -0.9422614574432373,
    "max": 0.664654016494751,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0006548060337081552,
    "std": 0.09901397675275803,
    "var": 0.009803768247365952,
    "min": -0.6882612705230713,
    "max": 0.7927200794219971,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0004247197648510337,
    "std": 0.10455109924077988,
    "var": 0.010930933058261871,
    "min": -0.7695441842079163,
    "max": 0.799746036529541,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0004886583774350584,
    "std": 0.11458002775907516,
    "var": 0.013128582388162613,
    "min": -0.89609295129776,
    "max": 0.6750077605247498,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.4593878388404846,
    "std": 0.16543564200401306,
    "var": 0.027368951588869095,
    "min": -0.8652403950691223,
    "max": -0.10721483826637268,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08467474579811096,
    "std": 0.30788305401802063,
    "var": 0.09479197859764099,
    "min": -1.177851915359497,
    "max": 1.2266167402267456,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.9815523624420166,
    "std": 0.8702003955841064,
    "var": 0.7572487592697144,
    "min": -1.02947998046875,
    "max": 3.7336788177490234,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.3281252980232239,
    "std": 0.13828064501285553,
    "var": 0.01912153884768486,
    "min": -0.5640544295310974,
    "max": 0.08959362655878067,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.1841641217470169,
    "std": 0.19370649755001068,
    "var": 0.03752220794558525,
    "min": -1.250831961631775,
    "max": 0.6177115440368652,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.0888683795928955,
    "std": 0.9216417074203491,
    "var": 0.8494234085083008,
    "min": -0.6230692267417908,
    "max": 4.078489303588867,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.27570396661758423,
    "std": 0.14771951735019684,
    "var": 0.021821055561304092,
    "min": -0.6207331418991089,
    "max": 0.09116854518651962,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.17585866153240204,
    "std": 0.20467734336853027,
    "var": 0.04189281538128853,
    "min": -1.482461929321289,
    "max": 0.6191263794898987,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.8349105715751648,
    "std": 0.7836088538169861,
    "var": 0.6140428185462952,
    "min": -0.5442495942115784,
    "max": 3.283379554748535,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.11023400723934174,
    "std": 0.0965489074587822,
    "var": 0.00932169146835804,
    "min": -0.3866546154022217,
    "max": 0.18227127194404602,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.0909074991941452,
    "std": 0.16787567734718323,
    "var": 0.028182242065668106,
    "min": -1.001402735710144,
    "max": 0.48683640360832214,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.002286480274051428,
    "std": 0.007922053337097168,
    "var": 6.275893247220665e-05,
    "min": -0.026626311242580414,
    "max": 0.020514830946922302,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.0003029670042451471,
    "std": 0.10851369798183441,
    "var": 0.011775223538279533,
    "min": -1.0282994508743286,
    "max": 0.9980832934379578,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.02289193496108055,
    "std": 0.37530481815338135,
    "var": 0.14085371792316437,
    "min": -2.569918632507324,
    "max": 2.164341688156128,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.1758241057395935,
    "std": 0.1146305724978447,
    "var": 0.01314016804099083,
    "min": -0.456706166267395,
    "max": 0.13968735933303833,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.075620636343956,
    "std": 0.16726107895374298,
    "var": 0.027976270765066147,
    "min": -1.0248883962631226,
    "max": 0.5651921033859253,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.11400335282087326,
    "std": 1.0540412664413452,
    "var": 1.111003041267395,
    "min": -2.847572088241577,
    "max": 2.517287015914917,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.013663224875926971,
    "std": 0.13390660285949707,
    "var": 0.017930977046489716,
    "min": -0.33510053157806396,
    "max": 0.4281260371208191,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.04573262110352516,
    "std": 0.16708683967590332,
    "var": 0.0279180109500885,
    "min": -1.0053343772888184,
    "max": 0.5451660752296448,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.3636972904205322,
    "std": 0.7269519567489624,
    "var": 0.5284591913223267,
    "min": -1.9906601905822754,
    "max": 2.2507009506225586,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.0143105648458004,
    "std": 0.09154687821865082,
    "var": 0.00838083028793335,
    "min": -0.17259535193443298,
    "max": 0.17101716995239258,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.001663943170569837,
    "std": 0.19949215650558472,
    "var": 0.03979711979627609,
    "min": -0.919592559337616,
    "max": 0.7494325041770935,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.004141129087656736,
    "std": 0.2957764267921448,
    "var": 0.08748369663953781,
    "min": -1.7253285646438599,
    "max": 1.5755640268325806,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.9357579350471497,
    "std": 0.4814496636390686,
    "var": 0.23179377615451813,
    "min": -2.309828042984009,
    "max": 0.39219701290130615,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.9306042790412903,
    "std": 0.48274070024490356,
    "var": 0.23303860425949097,
    "min": -2.390202522277832,
    "max": 0.024428466334939003,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.1669204235076904,
    "std": 0.5808821320533752,
    "var": 0.337424099445343,
    "min": -2.97473406791687,
    "max": 0.027639543637633324,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.576403021812439,
    "std": 0.5404722094535828,
    "var": 0.2921102046966553,
    "min": -3.391113758087158,
    "max": -0.08859781175851822,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.5951523780822754,
    "std": 0.4704233407974243,
    "var": 0.22129812836647034,
    "min": -2.8530352115631104,
    "max": -0.10800608992576599,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.63763427734375,
    "std": 0.6128443479537964,
    "var": 0.37557822465896606,
    "min": -3.0293266773223877,
    "max": -0.5050259232521057,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.78 | loss:  0.79
-----------------------------------------------------------------------------------------
| epoch 41 | 1000/1179 batches | ms/batch 1131.54 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.26
-----------------------------------------------------------------------------------------
| end of epoch  41 | time per epoch: 1330.76s |
| Train Metrics | accuracy:  0.68 | loss:  1.28
| Eval  Metrics | accuracy:  0.77 | loss:  0.81
-----------------------------------------------------------------------------------------
| epoch 42 | 1000/1179 batches | ms/batch 1131.05 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.29
-----------------------------------------------------------------------------------------
| end of epoch  42 | time per epoch: 1332.64s |
| Train Metrics | accuracy:  0.68 | loss:  1.29
| Eval  Metrics | accuracy:  0.77 | loss:  0.76
-----------------------------------------------------------------------------------------
| epoch 43 | 1000/1179 batches | ms/batch 1128.72 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.23
-----------------------------------------------------------------------------------------
| end of epoch  43 | time per epoch: 1331.82s |
| Train Metrics | accuracy:  0.68 | loss:  1.23
| Eval  Metrics | accuracy:  0.77 | loss:  0.78
-----------------------------------------------------------------------------------------
| epoch 44 | 1000/1179 batches | ms/batch 1142.98 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.26
-----------------------------------------------------------------------------------------
| end of epoch  44 | time per epoch: 1348.14s |
| Train Metrics | accuracy:  0.68 | loss:  1.26
| Eval  Metrics | accuracy:  0.77 | loss:  0.79
-----------------------------------------------------------------------------------------
| epoch 45 | 1000/1179 batches | ms/batch 1166.90 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.22
-----------------------------------------------------------------------------------------
| end of epoch  45 | time per epoch: 1374.18s |
| Train Metrics | accuracy:  0.68 | loss:  1.24
| Eval  Metrics | accuracy:  0.77 | loss:  0.81
-----------------------------------------------------------------------------------------
| epoch 46 | 1000/1179 batches | ms/batch 1168.76 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.27
-----------------------------------------------------------------------------------------
| end of epoch  46 | time per epoch: 1380.50s |
| Train Metrics | accuracy:  0.68 | loss:  1.27
| Eval  Metrics | accuracy:  0.78 | loss:  0.78
-----------------------------------------------------------------------------------------
| epoch 47 | 1000/1179 batches | ms/batch 1218.65 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.21
-----------------------------------------------------------------------------------------
| end of epoch  47 | time per epoch: 1440.37s |
| Train Metrics | accuracy:  0.68 | loss:  1.24
| Eval  Metrics | accuracy:  0.79 | loss:  0.72
-----------------------------------------------------------------------------------------
[2025-02-22 07:01:57,057][absl][INFO] - Saving checkpoint at step: 55413
[2025-02-22 07:01:57,059][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-22 07:01:57,059][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-22 07:01:57,060][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_55413.
[2025-02-22 07:01:57,080][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-22 07:01:57,081][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_55413.orbax-checkpoint-tmp-25
[2025-02-22 07:01:57,090][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-22 07:01:57,118][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-22 07:01:57,133][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 216.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 42 milliseconds) (per-host)
[2025-02-22 07:01:57,368][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-22 07:01:57,368][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 277 milliseconds) (per-host)
[2025-02-22 07:01:57,374][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-22 07:01:57,406][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_55413.orbax-checkpoint-tmp-25 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_55413
[2025-02-22 07:01:57,412][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_55413`.
[2025-02-22 07:01:57,412][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-22 07:01:57,414][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_43623
| epoch 48 | 1000/1179 batches | ms/batch 1222.72 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.28
-----------------------------------------------------------------------------------------
| end of epoch  48 | time per epoch: 1438.29s |
| Train Metrics | accuracy:  0.68 | loss:  1.27
| Eval  Metrics | accuracy:  0.78 | loss:  0.79
-----------------------------------------------------------------------------------------
| epoch 49 | 1000/1179 batches | ms/batch 1338.28 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.23
-----------------------------------------------------------------------------------------
| end of epoch  49 | time per epoch: 1571.67s |
| Train Metrics | accuracy:  0.69 | loss:  1.23
| Eval  Metrics | accuracy:  0.79 | loss:  0.73
-----------------------------------------------------------------------------------------
[2025-02-22 07:57:08,569][absl][INFO] - Saving checkpoint at step: 57771
[2025-02-22 07:57:08,571][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-22 07:57:08,571][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-22 07:57:08,572][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_57771.
[2025-02-22 07:57:08,581][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-22 07:57:08,582][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_57771.orbax-checkpoint-tmp-26
[2025-02-22 07:57:08,588][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-22 07:57:08,614][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-22 07:57:08,643][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 170.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 53 milliseconds) (per-host)
[2025-02-22 07:57:08,863][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-22 07:57:08,864][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 274 milliseconds) (per-host)
[2025-02-22 07:57:08,870][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-22 07:57:08,903][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_57771.orbax-checkpoint-tmp-26 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_57771
[2025-02-22 07:57:08,909][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_57771`.
[2025-02-22 07:57:08,909][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-22 07:57:08,911][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_55413
| epoch 50 | 1000/1179 batches | ms/batch 1300.37 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.24
-----------------------------------------------------------------------------------------
| end of epoch  50 | time per epoch: 1545.11s |
| Train Metrics | accuracy:  0.69 | loss:  1.23
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.15896593034267426,
    "std": 0.26770925521850586,
    "var": 0.07166825234889984,
    "min": -0.18405532836914062,
    "max": 0.9964267015457153,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.23681744933128357,
    "std": 0.111769899725914,
    "var": 0.012492510490119457,
    "min": 0.05244198814034462,
    "max": 0.6223574876785278,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.00014097616076469421,
    "std": 0.10428442060947418,
    "var": 0.010875239968299866,
    "min": -0.4177230894565582,
    "max": 0.43998268246650696,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.23261140286922455,
    "std": 0.16380827128887177,
    "var": 0.026833150535821915,
    "min": -0.10754517465829849,
    "max": 0.8245062232017517,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.3800738453865051,
    "std": 0.25387659668922424,
    "var": 0.06445333361625671,
    "min": 0.07117247581481934,
    "max": 1.2189393043518066,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0012456723488867283,
    "std": 0.10526661574840546,
    "var": 0.011081060394644737,
    "min": -0.42933177947998047,
    "max": 0.4998651146888733,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.24719539284706116,
    "std": 0.18545454740524292,
    "var": 0.034393392503261566,
    "min": -0.07525971531867981,
    "max": 0.8756041526794434,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.40713533759117126,
    "std": 0.29826784133911133,
    "var": 0.08896370977163315,
    "min": 0.051760002970695496,
    "max": 1.9988759756088257,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0006311451434157789,
    "std": 0.10546531528234482,
    "var": 0.01112293265759945,
    "min": -0.5482717752456665,
    "max": 0.49719443917274475,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.14546576142311096,
    "std": 0.22323225438594818,
    "var": 0.04983264207839966,
    "min": -0.32931846380233765,
    "max": 1.0117381811141968,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6503598690032959,
    "std": 0.24779978394508362,
    "var": 0.06140473484992981,
    "min": 0.07656309008598328,
    "max": 1.9329177141189575,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0004356505523901433,
    "std": 0.05917799100279808,
    "var": 0.003502034582197666,
    "min": -0.6485199332237244,
    "max": 0.653195321559906,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.1426529586315155,
    "std": 0.24183246493339539,
    "var": 0.05848294124007225,
    "min": -0.46417132019996643,
    "max": 1.1461683511734009,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.7160369753837585,
    "std": 0.27233827114105225,
    "var": 0.0741681382060051,
    "min": 0.10671743005514145,
    "max": 1.759328007698059,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 7.340884621953592e-05,
    "std": 0.06002125144004822,
    "var": 0.003602550830692053,
    "min": -0.40824681520462036,
    "max": 0.4400825500488281,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.04196430370211601,
    "std": 0.09963767975568771,
    "var": 0.009927667677402496,
    "min": -0.3262137174606323,
    "max": 0.18551695346832275,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.0103554725646973,
    "std": 0.24856039881706238,
    "var": 0.061782270669937134,
    "min": 0.6566786170005798,
    "max": 2.2479307651519775,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0004941277438774705,
    "std": 0.07716970145702362,
    "var": 0.005955163389444351,
    "min": -0.47481828927993774,
    "max": 0.586918830871582,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0004753089742735028,
    "std": 0.11442621052265167,
    "var": 0.013093357905745506,
    "min": -0.7711467146873474,
    "max": 0.600111722946167,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.0006916860002093017,
    "std": 0.12017809599637985,
    "var": 0.014442774467170238,
    "min": -0.8449646830558777,
    "max": 0.5482732057571411,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0020126113668084145,
    "std": 0.1187097355723381,
    "var": 0.014092001132667065,
    "min": -0.856476366519928,
    "max": 0.6986419558525085,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0008372112060897052,
    "std": 0.0896930992603302,
    "var": 0.008044851943850517,
    "min": -0.7727959156036377,
    "max": 0.7723919749259949,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00011333473958075047,
    "std": 0.10103701055049896,
    "var": 0.010208478197455406,
    "min": -0.7475028038024902,
    "max": 0.7133383750915527,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.00019708456238731742,
    "std": 0.11212082952260971,
    "var": 0.012571080587804317,
    "min": -0.8240727186203003,
    "max": 0.7260466814041138,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.4393348693847656,
    "std": 0.15493710339069366,
    "var": 0.024005508050322533,
    "min": -0.8231148719787598,
    "max": -0.14565524458885193,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08490044623613358,
    "std": 0.30581384897232056,
    "var": 0.09352211654186249,
    "min": -1.181214451789856,
    "max": 1.1316297054290771,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 1.0131032466888428,
    "std": 0.9274399876594543,
    "var": 0.8601449728012085,
    "min": -1.1776758432388306,
    "max": 3.759814977645874,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.32761624455451965,
    "std": 0.14407087862491608,
    "var": 0.020756417885422707,
    "min": -0.6423165202140808,
    "max": 0.031483761966228485,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.194371297955513,
    "std": 0.20722827315330505,
    "var": 0.0429435558617115,
    "min": -1.58591890335083,
    "max": 0.7201072573661804,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.1238977909088135,
    "std": 0.9403056502342224,
    "var": 0.8841747045516968,
    "min": -0.4875319004058838,
    "max": 4.013214588165283,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.2682982087135315,
    "std": 0.1611417680978775,
    "var": 0.025966672226786613,
    "min": -0.6416009664535522,
    "max": 0.10151014477014542,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.18565116822719574,
    "std": 0.21876509487628937,
    "var": 0.04785816743969917,
    "min": -1.4027085304260254,
    "max": 0.6256603598594666,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.9068217277526855,
    "std": 0.8037333488464355,
    "var": 0.6459872722625732,
    "min": -0.8056216239929199,
    "max": 3.118532180786133,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.11085562407970428,
    "std": 0.10171222686767578,
    "var": 0.010345377027988434,
    "min": -0.4162423014640808,
    "max": 0.13598211109638214,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08768585324287415,
    "std": 0.1720181554555893,
    "var": 0.029590249061584473,
    "min": -1.1850805282592773,
    "max": 0.5569812655448914,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0013122338568791747,
    "std": 0.0064292908646166325,
    "var": 4.133577749598771e-05,
    "min": -0.01966899260878563,
    "max": 0.01757492497563362,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.0007615300710313022,
    "std": 0.10780125856399536,
    "var": 0.011621112003922462,
    "min": -0.9701533317565918,
    "max": 0.9706727266311646,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.019244279712438583,
    "std": 0.37567663192749023,
    "var": 0.14113293588161469,
    "min": -2.7585246562957764,
    "max": 2.1719279289245605,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.17350463569164276,
    "std": 0.10970006138086319,
    "var": 0.012034103274345398,
    "min": -0.4728752374649048,
    "max": 0.13482022285461426,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07347098737955093,
    "std": 0.1692514717578888,
    "var": 0.028646061196923256,
    "min": -1.2500871419906616,
    "max": 0.6549819707870483,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.14230720698833466,
    "std": 1.0246714353561401,
    "var": 1.0499516725540161,
    "min": -2.763535499572754,
    "max": 2.522737503051758,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.023735571652650833,
    "std": 0.13501659035682678,
    "var": 0.01822948083281517,
    "min": -0.34553423523902893,
    "max": 0.37387773394584656,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.04547884687781334,
    "std": 0.1660274714231491,
    "var": 0.0275651216506958,
    "min": -1.0062204599380493,
    "max": 0.5705438256263733,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.356101393699646,
    "std": 0.6561129689216614,
    "var": 0.43048426508903503,
    "min": -1.9206790924072266,
    "max": 2.2105562686920166,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.012887680903077126,
    "std": 0.08266620337963104,
    "var": 0.006833700928837061,
    "min": -0.16915296018123627,
    "max": 0.14106342196464539,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0018958650762215257,
    "std": 0.20546865463256836,
    "var": 0.04221736639738083,
    "min": -0.9327713847160339,
    "max": 0.7423064112663269,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.006063605658710003,
    "std": 0.2937396466732025,
    "var": 0.08628298342227936,
    "min": -1.6039860248565674,
    "max": 1.357258915901184,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.6793975234031677,
    "std": 0.46760648488998413,
    "var": 0.21865582466125488,
    "min": -1.7675559520721436,
    "max": 0.5695329904556274,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.7433633804321289,
    "std": 0.4531667232513428,
    "var": 0.2053600698709488,
    "min": -2.2405354976654053,
    "max": 0.14173345267772675,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.0045230388641357,
    "std": 0.5295817852020264,
    "var": 0.28045690059661865,
    "min": -2.606808662414551,
    "max": 0.13499023020267487,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.526017427444458,
    "std": 0.504802405834198,
    "var": 0.25482550263404846,
    "min": -3.322570562362671,
    "max": -0.036710839718580246,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.4692810773849487,
    "std": 0.44395753741264343,
    "var": 0.19709829986095428,
    "min": -2.658280611038208,
    "max": -0.07816849648952484,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.508472204208374,
    "std": 0.6173421740531921,
    "var": 0.38111138343811035,
    "min": -3.0167763233184814,
    "max": -0.3142154812812805,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.78 | loss:  0.75
-----------------------------------------------------------------------------------------
| epoch 51 | 1000/1179 batches | ms/batch 1365.98 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.26
-----------------------------------------------------------------------------------------
| end of epoch  51 | time per epoch: 1610.62s |
| Train Metrics | accuracy:  0.68 | loss:  1.25
| Eval  Metrics | accuracy:  0.77 | loss:  0.79
-----------------------------------------------------------------------------------------
| epoch 52 | 1000/1179 batches | ms/batch 1365.09 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.23
-----------------------------------------------------------------------------------------
| end of epoch  52 | time per epoch: 1597.15s |
| Train Metrics | accuracy:  0.69 | loss:  1.22
| Eval  Metrics | accuracy:  0.77 | loss:  0.77
-----------------------------------------------------------------------------------------
| epoch 53 | 1000/1179 batches | ms/batch 1326.13 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.22
-----------------------------------------------------------------------------------------
| end of epoch  53 | time per epoch: 1557.90s |
| Train Metrics | accuracy:  0.69 | loss:  1.21
| Eval  Metrics | accuracy:  0.79 | loss:  0.71
-----------------------------------------------------------------------------------------
| epoch 54 | 1000/1179 batches | ms/batch 1313.77 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.24
-----------------------------------------------------------------------------------------
| end of epoch  54 | time per epoch: 1549.62s |
| Train Metrics | accuracy:  0.69 | loss:  1.24
| Eval  Metrics | accuracy:  0.79 | loss:  0.73
-----------------------------------------------------------------------------------------
[2025-02-22 10:20:31,525][absl][INFO] - Saving checkpoint at step: 63666
[2025-02-22 10:20:31,527][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-22 10:20:31,527][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-22 10:20:31,529][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_63666.
[2025-02-22 10:20:31,538][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-22 10:20:31,539][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_63666.orbax-checkpoint-tmp-27
[2025-02-22 10:20:31,546][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-22 10:20:32,070][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-22 10:20:32,091][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 16.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 543 milliseconds) (per-host)
[2025-02-22 10:20:32,341][absl][INFO] - ChainedFuture completed 1/1 futures in 0.25 seconds.
[2025-02-22 10:20:32,341][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 11.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 794 milliseconds) (per-host)
[2025-02-22 10:20:32,347][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-22 10:20:32,384][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_63666.orbax-checkpoint-tmp-27 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_63666
[2025-02-22 10:20:32,390][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_63666`.
[2025-02-22 10:20:32,390][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-22 10:20:32,392][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_57771
| epoch 55 | 1000/1179 batches | ms/batch 1344.57 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.28
-----------------------------------------------------------------------------------------
| end of epoch  55 | time per epoch: 1583.75s |
| Train Metrics | accuracy:  0.68 | loss:  1.27
| Eval  Metrics | accuracy:  0.76 | loss:  0.82
-----------------------------------------------------------------------------------------
| epoch 56 | 1000/1179 batches | ms/batch 1387.95 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.21
-----------------------------------------------------------------------------------------
| end of epoch  56 | time per epoch: 1644.62s |
| Train Metrics | accuracy:  0.69 | loss:  1.21
| Eval  Metrics | accuracy:  0.79 | loss:  0.75
-----------------------------------------------------------------------------------------
| epoch 57 | 1000/1179 batches | ms/batch 1453.10 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.20
-----------------------------------------------------------------------------------------
| end of epoch  57 | time per epoch: 1702.99s |
| Train Metrics | accuracy:  0.69 | loss:  1.20
| Eval  Metrics | accuracy:  0.78 | loss:  0.77
-----------------------------------------------------------------------------------------
| epoch 58 | 1000/1179 batches | ms/batch 1436.67 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.22
-----------------------------------------------------------------------------------------
| end of epoch  58 | time per epoch: 1693.82s |
| Train Metrics | accuracy:  0.69 | loss:  1.22
| Eval  Metrics | accuracy:  0.78 | loss:  0.78
-----------------------------------------------------------------------------------------
| epoch 59 | 1000/1179 batches | ms/batch 1434.96 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.21
-----------------------------------------------------------------------------------------
| end of epoch  59 | time per epoch: 1690.04s |
| Train Metrics | accuracy:  0.69 | loss:  1.22
| Eval  Metrics | accuracy:  0.79 | loss:  0.74
-----------------------------------------------------------------------------------------
| epoch 60 | 1000/1179 batches | ms/batch 1494.25 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.21
-----------------------------------------------------------------------------------------
| end of epoch  60 | time per epoch: 1777.33s |
| Train Metrics | accuracy:  0.69 | loss:  1.21
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.19151410460472107,
    "std": 0.29528066515922546,
    "var": 0.0871906727552414,
    "min": -0.17852991819381714,
    "max": 1.0312284231185913,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.24366621673107147,
    "std": 0.13017204403877258,
    "var": 0.0169447623193264,
    "min": 0.050573792308568954,
    "max": 0.684038519859314,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -1.603978125785943e-05,
    "std": 0.10719820111989975,
    "var": 0.011491455137729645,
    "min": -0.47756490111351013,
    "max": 0.48138436675071716,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.2388608455657959,
    "std": 0.1662674844264984,
    "var": 0.02764487825334072,
    "min": -0.0950799435377121,
    "max": 0.924554169178009,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.37994879484176636,
    "std": 0.2688772678375244,
    "var": 0.07229499518871307,
    "min": 0.09663843363523483,
    "max": 1.2184128761291504,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.001639382797293365,
    "std": 0.10922723263502121,
    "var": 0.011930588632822037,
    "min": -0.44764789938926697,
    "max": 0.5469531416893005,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.24860946834087372,
    "std": 0.18013474345207214,
    "var": 0.032448526471853256,
    "min": -0.07644697278738022,
    "max": 0.9123595356941223,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.4104882478713989,
    "std": 0.3122475743293762,
    "var": 0.09749855846166611,
    "min": 0.06742075085639954,
    "max": 2.061011791229248,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.000909765949472785,
    "std": 0.10877904295921326,
    "var": 0.011832879856228828,
    "min": -0.5925010442733765,
    "max": 0.563518226146698,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.1488029807806015,
    "std": 0.23351721465587616,
    "var": 0.05453029274940491,
    "min": -0.3832913041114807,
    "max": 1.0430556535720825,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6546338796615601,
    "std": 0.24826763570308685,
    "var": 0.06163681671023369,
    "min": 0.09058421105146408,
    "max": 2.1682651042938232,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.00028520854539237916,
    "std": 0.055864397436380386,
    "var": 0.003120831213891506,
    "min": -0.706469714641571,
    "max": 0.7341917753219604,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.14670351147651672,
    "std": 0.2459997832775116,
    "var": 0.06051589176058769,
    "min": -0.4867643415927887,
    "max": 1.1617406606674194,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.7005237340927124,
    "std": 0.2809654772281647,
    "var": 0.07894159853458405,
    "min": 0.10702765733003616,
    "max": 1.8724650144577026,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00010289040801580995,
    "std": 0.06008990854024887,
    "var": 0.0036107972264289856,
    "min": -0.4532545804977417,
    "max": 0.5123801231384277,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.0436786487698555,
    "std": 0.0991864949464798,
    "var": 0.009837960824370384,
    "min": -0.3528969883918762,
    "max": 0.21176008880138397,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.0369699001312256,
    "std": 0.25098931789398193,
    "var": 0.06299563497304916,
    "min": 0.6499479413032532,
    "max": 2.332500457763672,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00043048601946793497,
    "std": 0.0805673822760582,
    "var": 0.006491103209555149,
    "min": -0.5289992094039917,
    "max": 0.6538053154945374,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0013238966930657625,
    "std": 0.112724669277668,
    "var": 0.012706851586699486,
    "min": -0.7235209941864014,
    "max": 0.7297809720039368,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.00044902911758981645,
    "std": 0.11783463507890701,
    "var": 0.01388500165194273,
    "min": -0.8758444786071777,
    "max": 0.5577502846717834,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0016883168136700988,
    "std": 0.11513268947601318,
    "var": 0.013255536556243896,
    "min": -0.8646733164787292,
    "max": 0.806704044342041,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -3.902245589415543e-05,
    "std": 0.08135735988616943,
    "var": 0.006619020365178585,
    "min": -0.6825363636016846,
    "max": 0.7187304496765137,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.0001063765084836632,
    "std": 0.09804537147283554,
    "var": 0.009612894617021084,
    "min": -0.7094883322715759,
    "max": 0.612064003944397,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0005841504316776991,
    "std": 0.10897744446992874,
    "var": 0.01187608391046524,
    "min": -0.7945196032524109,
    "max": 0.6858688592910767,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.41684192419052124,
    "std": 0.1382542848587036,
    "var": 0.01911424845457077,
    "min": -0.7938599586486816,
    "max": -0.16209086775779724,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08830903470516205,
    "std": 0.29287219047546387,
    "var": 0.08577411621809006,
    "min": -1.1313592195510864,
    "max": 1.0930248498916626,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.9541292190551758,
    "std": 0.9292089939117432,
    "var": 0.8634294271469116,
    "min": -1.69334876537323,
    "max": 3.8146607875823975,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.32922786474227905,
    "std": 0.1435096114873886,
    "var": 0.020595010370016098,
    "min": -0.6918848752975464,
    "max": 0.039608318358659744,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.1998046189546585,
    "std": 0.21405844390392303,
    "var": 0.045821018517017365,
    "min": -1.5916858911514282,
    "max": 0.8588995337486267,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.105631709098816,
    "std": 0.9326520562171936,
    "var": 0.8698399066925049,
    "min": -0.6980135440826416,
    "max": 3.7797036170959473,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.2687712013721466,
    "std": 0.1615035980939865,
    "var": 0.026083413511514664,
    "min": -0.6388843059539795,
    "max": 0.09392130374908447,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.1942034810781479,
    "std": 0.22677525877952576,
    "var": 0.051427021622657776,
    "min": -1.4979661703109741,
    "max": 0.6906252503395081,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.9478291273117065,
    "std": 0.844822883605957,
    "var": 0.713725745677948,
    "min": -0.829928994178772,
    "max": 2.975186586380005,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.1154487133026123,
    "std": 0.10278446972370148,
    "var": 0.010564647614955902,
    "min": -0.41113460063934326,
    "max": 0.1461922526359558,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08552458882331848,
    "std": 0.1721663773059845,
    "var": 0.02964126504957676,
    "min": -1.3827846050262451,
    "max": 0.6217252612113953,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0016482309438288212,
    "std": 0.005974373314529657,
    "var": 3.56931341229938e-05,
    "min": -0.018088659271597862,
    "max": 0.011477747932076454,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.00044713853276334703,
    "std": 0.10695545375347137,
    "var": 0.011439469642937183,
    "min": -0.934779703617096,
    "max": 0.9201663732528687,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.016735563054680824,
    "std": 0.35998982191085815,
    "var": 0.1295926868915558,
    "min": -2.524108409881592,
    "max": 2.265850067138672,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.17371945083141327,
    "std": 0.10479346662759781,
    "var": 0.010981671512126923,
    "min": -0.49282002449035645,
    "max": 0.13360193371772766,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07402097433805466,
    "std": 0.16791923344135284,
    "var": 0.028196871280670166,
    "min": -1.2318687438964844,
    "max": 0.6655397415161133,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.14988911151885986,
    "std": 0.9888518452644348,
    "var": 0.9778279662132263,
    "min": -2.7801692485809326,
    "max": 2.5620951652526855,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.027432680130004883,
    "std": 0.13672611117362976,
    "var": 0.018694031983613968,
    "min": -0.3254554867744446,
    "max": 0.4241640567779541,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.04460122808814049,
    "std": 0.16408951580524445,
    "var": 0.02692537195980549,
    "min": -0.9394482374191284,
    "max": 0.5403986573219299,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.34201669692993164,
    "std": 0.6160425543785095,
    "var": 0.37950846552848816,
    "min": -1.893436074256897,
    "max": 2.0433990955352783,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.012747746892273426,
    "std": 0.08143993467092514,
    "var": 0.006632463540881872,
    "min": -0.20419220626354218,
    "max": 0.12956620752811432,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0019455525325611234,
    "std": 0.20825721323490143,
    "var": 0.04337106645107269,
    "min": -0.9829638004302979,
    "max": 0.794224739074707,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.0069418977946043015,
    "std": 0.288103848695755,
    "var": 0.08300382643938065,
    "min": -1.678551197052002,
    "max": 1.3553293943405151,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.5386403799057007,
    "std": 0.4367033541202545,
    "var": 0.19070982933044434,
    "min": -1.390248417854309,
    "max": 0.5883703231811523,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.6197293996810913,
    "std": 0.43109118938446045,
    "var": 0.18583962321281433,
    "min": -2.1112780570983887,
    "max": 0.25096258521080017,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.9128440618515015,
    "std": 0.4975578486919403,
    "var": 0.24756382405757904,
    "min": -2.310804605484009,
    "max": 0.28539156913757324,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.5749828815460205,
    "std": 0.5191612839698792,
    "var": 0.26952844858169556,
    "min": -3.2592215538024902,
    "max": 0.019848806783556938,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.3996992111206055,
    "std": 0.4253879487514496,
    "var": 0.18095490336418152,
    "min": -2.52359938621521,
    "max": -0.05516943708062172,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.4153711795806885,
    "std": 0.6165937781333923,
    "var": 0.38018786907196045,
    "min": -2.9646520614624023,
    "max": -0.04202989116311073,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.80 | loss:  0.71
-----------------------------------------------------------------------------------------
[2025-02-22 13:25:32,360][absl][INFO] - Saving checkpoint at step: 70740
[2025-02-22 13:25:32,362][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-22 13:25:32,362][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-22 13:25:32,363][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_70740.
[2025-02-22 13:25:32,366][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-22 13:25:32,367][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_70740.orbax-checkpoint-tmp-28
[2025-02-22 13:25:32,375][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-22 13:25:32,403][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-22 13:25:32,445][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 131.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 69 milliseconds) (per-host)
[2025-02-22 13:25:32,707][absl][INFO] - ChainedFuture completed 1/1 futures in 0.26 seconds.
[2025-02-22 13:25:32,707][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 27.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 331 milliseconds) (per-host)
[2025-02-22 13:25:32,713][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-22 13:25:32,746][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_70740.orbax-checkpoint-tmp-28 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_70740
[2025-02-22 13:25:32,752][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_70740`.
[2025-02-22 13:25:32,753][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-22 13:25:32,754][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_63666
| epoch 61 | 1000/1179 batches | ms/batch 1604.20 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.22
-----------------------------------------------------------------------------------------
| end of epoch  61 | time per epoch: 1883.00s |
| Train Metrics | accuracy:  0.69 | loss:  1.23
| Eval  Metrics | accuracy:  0.79 | loss:  0.76
-----------------------------------------------------------------------------------------
| epoch 62 | 1000/1179 batches | ms/batch 1548.46 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.22
-----------------------------------------------------------------------------------------
| end of epoch  62 | time per epoch: 1821.99s |
| Train Metrics | accuracy:  0.69 | loss:  1.22
| Eval  Metrics | accuracy:  0.79 | loss:  0.71
-----------------------------------------------------------------------------------------
| epoch 63 | 1000/1179 batches | ms/batch 1505.16 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.22
-----------------------------------------------------------------------------------------
| end of epoch  63 | time per epoch: 1771.09s |
| Train Metrics | accuracy:  0.69 | loss:  1.22
| Eval  Metrics | accuracy:  0.79 | loss:  0.72
-----------------------------------------------------------------------------------------
| epoch 64 | 1000/1179 batches | ms/batch 1539.76 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.18
-----------------------------------------------------------------------------------------
| end of epoch  64 | time per epoch: 1807.74s |
| Train Metrics | accuracy:  0.70 | loss:  1.19
| Eval  Metrics | accuracy:  0.78 | loss:  0.76
-----------------------------------------------------------------------------------------
| epoch 65 | 1000/1179 batches | ms/batch 1540.14 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.21
-----------------------------------------------------------------------------------------
| end of epoch  65 | time per epoch: 1825.48s |
| Train Metrics | accuracy:  0.69 | loss:  1.20
| Eval  Metrics | accuracy:  0.80 | loss:  0.71
-----------------------------------------------------------------------------------------
| epoch 66 | 1000/1179 batches | ms/batch 1538.23 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.21
-----------------------------------------------------------------------------------------
| end of epoch  66 | time per epoch: 1805.72s |
| Train Metrics | accuracy:  0.70 | loss:  1.20
| Eval  Metrics | accuracy:  0.79 | loss:  0.72
-----------------------------------------------------------------------------------------
| epoch 67 | 1000/1179 batches | ms/batch 1518.04 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.19
-----------------------------------------------------------------------------------------
| end of epoch  67 | time per epoch: 1787.75s |
| Train Metrics | accuracy:  0.70 | loss:  1.18
| Eval  Metrics | accuracy:  0.79 | loss:  0.72
-----------------------------------------------------------------------------------------
| epoch 68 | 1000/1179 batches | ms/batch 1515.35 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.20
-----------------------------------------------------------------------------------------
| end of epoch  68 | time per epoch: 1788.28s |
| Train Metrics | accuracy:  0.70 | loss:  1.20
| Eval  Metrics | accuracy:  0.80 | loss:  0.69
-----------------------------------------------------------------------------------------
| epoch 69 | 1000/1179 batches | ms/batch 1601.91 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.20
-----------------------------------------------------------------------------------------
| end of epoch  69 | time per epoch: 1872.86s |
| Train Metrics | accuracy:  0.70 | loss:  1.20
| Eval  Metrics | accuracy:  0.79 | loss:  0.73
-----------------------------------------------------------------------------------------
| epoch 70 | 1000/1179 batches | ms/batch 1566.99 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.17
-----------------------------------------------------------------------------------------
| end of epoch  70 | time per epoch: 1843.04s |
| Train Metrics | accuracy:  0.70 | loss:  1.18
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.2176463007926941,
    "std": 0.31469476222991943,
    "var": 0.09903280436992645,
    "min": -0.16699205338954926,
    "max": 1.0098803043365479,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.24987882375717163,
    "std": 0.13788984715938568,
    "var": 0.01901360973715782,
    "min": 0.04803472384810448,
    "max": 0.7532479166984558,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -5.39922621101141e-05,
    "std": 0.10952312499284744,
    "var": 0.011995314620435238,
    "min": -0.5374141335487366,
    "max": 0.5172195434570312,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.2428368628025055,
    "std": 0.17643484473228455,
    "var": 0.031129252165555954,
    "min": -0.080152228474617,
    "max": 0.965306282043457,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.37871918082237244,
    "std": 0.2791292667388916,
    "var": 0.07791315019130707,
    "min": 0.10125280171632767,
    "max": 1.1946120262145996,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0017852543387562037,
    "std": 0.11227405071258545,
    "var": 0.012605462223291397,
    "min": -0.4810211956501007,
    "max": 0.6233136057853699,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.24980854988098145,
    "std": 0.1716475784778595,
    "var": 0.029462892562150955,
    "min": -0.06608912348747253,
    "max": 0.9157117009162903,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.41234955191612244,
    "std": 0.3325853943824768,
    "var": 0.11061304807662964,
    "min": 0.07660926133394241,
    "max": 2.173971652984619,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0010575694032013416,
    "std": 0.11153408139944077,
    "var": 0.012439850717782974,
    "min": -0.6499506831169128,
    "max": 0.611619234085083,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.15218199789524078,
    "std": 0.24193423986434937,
    "var": 0.05853217840194702,
    "min": -0.3468342423439026,
    "max": 1.0401849746704102,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6649113893508911,
    "std": 0.2444840371608734,
    "var": 0.05977244675159454,
    "min": 0.10587267577648163,
    "max": 2.1952295303344727,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.00024190577096305788,
    "std": 0.05307314544916153,
    "var": 0.002816758817061782,
    "min": -0.7377938628196716,
    "max": 0.7600398063659668,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.147428959608078,
    "std": 0.24696102738380432,
    "var": 0.06098974868655205,
    "min": -0.4955110549926758,
    "max": 1.0801531076431274,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6911522746086121,
    "std": 0.2812119424343109,
    "var": 0.07908014953136444,
    "min": 0.1066906675696373,
    "max": 2.0395448207855225,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 4.6442604798357934e-05,
    "std": 0.06028027832508087,
    "var": 0.003633712185546756,
    "min": -0.5169497728347778,
    "max": 0.5767532587051392,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.043674223124980927,
    "std": 0.09708590060472488,
    "var": 0.009425671771168709,
    "min": -0.3556946814060211,
    "max": 0.1973487287759781,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.0620338916778564,
    "std": 0.2500278651714325,
    "var": 0.06251393258571625,
    "min": 0.6740639805793762,
    "max": 2.4065098762512207,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00043889053631573915,
    "std": 0.08335825800895691,
    "var": 0.0069485995918512344,
    "min": -0.6015506386756897,
    "max": 0.6908759474754333,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0009273124160245061,
    "std": 0.10848682373762131,
    "var": 0.011769391596317291,
    "min": -0.5979133248329163,
    "max": 0.6727439165115356,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0003640813229139894,
    "std": 0.11383198946714401,
    "var": 0.012957721948623657,
    "min": -0.835747241973877,
    "max": 0.6236228942871094,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0015219136839732528,
    "std": 0.11056298762559891,
    "var": 0.012224175035953522,
    "min": -0.7828081846237183,
    "max": 0.7635779976844788,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": 8.592578524257988e-05,
    "std": 0.07405512779951096,
    "var": 0.0054841614328324795,
    "min": -0.6022351980209351,
    "max": 0.6357241868972778,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00014602052397094667,
    "std": 0.09434958547353745,
    "var": 0.008901843801140785,
    "min": -0.7023566961288452,
    "max": 0.5821883678436279,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -9.331683395430446e-05,
    "std": 0.10496184974908829,
    "var": 0.011016990058124065,
    "min": -0.7680132389068604,
    "max": 0.6450825929641724,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.39564937353134155,
    "std": 0.12060327082872391,
    "var": 0.014545150101184845,
    "min": -0.67510986328125,
    "max": -0.16300471127033234,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.09324901551008224,
    "std": 0.2774761915206909,
    "var": 0.07699304074048996,
    "min": -1.1204652786254883,
    "max": 1.123111605644226,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.8677195310592651,
    "std": 0.886179506778717,
    "var": 0.7853140830993652,
    "min": -1.7644007205963135,
    "max": 3.475736379623413,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.32532477378845215,
    "std": 0.1347845047712326,
    "var": 0.018166862428188324,
    "min": -0.648451566696167,
    "max": 0.0820818543434143,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19979241490364075,
    "std": 0.21193493902683258,
    "var": 0.04491642117500305,
    "min": -1.3603379726409912,
    "max": 0.7669413089752197,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.0497305393218994,
    "std": 0.9119726419448853,
    "var": 0.8316941261291504,
    "min": -0.9912596940994263,
    "max": 3.436504364013672,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.2704426646232605,
    "std": 0.15894299745559692,
    "var": 0.025262877345085144,
    "min": -0.6246349811553955,
    "max": 0.08327791839838028,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.19755548238754272,
    "std": 0.22775976359844208,
    "var": 0.05187451094388962,
    "min": -1.3574713468551636,
    "max": 0.6658129096031189,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.9753842353820801,
    "std": 0.863550066947937,
    "var": 0.7457187175750732,
    "min": -0.8153303265571594,
    "max": 3.2708380222320557,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.11810529232025146,
    "std": 0.10194023698568344,
    "var": 0.010391812771558762,
    "min": -0.4103507399559021,
    "max": 0.11319243162870407,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08350910991430283,
    "std": 0.1713758409023285,
    "var": 0.02936968207359314,
    "min": -1.255994200706482,
    "max": 0.6063653230667114,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0012216910254210234,
    "std": 0.005514978431165218,
    "var": 3.041498530365061e-05,
    "min": -0.016484316438436508,
    "max": 0.013203819282352924,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.001070766826160252,
    "std": 0.10654368996620178,
    "var": 0.011351557448506355,
    "min": -0.8557730317115784,
    "max": 0.8696954846382141,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.016340864822268486,
    "std": 0.33956024050712585,
    "var": 0.11530116945505142,
    "min": -2.428642749786377,
    "max": 2.5649032592773438,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.1697777509689331,
    "std": 0.10133179277181625,
    "var": 0.010268133133649826,
    "min": -0.5241893529891968,
    "max": 0.0972612053155899,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07373199611902237,
    "std": 0.16590413451194763,
    "var": 0.027524180710315704,
    "min": -1.1607526540756226,
    "max": 0.630110502243042,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.153557687997818,
    "std": 0.9420377016067505,
    "var": 0.8874350786209106,
    "min": -2.691542863845825,
    "max": 2.558018684387207,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.03263538330793381,
    "std": 0.13782502710819244,
    "var": 0.01899573765695095,
    "min": -0.31162145733833313,
    "max": 0.3781491816043854,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.04381900280714035,
    "std": 0.1609077900648117,
    "var": 0.025891317054629326,
    "min": -0.9409624338150024,
    "max": 0.5666605830192566,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.3272128105163574,
    "std": 0.584082305431366,
    "var": 0.3411521315574646,
    "min": -1.8666808605194092,
    "max": 1.930090069770813,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.011811871081590652,
    "std": 0.0755133107304573,
    "var": 0.0057022604160010815,
    "min": -0.1762637495994568,
    "max": 0.12141884118318558,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.002285569440573454,
    "std": 0.21074643731117249,
    "var": 0.044414058327674866,
    "min": -1.0169867277145386,
    "max": 0.7525412440299988,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.007669137325137854,
    "std": 0.27700337767601013,
    "var": 0.076730877161026,
    "min": -1.4227405786514282,
    "max": 1.329899549484253,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.42293301224708557,
    "std": 0.4222151041030884,
    "var": 0.17826560139656067,
    "min": -1.1832239627838135,
    "max": 0.763112485408783,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.5094398260116577,
    "std": 0.4192512333393097,
    "var": 0.1757715940475464,
    "min": -1.959945559501648,
    "max": 0.3220338225364685,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.8339405059814453,
    "std": 0.48841822147369385,
    "var": 0.23855236172676086,
    "min": -2.136439800262451,
    "max": 0.3708442449569702,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.6808477640151978,
    "std": 0.5696300268173218,
    "var": 0.3244783580303192,
    "min": -3.1861019134521484,
    "max": 0.1122797429561615,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.345204472541809,
    "std": 0.4127601683139801,
    "var": 0.17037096619606018,
    "min": -2.441528797149658,
    "max": -0.01889234408736229,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.3379162549972534,
    "std": 0.6134459376335144,
    "var": 0.3763159513473511,
    "min": -2.8794198036193848,
    "max": 0.08036345988512039,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.80 | loss:  0.70
-----------------------------------------------------------------------------------------
| epoch 71 | 1000/1179 batches | ms/batch 1557.54 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.15
-----------------------------------------------------------------------------------------
| end of epoch  71 | time per epoch: 1853.92s |
| Train Metrics | accuracy:  0.71 | loss:  1.14
| Eval  Metrics | accuracy:  0.80 | loss:  0.70
-----------------------------------------------------------------------------------------
| epoch 72 | 1000/1179 batches | ms/batch 1674.85 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.17
-----------------------------------------------------------------------------------------
| end of epoch  72 | time per epoch: 1958.79s |
| Train Metrics | accuracy:  0.70 | loss:  1.17
| Eval  Metrics | accuracy:  0.79 | loss:  0.72
-----------------------------------------------------------------------------------------
| epoch 73 | 1000/1179 batches | ms/batch 1604.77 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.17
-----------------------------------------------------------------------------------------
| end of epoch  73 | time per epoch: 1892.92s |
| Train Metrics | accuracy:  0.70 | loss:  1.18
| Eval  Metrics | accuracy:  0.80 | loss:  0.71
-----------------------------------------------------------------------------------------
| epoch 74 | 1000/1179 batches | ms/batch 1565.66 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.18
-----------------------------------------------------------------------------------------
| end of epoch  74 | time per epoch: 1851.41s |
| Train Metrics | accuracy:  0.70 | loss:  1.20
| Eval  Metrics | accuracy:  0.79 | loss:  0.73
-----------------------------------------------------------------------------------------
| epoch 75 | 1000/1179 batches | ms/batch 1571.11 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.17
-----------------------------------------------------------------------------------------
| end of epoch  75 | time per epoch: 1850.38s |
| Train Metrics | accuracy:  0.71 | loss:  1.16
| Eval  Metrics | accuracy:  0.80 | loss:  0.69
-----------------------------------------------------------------------------------------
| epoch 76 | 1000/1179 batches | ms/batch 1603.57 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.14
-----------------------------------------------------------------------------------------
| end of epoch  76 | time per epoch: 1891.63s |
| Train Metrics | accuracy:  0.71 | loss:  1.14
| Eval  Metrics | accuracy:  0.81 | loss:  0.66
-----------------------------------------------------------------------------------------
[2025-02-22 22:26:55,968][absl][INFO] - Saving checkpoint at step: 89604
[2025-02-22 22:26:55,970][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-22 22:26:55,970][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-22 22:26:55,972][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_89604.
[2025-02-22 22:26:55,974][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-22 22:26:55,976][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_89604.orbax-checkpoint-tmp-29
[2025-02-22 22:26:56,033][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-22 22:26:56,062][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-22 22:26:56,099][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 141.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 64 milliseconds) (per-host)
[2025-02-22 22:26:56,318][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-22 22:26:56,318][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 283 milliseconds) (per-host)
[2025-02-22 22:26:56,324][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-22 22:26:56,357][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_89604.orbax-checkpoint-tmp-29 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_89604
[2025-02-22 22:26:56,364][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_89604`.
[2025-02-22 22:26:56,364][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-22 22:26:56,366][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_70740
| epoch 77 | 1000/1179 batches | ms/batch 1599.91 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.16
-----------------------------------------------------------------------------------------
| end of epoch  77 | time per epoch: 1887.28s |
| Train Metrics | accuracy:  0.70 | loss:  1.16
| Eval  Metrics | accuracy:  0.79 | loss:  0.72
-----------------------------------------------------------------------------------------
| epoch 78 | 1000/1179 batches | ms/batch 1618.82 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.20
-----------------------------------------------------------------------------------------
| end of epoch  78 | time per epoch: 1902.67s |
| Train Metrics | accuracy:  0.70 | loss:  1.20
| Eval  Metrics | accuracy:  0.80 | loss:  0.69
-----------------------------------------------------------------------------------------
| epoch 79 | 1000/1179 batches | ms/batch 1702.85 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.17
-----------------------------------------------------------------------------------------
| end of epoch  79 | time per epoch: 2034.70s |
| Train Metrics | accuracy:  0.70 | loss:  1.16
| Eval  Metrics | accuracy:  0.81 | loss:  0.68
-----------------------------------------------------------------------------------------
| epoch 80 | 1000/1179 batches | ms/batch 1732.38 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.16
-----------------------------------------------------------------------------------------
| end of epoch  80 | time per epoch: 2036.75s |
| Train Metrics | accuracy:  0.71 | loss:  1.14
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.2378116250038147,
    "std": 0.3386487364768982,
    "var": 0.11468296498060226,
    "min": -0.16959671676158905,
    "max": 1.0050468444824219,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.24328570067882538,
    "std": 0.13353009521961212,
    "var": 0.01783028617501259,
    "min": 0.05428856611251831,
    "max": 0.657602846622467,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0004927050904370844,
    "std": 0.1115989163517952,
    "var": 0.012454317882657051,
    "min": -0.5695008039474487,
    "max": 0.5381145477294922,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.25096559524536133,
    "std": 0.19054996967315674,
    "var": 0.036309294402599335,
    "min": -0.08113094419240952,
    "max": 1.0239827632904053,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.37877434492111206,
    "std": 0.29663217067718506,
    "var": 0.0879906415939331,
    "min": 0.08655265718698502,
    "max": 1.2951518297195435,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0019179328810423613,
    "std": 0.11495012789964676,
    "var": 0.01321353204548359,
    "min": -0.5416261553764343,
    "max": 0.702170193195343,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2498217523097992,
    "std": 0.1664435863494873,
    "var": 0.02770346961915493,
    "min": -0.09101755172014236,
    "max": 0.8554758429527283,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.4187355637550354,
    "std": 0.34213507175445557,
    "var": 0.11705639958381653,
    "min": 0.06273089349269867,
    "max": 2.267293691635132,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0009834500961005688,
    "std": 0.11396114528179169,
    "var": 0.01298714242875576,
    "min": -0.7079658508300781,
    "max": 0.6727315187454224,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.15374469757080078,
    "std": 0.24386225640773773,
    "var": 0.05946880206465721,
    "min": -0.4584626257419586,
    "max": 1.0504194498062134,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6736117601394653,
    "std": 0.23392464220523834,
    "var": 0.054720740765333176,
    "min": 0.0879429280757904,
    "max": 2.169942617416382,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0001319646544288844,
    "std": 0.05080587416887283,
    "var": 0.002581236883997917,
    "min": -0.7395263910293579,
    "max": 0.7451999187469482,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.1450873464345932,
    "std": 0.24354931712150574,
    "var": 0.05931627005338669,
    "min": -0.4420386254787445,
    "max": 1.0906356573104858,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6862101554870605,
    "std": 0.2803952097892761,
    "var": 0.07862148433923721,
    "min": 0.12989996373653412,
    "max": 2.295822858810425,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 2.1635996745317243e-05,
    "std": 0.06054999679327011,
    "var": 0.003666302189230919,
    "min": -0.5546820759773254,
    "max": 0.6687970161437988,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.04195261001586914,
    "std": 0.09565594792366028,
    "var": 0.009150059893727303,
    "min": -0.3325282633304596,
    "max": 0.25493136048316956,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.0863678455352783,
    "std": 0.253552109003067,
    "var": 0.0642886757850647,
    "min": 0.6700848937034607,
    "max": 2.4966533184051514,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0005205310299061239,
    "std": 0.08567845076322556,
    "var": 0.0073407976888120174,
    "min": -0.6597293615341187,
    "max": 0.7177587151527405,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0007567134452983737,
    "std": 0.10541757941246033,
    "var": 0.011112866923213005,
    "min": -0.5098658800125122,
    "max": 0.6527246236801147,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.00033926143078133464,
    "std": 0.10925155878067017,
    "var": 0.011935903690755367,
    "min": -0.7760838866233826,
    "max": 0.6164491772651672,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0014179333811625838,
    "std": 0.10618580132722855,
    "var": 0.011275425553321838,
    "min": -0.6772698163986206,
    "max": 0.7235633730888367,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": 0.0002692369744181633,
    "std": 0.06853761523962021,
    "var": 0.004697404336184263,
    "min": -0.5362016558647156,
    "max": 0.6036790013313293,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00015809517935849726,
    "std": 0.09067557007074356,
    "var": 0.008222059346735477,
    "min": -0.5948503613471985,
    "max": 0.5161469578742981,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0005812802701257169,
    "std": 0.1003183126449585,
    "var": 0.010063763707876205,
    "min": -0.7377066612243652,
    "max": 0.6198245286941528,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3744403123855591,
    "std": 0.10989683866500854,
    "var": 0.012077314779162407,
    "min": -0.6690098643302917,
    "max": -0.11158662289381027,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.09516891092061996,
    "std": 0.2600851356983185,
    "var": 0.06764427572488785,
    "min": -1.0504724979400635,
    "max": 0.9896782636642456,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.8017104864120483,
    "std": 0.8686043620109558,
    "var": 0.7544735670089722,
    "min": -1.8555951118469238,
    "max": 3.2495150566101074,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.3201335370540619,
    "std": 0.12996353209018707,
    "var": 0.016890522092580795,
    "min": -0.6988557577133179,
    "max": 0.06797535717487335,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.20110902190208435,
    "std": 0.2101731300354004,
    "var": 0.0441727451980114,
    "min": -1.2325903177261353,
    "max": 0.8287099003791809,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.9810333251953125,
    "std": 0.9068977236747742,
    "var": 0.8224635124206543,
    "min": -1.2181557416915894,
    "max": 3.050734519958496,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.27570605278015137,
    "std": 0.16148129105567932,
    "var": 0.02607620880007744,
    "min": -0.6484248042106628,
    "max": 0.1010233536362648,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.20244915783405304,
    "std": 0.22611773014068604,
    "var": 0.05112922936677933,
    "min": -1.3600960969924927,
    "max": 0.7178910970687866,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.965082049369812,
    "std": 0.8867068290710449,
    "var": 0.786249041557312,
    "min": -0.9775049686431885,
    "max": 3.3015401363372803,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.12105131149291992,
    "std": 0.10031748563051224,
    "var": 0.010063597932457924,
    "min": -0.38794082403182983,
    "max": 0.11561203002929688,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08198805153369904,
    "std": 0.16914208233356476,
    "var": 0.02860904671251774,
    "min": -1.2195584774017334,
    "max": 0.5287985801696777,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0009270262671634555,
    "std": 0.00559498555958271,
    "var": 3.130386539851315e-05,
    "min": -0.023870771750807762,
    "max": 0.0131599185988307,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.001320019131526351,
    "std": 0.10428966581821442,
    "var": 0.010876335203647614,
    "min": -0.80925452709198,
    "max": 0.8581309914588928,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.014364209957420826,
    "std": 0.32068243622779846,
    "var": 0.10283723473548889,
    "min": -2.2803051471710205,
    "max": 2.528981924057007,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.16515092551708221,
    "std": 0.09766855090856552,
    "var": 0.009539145976305008,
    "min": -0.5030447840690613,
    "max": 0.09928575158119202,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07314932346343994,
    "std": 0.16361336410045624,
    "var": 0.026769334450364113,
    "min": -1.3451441526412964,
    "max": 0.5823413133621216,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.16127702593803406,
    "std": 0.8965696692466736,
    "var": 0.8038371801376343,
    "min": -2.58782696723938,
    "max": 2.581268548965454,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.03421509265899658,
    "std": 0.13283856213092804,
    "var": 0.01764608547091484,
    "min": -0.28043437004089355,
    "max": 0.3708269000053406,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.042127322405576706,
    "std": 0.1576526165008545,
    "var": 0.024854348972439766,
    "min": -0.9920557141304016,
    "max": 0.5408344864845276,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.31265950202941895,
    "std": 0.5503779649734497,
    "var": 0.30291593074798584,
    "min": -1.7300524711608887,
    "max": 1.8047412633895874,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.011570841073989868,
    "std": 0.07635433971881866,
    "var": 0.005829985719174147,
    "min": -0.1878906637430191,
    "max": 0.10922343283891678,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0020979742985218763,
    "std": 0.21171019971370697,
    "var": 0.044821206480264664,
    "min": -1.004420280456543,
    "max": 0.7911191582679749,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.00791780836880207,
    "std": 0.2690863609313965,
    "var": 0.07240746915340424,
    "min": -1.3108645677566528,
    "max": 1.2545380592346191,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.3214964270591736,
    "std": 0.39537155628204346,
    "var": 0.15631867945194244,
    "min": -1.09245765209198,
    "max": 0.8974661231040955,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.4355407953262329,
    "std": 0.3993009924888611,
    "var": 0.1594412922859192,
    "min": -1.8190467357635498,
    "max": 0.3559928238391876,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.7715191841125488,
    "std": 0.480409175157547,
    "var": 0.23079298436641693,
    "min": -2.0224666595458984,
    "max": 0.42922288179397583,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.8012220859527588,
    "std": 0.6410999894142151,
    "var": 0.41100919246673584,
    "min": -3.166344165802002,
    "max": 0.2560584247112274,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.3065450191497803,
    "std": 0.4068294167518616,
    "var": 0.1655101776123047,
    "min": -2.3679428100585938,
    "max": 0.04236984997987747,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.283972978591919,
    "std": 0.6097447276115417,
    "var": 0.3717886805534363,
    "min": -2.8641040325164795,
    "max": 0.14584919810295105,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.81 | loss:  0.66
-----------------------------------------------------------------------------------------
| epoch 81 | 1000/1179 batches | ms/batch 1700.87 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.16
-----------------------------------------------------------------------------------------
| end of epoch  81 | time per epoch: 1992.48s |
| Train Metrics | accuracy:  0.71 | loss:  1.17
| Eval  Metrics | accuracy:  0.80 | loss:  0.71
-----------------------------------------------------------------------------------------
| epoch 82 | 1000/1179 batches | ms/batch 1657.47 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.15
-----------------------------------------------------------------------------------------
| end of epoch  82 | time per epoch: 1954.18s |
| Train Metrics | accuracy:  0.71 | loss:  1.15
| Eval  Metrics | accuracy:  0.80 | loss:  0.70
-----------------------------------------------------------------------------------------
| epoch 83 | 1000/1179 batches | ms/batch 1728.00 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.17
-----------------------------------------------------------------------------------------
| end of epoch  83 | time per epoch: 2028.83s |
| Train Metrics | accuracy:  0.71 | loss:  1.16
| Eval  Metrics | accuracy:  0.78 | loss:  0.72
-----------------------------------------------------------------------------------------
| epoch 84 | 1000/1179 batches | ms/batch 1681.50 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.12
-----------------------------------------------------------------------------------------
| end of epoch  84 | time per epoch: 1977.48s |
| Train Metrics | accuracy:  0.72 | loss:  1.11
| Eval  Metrics | accuracy:  0.81 | loss:  0.68
-----------------------------------------------------------------------------------------
| epoch 85 | 1000/1179 batches | ms/batch 1723.84 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.15
-----------------------------------------------------------------------------------------
| end of epoch  85 | time per epoch: 2033.42s |
| Train Metrics | accuracy:  0.71 | loss:  1.14
| Eval  Metrics | accuracy:  0.80 | loss:  0.68
-----------------------------------------------------------------------------------------
| epoch 86 | 1000/1179 batches | ms/batch 1758.00 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.14
-----------------------------------------------------------------------------------------
| end of epoch  86 | time per epoch: 2062.22s |
| Train Metrics | accuracy:  0.71 | loss:  1.14
| Eval  Metrics | accuracy:  0.80 | loss:  0.66
-----------------------------------------------------------------------------------------
| epoch 87 | 1000/1179 batches | ms/batch 1757.24 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.17
-----------------------------------------------------------------------------------------
| end of epoch  87 | time per epoch: 2067.44s |
| Train Metrics | accuracy:  0.71 | loss:  1.17
| Eval  Metrics | accuracy:  0.80 | loss:  0.67
-----------------------------------------------------------------------------------------
| epoch 88 | 1000/1179 batches | ms/batch 1746.21 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.16
-----------------------------------------------------------------------------------------
| end of epoch  88 | time per epoch: 2055.73s |
| Train Metrics | accuracy:  0.71 | loss:  1.15
| Eval  Metrics | accuracy:  0.81 | loss:  0.67
-----------------------------------------------------------------------------------------
| epoch 89 | 1000/1179 batches | ms/batch 1738.90 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.15
-----------------------------------------------------------------------------------------
| end of epoch  89 | time per epoch: 2050.55s |
| Train Metrics | accuracy:  0.71 | loss:  1.16
| Eval  Metrics | accuracy:  0.81 | loss:  0.66
-----------------------------------------------------------------------------------------
[2025-02-23 06:28:00,552][absl][INFO] - Saving checkpoint at step: 104931
[2025-02-23 06:28:00,554][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-23 06:28:00,554][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-23 06:28:00,556][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_104931.
[2025-02-23 06:28:00,576][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-23 06:28:00,577][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_104931.orbax-checkpoint-tmp-30
[2025-02-23 06:28:00,586][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-23 06:28:00,614][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-23 06:28:00,644][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 162.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 56 milliseconds) (per-host)
[2025-02-23 06:28:00,858][absl][INFO] - ChainedFuture completed 1/1 futures in 0.21 seconds.
[2025-02-23 06:28:00,858][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 271 milliseconds) (per-host)
[2025-02-23 06:28:00,864][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-23 06:28:00,900][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_104931.orbax-checkpoint-tmp-30 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_104931
[2025-02-23 06:28:00,907][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_104931`.
[2025-02-23 06:28:00,907][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-23 06:28:00,909][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_89604
| epoch 90 | 1000/1179 batches | ms/batch 1759.25 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.15
-----------------------------------------------------------------------------------------
| end of epoch  90 | time per epoch: 2095.69s |
| Train Metrics | accuracy:  0.71 | loss:  1.14
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.25413089990615845,
    "std": 0.35262560844421387,
    "var": 0.1243448257446289,
    "min": -0.20515990257263184,
    "max": 1.0247628688812256,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.24839918315410614,
    "std": 0.14496494829654694,
    "var": 0.021014835685491562,
    "min": 0.05332569032907486,
    "max": 0.7326517105102539,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.00041300192242488265,
    "std": 0.11352968215942383,
    "var": 0.012888988479971886,
    "min": -0.5950404405593872,
    "max": 0.5528340935707092,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.2586967647075653,
    "std": 0.20688559114933014,
    "var": 0.04280164837837219,
    "min": -0.08826959133148193,
    "max": 1.1044329404830933,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.3691174387931824,
    "std": 0.2990627884864807,
    "var": 0.0894385576248169,
    "min": 0.06745180487632751,
    "max": 1.3256416320800781,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0018416715320199728,
    "std": 0.11694785207509995,
    "var": 0.013676799833774567,
    "min": -0.5826749801635742,
    "max": 0.7579689025878906,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2532551884651184,
    "std": 0.1681113988161087,
    "var": 0.028261443600058556,
    "min": -0.08511772751808167,
    "max": 0.8188947439193726,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.4162271022796631,
    "std": 0.3505048453807831,
    "var": 0.12285365909337997,
    "min": 0.05803263187408447,
    "max": 2.1973400115966797,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0010092525044456124,
    "std": 0.11584075540304184,
    "var": 0.013419080525636673,
    "min": -0.7546771764755249,
    "max": 0.7022889256477356,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.15857139229774475,
    "std": 0.24867641925811768,
    "var": 0.061839960515499115,
    "min": -0.5110812187194824,
    "max": 1.0328516960144043,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6812739372253418,
    "std": 0.23060071468353271,
    "var": 0.05317668616771698,
    "min": 0.11562927067279816,
    "max": 2.187276601791382,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0001558036165079102,
    "std": 0.0487089529633522,
    "var": 0.002372562186792493,
    "min": -0.7421444654464722,
    "max": 0.7369886040687561,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.15143710374832153,
    "std": 0.24821752309799194,
    "var": 0.06161194294691086,
    "min": -0.39320412278175354,
    "max": 1.1595406532287598,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6808193922042847,
    "std": 0.28023311495780945,
    "var": 0.07853060960769653,
    "min": 0.15660853683948517,
    "max": 2.335902690887451,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 1.8109989468939602e-05,
    "std": 0.06089507043361664,
    "var": 0.003708209842443466,
    "min": -0.5605359673500061,
    "max": 0.7218016982078552,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.04038079082965851,
    "std": 0.09444062411785126,
    "var": 0.008919031359255314,
    "min": -0.3220492899417877,
    "max": 0.2532575726509094,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.109140396118164,
    "std": 0.25591883063316345,
    "var": 0.06549444794654846,
    "min": 0.6845558285713196,
    "max": 2.5178136825561523,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0004906178219243884,
    "std": 0.08746366202831268,
    "var": 0.007649892009794712,
    "min": -0.7056335806846619,
    "max": 0.7447280883789062,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00020794423471670598,
    "std": 0.10091294348239899,
    "var": 0.010183421894907951,
    "min": -0.5644372701644897,
    "max": 0.6045334935188293,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -6.575735460501164e-05,
    "std": 0.10455471277236938,
    "var": 0.010931688360869884,
    "min": -0.6604301333427429,
    "max": 0.61208575963974,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0006572703714482486,
    "std": 0.1013905480504036,
    "var": 0.010280043818056583,
    "min": -0.6113272309303284,
    "max": 0.6479645371437073,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00016253627836704254,
    "std": 0.0636410191655159,
    "var": 0.0040501793846488,
    "min": -0.5409529209136963,
    "max": 0.5770236849784851,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00024556322023272514,
    "std": 0.08680670708417892,
    "var": 0.007535404525697231,
    "min": -0.5551262497901917,
    "max": 0.5097145438194275,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -9.36584547162056e-06,
    "std": 0.09542209655046463,
    "var": 0.009105376899242401,
    "min": -0.6801642775535583,
    "max": 0.5677672028541565,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3589700162410736,
    "std": 0.10136272758245468,
    "var": 0.010274402797222137,
    "min": -0.6717187762260437,
    "max": -0.12317714095115662,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.10091464221477509,
    "std": 0.24895702302455902,
    "var": 0.06197959929704666,
    "min": -1.1010798215866089,
    "max": 1.0634199380874634,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.7549842596054077,
    "std": 0.8582160472869873,
    "var": 0.7365347743034363,
    "min": -1.8220685720443726,
    "max": 3.130244016647339,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.3164350986480713,
    "std": 0.12868866324424744,
    "var": 0.016560770571231842,
    "min": -0.6889426112174988,
    "max": 0.0874100923538208,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19873455166816711,
    "std": 0.20762531459331512,
    "var": 0.043108273297548294,
    "min": -1.231764554977417,
    "max": 0.761587917804718,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.9191673994064331,
    "std": 0.903608500957489,
    "var": 0.8165082931518555,
    "min": -1.4098812341690063,
    "max": 2.88572359085083,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.2796940207481384,
    "std": 0.16217796504497528,
    "var": 0.02630169317126274,
    "min": -0.6413707733154297,
    "max": 0.10253801941871643,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.20296631753444672,
    "std": 0.22377246618270874,
    "var": 0.05007411912083626,
    "min": -1.3181352615356445,
    "max": 0.7397097945213318,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.9460043907165527,
    "std": 0.9003995656967163,
    "var": 0.81071937084198,
    "min": -1.0419766902923584,
    "max": 3.302284002304077,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.12490015476942062,
    "std": 0.09496467560529709,
    "var": 0.009018288925290108,
    "min": -0.3471936285495758,
    "max": 0.11561106145381927,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.0808405801653862,
    "std": 0.16719895601272583,
    "var": 0.027955492958426476,
    "min": -1.1904590129852295,
    "max": 0.5948584079742432,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0009802490239962935,
    "std": 0.005060592200607061,
    "var": 2.560959183028899e-05,
    "min": -0.02340823970735073,
    "max": 0.01311655342578888,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.0013758018612861633,
    "std": 0.10314217954874039,
    "var": 0.010638309642672539,
    "min": -0.7517336010932922,
    "max": 0.8624303936958313,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.013740715570747852,
    "std": 0.3014834523200989,
    "var": 0.09089227020740509,
    "min": -2.1419618129730225,
    "max": 2.452436685562134,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.1640225648880005,
    "std": 0.09247706830501556,
    "var": 0.008552009239792824,
    "min": -0.4779244065284729,
    "max": 0.10619133710861206,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07279009371995926,
    "std": 0.16047243773937225,
    "var": 0.025751402601599693,
    "min": -1.3622633218765259,
    "max": 0.5629202127456665,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.15886934101581573,
    "std": 0.8447639346122742,
    "var": 0.7136260867118835,
    "min": -2.382211446762085,
    "max": 2.4246182441711426,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.041117213666439056,
    "std": 0.1338052749633789,
    "var": 0.017903853207826614,
    "min": -0.27339911460876465,
    "max": 0.35933348536491394,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.04071836546063423,
    "std": 0.15305426716804504,
    "var": 0.02342561073601246,
    "min": -0.9200093746185303,
    "max": 0.5971759557723999,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.3070716857910156,
    "std": 0.5139442086219788,
    "var": 0.26413866877555847,
    "min": -1.4191761016845703,
    "max": 1.6299916505813599,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.010807523503899574,
    "std": 0.06994058936834335,
    "var": 0.004891686607152224,
    "min": -0.17015916109085083,
    "max": 0.1069980189204216,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0024451962672173977,
    "std": 0.21296271681785583,
    "var": 0.04535311833024025,
    "min": -0.9577248692512512,
    "max": 0.7787224054336548,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.008015087805688381,
    "std": 0.256565660238266,
    "var": 0.0658259391784668,
    "min": -1.2849667072296143,
    "max": 1.2753145694732666,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.26847195625305176,
    "std": 0.38285303115844727,
    "var": 0.14657644927501678,
    "min": -1.0201278924942017,
    "max": 0.9740169048309326,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.3706739544868469,
    "std": 0.39158087968826294,
    "var": 0.1533356010913849,
    "min": -1.7192820310592651,
    "max": 0.47207608819007874,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.7211545705795288,
    "std": 0.47841840982437134,
    "var": 0.22888419032096863,
    "min": -1.979310154914856,
    "max": 0.46586987376213074,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.8660194873809814,
    "std": 0.6761992573738098,
    "var": 0.45724549889564514,
    "min": -3.14067006111145,
    "max": 0.3917235732078552,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.2609295845031738,
    "std": 0.4098809063434601,
    "var": 0.16800236701965332,
    "min": -2.348445177078247,
    "max": 0.11589418351650238,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.2325308322906494,
    "std": 0.604508101940155,
    "var": 0.36543008685112,
    "min": -2.811476707458496,
    "max": 0.20167632400989532,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.81 | loss:  0.65
-----------------------------------------------------------------------------------------
| epoch 91 | 1000/1179 batches | ms/batch 1773.43 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.16
-----------------------------------------------------------------------------------------
| end of epoch  91 | time per epoch: 2088.84s |
| Train Metrics | accuracy:  0.71 | loss:  1.16
| Eval  Metrics | accuracy:  0.81 | loss:  0.64
-----------------------------------------------------------------------------------------
[2025-02-23 07:45:10,223][absl][INFO] - Saving checkpoint at step: 107289
[2025-02-23 07:45:10,226][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-23 07:45:10,226][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-23 07:45:10,227][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_107289.
[2025-02-23 07:45:10,236][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-23 07:45:10,237][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_107289.orbax-checkpoint-tmp-31
[2025-02-23 07:45:10,245][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-23 07:45:10,272][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-23 07:45:10,294][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 187.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 48 milliseconds) (per-host)
[2025-02-23 07:45:10,537][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-23 07:45:10,537][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 291 milliseconds) (per-host)
[2025-02-23 07:45:10,543][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-23 07:45:10,575][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_107289.orbax-checkpoint-tmp-31 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_107289
[2025-02-23 07:45:10,581][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_107289`.
[2025-02-23 07:45:10,581][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-23 07:45:10,583][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_104931
| epoch 92 | 1000/1179 batches | ms/batch 1768.26 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.13
-----------------------------------------------------------------------------------------
| end of epoch  92 | time per epoch: 2094.03s |
| Train Metrics | accuracy:  0.72 | loss:  1.13
| Eval  Metrics | accuracy:  0.81 | loss:  0.66
-----------------------------------------------------------------------------------------
| epoch 93 | 1000/1179 batches | ms/batch 1777.81 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.13
-----------------------------------------------------------------------------------------
| end of epoch  93 | time per epoch: 2107.26s |
| Train Metrics | accuracy:  0.72 | loss:  1.12
| Eval  Metrics | accuracy:  0.80 | loss:  0.71
-----------------------------------------------------------------------------------------
| epoch 94 | 1000/1179 batches | ms/batch 1825.91 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.12
-----------------------------------------------------------------------------------------
| end of epoch  94 | time per epoch: 2149.56s |
| Train Metrics | accuracy:  0.72 | loss:  1.13
| Eval  Metrics | accuracy:  0.80 | loss:  0.68
-----------------------------------------------------------------------------------------
| epoch 95 | 1000/1179 batches | ms/batch 1853.82 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.09
-----------------------------------------------------------------------------------------
| end of epoch  95 | time per epoch: 2197.73s |
| Train Metrics | accuracy:  0.72 | loss:  1.10
| Eval  Metrics | accuracy:  0.82 | loss:  0.64
-----------------------------------------------------------------------------------------
[2025-02-23 10:23:10,418][absl][INFO] - Saving checkpoint at step: 112005
[2025-02-23 10:23:10,420][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-23 10:23:10,421][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-23 10:23:10,422][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_112005.
[2025-02-23 10:23:10,432][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-23 10:23:10,433][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_112005.orbax-checkpoint-tmp-32
[2025-02-23 10:23:10,441][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-23 10:23:10,469][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-23 10:23:10,498][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 163.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 56 milliseconds) (per-host)
[2025-02-23 10:23:10,763][absl][INFO] - ChainedFuture completed 1/1 futures in 0.27 seconds.
[2025-02-23 10:23:10,763][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 28.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 322 milliseconds) (per-host)
[2025-02-23 10:23:10,770][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-23 10:23:10,806][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_112005.orbax-checkpoint-tmp-32 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_112005
[2025-02-23 10:23:10,812][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_112005`.
[2025-02-23 10:23:10,813][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-23 10:23:10,815][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_107289
| epoch 96 | 1000/1179 batches | ms/batch 1897.66 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.09
-----------------------------------------------------------------------------------------
| end of epoch  96 | time per epoch: 2235.25s |
| Train Metrics | accuracy:  0.72 | loss:  1.09
| Eval  Metrics | accuracy:  0.82 | loss:  0.63
-----------------------------------------------------------------------------------------
[2025-02-23 11:04:42,152][absl][INFO] - Saving checkpoint at step: 113184
[2025-02-23 11:04:42,154][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-23 11:04:42,154][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-23 11:04:42,156][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_113184.
[2025-02-23 11:04:42,175][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-23 11:04:42,176][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_113184.orbax-checkpoint-tmp-33
[2025-02-23 11:04:42,184][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-23 11:04:42,211][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-23 11:04:42,242][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 160.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 56 milliseconds) (per-host)
[2025-02-23 11:04:42,824][absl][INFO] - ChainedFuture completed 1/1 futures in 0.57 seconds.
[2025-02-23 11:04:42,824][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 14.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 638 milliseconds) (per-host)
[2025-02-23 11:04:42,830][absl][INFO] - Wrote Metadata={'item_handlers': 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler', 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1740326682180309810, 'commit_timestamp_nsecs': None, 'custom': {}}, json={"item_handlers": "orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler", "metrics": {}, "performance_metrics": {}, "init_timestamp_nsecs": 1740326682180309810, "commit_timestamp_nsecs": null, "custom": {}} to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_113184.orbax-checkpoint-tmp-33/_CHECKPOINT_METADATA
[2025-02-23 11:04:42,830][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-23 11:04:42,865][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_113184.orbax-checkpoint-tmp-33 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_113184
[2025-02-23 11:04:42,872][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_113184`.
[2025-02-23 11:04:42,872][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-23 11:04:42,873][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_112005
| epoch 97 | 1000/1179 batches | ms/batch 1891.81 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.13
-----------------------------------------------------------------------------------------
| end of epoch  97 | time per epoch: 2237.67s |
| Train Metrics | accuracy:  0.72 | loss:  1.12
| Eval  Metrics | accuracy:  0.81 | loss:  0.65
-----------------------------------------------------------------------------------------
| epoch 98 | 1000/1179 batches | ms/batch 1878.09 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.11
-----------------------------------------------------------------------------------------
| end of epoch  98 | time per epoch: 2207.89s |
| Train Metrics | accuracy:  0.72 | loss:  1.12
| Eval  Metrics | accuracy:  0.81 | loss:  0.67
-----------------------------------------------------------------------------------------
| epoch 99 | 1000/1179 batches | ms/batch 1834.54 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.15
-----------------------------------------------------------------------------------------
| end of epoch  99 | time per epoch: 2138.38s |
| Train Metrics | accuracy:  0.72 | loss:  1.14
| Eval  Metrics | accuracy:  0.82 | loss:  0.61
-----------------------------------------------------------------------------------------
| epoch 100 | 1000/1179 batches | ms/batch 1934.05 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.10
-----------------------------------------------------------------------------------------
| end of epoch 100 | time per epoch: 2278.47s |
| Train Metrics | accuracy:  0.72 | loss:  1.10
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.2679484486579895,
    "std": 0.36381226778030396,
    "var": 0.1323593556880951,
    "min": -0.27942973375320435,
    "max": 1.0299607515335083,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.24677029252052307,
    "std": 0.14807331562042236,
    "var": 0.021925708279013634,
    "min": 0.062046781182289124,
    "max": 0.7177215814590454,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0005981290014460683,
    "std": 0.11477912217378616,
    "var": 0.013174246996641159,
    "min": -0.6355211734771729,
    "max": 0.5609710812568665,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.2673860192298889,
    "std": 0.21798595786094666,
    "var": 0.04751787707209587,
    "min": -0.07044531404972076,
    "max": 1.0903538465499878,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.37488245964050293,
    "std": 0.31163665652275085,
    "var": 0.09711740911006927,
    "min": 0.0844215378165245,
    "max": 1.3411221504211426,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0019162737298756838,
    "std": 0.11856730282306671,
    "var": 0.014058205299079418,
    "min": -0.609740674495697,
    "max": 0.7954179644584656,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2559407353401184,
    "std": 0.1684718281030655,
    "var": 0.028382759541273117,
    "min": -0.08160734176635742,
    "max": 0.8201667666435242,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.4142802655696869,
    "std": 0.3560018539428711,
    "var": 0.1267373263835907,
    "min": 0.0665656179189682,
    "max": 2.2268426418304443,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0010286138858646154,
    "std": 0.11730317771434784,
    "var": 0.01376003585755825,
    "min": -0.7792749404907227,
    "max": 0.7234107851982117,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.16016998887062073,
    "std": 0.24435871839523315,
    "var": 0.059711188077926636,
    "min": -0.47642362117767334,
    "max": 1.017285704612732,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6892253756523132,
    "std": 0.22939267754554749,
    "var": 0.05262099951505661,
    "min": 0.11482569575309753,
    "max": 2.2537178993225098,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -8.198743307730183e-05,
    "std": 0.0469171367585659,
    "var": 0.0022012176923453808,
    "min": -0.7375751733779907,
    "max": 0.7345916628837585,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.15571558475494385,
    "std": 0.24493823945522308,
    "var": 0.059994738548994064,
    "min": -0.38631778955459595,
    "max": 1.0992335081100464,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6751176714897156,
    "std": 0.2876724898815155,
    "var": 0.08275546133518219,
    "min": 0.14505894482135773,
    "max": 2.594998359680176,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 1.767947105690837e-05,
    "std": 0.06128372251987457,
    "var": 0.003755694953724742,
    "min": -0.5682621598243713,
    "max": 0.7461143136024475,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.03545984625816345,
    "std": 0.08961611986160278,
    "var": 0.008031048811972141,
    "min": -0.3037496507167816,
    "max": 0.26251697540283203,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.135891079902649,
    "std": 0.2590339779853821,
    "var": 0.06709861010313034,
    "min": 0.7308088541030884,
    "max": 2.551417827606201,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00039449764881283045,
    "std": 0.0888700783252716,
    "var": 0.00789789017289877,
    "min": -0.7710796594619751,
    "max": 0.7769780158996582,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0004521471564657986,
    "std": 0.09606260061264038,
    "var": 0.009228022769093513,
    "min": -0.5960322022438049,
    "max": 0.584771990776062,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 5.8414414525032043e-05,
    "std": 0.09902449697256088,
    "var": 0.009805850684642792,
    "min": -0.6000301241874695,
    "max": 0.604193389415741,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0012850661296397448,
    "std": 0.0956975668668747,
    "var": 0.009158024564385414,
    "min": -0.543002188205719,
    "max": 0.6612362265586853,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -6.246351404115558e-06,
    "std": 0.059021640568971634,
    "var": 0.0034835543483495712,
    "min": -0.4926641881465912,
    "max": 0.49707284569740295,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.00010937541810562834,
    "std": 0.08291856944561005,
    "var": 0.00687548890709877,
    "min": -0.4855576753616333,
    "max": 0.5047503709793091,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.00012660415086429566,
    "std": 0.09037064760923386,
    "var": 0.00816685426980257,
    "min": -0.6201856136322021,
    "max": 0.5587761402130127,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3492448329925537,
    "std": 0.09816478192806244,
    "var": 0.009636323899030685,
    "min": -0.5926680564880371,
    "max": -0.11649224162101746,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.10364168882369995,
    "std": 0.23816555738449097,
    "var": 0.056722838431596756,
    "min": -1.127945899963379,
    "max": 1.0574854612350464,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.679861307144165,
    "std": 0.815930187702179,
    "var": 0.6657420992851257,
    "min": -1.513981819152832,
    "max": 2.865767478942871,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.3160805404186249,
    "std": 0.12390092760324478,
    "var": 0.015351439826190472,
    "min": -0.7172480225563049,
    "max": 0.07262913882732391,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19742120802402496,
    "std": 0.2053452432155609,
    "var": 0.04216666892170906,
    "min": -1.2711619138717651,
    "max": 0.6666256785392761,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.8533853888511658,
    "std": 0.9013614654541016,
    "var": 0.812452495098114,
    "min": -1.5029757022857666,
    "max": 2.5817246437072754,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.2776792049407959,
    "std": 0.15513962507247925,
    "var": 0.024068303406238556,
    "min": -0.6426623463630676,
    "max": 0.07759971171617508,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.20489440858364105,
    "std": 0.2197488695383072,
    "var": 0.04828956723213196,
    "min": -1.3545293807983398,
    "max": 0.7564759254455566,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.9139053225517273,
    "std": 0.8960358500480652,
    "var": 0.8028802871704102,
    "min": -1.0548378229141235,
    "max": 3.085104465484619,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.12916073203086853,
    "std": 0.09385263174772263,
    "var": 0.0088083166629076,
    "min": -0.35948970913887024,
    "max": 0.10718116909265518,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07878747582435608,
    "std": 0.16398470103740692,
    "var": 0.026890985667705536,
    "min": -1.200231909751892,
    "max": 0.5867438912391663,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0005689057288691401,
    "std": 0.004510278347879648,
    "var": 2.0342609786894172e-05,
    "min": -0.014054305851459503,
    "max": 0.013673613779246807,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.0008796355105005205,
    "std": 0.10097812861204147,
    "var": 0.010196583345532417,
    "min": -0.7329457402229309,
    "max": 0.8489429950714111,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.01244047936052084,
    "std": 0.27982601523399353,
    "var": 0.07830259948968887,
    "min": -1.9088330268859863,
    "max": 2.3113646507263184,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.1616981029510498,
    "std": 0.08932606130838394,
    "var": 0.00797914620488882,
    "min": -0.45814287662506104,
    "max": 0.06115153804421425,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07247600704431534,
    "std": 0.1566777229309082,
    "var": 0.024547908455133438,
    "min": -1.421059250831604,
    "max": 0.5398918390274048,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.15840119123458862,
    "std": 0.7913284301757812,
    "var": 0.6262006759643555,
    "min": -2.227844715118408,
    "max": 2.475768566131592,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.047501340508461,
    "std": 0.13159851729869843,
    "var": 0.01731817051768303,
    "min": -0.2609153687953949,
    "max": 0.35058432817459106,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.03875292092561722,
    "std": 0.14830642938613892,
    "var": 0.021994799375534058,
    "min": -0.8752204179763794,
    "max": 0.5564830899238586,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.2970280647277832,
    "std": 0.4793112277984619,
    "var": 0.229739248752594,
    "min": -1.213478922843933,
    "max": 1.6096707582473755,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.010515192523598671,
    "std": 0.06750398129224777,
    "var": 0.004556787200272083,
    "min": -0.1620067059993744,
    "max": 0.08284273743629456,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0027173866983503103,
    "std": 0.21365176141262054,
    "var": 0.04564707726240158,
    "min": -0.9777426719665527,
    "max": 0.8019788861274719,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.00893727783113718,
    "std": 0.24414066970348358,
    "var": 0.059604667127132416,
    "min": -1.3063379526138306,
    "max": 1.2875699996948242,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.23075872659683228,
    "std": 0.3637332022190094,
    "var": 0.13230183720588684,
    "min": -1.0197029113769531,
    "max": 1.010197639465332,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.33323410153388977,
    "std": 0.3859054148197174,
    "var": 0.14892299473285675,
    "min": -1.647693157196045,
    "max": 0.45603591203689575,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.6679194569587708,
    "std": 0.4731489419937134,
    "var": 0.2238699346780777,
    "min": -1.870413064956665,
    "max": 0.4760904908180237,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.8984118700027466,
    "std": 0.6982665657997131,
    "var": 0.4875762462615967,
    "min": -3.058960199356079,
    "max": 0.5343641638755798,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.2091104984283447,
    "std": 0.4112713932991028,
    "var": 0.1691441535949707,
    "min": -2.2835075855255127,
    "max": 0.1436886042356491,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.1894075870513916,
    "std": 0.6009722352027893,
    "var": 0.36116763949394226,
    "min": -2.790571689605713,
    "max": 0.25648775696754456,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.82 | loss:  0.64
-----------------------------------------------------------------------------------------
[2025-02-23 13:48:09,479][absl][INFO] - Saving checkpoint at step: 117900
[2025-02-23 13:48:09,482][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-23 13:48:09,482][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-23 13:48:09,483][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_117900.
[2025-02-23 13:48:09,486][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-23 13:48:09,487][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_117900.orbax-checkpoint-tmp-34
[2025-02-23 13:48:09,496][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-23 13:48:09,524][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-23 13:48:09,557][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 151.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 60 milliseconds) (per-host)
[2025-02-23 13:48:09,830][absl][INFO] - ChainedFuture completed 1/1 futures in 0.27 seconds.
[2025-02-23 13:48:09,830][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 27.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 333 milliseconds) (per-host)
[2025-02-23 13:48:09,836][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-23 13:48:09,871][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_117900.orbax-checkpoint-tmp-34 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_117900
[2025-02-23 13:48:09,877][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_117900`.
[2025-02-23 13:48:09,877][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-23 13:48:09,879][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_113184
| epoch 101 | 1000/1179 batches | ms/batch 1950.00 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.08
-----------------------------------------------------------------------------------------
| end of epoch 101 | time per epoch: 2299.71s |
| Train Metrics | accuracy:  0.73 | loss:  1.08
| Eval  Metrics | accuracy:  0.81 | loss:  0.64
-----------------------------------------------------------------------------------------
| epoch 102 | 1000/1179 batches | ms/batch 1966.56 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.12
-----------------------------------------------------------------------------------------
| end of epoch 102 | time per epoch: 2314.97s |
| Train Metrics | accuracy:  0.72 | loss:  1.12
| Eval  Metrics | accuracy:  0.82 | loss:  0.64
-----------------------------------------------------------------------------------------
| epoch 103 | 1000/1179 batches | ms/batch 1964.51 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.10
-----------------------------------------------------------------------------------------
| end of epoch 103 | time per epoch: 2314.87s |
| Train Metrics | accuracy:  0.73 | loss:  1.09
| Eval  Metrics | accuracy:  0.81 | loss:  0.63
-----------------------------------------------------------------------------------------
| epoch 104 | 1000/1179 batches | ms/batch 1973.77 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.09
-----------------------------------------------------------------------------------------
| end of epoch 104 | time per epoch: 2326.12s |
| Train Metrics | accuracy:  0.73 | loss:  1.09
| Eval  Metrics | accuracy:  0.82 | loss:  0.63
-----------------------------------------------------------------------------------------
| epoch 105 | 1000/1179 batches | ms/batch 2048.82 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.07
-----------------------------------------------------------------------------------------
| end of epoch 105 | time per epoch: 2444.40s |
| Train Metrics | accuracy:  0.73 | loss:  1.08
| Eval  Metrics | accuracy:  0.82 | loss:  0.64
-----------------------------------------------------------------------------------------
| epoch 106 | 1000/1179 batches | ms/batch 2282.24 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.11
-----------------------------------------------------------------------------------------
| end of epoch 106 | time per epoch: 2689.25s |
| Train Metrics | accuracy:  0.73 | loss:  1.11
| Eval  Metrics | accuracy:  0.82 | loss:  0.65
-----------------------------------------------------------------------------------------
| epoch 107 | 1000/1179 batches | ms/batch 2313.35 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.11
-----------------------------------------------------------------------------------------
| end of epoch 107 | time per epoch: 2724.70s |
| Train Metrics | accuracy:  0.72 | loss:  1.11
| Eval  Metrics | accuracy:  0.82 | loss:  0.62
-----------------------------------------------------------------------------------------
| epoch 108 | 1000/1179 batches | ms/batch 2323.81 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.06
-----------------------------------------------------------------------------------------
| end of epoch 108 | time per epoch: 2736.73s |
| Train Metrics | accuracy:  0.73 | loss:  1.07
| Eval  Metrics | accuracy:  0.82 | loss:  0.63
-----------------------------------------------------------------------------------------
| epoch 109 | 1000/1179 batches | ms/batch 2327.13 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.11
-----------------------------------------------------------------------------------------
| end of epoch 109 | time per epoch: 2735.25s |
| Train Metrics | accuracy:  0.73 | loss:  1.11
| Eval  Metrics | accuracy:  0.82 | loss:  0.64
-----------------------------------------------------------------------------------------
| epoch 110 | 1000/1179 batches | ms/batch 2304.51 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.04
-----------------------------------------------------------------------------------------
| end of epoch 110 | time per epoch: 2735.16s |
| Train Metrics | accuracy:  0.74 | loss:  1.05
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.27450284361839294,
    "std": 0.3734130859375,
    "var": 0.13943734765052795,
    "min": -0.4172947406768799,
    "max": 1.0408501625061035,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.24914002418518066,
    "std": 0.15956617891788483,
    "var": 0.025461366400122643,
    "min": 0.05351053178310394,
    "max": 0.8521375060081482,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0007406935910694301,
    "std": 0.11570713669061661,
    "var": 0.013388141058385372,
    "min": -0.6621102094650269,
    "max": 0.5775139331817627,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.2739190459251404,
    "std": 0.22854416072368622,
    "var": 0.05223242938518524,
    "min": -0.061508163809776306,
    "max": 1.1111195087432861,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.3752546012401581,
    "std": 0.3267316520214081,
    "var": 0.10675358027219772,
    "min": 0.06871123611927032,
    "max": 1.3735647201538086,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0019070975249633193,
    "std": 0.1195874810218811,
    "var": 0.014301165007054806,
    "min": -0.6210861206054688,
    "max": 0.8330825567245483,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.25848257541656494,
    "std": 0.17008133232593536,
    "var": 0.02892765961587429,
    "min": -0.0720459446310997,
    "max": 0.8633572459220886,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.4195692539215088,
    "std": 0.3769758641719818,
    "var": 0.14211080968379974,
    "min": 0.061513252556324005,
    "max": 2.33221697807312,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0010316729312762618,
    "std": 0.11846431344747543,
    "var": 0.014033793471753597,
    "min": -0.8031966090202332,
    "max": 0.7449451684951782,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.1648309826850891,
    "std": 0.2432398796081543,
    "var": 0.05916563794016838,
    "min": -0.451402485370636,
    "max": 1.0120446681976318,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6923543810844421,
    "std": 0.22841230034828186,
    "var": 0.05217217653989792,
    "min": 0.16145075857639313,
    "max": 2.295413017272949,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -6.363368356687715e-06,
    "std": 0.0453856959939003,
    "var": 0.0020598615519702435,
    "min": -0.7358195781707764,
    "max": 0.7414092421531677,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.16110146045684814,
    "std": 0.24302618205547333,
    "var": 0.05906172841787338,
    "min": -0.37297314405441284,
    "max": 1.1180733442306519,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6691390872001648,
    "std": 0.2857423722743988,
    "var": 0.08164870738983154,
    "min": 0.15475037693977356,
    "max": 2.618472099304199,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": -1.9615012206486426e-05,
    "std": 0.06161552295088768,
    "var": 0.003796472679823637,
    "min": -0.5790470242500305,
    "max": 0.7637287974357605,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.033752910792827606,
    "std": 0.08830497413873672,
    "var": 0.007797767873853445,
    "min": -0.27199283242225647,
    "max": 0.2335074245929718,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.1568543910980225,
    "std": 0.26234546303749084,
    "var": 0.0688251405954361,
    "min": 0.7425391674041748,
    "max": 2.5933356285095215,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00029664632165804505,
    "std": 0.08987528830766678,
    "var": 0.00807756744325161,
    "min": -0.8136664628982544,
    "max": 0.8043832182884216,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0007684838492423296,
    "std": 0.09064938127994537,
    "var": 0.008217310532927513,
    "min": -0.5460887551307678,
    "max": 0.5497409105300903,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00015051609079819173,
    "std": 0.0933944582939148,
    "var": 0.008722525089979172,
    "min": -0.6212351322174072,
    "max": 0.5538925528526306,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0008423062972724438,
    "std": 0.0907338336110115,
    "var": 0.008232628926634789,
    "min": -0.5559504628181458,
    "max": 0.6008262038230896,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00024252389266621321,
    "std": 0.05461987107992172,
    "var": 0.0029833305161446333,
    "min": -0.3921460807323456,
    "max": 0.41231387853622437,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0003702637040987611,
    "std": 0.07840994000434875,
    "var": 0.0061481185257434845,
    "min": -0.48850440979003906,
    "max": 0.44340094923973083,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -9.014869283419102e-05,
    "std": 0.08481478691101074,
    "var": 0.007193548139184713,
    "min": -0.5785865187644958,
    "max": 0.536608099937439,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.33957165479660034,
    "std": 0.09489608556032181,
    "var": 0.00900526624172926,
    "min": -0.6022774577140808,
    "max": -0.13003148138523102,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.10505425930023193,
    "std": 0.23317430913448334,
    "var": 0.05437025800347328,
    "min": -1.1499950885772705,
    "max": 1.0230733156204224,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.6425701975822449,
    "std": 0.7959242463111877,
    "var": 0.6334954500198364,
    "min": -1.3994932174682617,
    "max": 2.7235007286071777,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.312946617603302,
    "std": 0.12784256041049957,
    "var": 0.016343718394637108,
    "min": -0.7180210947990417,
    "max": 0.09282471984624863,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19533295929431915,
    "std": 0.20256687700748444,
    "var": 0.041033342480659485,
    "min": -1.1329360008239746,
    "max": 0.7475718855857849,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.7779709696769714,
    "std": 0.8703480958938599,
    "var": 0.7575057744979858,
    "min": -1.5392869710922241,
    "max": 2.247959852218628,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.2783806025981903,
    "std": 0.1564866453409195,
    "var": 0.024488072842359543,
    "min": -0.6419954299926758,
    "max": 0.08351480215787888,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.20536068081855774,
    "std": 0.21750189363956451,
    "var": 0.04730707406997681,
    "min": -1.3505361080169678,
    "max": 0.7518761157989502,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.8705117106437683,
    "std": 0.879226565361023,
    "var": 0.7730393409729004,
    "min": -0.9893373250961304,
    "max": 3.017843246459961,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.1327752023935318,
    "std": 0.09235520660877228,
    "var": 0.008529484272003174,
    "min": -0.3768361806869507,
    "max": 0.08918238431215286,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07715453952550888,
    "std": 0.16046501696109772,
    "var": 0.025749024003744125,
    "min": -1.2742164134979248,
    "max": 0.5652905702590942,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0009346093866042793,
    "std": 0.003797375364229083,
    "var": 1.442006032448262e-05,
    "min": -0.015019728802144527,
    "max": 0.008371914736926556,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.001685607130639255,
    "std": 0.0986701175570488,
    "var": 0.009735791943967342,
    "min": -0.7077466249465942,
    "max": 0.8108787536621094,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.009077154099941254,
    "std": 0.2591498792171478,
    "var": 0.06715866178274155,
    "min": -1.7332837581634521,
    "max": 2.129483461380005,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15759482979774475,
    "std": 0.08688050508499146,
    "var": 0.007548222318291664,
    "min": -0.44784221053123474,
    "max": 0.06386781483888626,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07127340883016586,
    "std": 0.1529184877872467,
    "var": 0.02338406629860401,
    "min": -1.4186238050460815,
    "max": 0.5273536443710327,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.15328453481197357,
    "std": 0.7395088076591492,
    "var": 0.5468733310699463,
    "min": -2.0911574363708496,
    "max": 2.4069979190826416,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.05098846182227135,
    "std": 0.13111348450183868,
    "var": 0.01719074696302414,
    "min": -0.22450880706310272,
    "max": 0.33194729685783386,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.03737744688987732,
    "std": 0.14324961602687836,
    "var": 0.02052045240998268,
    "min": -0.8398368954658508,
    "max": 0.5301922559738159,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.2876793146133423,
    "std": 0.45035532116889954,
    "var": 0.20281991362571716,
    "min": -0.9930127263069153,
    "max": 1.5018541812896729,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.010430287569761276,
    "std": 0.06601601094007492,
    "var": 0.004358114209026098,
    "min": -0.17624790966510773,
    "max": 0.09910494834184647,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.002612251089885831,
    "std": 0.21357378363609314,
    "var": 0.045613765716552734,
    "min": -0.9782800078392029,
    "max": 0.8140655755996704,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.008999875746667385,
    "std": 0.23165474832057953,
    "var": 0.05366392433643341,
    "min": -1.1609277725219727,
    "max": 1.1684205532073975,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.19866305589675903,
    "std": 0.3518352806568146,
    "var": 0.12378807365894318,
    "min": -1.049135684967041,
    "max": 1.0147634744644165,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.29610002040863037,
    "std": 0.37414178252220154,
    "var": 0.13998205959796906,
    "min": -1.5808125734329224,
    "max": 0.5247107744216919,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.6250251531600952,
    "std": 0.46938955783843994,
    "var": 0.22032657265663147,
    "min": -1.7746467590332031,
    "max": 0.5007147192955017,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.9082350730895996,
    "std": 0.707019031047821,
    "var": 0.49987587332725525,
    "min": -3.026686429977417,
    "max": 0.6251254677772522,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.1569089889526367,
    "std": 0.4123619496822357,
    "var": 0.17004238069057465,
    "min": -2.2774384021759033,
    "max": 0.20856915414333344,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.1510440111160278,
    "std": 0.6009222865104675,
    "var": 0.36110761761665344,
    "min": -2.743276357650757,
    "max": 0.2651117146015167,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.81 | loss:  0.66
-----------------------------------------------------------------------------------------
| epoch 111 | 1000/1179 batches | ms/batch 2326.42 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.11
-----------------------------------------------------------------------------------------
| end of epoch 111 | time per epoch: 2751.44s |
| Train Metrics | accuracy:  0.73 | loss:  1.10
| Eval  Metrics | accuracy:  0.82 | loss:  0.61
-----------------------------------------------------------------------------------------
| epoch 112 | 1000/1179 batches | ms/batch 2325.88 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.10
-----------------------------------------------------------------------------------------
| end of epoch 112 | time per epoch: 2778.99s |
| Train Metrics | accuracy:  0.73 | loss:  1.08
| Eval  Metrics | accuracy:  0.82 | loss:  0.61
-----------------------------------------------------------------------------------------
| epoch 113 | 1000/1179 batches | ms/batch 2379.57 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.09
-----------------------------------------------------------------------------------------
| end of epoch 113 | time per epoch: 2784.11s |
| Train Metrics | accuracy:  0.73 | loss:  1.08
| Eval  Metrics | accuracy:  0.82 | loss:  0.61
-----------------------------------------------------------------------------------------
| epoch 114 | 1000/1179 batches | ms/batch 2273.32 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.07
-----------------------------------------------------------------------------------------
| end of epoch 114 | time per epoch: 2687.61s |
| Train Metrics | accuracy:  0.73 | loss:  1.08
| Eval  Metrics | accuracy:  0.81 | loss:  0.65
-----------------------------------------------------------------------------------------
| epoch 115 | 1000/1179 batches | ms/batch 2235.60 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.07
-----------------------------------------------------------------------------------------
| end of epoch 115 | time per epoch: 2623.99s |
| Train Metrics | accuracy:  0.74 | loss:  1.06
| Eval  Metrics | accuracy:  0.82 | loss:  0.62
-----------------------------------------------------------------------------------------
| epoch 116 | 1000/1179 batches | ms/batch 2176.17 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.08
-----------------------------------------------------------------------------------------
| end of epoch 116 | time per epoch: 2566.28s |
| Train Metrics | accuracy:  0.73 | loss:  1.09
| Eval  Metrics | accuracy:  0.79 | loss:  0.74
-----------------------------------------------------------------------------------------
| epoch 117 | 1000/1179 batches | ms/batch 2189.75 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.05
-----------------------------------------------------------------------------------------
| end of epoch 117 | time per epoch: 2581.45s |
| Train Metrics | accuracy:  0.74 | loss:  1.06
| Eval  Metrics | accuracy:  0.82 | loss:  0.62
-----------------------------------------------------------------------------------------
| epoch 118 | 1000/1179 batches | ms/batch 2200.77 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.06
-----------------------------------------------------------------------------------------
| end of epoch 118 | time per epoch: 2576.73s |
| Train Metrics | accuracy:  0.74 | loss:  1.05
| Eval  Metrics | accuracy:  0.82 | loss:  0.61
-----------------------------------------------------------------------------------------
| epoch 119 | 1000/1179 batches | ms/batch 2081.69 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.02
-----------------------------------------------------------------------------------------
| end of epoch 119 | time per epoch: 2454.33s |
| Train Metrics | accuracy:  0.74 | loss:  1.03
| Eval  Metrics | accuracy:  0.83 | loss:  0.61
-----------------------------------------------------------------------------------------
[2025-02-24 04:56:34,621][absl][INFO] - Saving checkpoint at step: 140301
[2025-02-24 04:56:34,624][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 04:56:34,624][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 04:56:34,625][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_140301.
[2025-02-24 04:56:34,628][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 04:56:34,629][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_140301.orbax-checkpoint-tmp-35
[2025-02-24 04:56:34,686][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 04:56:34,713][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 04:56:34,742][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 165.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 55 milliseconds) (per-host)
[2025-02-24 04:56:34,959][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-24 04:56:34,959][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 272 milliseconds) (per-host)
[2025-02-24 04:56:34,965][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 04:56:34,997][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_140301.orbax-checkpoint-tmp-35 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_140301
[2025-02-24 04:56:35,003][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_140301`.
[2025-02-24 04:56:35,003][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 04:56:35,006][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_117900
| epoch 120 | 1000/1179 batches | ms/batch 2093.26 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.09
-----------------------------------------------------------------------------------------
| end of epoch 120 | time per epoch: 2467.29s |
| Train Metrics | accuracy:  0.73 | loss:  1.08
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.2862132787704468,
    "std": 0.3873354196548462,
    "var": 0.15002873539924622,
    "min": -0.4898855984210968,
    "max": 1.0798640251159668,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.24810096621513367,
    "std": 0.17420963943004608,
    "var": 0.030348997563123703,
    "min": 0.0509113185107708,
    "max": 0.9053626656532288,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0009615190210752189,
    "std": 0.11640768498182297,
    "var": 0.013550749979913235,
    "min": -0.6815618276596069,
    "max": 0.586754560470581,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.27784019708633423,
    "std": 0.23664459586143494,
    "var": 0.056000664830207825,
    "min": -0.04988313838839531,
    "max": 1.0953987836837769,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.38074785470962524,
    "std": 0.3397354483604431,
    "var": 0.11542018502950668,
    "min": 0.06305836886167526,
    "max": 1.4342577457427979,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0018835559021681547,
    "std": 0.1203586608171463,
    "var": 0.014486206695437431,
    "min": -0.6364571452140808,
    "max": 0.8576129078865051,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.26304465532302856,
    "std": 0.1741998940706253,
    "var": 0.030345603823661804,
    "min": -0.06975460052490234,
    "max": 0.9212160706520081,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.4172220826148987,
    "std": 0.3807790279388428,
    "var": 0.1449926644563675,
    "min": 0.04497641697525978,
    "max": 2.348267078399658,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.001036131870932877,
    "std": 0.11922147125005722,
    "var": 0.014213759452104568,
    "min": -0.8198572397232056,
    "max": 0.7551803588867188,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.17397689819335938,
    "std": 0.24328675866127014,
    "var": 0.05918844789266586,
    "min": -0.4165221154689789,
    "max": 1.0512148141860962,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6928769946098328,
    "std": 0.22602421045303345,
    "var": 0.051086943596601486,
    "min": 0.16055598855018616,
    "max": 2.3348388671875,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -4.469616033020429e-05,
    "std": 0.04418763890862465,
    "var": 0.0019525474635884166,
    "min": -0.7371311783790588,
    "max": 0.7463339567184448,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.16847199201583862,
    "std": 0.24252139031887054,
    "var": 0.05881662294268608,
    "min": -0.348286509513855,
    "max": 1.1444441080093384,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6656472682952881,
    "std": 0.28077247738838196,
    "var": 0.0788331925868988,
    "min": 0.1459718942642212,
    "max": 2.6289162635803223,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 7.358647417277098e-05,
    "std": 0.06189560145139694,
    "var": 0.0038310657255351543,
    "min": -0.597844123840332,
    "max": 0.7765993475914001,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.027686549350619316,
    "std": 0.08383110165596008,
    "var": 0.007027653511613607,
    "min": -0.24980731308460236,
    "max": 0.22109849750995636,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.1817729473114014,
    "std": 0.25854548811912537,
    "var": 0.06684576719999313,
    "min": 0.7651280760765076,
    "max": 2.5482494831085205,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00024301580560859293,
    "std": 0.09057258069515228,
    "var": 0.00820339284837246,
    "min": -0.8529688119888306,
    "max": 0.817308783531189,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0008468016749247909,
    "std": 0.08566401898860931,
    "var": 0.007338324096053839,
    "min": -0.5654882788658142,
    "max": 0.44009268283843994,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00025587313575670123,
    "std": 0.08744797855615616,
    "var": 0.0076471492648124695,
    "min": -0.5410648584365845,
    "max": 0.5444175601005554,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.000892861164174974,
    "std": 0.08465283364057541,
    "var": 0.007166102062910795,
    "min": -0.5270587801933289,
    "max": 0.5575000047683716,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -8.007383439689875e-05,
    "std": 0.05056991055607796,
    "var": 0.0025573158636689186,
    "min": -0.34945136308670044,
    "max": 0.3662371039390564,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00011828194692498073,
    "std": 0.07387474924325943,
    "var": 0.005457478575408459,
    "min": -0.4845348000526428,
    "max": 0.44171860814094543,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -1.2050072655256372e-05,
    "std": 0.07927967607975006,
    "var": 0.006285266950726509,
    "min": -0.5694512128829956,
    "max": 0.4942861497402191,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3354971408843994,
    "std": 0.09542439132928848,
    "var": 0.00910581462085247,
    "min": -0.5804919004440308,
    "max": -0.11424747109413147,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.10559874027967453,
    "std": 0.22701823711395264,
    "var": 0.05153728276491165,
    "min": -1.1624757051467896,
    "max": 0.9725475907325745,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.5945543050765991,
    "std": 0.7665922045707703,
    "var": 0.5876636505126953,
    "min": -1.3016886711120605,
    "max": 2.6209561824798584,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.30725789070129395,
    "std": 0.12997619807720184,
    "var": 0.016893811523914337,
    "min": -0.6728783249855042,
    "max": 0.08708883821964264,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19294992089271545,
    "std": 0.1979663074016571,
    "var": 0.03919065743684769,
    "min": -1.1371350288391113,
    "max": 0.786357045173645,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.7168405055999756,
    "std": 0.8403758406639099,
    "var": 0.7062315940856934,
    "min": -1.5108118057250977,
    "max": 2.1162095069885254,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.28013473749160767,
    "std": 0.15359200537204742,
    "var": 0.02359050326049328,
    "min": -0.6579369306564331,
    "max": 0.0838780477643013,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.20653612911701202,
    "std": 0.21454086899757385,
    "var": 0.046027787029743195,
    "min": -1.423048496246338,
    "max": 0.7293648719787598,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.8217592239379883,
    "std": 0.8614004850387573,
    "var": 0.742010772228241,
    "min": -1.0958222150802612,
    "max": 2.957521438598633,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.1366838812828064,
    "std": 0.08870550990104675,
    "var": 0.00786866806447506,
    "min": -0.39013463258743286,
    "max": 0.08488458395004272,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07620932161808014,
    "std": 0.15655729174613953,
    "var": 0.024510188028216362,
    "min": -1.3577712774276733,
    "max": 0.5231545567512512,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0009314781054854393,
    "std": 0.0038404741790145636,
    "var": 1.4749241927347612e-05,
    "min": -0.019132327288389206,
    "max": 0.008039531297981739,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.0013720361748710275,
    "std": 0.09580080956220627,
    "var": 0.009177795611321926,
    "min": -0.6881433725357056,
    "max": 0.7980000972747803,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.00928721483796835,
    "std": 0.23827777802944183,
    "var": 0.05677630007266998,
    "min": -1.596707820892334,
    "max": 1.9551069736480713,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.1549345850944519,
    "std": 0.0818338468670845,
    "var": 0.006696778349578381,
    "min": -0.4593915641307831,
    "max": 0.03867613896727562,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07066520303487778,
    "std": 0.14868241548538208,
    "var": 0.022106463089585304,
    "min": -1.4341024160385132,
    "max": 0.4828997850418091,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.14503268897533417,
    "std": 0.6827970743179321,
    "var": 0.46621188521385193,
    "min": -1.9363510608673096,
    "max": 2.3443334102630615,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.055803485214710236,
    "std": 0.1263001710176468,
    "var": 0.0159517340362072,
    "min": -0.24265402555465698,
    "max": 0.33815285563468933,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.03472893312573433,
    "std": 0.13822618126869202,
    "var": 0.01910647749900818,
    "min": -0.8299502730369568,
    "max": 0.48876070976257324,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.2783659100532532,
    "std": 0.4164485037326813,
    "var": 0.17342935502529144,
    "min": -0.8237879872322083,
    "max": 1.3997935056686401,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.009870382957160473,
    "std": 0.06300584226846695,
    "var": 0.003969736862927675,
    "min": -0.15991689264774323,
    "max": 0.08301305025815964,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.002454610075801611,
    "std": 0.21355602145195007,
    "var": 0.04560617730021477,
    "min": -0.9104220867156982,
    "max": 0.8083601593971252,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.008764807134866714,
    "std": 0.21877798438072205,
    "var": 0.04786381125450134,
    "min": -1.0303163528442383,
    "max": 1.0350087881088257,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.16478389501571655,
    "std": 0.3406510651111603,
    "var": 0.11604314297437668,
    "min": -1.032910943031311,
    "max": 1.0108572244644165,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.26508939266204834,
    "std": 0.36920300126075745,
    "var": 0.1363108605146408,
    "min": -1.5421115159988403,
    "max": 0.5292981266975403,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.5888994932174683,
    "std": 0.4625765383243561,
    "var": 0.21397705376148224,
    "min": -1.6991262435913086,
    "max": 0.4928058683872223,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.8879832029342651,
    "std": 0.7150397300720215,
    "var": 0.5112818479537964,
    "min": -2.9894614219665527,
    "max": 0.6984422206878662,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.112802267074585,
    "std": 0.4153100550174713,
    "var": 0.1724824607372284,
    "min": -2.2381951808929443,
    "max": 0.249702587723732,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.1127026081085205,
    "std": 0.5982922911643982,
    "var": 0.3579536974430084,
    "min": -2.7167649269104004,
    "max": 0.273576021194458,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.82 | loss:  0.62
-----------------------------------------------------------------------------------------
| epoch 121 | 1000/1179 batches | ms/batch 2107.13 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.06
-----------------------------------------------------------------------------------------
| end of epoch 121 | time per epoch: 2486.48s |
| Train Metrics | accuracy:  0.74 | loss:  1.07
| Eval  Metrics | accuracy:  0.82 | loss:  0.65
-----------------------------------------------------------------------------------------
| epoch 122 | 1000/1179 batches | ms/batch 2121.77 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.06
-----------------------------------------------------------------------------------------
| end of epoch 122 | time per epoch: 2501.95s |
| Train Metrics | accuracy:  0.74 | loss:  1.05
| Eval  Metrics | accuracy:  0.83 | loss:  0.59
-----------------------------------------------------------------------------------------
[2025-02-24 07:14:48,634][absl][INFO] - Saving checkpoint at step: 143838
[2025-02-24 07:14:48,636][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 07:14:48,637][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 07:14:48,638][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_143838.
[2025-02-24 07:14:48,653][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 07:14:48,655][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_143838.orbax-checkpoint-tmp-36
[2025-02-24 07:14:48,664][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 07:14:48,690][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 07:14:48,719][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 168.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-24 07:14:48,947][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-24 07:14:48,948][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 283 milliseconds) (per-host)
[2025-02-24 07:14:48,953][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 07:14:48,986][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_143838.orbax-checkpoint-tmp-36 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_143838
[2025-02-24 07:14:48,991][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_143838`.
[2025-02-24 07:14:48,992][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 07:14:48,993][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_140301
| epoch 123 | 1000/1179 batches | ms/batch 2139.77 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.05
-----------------------------------------------------------------------------------------
| end of epoch 123 | time per epoch: 2522.81s |
| Train Metrics | accuracy:  0.74 | loss:  1.06
| Eval  Metrics | accuracy:  0.83 | loss:  0.60
-----------------------------------------------------------------------------------------
[2025-02-24 08:01:36,290][absl][INFO] - Saving checkpoint at step: 145017
[2025-02-24 08:01:36,292][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 08:01:36,292][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 08:01:36,293][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_145017.
[2025-02-24 08:01:36,302][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 08:01:36,303][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_145017.orbax-checkpoint-tmp-37
[2025-02-24 08:01:36,311][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 08:01:36,337][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 08:01:36,374][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 146.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 62 milliseconds) (per-host)
[2025-02-24 08:01:36,612][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-24 08:01:36,612][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 300 milliseconds) (per-host)
[2025-02-24 08:01:36,618][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 08:01:36,652][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_145017.orbax-checkpoint-tmp-37 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_145017
[2025-02-24 08:01:36,659][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_145017`.
[2025-02-24 08:01:36,659][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 08:01:36,660][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_143838
| epoch 124 | 1000/1179 batches | ms/batch 2148.53 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.03
-----------------------------------------------------------------------------------------
| end of epoch 124 | time per epoch: 2533.37s |
| Train Metrics | accuracy:  0.75 | loss:  1.02
| Eval  Metrics | accuracy:  0.82 | loss:  0.62
-----------------------------------------------------------------------------------------
| epoch 125 | 1000/1179 batches | ms/batch 2164.71 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.05
-----------------------------------------------------------------------------------------
| end of epoch 125 | time per epoch: 2553.31s |
| Train Metrics | accuracy:  0.74 | loss:  1.04
| Eval  Metrics | accuracy:  0.83 | loss:  0.59
-----------------------------------------------------------------------------------------
| epoch 126 | 1000/1179 batches | ms/batch 2228.33 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.06
-----------------------------------------------------------------------------------------
| end of epoch 126 | time per epoch: 2624.56s |
| Train Metrics | accuracy:  0.74 | loss:  1.06
| Eval  Metrics | accuracy:  0.83 | loss:  0.59
-----------------------------------------------------------------------------------------
| epoch 127 | 1000/1179 batches | ms/batch 2214.86 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.03
-----------------------------------------------------------------------------------------
| end of epoch 127 | time per epoch: 2611.24s |
| Train Metrics | accuracy:  0.75 | loss:  1.03
| Eval  Metrics | accuracy:  0.82 | loss:  0.61
-----------------------------------------------------------------------------------------
| epoch 128 | 1000/1179 batches | ms/batch 2249.61 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.05
-----------------------------------------------------------------------------------------
| end of epoch 128 | time per epoch: 2651.65s |
| Train Metrics | accuracy:  0.74 | loss:  1.05
| Eval  Metrics | accuracy:  0.83 | loss:  0.60
-----------------------------------------------------------------------------------------
[2025-02-24 12:02:10,025][absl][INFO] - Saving checkpoint at step: 150912
[2025-02-24 12:02:10,035][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 12:02:10,039][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 12:02:10,049][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_150912.
[2025-02-24 12:02:10,063][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 12:02:10,067][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_150912.orbax-checkpoint-tmp-38
[2025-02-24 12:02:10,101][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 12:02:10,150][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 12:02:10,176][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 133.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 68 milliseconds) (per-host)
[2025-02-24 12:02:10,431][absl][INFO] - ChainedFuture completed 1/1 futures in 0.25 seconds.
[2025-02-24 12:02:10,431][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 27.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 327 milliseconds) (per-host)
[2025-02-24 12:02:10,440][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 12:02:10,477][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_150912.orbax-checkpoint-tmp-38 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_150912
[2025-02-24 12:02:10,484][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_150912`.
[2025-02-24 12:02:10,484][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 12:02:10,487][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_145017
| epoch 129 | 1000/1179 batches | ms/batch 2337.02 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.02
-----------------------------------------------------------------------------------------
| end of epoch 129 | time per epoch: 2764.08s |
| Train Metrics | accuracy:  0.75 | loss:  1.02
| Eval  Metrics | accuracy:  0.83 | loss:  0.59
-----------------------------------------------------------------------------------------
| epoch 130 | 1000/1179 batches | ms/batch 2368.56 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.04
-----------------------------------------------------------------------------------------
| end of epoch 130 | time per epoch: 2809.06s |
| Train Metrics | accuracy:  0.75 | loss:  1.03
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.29081830382347107,
    "std": 0.3911086618900299,
    "var": 0.1529659926891327,
    "min": -0.4985468089580536,
    "max": 1.096619725227356,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.24973224103450775,
    "std": 0.1887837052345276,
    "var": 0.035639286041259766,
    "min": 0.03807590529322624,
    "max": 1.0199270248413086,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0008464545826427639,
    "std": 0.11684095859527588,
    "var": 0.013651810586452484,
    "min": -0.6935428977012634,
    "max": 0.5871416330337524,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.2850150465965271,
    "std": 0.2510042190551758,
    "var": 0.06300312280654907,
    "min": -0.047319117933511734,
    "max": 1.1591829061508179,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.3800956904888153,
    "std": 0.34640491008758545,
    "var": 0.11999636888504028,
    "min": 0.05794946476817131,
    "max": 1.4709548950195312,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0018195214215666056,
    "std": 0.12085221707820892,
    "var": 0.014605259522795677,
    "min": -0.648668646812439,
    "max": 0.8758747577667236,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.26630985736846924,
    "std": 0.17637328803539276,
    "var": 0.03110753558576107,
    "min": -0.04136113077402115,
    "max": 0.9622484445571899,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.42148345708847046,
    "std": 0.39334940910339355,
    "var": 0.15472376346588135,
    "min": 0.05515173077583313,
    "max": 2.3868205547332764,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.001147350762039423,
    "std": 0.1196293979883194,
    "var": 0.01431119255721569,
    "min": -0.8271856307983398,
    "max": 0.7644941210746765,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.1827818751335144,
    "std": 0.2408030927181244,
    "var": 0.05798613280057907,
    "min": -0.3739076554775238,
    "max": 1.0498087406158447,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6909067034721375,
    "std": 0.22574837505817413,
    "var": 0.05096232891082764,
    "min": 0.1466568410396576,
    "max": 2.337371349334717,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -1.3862649211660028e-05,
    "std": 0.04330900311470032,
    "var": 0.0018756696954369545,
    "min": -0.7339555025100708,
    "max": 0.7421150803565979,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.17770898342132568,
    "std": 0.24097442626953125,
    "var": 0.05806867778301239,
    "min": -0.32453227043151855,
    "max": 1.1578387022018433,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6612883806228638,
    "std": 0.28136661648750305,
    "var": 0.07916717231273651,
    "min": 0.13616688549518585,
    "max": 2.71671986579895,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 8.916251681512222e-05,
    "std": 0.062082190066576004,
    "var": 0.003854198381304741,
    "min": -0.613167941570282,
    "max": 0.7818732261657715,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.02135605737566948,
    "std": 0.08300943672657013,
    "var": 0.006890567019581795,
    "min": -0.2523742616176605,
    "max": 0.2442523092031479,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.206968903541565,
    "std": 0.26271572709083557,
    "var": 0.06901955604553223,
    "min": 0.7601482272148132,
    "max": 2.6111128330230713,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0002339246857445687,
    "std": 0.09103114902973175,
    "var": 0.008286669850349426,
    "min": -0.8911190032958984,
    "max": 0.825181782245636,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0011147753102704883,
    "std": 0.07941770553588867,
    "var": 0.006307171657681465,
    "min": -0.5238043069839478,
    "max": 0.42758235335350037,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 7.524995453422889e-05,
    "std": 0.08109921962022781,
    "var": 0.006577083840966225,
    "min": -0.5297377705574036,
    "max": 0.5407987833023071,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.001192488707602024,
    "std": 0.07848771661520004,
    "var": 0.006160322111099958,
    "min": -0.5147721767425537,
    "max": 0.5059685111045837,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -7.966646080603823e-05,
    "std": 0.046973131597042084,
    "var": 0.002206475241109729,
    "min": -0.4114358425140381,
    "max": 0.3380829989910126,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0001510878500994295,
    "std": 0.06942111253738403,
    "var": 0.004819290712475777,
    "min": -0.48063787817955017,
    "max": 0.3985963761806488,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.00010913591540884227,
    "std": 0.07386206835508347,
    "var": 0.005455605685710907,
    "min": -0.5371332168579102,
    "max": 0.46732017397880554,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3271371126174927,
    "std": 0.09430397301912308,
    "var": 0.008893238380551338,
    "min": -0.5556939840316772,
    "max": -0.10637259483337402,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.10623157769441605,
    "std": 0.2233266830444336,
    "var": 0.04987480863928795,
    "min": -1.1653237342834473,
    "max": 0.9821862578392029,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.5497786402702332,
    "std": 0.7273412346839905,
    "var": 0.5290252566337585,
    "min": -1.2844833135604858,
    "max": 2.473616361618042,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.3056620955467224,
    "std": 0.1299103945493698,
    "var": 0.016876710578799248,
    "min": -0.6898527145385742,
    "max": 0.0585230216383934,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.1936856061220169,
    "std": 0.19703985750675201,
    "var": 0.03882470726966858,
    "min": -1.2047721147537231,
    "max": 0.7601507902145386,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.6602251529693604,
    "std": 0.8143534660339355,
    "var": 0.6631715297698975,
    "min": -1.5561484098434448,
    "max": 2.091207265853882,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.28095629811286926,
    "std": 0.15093323588371277,
    "var": 0.02278084307909012,
    "min": -0.6797574162483215,
    "max": 0.07238498330116272,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.20754702389240265,
    "std": 0.21203163266181946,
    "var": 0.044957417994737625,
    "min": -1.3881850242614746,
    "max": 0.7420369386672974,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.7648743987083435,
    "std": 0.8280078172683716,
    "var": 0.6855969429016113,
    "min": -1.0662167072296143,
    "max": 2.8184094429016113,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.13885653018951416,
    "std": 0.08675156533718109,
    "var": 0.007525834254920483,
    "min": -0.40906140208244324,
    "max": 0.07823195308446884,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07491260766983032,
    "std": 0.1527811735868454,
    "var": 0.023342089727520943,
    "min": -1.3816207647323608,
    "max": 0.5156955122947693,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0009008992929011583,
    "std": 0.0033085052855312824,
    "var": 1.0946207112283446e-05,
    "min": -0.014029083773493767,
    "max": 0.00837248470634222,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.0011624140897765756,
    "std": 0.09388504177331924,
    "var": 0.008814400993287563,
    "min": -0.718765139579773,
    "max": 0.7656012773513794,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.007978927344083786,
    "std": 0.21924790740013123,
    "var": 0.04806964471936226,
    "min": -1.4612609148025513,
    "max": 1.7616283893585205,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.1522788405418396,
    "std": 0.07910402119159698,
    "var": 0.006257446017116308,
    "min": -0.44453296065330505,
    "max": 0.031447578221559525,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.06941566616296768,
    "std": 0.14516513049602509,
    "var": 0.021072914823889732,
    "min": -1.4752581119537354,
    "max": 0.4637683033943176,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.1372928023338318,
    "std": 0.6262916326522827,
    "var": 0.3922411799430847,
    "min": -1.7610901594161987,
    "max": 2.230558395385742,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.06231598183512688,
    "std": 0.12448961287736893,
    "var": 0.015497663989663124,
    "min": -0.26071295142173767,
    "max": 0.34710007905960083,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.03296952694654465,
    "std": 0.13343940675258636,
    "var": 0.017806073650717735,
    "min": -0.8150294423103333,
    "max": 0.5169083476066589,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.2658451497554779,
    "std": 0.3841378688812256,
    "var": 0.14756189286708832,
    "min": -0.6990898251533508,
    "max": 1.2874784469604492,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.009964046999812126,
    "std": 0.06318800896406174,
    "var": 0.003992724698036909,
    "min": -0.1665167361497879,
    "max": 0.08367052674293518,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.002570515498518944,
    "std": 0.21365736424922943,
    "var": 0.04564947262406349,
    "min": -0.8942042589187622,
    "max": 0.7722001671791077,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.008989298716187477,
    "std": 0.20637774467468262,
    "var": 0.042591776698827744,
    "min": -1.023203730583191,
    "max": 1.0436222553253174,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.14421537518501282,
    "std": 0.3325212895870209,
    "var": 0.11057041585445404,
    "min": -0.9835010766983032,
    "max": 1.0410040616989136,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.23573637008666992,
    "std": 0.36485835909843445,
    "var": 0.13312162458896637,
    "min": -1.5148106813430786,
    "max": 0.5625467896461487,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.5525779128074646,
    "std": 0.4652186632156372,
    "var": 0.21642839908599854,
    "min": -1.6642976999282837,
    "max": 0.502916693687439,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.8538048267364502,
    "std": 0.7156190872192383,
    "var": 0.512110710144043,
    "min": -3.109260082244873,
    "max": 0.7881690859794617,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.0613046884536743,
    "std": 0.41565507650375366,
    "var": 0.17276914417743683,
    "min": -2.226289749145508,
    "max": 0.29451581835746765,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.0774434804916382,
    "std": 0.5937826037406921,
    "var": 0.352577805519104,
    "min": -2.700291872024536,
    "max": 0.2469528168439865,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.83 | loss:  0.56
-----------------------------------------------------------------------------------------
[2025-02-24 13:45:45,776][absl][INFO] - Saving checkpoint at step: 153270
[2025-02-24 13:45:45,779][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 13:45:45,779][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 13:45:45,781][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_153270.
[2025-02-24 13:45:45,784][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 13:45:45,785][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_153270.orbax-checkpoint-tmp-39
[2025-02-24 13:45:45,795][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 13:45:45,826][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 13:45:45,858][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 146.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 62 milliseconds) (per-host)
[2025-02-24 13:45:46,116][absl][INFO] - ChainedFuture completed 1/1 futures in 0.26 seconds.
[2025-02-24 13:45:46,116][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 28.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 320 milliseconds) (per-host)
[2025-02-24 13:45:46,123][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 13:45:46,162][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_153270.orbax-checkpoint-tmp-39 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_153270
[2025-02-24 13:45:46,168][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_153270`.
[2025-02-24 13:45:46,168][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 13:45:46,170][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_150912
| epoch 131 | 1000/1179 batches | ms/batch 2518.49 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.02
-----------------------------------------------------------------------------------------
| end of epoch 131 | time per epoch: 2964.35s |
| Train Metrics | accuracy:  0.75 | loss:  1.02
| Eval  Metrics | accuracy:  0.83 | loss:  0.57
-----------------------------------------------------------------------------------------
| epoch 132 | 1000/1179 batches | ms/batch 2405.81 | Performance/Training accuracy:  0.76 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 132 | time per epoch: 2819.17s |
| Train Metrics | accuracy:  0.76 | loss:  0.99
| Eval  Metrics | accuracy:  0.83 | loss:  0.58
-----------------------------------------------------------------------------------------
| epoch 133 | 1000/1179 batches | ms/batch 2350.67 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 133 | time per epoch: 2772.74s |
| Train Metrics | accuracy:  0.75 | loss:  1.01
| Eval  Metrics | accuracy:  0.84 | loss:  0.56
-----------------------------------------------------------------------------------------
[2025-02-24 16:24:10,913][absl][INFO] - Saving checkpoint at step: 156807
[2025-02-24 16:24:10,915][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 16:24:10,915][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 16:24:10,917][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_156807.
[2025-02-24 16:24:10,919][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 16:24:10,920][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_156807.orbax-checkpoint-tmp-40
[2025-02-24 16:24:10,964][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 16:24:10,993][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 16:24:11,025][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 152.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 59 milliseconds) (per-host)
[2025-02-24 16:24:11,279][absl][INFO] - ChainedFuture completed 1/1 futures in 0.25 seconds.
[2025-02-24 16:24:11,279][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 29.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 314 milliseconds) (per-host)
[2025-02-24 16:24:11,286][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 16:24:11,322][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_156807.orbax-checkpoint-tmp-40 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_156807
[2025-02-24 16:24:11,330][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_156807`.
[2025-02-24 16:24:11,330][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 16:24:11,332][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_153270
| epoch 134 | 1000/1179 batches | ms/batch 2452.90 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.02
-----------------------------------------------------------------------------------------
| end of epoch 134 | time per epoch: 2898.63s |
| Train Metrics | accuracy:  0.75 | loss:  1.01
| Eval  Metrics | accuracy:  0.83 | loss:  0.58
-----------------------------------------------------------------------------------------
| epoch 135 | 1000/1179 batches | ms/batch 2442.87 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 135 | time per epoch: 2891.13s |
| Train Metrics | accuracy:  0.75 | loss:  1.00
| Eval  Metrics | accuracy:  0.83 | loss:  0.58
-----------------------------------------------------------------------------------------
| epoch 136 | 1000/1179 batches | ms/batch 2453.01 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.03
-----------------------------------------------------------------------------------------
| end of epoch 136 | time per epoch: 2885.54s |
| Train Metrics | accuracy:  0.75 | loss:  1.02
| Eval  Metrics | accuracy:  0.84 | loss:  0.57
-----------------------------------------------------------------------------------------
| epoch 137 | 1000/1179 batches | ms/batch 2429.62 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.02
-----------------------------------------------------------------------------------------
| end of epoch 137 | time per epoch: 2859.23s |
| Train Metrics | accuracy:  0.75 | loss:  1.01
| Eval  Metrics | accuracy:  0.84 | loss:  0.59
-----------------------------------------------------------------------------------------
[2025-02-24 19:58:08,545][absl][INFO] - Saving checkpoint at step: 161523
[2025-02-24 19:58:08,546][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 19:58:08,547][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 19:58:08,548][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_161523.
[2025-02-24 19:58:08,557][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 19:58:08,558][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_161523.orbax-checkpoint-tmp-41
[2025-02-24 19:58:08,600][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 19:58:08,628][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 19:58:08,658][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 160.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 57 milliseconds) (per-host)
[2025-02-24 19:58:09,567][absl][INFO] - ChainedFuture completed 1/1 futures in 0.91 seconds.
[2025-02-24 19:58:09,567][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 9.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 966 milliseconds) (per-host)
[2025-02-24 19:58:09,574][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 19:58:09,610][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_161523.orbax-checkpoint-tmp-41 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_161523
[2025-02-24 19:58:09,617][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_161523`.
[2025-02-24 19:58:09,618][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 19:58:09,619][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_156807
| epoch 138 | 1000/1179 batches | ms/batch 2475.09 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.98
-----------------------------------------------------------------------------------------
| end of epoch 138 | time per epoch: 2929.35s |
| Train Metrics | accuracy:  0.76 | loss:  0.99
| Eval  Metrics | accuracy:  0.83 | loss:  0.58
-----------------------------------------------------------------------------------------
| epoch 139 | 1000/1179 batches | ms/batch 2473.95 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.02
-----------------------------------------------------------------------------------------
| end of epoch 139 | time per epoch: 2920.03s |
| Train Metrics | accuracy:  0.75 | loss:  1.02
| Eval  Metrics | accuracy:  0.83 | loss:  0.59
-----------------------------------------------------------------------------------------
| epoch 140 | 1000/1179 batches | ms/batch 2513.22 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 140 | time per epoch: 2972.25s |
| Train Metrics | accuracy:  0.75 | loss:  1.01
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.3016178607940674,
    "std": 0.4060400128364563,
    "var": 0.16486848890781403,
    "min": -0.5056796073913574,
    "max": 1.12224280834198,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.24548296630382538,
    "std": 0.19262440502643585,
    "var": 0.03710415959358215,
    "min": 0.03313116729259491,
    "max": 1.0481443405151367,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0008977482793852687,
    "std": 0.11719989031553268,
    "var": 0.013735814951360226,
    "min": -0.7040680050849915,
    "max": 0.5932488441467285,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.293213427066803,
    "std": 0.26306989789009094,
    "var": 0.06920577585697174,
    "min": -0.04244342818856239,
    "max": 1.1454411745071411,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.3811510503292084,
    "std": 0.360811322927475,
    "var": 0.13018479943275452,
    "min": 0.053581591695547104,
    "max": 1.4874157905578613,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0017363352235406637,
    "std": 0.1211419478058815,
    "var": 0.01467537134885788,
    "min": -0.6545960903167725,
    "max": 0.8863204717636108,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2704983949661255,
    "std": 0.1802363246679306,
    "var": 0.03248513117432594,
    "min": -0.0346880666911602,
    "max": 0.9867827892303467,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.4221234917640686,
    "std": 0.40237346291542053,
    "var": 0.16190439462661743,
    "min": 0.03967536613345146,
    "max": 2.4620909690856934,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0010971645824611187,
    "std": 0.11991322785615921,
    "var": 0.014379182830452919,
    "min": -0.8334081768989563,
    "max": 0.7691808342933655,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.1898660659790039,
    "std": 0.23761506378650665,
    "var": 0.0564609169960022,
    "min": -0.33361420035362244,
    "max": 1.015170693397522,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6861152648925781,
    "std": 0.22601915895938873,
    "var": 0.05108465999364853,
    "min": 0.14071108400821686,
    "max": 2.3858771324157715,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -6.527639925479889e-05,
    "std": 0.042708881199359894,
    "var": 0.0018240486970171332,
    "min": -0.7301508784294128,
    "max": 0.7398356199264526,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.1838933676481247,
    "std": 0.2371084988117218,
    "var": 0.056220442056655884,
    "min": -0.3089935779571533,
    "max": 1.139268398284912,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6577269434928894,
    "std": 0.2806638181209564,
    "var": 0.0787721797823906,
    "min": 0.1336175501346588,
    "max": 2.7346885204315186,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00010026982636190951,
    "std": 0.06222999468445778,
    "var": 0.003872572211548686,
    "min": -0.6247477531433105,
    "max": 0.7826567888259888,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.0173221156001091,
    "std": 0.08398120850324631,
    "var": 0.007052843924611807,
    "min": -0.2517828643321991,
    "max": 0.2637968957424164,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.2309716939926147,
    "std": 0.26314446330070496,
    "var": 0.06924501061439514,
    "min": 0.7579123973846436,
    "max": 2.6230549812316895,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0001961324887815863,
    "std": 0.09130124747753143,
    "var": 0.008335918188095093,
    "min": -0.914264976978302,
    "max": 0.8334690928459167,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0008161291480064392,
    "std": 0.07393624633550644,
    "var": 0.005466568283736706,
    "min": -0.4858541190624237,
    "max": 0.4020007252693176,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00016479530313517898,
    "std": 0.07508542388677597,
    "var": 0.005637821741402149,
    "min": -0.4944029450416565,
    "max": 0.4931350350379944,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0008555365493521094,
    "std": 0.07281821221113205,
    "var": 0.005302491597831249,
    "min": -0.4845615327358246,
    "max": 0.4996917247772217,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00019216942018829286,
    "std": 0.043590858578681946,
    "var": 0.0019001628970727324,
    "min": -0.41565263271331787,
    "max": 0.3689495027065277,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 3.254042167100124e-05,
    "std": 0.06506646424531937,
    "var": 0.004233645275235176,
    "min": -0.40715888142585754,
    "max": 0.36919769644737244,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0001783246116247028,
    "std": 0.06854286789894104,
    "var": 0.004698124714195728,
    "min": -0.47466593980789185,
    "max": 0.43355792760849,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.32385218143463135,
    "std": 0.09747027605772018,
    "var": 0.009500455111265182,
    "min": -0.5711010694503784,
    "max": -0.12032651901245117,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.1063753068447113,
    "std": 0.21998459100723267,
    "var": 0.04839321970939636,
    "min": -1.2404650449752808,
    "max": 0.9889733791351318,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.5177954435348511,
    "std": 0.6945124268531799,
    "var": 0.4823475480079651,
    "min": -1.1625052690505981,
    "max": 2.3093721866607666,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.3041754364967346,
    "std": 0.12762869894504547,
    "var": 0.016289085149765015,
    "min": -0.6771860718727112,
    "max": 0.05044218525290489,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.1925586611032486,
    "std": 0.19335101544857025,
    "var": 0.03738461807370186,
    "min": -1.2032654285430908,
    "max": 0.6842430830001831,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.613325834274292,
    "std": 0.7792814373970032,
    "var": 0.6072795391082764,
    "min": -1.5713144540786743,
    "max": 1.9939583539962769,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.28163644671440125,
    "std": 0.14616279304027557,
    "var": 0.02136356197297573,
    "min": -0.7119080424308777,
    "max": 0.054204560816287994,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.2067527323961258,
    "std": 0.20913098752498627,
    "var": 0.043735768646001816,
    "min": -1.361948847770691,
    "max": 0.7296231985092163,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.7170218229293823,
    "std": 0.7940324544906616,
    "var": 0.6304875612258911,
    "min": -1.0577837228775024,
    "max": 2.630506753921509,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.14169982075691223,
    "std": 0.08433391153812408,
    "var": 0.007112208753824234,
    "min": -0.4145050048828125,
    "max": 0.060882817953825,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07434605062007904,
    "std": 0.14892108738422394,
    "var": 0.02217749133706093,
    "min": -1.4148831367492676,
    "max": 0.49831244349479675,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.001010983600281179,
    "std": 0.003047209233045578,
    "var": 9.285484338761307e-06,
    "min": -0.011269442737102509,
    "max": 0.008386662229895592,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.0010089068673551083,
    "std": 0.09131360054016113,
    "var": 0.008338173851370811,
    "min": -0.67779541015625,
    "max": 0.7349395155906677,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.006731817964464426,
    "std": 0.20160293579101562,
    "var": 0.04064374417066574,
    "min": -1.3244287967681885,
    "max": 1.5962765216827393,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.1507771909236908,
    "std": 0.0768117681145668,
    "var": 0.005900047719478607,
    "min": -0.47373542189598083,
    "max": 0.023493533954024315,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.06920979917049408,
    "std": 0.14111001789569855,
    "var": 0.01991203799843788,
    "min": -1.5617696046829224,
    "max": 0.5058786869049072,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.1263113021850586,
    "std": 0.5764959454536438,
    "var": 0.332347571849823,
    "min": -1.592074990272522,
    "max": 2.0812723636627197,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.0669708102941513,
    "std": 0.12333658337593079,
    "var": 0.015211913734674454,
    "min": -0.24887052178382874,
    "max": 0.37012654542922974,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.031114378944039345,
    "std": 0.12882210314273834,
    "var": 0.016595134511590004,
    "min": -0.8197512030601501,
    "max": 0.4976574182510376,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.2531026601791382,
    "std": 0.3539939522743225,
    "var": 0.1253117322921753,
    "min": -0.6423012614250183,
    "max": 1.2165776491165161,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.009863960556685925,
    "std": 0.06354213505983353,
    "var": 0.00403760327026248,
    "min": -0.17284658551216125,
    "max": 0.08495574444532394,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.00261277356185019,
    "std": 0.21389922499656677,
    "var": 0.045752882957458496,
    "min": -0.875228762626648,
    "max": 0.8154431581497192,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.00889833364635706,
    "std": 0.19464141130447388,
    "var": 0.037885282188653946,
    "min": -0.8924416899681091,
    "max": 0.9047049283981323,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.1154412180185318,
    "std": 0.3248845040798187,
    "var": 0.10554993897676468,
    "min": -0.9227117896080017,
    "max": 1.0637092590332031,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.2038441002368927,
    "std": 0.36143186688423157,
    "var": 0.13063299655914307,
    "min": -1.4891849756240845,
    "max": 0.5470197796821594,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.5113774538040161,
    "std": 0.45405808091163635,
    "var": 0.2061687409877777,
    "min": -1.5760658979415894,
    "max": 0.49124908447265625,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.790884017944336,
    "std": 0.7014127373695374,
    "var": 0.49197983741760254,
    "min": -2.9945619106292725,
    "max": 0.8342207670211792,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.012276530265808,
    "std": 0.41520917415618896,
    "var": 0.1723986566066742,
    "min": -2.17958664894104,
    "max": 0.2991315722465515,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.0472053289413452,
    "std": 0.591728150844574,
    "var": 0.3501421809196472,
    "min": -2.6666958332061768,
    "max": 0.23224470019340515,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.83 | loss:  0.60
-----------------------------------------------------------------------------------------
| epoch 141 | 1000/1179 batches | ms/batch 2456.58 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.97
-----------------------------------------------------------------------------------------
| end of epoch 141 | time per epoch: 2892.52s |
| Train Metrics | accuracy:  0.76 | loss:  0.98
| Eval  Metrics | accuracy:  0.84 | loss:  0.57
-----------------------------------------------------------------------------------------
| epoch 142 | 1000/1179 batches | ms/batch 2550.61 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.99
-----------------------------------------------------------------------------------------
| end of epoch 142 | time per epoch: 3020.50s |
| Train Metrics | accuracy:  0.76 | loss:  1.00
| Eval  Metrics | accuracy:  0.83 | loss:  0.58
-----------------------------------------------------------------------------------------
| epoch 143 | 1000/1179 batches | ms/batch 2597.62 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.98
-----------------------------------------------------------------------------------------
| end of epoch 143 | time per epoch: 3070.98s |
| Train Metrics | accuracy:  0.76 | loss:  0.99
| Eval  Metrics | accuracy:  0.84 | loss:  0.57
-----------------------------------------------------------------------------------------
[2025-02-25 01:28:37,182][absl][INFO] - Saving checkpoint at step: 168597
[2025-02-25 01:28:37,184][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 01:28:37,185][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 01:28:37,186][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_168597.
[2025-02-25 01:28:37,195][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 01:28:37,196][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_168597.orbax-checkpoint-tmp-42
[2025-02-25 01:28:37,206][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 01:28:37,234][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 01:28:37,271][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 141.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 64 milliseconds) (per-host)
[2025-02-25 01:28:37,503][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-25 01:28:37,503][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 296 milliseconds) (per-host)
[2025-02-25 01:28:37,510][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 01:28:37,544][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_168597.orbax-checkpoint-tmp-42 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_168597
[2025-02-25 01:28:37,550][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_168597`.
[2025-02-25 01:28:37,551][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 01:28:37,552][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_161523
| epoch 144 | 1000/1179 batches | ms/batch 2566.86 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.99
-----------------------------------------------------------------------------------------
| end of epoch 144 | time per epoch: 3024.88s |
| Train Metrics | accuracy:  0.76 | loss:  1.00
| Eval  Metrics | accuracy:  0.84 | loss:  0.57
-----------------------------------------------------------------------------------------
| epoch 145 | 1000/1179 batches | ms/batch 2524.84 | Performance/Training accuracy:  0.76 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 145 | time per epoch: 2977.36s |
| Train Metrics | accuracy:  0.76 | loss:  1.01
| Eval  Metrics | accuracy:  0.84 | loss:  0.59
-----------------------------------------------------------------------------------------
[2025-02-25 03:20:11,894][absl][INFO] - Saving checkpoint at step: 170955
[2025-02-25 03:20:11,896][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 03:20:11,896][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 03:20:11,897][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_170955.
[2025-02-25 03:20:11,906][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 03:20:11,907][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_170955.orbax-checkpoint-tmp-43
[2025-02-25 03:20:11,915][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 03:20:11,943][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 03:20:11,980][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 142.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 64 milliseconds) (per-host)
[2025-02-25 03:20:12,203][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-25 03:20:12,203][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 287 milliseconds) (per-host)
[2025-02-25 03:20:12,210][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 03:20:12,256][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_170955.orbax-checkpoint-tmp-43 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_170955
[2025-02-25 03:20:12,262][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_170955`.
[2025-02-25 03:20:12,262][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 03:20:12,263][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_168597
| epoch 146 | 1000/1179 batches | ms/batch 2505.41 | Performance/Training accuracy:  0.76 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 146 | time per epoch: 2941.14s |
| Train Metrics | accuracy:  0.76 | loss:  1.00
| Eval  Metrics | accuracy:  0.84 | loss:  0.56
-----------------------------------------------------------------------------------------
| epoch 147 | 1000/1179 batches | ms/batch 2520.45 | Performance/Training accuracy:  0.76 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 147 | time per epoch: 2964.29s |
| Train Metrics | accuracy:  0.76 | loss:  1.00
| Eval  Metrics | accuracy:  0.84 | loss:  0.53
-----------------------------------------------------------------------------------------
[2025-02-25 05:09:43,782][absl][INFO] - Saving checkpoint at step: 173313
[2025-02-25 05:09:43,784][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 05:09:43,785][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 05:09:43,786][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_173313.
[2025-02-25 05:09:43,794][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 05:09:43,795][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_173313.orbax-checkpoint-tmp-44
[2025-02-25 05:09:43,803][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 05:09:43,830][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 05:09:43,860][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 159.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 57 milliseconds) (per-host)
[2025-02-25 05:09:44,103][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-25 05:09:44,104][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 300 milliseconds) (per-host)
[2025-02-25 05:09:44,109][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 05:09:44,140][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_173313.orbax-checkpoint-tmp-44 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_173313
[2025-02-25 05:09:44,146][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_173313`.
[2025-02-25 05:09:44,146][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 05:09:44,148][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_170955
| epoch 148 | 1000/1179 batches | ms/batch 2474.53 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.95
-----------------------------------------------------------------------------------------
| end of epoch 148 | time per epoch: 2917.50s |
| Train Metrics | accuracy:  0.77 | loss:  0.96
| Eval  Metrics | accuracy:  0.85 | loss:  0.54
-----------------------------------------------------------------------------------------
[2025-02-25 06:04:00,988][absl][INFO] - Saving checkpoint at step: 174492
[2025-02-25 06:04:00,989][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 06:04:00,990][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 06:04:00,991][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_174492.
[2025-02-25 06:04:00,999][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 06:04:01,000][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_174492.orbax-checkpoint-tmp-45
[2025-02-25 06:04:01,011][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 06:04:01,039][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 06:04:01,075][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 144.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 63 milliseconds) (per-host)
[2025-02-25 06:04:01,305][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-25 06:04:01,305][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 293 milliseconds) (per-host)
[2025-02-25 06:04:01,311][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 06:04:01,346][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_174492.orbax-checkpoint-tmp-45 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_174492
[2025-02-25 06:04:01,352][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_174492`.
[2025-02-25 06:04:01,352][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 06:04:01,354][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_173313
| epoch 149 | 1000/1179 batches | ms/batch 2488.05 | Performance/Training accuracy:  0.76 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 149 | time per epoch: 2933.74s |
| Train Metrics | accuracy:  0.76 | loss:  0.99
| Eval  Metrics | accuracy:  0.84 | loss:  0.54
-----------------------------------------------------------------------------------------
| epoch 150 | 1000/1179 batches | ms/batch 2504.75 | Performance/Training accuracy:  0.76 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 150 | time per epoch: 2954.23s |
| Train Metrics | accuracy:  0.76 | loss:  1.00
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.3052321672439575,
    "std": 0.4102315902709961,
    "var": 0.16828995943069458,
    "min": -0.4857865273952484,
    "max": 1.1580159664154053,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.2469773143529892,
    "std": 0.205741748213768,
    "var": 0.04232966527342796,
    "min": 0.027799831703305244,
    "max": 1.1248481273651123,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0009182742796838284,
    "std": 0.11736809462308884,
    "var": 0.013775269500911236,
    "min": -0.7050596475601196,
    "max": 0.5953063368797302,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.2973008155822754,
    "std": 0.2747829556465149,
    "var": 0.07550567388534546,
    "min": -0.037144411355257034,
    "max": 1.1838374137878418,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.3802914619445801,
    "std": 0.36892780661582947,
    "var": 0.13610772788524628,
    "min": 0.041077181696891785,
    "max": 1.5060985088348389,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0017240101005882025,
    "std": 0.12126252055168152,
    "var": 0.014704599045217037,
    "min": -0.6516005396842957,
    "max": 0.8928470611572266,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2731134295463562,
    "std": 0.18443211913108826,
    "var": 0.03401520848274231,
    "min": -0.02272072620689869,
    "max": 0.9905306100845337,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.42336827516555786,
    "std": 0.4126162528991699,
    "var": 0.17025217413902283,
    "min": 0.036622822284698486,
    "max": 2.492347002029419,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0010895230807363987,
    "std": 0.12006866186857224,
    "var": 0.014416484162211418,
    "min": -0.8383516073226929,
    "max": 0.7751107215881348,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.19693800806999207,
    "std": 0.2366003841161728,
    "var": 0.05597974359989166,
    "min": -0.32790106534957886,
    "max": 1.0347044467926025,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6803626418113708,
    "std": 0.22748397290706635,
    "var": 0.051748957484960556,
    "min": 0.13333521783351898,
    "max": 2.3965835571289062,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -4.9814971134765074e-05,
    "std": 0.04233799874782562,
    "var": 0.0017925063148140907,
    "min": -0.7293109893798828,
    "max": 0.7386020421981812,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.19141745567321777,
    "std": 0.23544131219387054,
    "var": 0.05543261393904686,
    "min": -0.28159013390541077,
    "max": 1.1623153686523438,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6553832292556763,
    "std": 0.2811044156551361,
    "var": 0.0790196880698204,
    "min": 0.12442225217819214,
    "max": 2.757427930831909,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0001332840183749795,
    "std": 0.06230846419930458,
    "var": 0.00388234481215477,
    "min": -0.6274543404579163,
    "max": 0.789461612701416,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.01275385357439518,
    "std": 0.0823298841714859,
    "var": 0.006778210401535034,
    "min": -0.2413090467453003,
    "max": 0.25585925579071045,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.2532154321670532,
    "std": 0.26505380868911743,
    "var": 0.07025352120399475,
    "min": 0.8006162643432617,
    "max": 2.65519380569458,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0001675062085269019,
    "std": 0.0914517343044281,
    "var": 0.008363420143723488,
    "min": -0.9249534010887146,
    "max": 0.8369818925857544,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.000641043356154114,
    "std": 0.06871383637189865,
    "var": 0.0047215912491083145,
    "min": -0.4451403021812439,
    "max": 0.35426974296569824,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -6.606883835047483e-05,
    "std": 0.06945855170488358,
    "var": 0.0048244912177324295,
    "min": -0.467282235622406,
    "max": 0.4730229377746582,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0006154091097414494,
    "std": 0.06739206612110138,
    "var": 0.004541690926998854,
    "min": -0.42495596408843994,
    "max": 0.4552132487297058,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": 2.1069216018076986e-05,
    "std": 0.040839847177267075,
    "var": 0.0016678932588547468,
    "min": -0.3859092891216278,
    "max": 0.3688572645187378,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 2.7151749236509204e-05,
    "std": 0.060722243040800095,
    "var": 0.003687190590426326,
    "min": -0.3904191553592682,
    "max": 0.34587031602859497,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": 7.640811236342415e-05,
    "std": 0.06374941021203995,
    "var": 0.004063987638801336,
    "min": -0.43419259786605835,
    "max": 0.40297913551330566,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.31921520829200745,
    "std": 0.09960216283798218,
    "var": 0.009920591488480568,
    "min": -0.5623136162757874,
    "max": -0.1044381633400917,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.10592353343963623,
    "std": 0.21855929493904114,
    "var": 0.04776816442608833,
    "min": -1.2537295818328857,
    "max": 0.9456855654716492,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.4863744378089905,
    "std": 0.6660076379776001,
    "var": 0.44356614351272583,
    "min": -1.0830186605453491,
    "max": 2.2601020336151123,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.30256956815719604,
    "std": 0.12704257667064667,
    "var": 0.016139816492795944,
    "min": -0.6651124358177185,
    "max": 0.027236290276050568,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.1913585215806961,
    "std": 0.19103127717971802,
    "var": 0.03649294748902321,
    "min": -1.147979497909546,
    "max": 0.6842644810676575,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.5735403299331665,
    "std": 0.7498902678489685,
    "var": 0.5623353719711304,
    "min": -1.5987176895141602,
    "max": 1.9144909381866455,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.283236026763916,
    "std": 0.1430143564939499,
    "var": 0.020453104749321938,
    "min": -0.7318205833435059,
    "max": 0.03323259577155113,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.2066628634929657,
    "std": 0.20616205036640167,
    "var": 0.04250279441475868,
    "min": -1.3583847284317017,
    "max": 0.7319336533546448,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.6699849367141724,
    "std": 0.7577570676803589,
    "var": 0.5741958022117615,
    "min": -1.009844183921814,
    "max": 2.5380606651306152,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.14424529671669006,
    "std": 0.08314719796180725,
    "var": 0.006913457065820694,
    "min": -0.42408889532089233,
    "max": 0.05378126725554466,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07383640855550766,
    "std": 0.14546671509742737,
    "var": 0.021160567179322243,
    "min": -1.4145288467407227,
    "max": 0.49590224027633667,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0007956426125019789,
    "std": 0.0025695087388157845,
    "var": 6.602375833608676e-06,
    "min": -0.01055284682661295,
    "max": 0.007217555772513151,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.001117318868637085,
    "std": 0.08846255391836166,
    "var": 0.007825623266398907,
    "min": -0.6280924677848816,
    "max": 0.6832243204116821,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.005787420552223921,
    "std": 0.18594993650913239,
    "var": 0.034577377140522,
    "min": -1.2122811079025269,
    "max": 1.4793636798858643,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15155431628227234,
    "std": 0.07496874779462814,
    "var": 0.0056203133426606655,
    "min": -0.4572504758834839,
    "max": 0.024206101894378662,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.06894649565219879,
    "std": 0.13758036494255066,
    "var": 0.01892835833132267,
    "min": -1.5396472215652466,
    "max": 0.4828234314918518,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.11548605561256409,
    "std": 0.5318005084991455,
    "var": 0.28281182050704956,
    "min": -1.468685507774353,
    "max": 1.9434946775436401,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.07059793174266815,
    "std": 0.12030502408742905,
    "var": 0.014473299495875835,
    "min": -0.252394437789917,
    "max": 0.36589154601097107,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.02938372828066349,
    "std": 0.12495145946741104,
    "var": 0.015612867660820484,
    "min": -0.828912615776062,
    "max": 0.46387916803359985,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.23826804757118225,
    "std": 0.32822921872138977,
    "var": 0.10773442685604095,
    "min": -0.557307779788971,
    "max": 1.1234923601150513,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.009691236540675163,
    "std": 0.062339235097169876,
    "var": 0.00388618023134768,
    "min": -0.1632871925830841,
    "max": 0.07908251136541367,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.002609947929158807,
    "std": 0.2138209491968155,
    "var": 0.04571940004825592,
    "min": -0.8871036767959595,
    "max": 0.790717363357544,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.008464094251394272,
    "std": 0.18359877169132233,
    "var": 0.03370850905776024,
    "min": -0.8142809867858887,
    "max": 0.8494677543640137,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.0922829657793045,
    "std": 0.318033367395401,
    "var": 0.10114522278308868,
    "min": -0.8559756278991699,
    "max": 1.097165822982788,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.17873786389827728,
    "std": 0.3611438274383545,
    "var": 0.1304248571395874,
    "min": -1.4653931856155396,
    "max": 0.5772489905357361,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.48283740878105164,
    "std": 0.44858047366142273,
    "var": 0.2012244462966919,
    "min": -1.5330637693405151,
    "max": 0.5105020999908447,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.714996337890625,
    "std": 0.6819729804992676,
    "var": 0.4650871455669403,
    "min": -2.896627902984619,
    "max": 0.8482236266136169,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.968504786491394,
    "std": 0.4167023301124573,
    "var": 0.17364081740379333,
    "min": -2.164644479751587,
    "max": 0.31250712275505066,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.0204486846923828,
    "std": 0.5873708128929138,
    "var": 0.34500449895858765,
    "min": -2.655059814453125,
    "max": 0.21463054418563843,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.84 | loss:  0.55
-----------------------------------------------------------------------------------------
| epoch 151 | 1000/1179 batches | ms/batch 2509.77 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.97
-----------------------------------------------------------------------------------------
| end of epoch 151 | time per epoch: 2961.39s |
| Train Metrics | accuracy:  0.76 | loss:  0.97
| Eval  Metrics | accuracy:  0.84 | loss:  0.57
-----------------------------------------------------------------------------------------
| epoch 152 | 1000/1179 batches | ms/batch 2530.33 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.96
-----------------------------------------------------------------------------------------
| end of epoch 152 | time per epoch: 2991.74s |
| Train Metrics | accuracy:  0.77 | loss:  0.96
| Eval  Metrics | accuracy:  0.84 | loss:  0.56
-----------------------------------------------------------------------------------------
| epoch 153 | 1000/1179 batches | ms/batch 2586.26 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.98
-----------------------------------------------------------------------------------------
| end of epoch 153 | time per epoch: 3046.77s |
| Train Metrics | accuracy:  0.76 | loss:  0.99
| Eval  Metrics | accuracy:  0.84 | loss:  0.53
-----------------------------------------------------------------------------------------
| epoch 154 | 1000/1179 batches | ms/batch 2579.73 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.94
-----------------------------------------------------------------------------------------
| end of epoch 154 | time per epoch: 3048.91s |
| Train Metrics | accuracy:  0.77 | loss:  0.93
| Eval  Metrics | accuracy:  0.84 | loss:  0.55
-----------------------------------------------------------------------------------------
| epoch 155 | 1000/1179 batches | ms/batch 2700.91 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.96
-----------------------------------------------------------------------------------------
| end of epoch 155 | time per epoch: 3169.39s |
| Train Metrics | accuracy:  0.77 | loss:  0.96
| Eval  Metrics | accuracy:  0.84 | loss:  0.57
-----------------------------------------------------------------------------------------
| epoch 156 | 1000/1179 batches | ms/batch 2776.43 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.95
-----------------------------------------------------------------------------------------
| end of epoch 156 | time per epoch: 3312.14s |
| Train Metrics | accuracy:  0.77 | loss:  0.95
| Eval  Metrics | accuracy:  0.85 | loss:  0.53
-----------------------------------------------------------------------------------------
[2025-02-25 13:38:34,430][absl][INFO] - Saving checkpoint at step: 183924
[2025-02-25 13:38:34,432][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 13:38:34,432][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 13:38:34,434][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_183924.
[2025-02-25 13:38:34,437][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 13:38:34,438][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_183924.orbax-checkpoint-tmp-46
[2025-02-25 13:38:34,453][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 13:38:34,483][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 13:38:34,519][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 140.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 65 milliseconds) (per-host)
[2025-02-25 13:38:34,770][absl][INFO] - ChainedFuture completed 1/1 futures in 0.25 seconds.
[2025-02-25 13:38:34,770][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 28.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 316 milliseconds) (per-host)
[2025-02-25 13:38:34,779][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 13:38:34,821][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_183924.orbax-checkpoint-tmp-46 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_183924
[2025-02-25 13:38:34,829][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_183924`.
[2025-02-25 13:38:34,829][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 13:38:34,831][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_174492
| epoch 157 | 1000/1179 batches | ms/batch 2852.97 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.95
-----------------------------------------------------------------------------------------
| end of epoch 157 | time per epoch: 3340.96s |
| Train Metrics | accuracy:  0.77 | loss:  0.95
| Eval  Metrics | accuracy:  0.85 | loss:  0.56
-----------------------------------------------------------------------------------------
| epoch 158 | 1000/1179 batches | ms/batch 2729.14 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.96
-----------------------------------------------------------------------------------------
| end of epoch 158 | time per epoch: 3220.38s |
| Train Metrics | accuracy:  0.77 | loss:  0.97
| Eval  Metrics | accuracy:  0.85 | loss:  0.54
-----------------------------------------------------------------------------------------
[2025-02-25 15:39:57,964][absl][INFO] - Saving checkpoint at step: 186282
[2025-02-25 15:39:57,966][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 15:39:57,966][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 15:39:57,968][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_186282.
[2025-02-25 15:39:57,977][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 15:39:57,979][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_186282.orbax-checkpoint-tmp-47
[2025-02-25 15:39:58,011][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 15:39:58,038][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 15:39:58,070][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 158.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 57 milliseconds) (per-host)
[2025-02-25 15:39:58,321][absl][INFO] - ChainedFuture completed 1/1 futures in 0.25 seconds.
[2025-02-25 15:39:58,321][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 29.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 308 milliseconds) (per-host)
[2025-02-25 15:39:58,327][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 15:39:58,361][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_186282.orbax-checkpoint-tmp-47 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_186282
[2025-02-25 15:39:58,367][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_186282`.
[2025-02-25 15:39:58,367][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 15:39:58,370][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_183924
| epoch 159 | 1000/1179 batches | ms/batch 2708.24 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.97
-----------------------------------------------------------------------------------------
| end of epoch 159 | time per epoch: 3185.48s |
| Train Metrics | accuracy:  0.77 | loss:  0.96
| Eval  Metrics | accuracy:  0.85 | loss:  0.53
-----------------------------------------------------------------------------------------
[2025-02-25 16:39:08,323][absl][INFO] - Saving checkpoint at step: 187461
[2025-02-25 16:39:08,326][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 16:39:08,326][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 16:39:08,327][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_187461.
[2025-02-25 16:39:08,336][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 16:39:08,337][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_187461.orbax-checkpoint-tmp-48
[2025-02-25 16:39:08,346][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 16:39:08,373][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 16:39:08,404][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 157.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 58 milliseconds) (per-host)
[2025-02-25 16:39:08,630][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-25 16:39:08,630][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 284 milliseconds) (per-host)
[2025-02-25 16:39:08,636][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 16:39:08,672][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_187461.orbax-checkpoint-tmp-48 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_187461
[2025-02-25 16:39:08,679][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_187461`.
[2025-02-25 16:39:08,679][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 16:39:08,681][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_186282
| epoch 160 | 1000/1179 batches | ms/batch 2689.49 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.97
-----------------------------------------------------------------------------------------
| end of epoch 160 | time per epoch: 3162.87s |
| Train Metrics | accuracy:  0.77 | loss:  0.97
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.3095253109931946,
    "std": 0.41849881410598755,
    "var": 0.17514126002788544,
    "min": -0.49419593811035156,
    "max": 1.1643306016921997,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.2455575168132782,
    "std": 0.21291294693946838,
    "var": 0.0453319251537323,
    "min": 0.017263418063521385,
    "max": 1.148155689239502,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0009184504742734134,
    "std": 0.11751475185155869,
    "var": 0.013809717260301113,
    "min": -0.7037010788917542,
    "max": 0.5942776799201965,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.30124759674072266,
    "std": 0.2842410206794739,
    "var": 0.08079295605421066,
    "min": -0.03677477315068245,
    "max": 1.1952472925186157,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.38198956847190857,
    "std": 0.3769465386867523,
    "var": 0.14208868145942688,
    "min": 0.03387288376688957,
    "max": 1.5060770511627197,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0017539511900395155,
    "std": 0.1213412955403328,
    "var": 0.014723710715770721,
    "min": -0.6517339944839478,
    "max": 0.895287275314331,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2733754813671112,
    "std": 0.18772190809249878,
    "var": 0.03523951396346092,
    "min": -0.02895853854715824,
    "max": 0.997914731502533,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.4241042733192444,
    "std": 0.4199516475200653,
    "var": 0.1763594001531601,
    "min": 0.032955002039670944,
    "max": 2.533397912979126,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0010961014777421951,
    "std": 0.120115727186203,
    "var": 0.0144277885556221,
    "min": -0.840825080871582,
    "max": 0.7778624296188354,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.20222541689872742,
    "std": 0.23347902297973633,
    "var": 0.05451245605945587,
    "min": -0.30500903725624084,
    "max": 1.0282080173492432,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6744219064712524,
    "std": 0.22715920209884644,
    "var": 0.05160130560398102,
    "min": 0.1275012195110321,
    "max": 2.4184892177581787,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -4.918049671687186e-05,
    "std": 0.042169053107500076,
    "var": 0.0017782291397452354,
    "min": -0.7286638021469116,
    "max": 0.736758828163147,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.19893638789653778,
    "std": 0.23364011943340302,
    "var": 0.0545877069234848,
    "min": -0.2732546031475067,
    "max": 1.1623268127441406,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6527425646781921,
    "std": 0.2796066999435425,
    "var": 0.07817991077899933,
    "min": 0.11817555129528046,
    "max": 2.7598447799682617,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00013930629938840866,
    "std": 0.06236455217003822,
    "var": 0.003889337182044983,
    "min": -0.6301637887954712,
    "max": 0.7998332381248474,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.009294457733631134,
    "std": 0.08177895843982697,
    "var": 0.0066877976059913635,
    "min": -0.23705008625984192,
    "max": 0.25926634669303894,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.2720332145690918,
    "std": 0.26623815298080444,
    "var": 0.07088275253772736,
    "min": 0.8075421452522278,
    "max": 2.6569464206695557,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00012950145173817873,
    "std": 0.09152328968048096,
    "var": 0.008376512676477432,
    "min": -0.9342591762542725,
    "max": 0.8399070501327515,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0004697965341620147,
    "std": 0.06444667279720306,
    "var": 0.004153373651206493,
    "min": -0.43193405866622925,
    "max": 0.35184118151664734,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -7.996652129804716e-05,
    "std": 0.06486979871988297,
    "var": 0.004208090715110302,
    "min": -0.4361245036125183,
    "max": 0.45230671763420105,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.000883677217643708,
    "std": 0.0627974197268486,
    "var": 0.003943515941500664,
    "min": -0.4021358788013458,
    "max": 0.41777756810188293,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -2.0169973140582442e-05,
    "std": 0.03862598165869713,
    "var": 0.001491966424509883,
    "min": -0.36932599544525146,
    "max": 0.3616138994693756,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 6.710850720992312e-05,
    "std": 0.05714792013168335,
    "var": 0.003265884704887867,
    "min": -0.36565136909484863,
    "max": 0.31842687726020813,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": 1.8696087863645516e-05,
    "std": 0.059512216597795486,
    "var": 0.0035417042672634125,
    "min": -0.41022035479545593,
    "max": 0.36498531699180603,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.31606754660606384,
    "std": 0.09960868954658508,
    "var": 0.009921891614794731,
    "min": -0.5519660115242004,
    "max": -0.10553181916475296,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.10566481202840805,
    "std": 0.21707820892333984,
    "var": 0.04712294787168503,
    "min": -1.2593055963516235,
    "max": 0.9724783897399902,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.462777316570282,
    "std": 0.6461641788482666,
    "var": 0.4175281524658203,
    "min": -1.0126090049743652,
    "max": 2.2437896728515625,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.30174246430397034,
    "std": 0.1274745613336563,
    "var": 0.01624976471066475,
    "min": -0.6842385530471802,
    "max": 0.014002662152051926,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.1910158395767212,
    "std": 0.1892460435628891,
    "var": 0.0358140654861927,
    "min": -1.1573954820632935,
    "max": 0.6763035655021667,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.5407384634017944,
    "std": 0.7237743735313416,
    "var": 0.523849368095398,
    "min": -1.6253471374511719,
    "max": 1.8243067264556885,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.28393125534057617,
    "std": 0.1407865732908249,
    "var": 0.019820861518383026,
    "min": -0.7406606078147888,
    "max": 0.025853600353002548,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.20546971261501312,
    "std": 0.20354528725147247,
    "var": 0.04143068566918373,
    "min": -1.3381474018096924,
    "max": 0.7206594944000244,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.6276277303695679,
    "std": 0.7280125617980957,
    "var": 0.530002236366272,
    "min": -0.9952663779258728,
    "max": 2.4404523372650146,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.14684584736824036,
    "std": 0.08184485137462616,
    "var": 0.006698579993098974,
    "min": -0.42632436752319336,
    "max": 0.0452340804040432,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07353106886148453,
    "std": 0.1423538327217102,
    "var": 0.02026461623609066,
    "min": -1.4320179224014282,
    "max": 0.48159027099609375,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0007109130965545774,
    "std": 0.0022508699912577868,
    "var": 5.066415724286344e-06,
    "min": -0.009987005032598972,
    "max": 0.004854344762861729,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.0011581076541915536,
    "std": 0.08576492220163345,
    "var": 0.007355622015893459,
    "min": -0.581623911857605,
    "max": 0.6583543419837952,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.00529932975769043,
    "std": 0.17294488847255707,
    "var": 0.029909934848546982,
    "min": -1.116711974143982,
    "max": 1.3737221956253052,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15165938436985016,
    "std": 0.07245048880577087,
    "var": 0.005249073263257742,
    "min": -0.4606437385082245,
    "max": 0.014085627160966396,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.06844326108694077,
    "std": 0.13476233184337616,
    "var": 0.018160885199904442,
    "min": -1.5764437913894653,
    "max": 0.44855406880378723,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.10778452455997467,
    "std": 0.49251410365104675,
    "var": 0.242570161819458,
    "min": -1.367376446723938,
    "max": 1.8238046169281006,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.07508794963359833,
    "std": 0.11811334639787674,
    "var": 0.013950763270258904,
    "min": -0.24343694746494293,
    "max": 0.3594589829444885,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.027549996972084045,
    "std": 0.12165168672800064,
    "var": 0.014799132943153381,
    "min": -0.7924352884292603,
    "max": 0.45459499955177307,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.22825214266777039,
    "std": 0.3043022155761719,
    "var": 0.09259983152151108,
    "min": -0.45239880681037903,
    "max": 1.0401979684829712,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.009770993143320084,
    "std": 0.06194894760847092,
    "var": 0.003837672295048833,
    "min": -0.1627761423587799,
    "max": 0.08133380115032196,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.002761661075055599,
    "std": 0.2141340672969818,
    "var": 0.045853398740291595,
    "min": -0.8941445350646973,
    "max": 0.7921876311302185,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.008332961238920689,
    "std": 0.17407292127609253,
    "var": 0.030301382765173912,
    "min": -0.7654931545257568,
    "max": 0.8052616715431213,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.06967085599899292,
    "std": 0.31022658944129944,
    "var": 0.09624054282903671,
    "min": -0.8298912644386292,
    "max": 1.0809571743011475,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.16000710427761078,
    "std": 0.3564060628414154,
    "var": 0.1270252764225006,
    "min": -1.4336885213851929,
    "max": 0.5911820530891418,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.45838049054145813,
    "std": 0.4418902099132538,
    "var": 0.1952669620513916,
    "min": -1.489841341972351,
    "max": 0.5219135284423828,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.650568962097168,
    "std": 0.6661210060119629,
    "var": 0.44371721148490906,
    "min": -2.831861972808838,
    "max": 0.8506091833114624,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.929950475692749,
    "std": 0.41535964608192444,
    "var": 0.172523632645607,
    "min": -2.133880615234375,
    "max": 0.31113624572753906,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.9968541264533997,
    "std": 0.5818988680839539,
    "var": 0.3386062979698181,
    "min": -2.6230521202087402,
    "max": 0.20386753976345062,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 161 | 1000/1179 batches | ms/batch 2675.87 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.93
-----------------------------------------------------------------------------------------
| end of epoch 161 | time per epoch: 3152.19s |
| Train Metrics | accuracy:  0.78 | loss:  0.93
| Eval  Metrics | accuracy:  0.84 | loss:  0.56
-----------------------------------------------------------------------------------------
| epoch 162 | 1000/1179 batches | ms/batch 2728.71 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.95
-----------------------------------------------------------------------------------------
| end of epoch 162 | time per epoch: 3252.89s |
| Train Metrics | accuracy:  0.77 | loss:  0.95
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 163 | 1000/1179 batches | ms/batch 2723.82 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.92
-----------------------------------------------------------------------------------------
| end of epoch 163 | time per epoch: 3202.74s |
| Train Metrics | accuracy:  0.78 | loss:  0.93
| Eval  Metrics | accuracy:  0.85 | loss:  0.54
-----------------------------------------------------------------------------------------
| epoch 164 | 1000/1179 batches | ms/batch 2696.38 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.97
-----------------------------------------------------------------------------------------
| end of epoch 164 | time per epoch: 3186.74s |
| Train Metrics | accuracy:  0.77 | loss:  0.97
| Eval  Metrics | accuracy:  0.85 | loss:  0.51
-----------------------------------------------------------------------------------------
[2025-02-25 21:35:47,424][absl][INFO] - Saving checkpoint at step: 193356
[2025-02-25 21:35:47,427][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 21:35:47,427][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 21:35:47,429][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_193356.
[2025-02-25 21:35:47,437][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 21:35:47,438][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_193356.orbax-checkpoint-tmp-49
[2025-02-25 21:35:47,457][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 21:35:47,484][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 21:35:47,519][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 148.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 61 milliseconds) (per-host)
[2025-02-25 21:35:48,189][absl][INFO] - ChainedFuture completed 1/1 futures in 0.67 seconds.
[2025-02-25 21:35:48,189][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 12.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 731 milliseconds) (per-host)
[2025-02-25 21:35:48,195][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 21:35:48,229][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_193356.orbax-checkpoint-tmp-49 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_193356
[2025-02-25 21:35:48,236][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_193356`.
[2025-02-25 21:35:48,236][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 21:35:48,238][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_187461
| epoch 165 | 1000/1179 batches | ms/batch 2737.42 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.93
-----------------------------------------------------------------------------------------
| end of epoch 165 | time per epoch: 3230.35s |
| Train Metrics | accuracy:  0.78 | loss:  0.93
| Eval  Metrics | accuracy:  0.85 | loss:  0.51
-----------------------------------------------------------------------------------------
[2025-02-25 22:35:55,896][absl][INFO] - Saving checkpoint at step: 194535
[2025-02-25 22:35:55,899][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 22:35:55,899][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 22:35:55,901][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_194535.
[2025-02-25 22:35:55,909][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 22:35:55,910][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_194535.orbax-checkpoint-tmp-50
[2025-02-25 22:35:55,922][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 22:35:55,951][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 22:35:55,970][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 194.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 46 milliseconds) (per-host)
[2025-02-25 22:35:56,243][absl][INFO] - ChainedFuture completed 1/1 futures in 0.27 seconds.
[2025-02-25 22:35:56,244][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 28.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 320 milliseconds) (per-host)
[2025-02-25 22:35:56,250][absl][INFO] - Updated Metadata={'item_handlers': 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler', 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1740540955918605139, 'commit_timestamp_nsecs': None, 'custom': {}} to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_194535.orbax-checkpoint-tmp-50/_CHECKPOINT_METADATA
[2025-02-25 22:35:56,250][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 22:35:56,284][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_194535.orbax-checkpoint-tmp-50 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_194535
[2025-02-25 22:35:56,290][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_194535`.
[2025-02-25 22:35:56,290][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 22:35:56,291][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_193356
| epoch 166 | 1000/1179 batches | ms/batch 2817.67 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.92
-----------------------------------------------------------------------------------------
| end of epoch 166 | time per epoch: 3329.80s |
| Train Metrics | accuracy:  0.78 | loss:  0.92
| Eval  Metrics | accuracy:  0.85 | loss:  0.54
-----------------------------------------------------------------------------------------
| epoch 167 | 1000/1179 batches | ms/batch 2858.00 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.95
-----------------------------------------------------------------------------------------
| end of epoch 167 | time per epoch: 3373.94s |
| Train Metrics | accuracy:  0.77 | loss:  0.95
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 168 | 1000/1179 batches | ms/batch 2878.95 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.92
-----------------------------------------------------------------------------------------
| end of epoch 168 | time per epoch: 3382.19s |
| Train Metrics | accuracy:  0.78 | loss:  0.93
| Eval  Metrics | accuracy:  0.85 | loss:  0.51
-----------------------------------------------------------------------------------------
[2025-02-26 01:43:34,365][absl][INFO] - Saving checkpoint at step: 198072
[2025-02-26 01:43:34,367][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 01:43:34,368][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 01:43:34,370][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_198072.
[2025-02-26 01:43:34,389][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 01:43:34,390][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_198072.orbax-checkpoint-tmp-51
[2025-02-26 01:43:34,430][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 01:43:34,462][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 01:43:34,494][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 147.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 62 milliseconds) (per-host)
[2025-02-26 01:43:34,730][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-26 01:43:34,730][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 298 milliseconds) (per-host)
[2025-02-26 01:43:34,736][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 01:43:34,773][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_198072.orbax-checkpoint-tmp-51 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_198072
[2025-02-26 01:43:34,779][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_198072`.
[2025-02-26 01:43:34,779][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 01:43:34,782][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_194535
| epoch 169 | 1000/1179 batches | ms/batch 2876.30 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.91
-----------------------------------------------------------------------------------------
| end of epoch 169 | time per epoch: 3373.85s |
| Train Metrics | accuracy:  0.78 | loss:  0.91
| Eval  Metrics | accuracy:  0.85 | loss:  0.54
-----------------------------------------------------------------------------------------
| epoch 170 | 1000/1179 batches | ms/batch 2803.98 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.92
-----------------------------------------------------------------------------------------
| end of epoch 170 | time per epoch: 3305.80s |
| Train Metrics | accuracy:  0.78 | loss:  0.93
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.3127521872520447,
    "std": 0.422495037317276,
    "var": 0.17850206792354584,
    "min": -0.5005093812942505,
    "max": 1.1808925867080688,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.2440335601568222,
    "std": 0.21719378232955933,
    "var": 0.047173138707876205,
    "min": 0.014494390226900578,
    "max": 1.168282151222229,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0009491470409557223,
    "std": 0.11756692081689835,
    "var": 0.01382198091596365,
    "min": -0.7040393352508545,
    "max": 0.5934082865715027,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.30457577109336853,
    "std": 0.2911140024662018,
    "var": 0.08474735915660858,
    "min": -0.03441799059510231,
    "max": 1.1978495121002197,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.3816194534301758,
    "std": 0.38096383213996887,
    "var": 0.14513345062732697,
    "min": 0.030659819021821022,
    "max": 1.507568120956421,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0017305968794971704,
    "std": 0.12137603759765625,
    "var": 0.01473214291036129,
    "min": -0.652273952960968,
    "max": 0.8961584568023682,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2746495008468628,
    "std": 0.19140106439590454,
    "var": 0.03663436695933342,
    "min": -0.02694915421307087,
    "max": 1.015738606452942,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.42420631647109985,
    "std": 0.42356032133102417,
    "var": 0.17940334975719452,
    "min": 0.03336457163095474,
    "max": 2.5497984886169434,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.001072365208528936,
    "std": 0.12014836072921753,
    "var": 0.014435629360377789,
    "min": -0.8414660692214966,
    "max": 0.7801535725593567,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.20610636472702026,
    "std": 0.23224301636219025,
    "var": 0.05393682047724724,
    "min": -0.2985416352748871,
    "max": 1.0254266262054443,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6691009402275085,
    "std": 0.2268294394016266,
    "var": 0.05145159363746643,
    "min": 0.12475063651800156,
    "max": 2.4190051555633545,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -4.994622941012494e-05,
    "std": 0.042113978415727615,
    "var": 0.0017735871952027082,
    "min": -0.7300759553909302,
    "max": 0.7352287769317627,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.20496968924999237,
    "std": 0.23355653882026672,
    "var": 0.054548658430576324,
    "min": -0.25979623198509216,
    "max": 1.1770451068878174,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6491100788116455,
    "std": 0.27698278427124023,
    "var": 0.07671946287155151,
    "min": 0.1181078627705574,
    "max": 2.7298762798309326,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00013544579269364476,
    "std": 0.06239716336131096,
    "var": 0.003893406130373478,
    "min": -0.6285375952720642,
    "max": 0.8076013326644897,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.006169469095766544,
    "std": 0.08085621893405914,
    "var": 0.006537728011608124,
    "min": -0.22806014120578766,
    "max": 0.2645110785961151,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.2857993841171265,
    "std": 0.26806578040122986,
    "var": 0.07185926288366318,
    "min": 0.814436674118042,
    "max": 2.6838245391845703,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00011892170732608065,
    "std": 0.09155476093292236,
    "var": 0.008382274769246578,
    "min": -0.940669059753418,
    "max": 0.8414058685302734,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0004873964935541153,
    "std": 0.06114781275391579,
    "var": 0.003739055246114731,
    "min": -0.4045965373516083,
    "max": 0.3369074761867523,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -8.48111740197055e-05,
    "std": 0.06144707649946213,
    "var": 0.0037757433019578457,
    "min": -0.3986026346683502,
    "max": 0.44301021099090576,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0008151877555064857,
    "std": 0.059433676302433014,
    "var": 0.003532361937686801,
    "min": -0.3837967813014984,
    "max": 0.3945934772491455,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": 1.132577563112136e-05,
    "std": 0.037191931158304214,
    "var": 0.001383239752613008,
    "min": -0.34732288122177124,
    "max": 0.3504578173160553,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 3.2462674425914884e-05,
    "std": 0.05445496737957001,
    "var": 0.002965343650430441,
    "min": -0.3520587980747223,
    "max": 0.2975863814353943,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": 7.460937922587618e-05,
    "std": 0.05645862594246864,
    "var": 0.0031875763088464737,
    "min": -0.394001841545105,
    "max": 0.3471736013889313,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3136112093925476,
    "std": 0.10062374174594879,
    "var": 0.01012513693422079,
    "min": -0.5566897988319397,
    "max": -0.11520497500896454,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.10519362986087799,
    "std": 0.21557538211345673,
    "var": 0.04647274315357208,
    "min": -1.262096881866455,
    "max": 0.9870398640632629,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.4444309175014496,
    "std": 0.6322722434997559,
    "var": 0.3997681736946106,
    "min": -0.997092068195343,
    "max": 2.216315269470215,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.30042311549186707,
    "std": 0.12723040580749512,
    "var": 0.016187578439712524,
    "min": -0.6743263602256775,
    "max": 0.007975415326654911,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19003622233867645,
    "std": 0.1881852149963379,
    "var": 0.035413675010204315,
    "min": -1.1670641899108887,
    "max": 0.693115234375,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.51734858751297,
    "std": 0.7039899826049805,
    "var": 0.4956018924713135,
    "min": -1.6135170459747314,
    "max": 1.7851489782333374,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.28521794080734253,
    "std": 0.13724425435066223,
    "var": 0.018835987895727158,
    "min": -0.746640145778656,
    "max": 0.013699818402528763,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.20497260987758636,
    "std": 0.2016477882862091,
    "var": 0.04066183418035507,
    "min": -1.2952733039855957,
    "max": 0.7278555631637573,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.5965419411659241,
    "std": 0.7043983340263367,
    "var": 0.4961770474910736,
    "min": -0.9959691762924194,
    "max": 2.361254930496216,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.14900733530521393,
    "std": 0.08017236739397049,
    "var": 0.00642760843038559,
    "min": -0.4171435236930847,
    "max": 0.04297251999378204,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07338450103998184,
    "std": 0.13998162746429443,
    "var": 0.019594857469201088,
    "min": -1.429040551185608,
    "max": 0.4822610318660736,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0007685701129958034,
    "std": 0.001988421892747283,
    "var": 3.953821760660503e-06,
    "min": -0.008029925636947155,
    "max": 0.005206692963838577,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.0011916408548131585,
    "std": 0.08362120389938354,
    "var": 0.0069925058633089066,
    "min": -0.5599173903465271,
    "max": 0.6379157900810242,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.004689719993621111,
    "std": 0.1633099764585495,
    "var": 0.026670150458812714,
    "min": -1.0592280626296997,
    "max": 1.3028619289398193,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.1528547704219818,
    "std": 0.07202868163585663,
    "var": 0.005188130773603916,
    "min": -0.46033981442451477,
    "max": 0.014474533498287201,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.06840182095766068,
    "std": 0.1325400173664093,
    "var": 0.017566855996847153,
    "min": -1.6123408079147339,
    "max": 0.4370648264884949,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.10117285698652267,
    "std": 0.46516385674476624,
    "var": 0.2163774073123932,
    "min": -1.301946759223938,
    "max": 1.7325900793075562,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.07720496505498886,
    "std": 0.11633700132369995,
    "var": 0.013534298166632652,
    "min": -0.2321813553571701,
    "max": 0.35791322588920593,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.026449153199791908,
    "std": 0.11927428096532822,
    "var": 0.014226353727281094,
    "min": -0.8023129105567932,
    "max": 0.4657424986362457,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.22011905908584595,
    "std": 0.2870216369628906,
    "var": 0.08238141983747482,
    "min": -0.409127801656723,
    "max": 0.9774330854415894,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.00980647187680006,
    "std": 0.06161991506814957,
    "var": 0.003797014243900776,
    "min": -0.164865642786026,
    "max": 0.079252690076828,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0027868144679814577,
    "std": 0.21441024541854858,
    "var": 0.04597175866365433,
    "min": -0.8942987322807312,
    "max": 0.8068389296531677,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.008046384900808334,
    "std": 0.16706544160842896,
    "var": 0.027910863980650902,
    "min": -0.7278610467910767,
    "max": 0.7845849990844727,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.054662492126226425,
    "std": 0.3049021363258362,
    "var": 0.09296531975269318,
    "min": -0.7772000432014465,
    "max": 1.100396752357483,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.14320054650306702,
    "std": 0.3520815670490265,
    "var": 0.1239614263176918,
    "min": -1.4074327945709229,
    "max": 0.6183074116706848,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.44107475876808167,
    "std": 0.4358992278575897,
    "var": 0.19000813364982605,
    "min": -1.4551513195037842,
    "max": 0.5286231637001038,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.5960861444473267,
    "std": 0.6516711711883545,
    "var": 0.424675315618515,
    "min": -2.7659988403320312,
    "max": 0.8588504195213318,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.9011651277542114,
    "std": 0.41355398297309875,
    "var": 0.17102688550949097,
    "min": -2.1121675968170166,
    "max": 0.3029891550540924,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.9818384051322937,
    "std": 0.5778694748878479,
    "var": 0.33393314480781555,
    "min": -2.598522901535034,
    "max": 0.20087462663650513,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.85 | loss:  0.53
-----------------------------------------------------------------------------------------
| epoch 171 | 1000/1179 batches | ms/batch 2842.19 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.92
-----------------------------------------------------------------------------------------
| end of epoch 171 | time per epoch: 3350.28s |
| Train Metrics | accuracy:  0.78 | loss:  0.92
| Eval  Metrics | accuracy:  0.85 | loss:  0.50
-----------------------------------------------------------------------------------------
| epoch 172 | 1000/1179 batches | ms/batch 2784.26 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.89
-----------------------------------------------------------------------------------------
| end of epoch 172 | time per epoch: 3290.45s |
| Train Metrics | accuracy:  0.78 | loss:  0.89
| Eval  Metrics | accuracy:  0.85 | loss:  0.51
-----------------------------------------------------------------------------------------
| epoch 173 | 1000/1179 batches | ms/batch 2825.15 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.90
-----------------------------------------------------------------------------------------
| end of epoch 173 | time per epoch: 3320.69s |
| Train Metrics | accuracy:  0.78 | loss:  0.89
| Eval  Metrics | accuracy:  0.85 | loss:  0.51
-----------------------------------------------------------------------------------------
| epoch 174 | 1000/1179 batches | ms/batch 2861.08 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.89
-----------------------------------------------------------------------------------------
| end of epoch 174 | time per epoch: 3377.34s |
| Train Metrics | accuracy:  0.79 | loss:  0.89
| Eval  Metrics | accuracy:  0.85 | loss:  0.50
-----------------------------------------------------------------------------------------
| epoch 175 | 1000/1179 batches | ms/batch 2858.27 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.90
-----------------------------------------------------------------------------------------
| end of epoch 175 | time per epoch: 3370.43s |
| Train Metrics | accuracy:  0.79 | loss:  0.90
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 176 | 1000/1179 batches | ms/batch 2906.07 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.88
-----------------------------------------------------------------------------------------
| end of epoch 176 | time per epoch: 3409.84s |
| Train Metrics | accuracy:  0.79 | loss:  0.90
| Eval  Metrics | accuracy:  0.85 | loss:  0.50
-----------------------------------------------------------------------------------------
| epoch 177 | 1000/1179 batches | ms/batch 3030.68 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.91
-----------------------------------------------------------------------------------------
| end of epoch 177 | time per epoch: 3574.47s |
| Train Metrics | accuracy:  0.78 | loss:  0.91
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 178 | 1000/1179 batches | ms/batch 3219.41 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.90
-----------------------------------------------------------------------------------------
| end of epoch 178 | time per epoch: 3819.19s |
| Train Metrics | accuracy:  0.78 | loss:  0.91
| Eval  Metrics | accuracy:  0.86 | loss:  0.51
-----------------------------------------------------------------------------------------
[2025-02-26 12:19:40,214][absl][INFO] - Saving checkpoint at step: 209862
[2025-02-26 12:19:40,217][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 12:19:40,217][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 12:19:40,219][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_209862.
[2025-02-26 12:19:40,227][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 12:19:40,229][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_209862.orbax-checkpoint-tmp-52
[2025-02-26 12:19:40,238][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 12:19:40,267][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 12:19:40,289][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 184.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 49 milliseconds) (per-host)
[2025-02-26 12:19:40,553][absl][INFO] - ChainedFuture completed 1/1 futures in 0.26 seconds.
[2025-02-26 12:19:40,554][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 29.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 314 milliseconds) (per-host)
[2025-02-26 12:19:40,560][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 12:19:40,594][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_209862.orbax-checkpoint-tmp-52 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_209862
[2025-02-26 12:19:40,601][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_209862`.
[2025-02-26 12:19:40,601][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 12:19:40,603][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-21-14-13-07/checkpoints/checkpoint_198072
slurmstepd: error: *** JOB 21508903 ON gl1524 CANCELLED AT 2025-02-26T14:13:06 DUE TO TIME LIMIT ***
