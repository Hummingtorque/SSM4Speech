WARNING:absl:Tensorflow library not found, tensorflow.io.gfile operations will use native shim calls. GCS paths (i.e. 'gs://...') cannot be accessed.
INFO:2025-02-24 16:09:55,288:jax._src.xla_bridge:945: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
seed: 1234
checkpoint: null
data_dir: ./data
output_dir: ./outputs/${now:%Y-%m-%d-%H-%M-%S}
checkpoint_dir: ./checkpoints
model:
  ssm_init:
    C_init: lecun_normal
    dt_min: 0.0015
    dt_max: 0.1
    conj_sym: true
    clip_eigs: false
  ssm:
    discretization: async
    d_model: 96
    d_ssm: 128
    ssm_block_size: 16
    num_stages: 2
    num_layers_per_stage: 3
    dropout: 0.23
    classification_mode: pool
    prenorm: true
    batchnorm: true
    bn_momentum: 0.95
    pooling_stride: 8
    pooling_mode: avgpool
    state_expansion_factor: 2
task:
  name: ssc-classification
training:
  num_epochs: 200
  per_device_batch_size: 32
  per_device_eval_batch_size: 64
  num_workers: 0
  time_jitter: 3
  spatial_jitter: 1.0
  noise: 100
  drop_event: 0.1
  max_drop_chunk: 0.02
  cut_mix: 0.3
  time_skew: 1.05
  pad_unit: 8192
optimizer:
  ssm_base_lr: 5.0e-06
  lr_factor: 5
  warmup_epochs: 20
  ssm_weight_decay: 0.0
  weight_decay: 0.05
  schedule: cosine
  accumulation_steps: 1
logging:
  log_dir: ${output_dir}
  interval: 1000
  wandb: false
  summary_metric: Performance/Validation accuracy
  project: ???
  entity: ???

[2025-02-24 16:09:55,288][jax._src.xla_bridge][INFO] - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
INFO:2025-02-24 16:09:55,288:jax._src.xla_bridge:945: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-02-24 16:09:55,288][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[*] Loading dataset...
[*] Generating Spiking Speech Commands Classification Dataset
[*] Creating model...
[*] Initializing model state...
[SequenceLayer] Layer 0: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.1
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 2: using manual_lambda = -0.1
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 0: using manual_lambda = -0.1
SSM: 96 -> 256 -> 192 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.1
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 2: using manual_lambda = -0.1
SSM: 192 -> 256 -> 192
[*] Model parameter count: 597731
[*] Using gradient accumulation with 1 steps
[*] Running training on 2 GPUs
[*] Logging to ./outputs/2025-02-24-16-09-54
[*] Number of model parameters: 597731
[*] Running training...
[SequenceLayer] Layer 0: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.1
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 2: using manual_lambda = -0.1
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 0: using manual_lambda = -0.1
SSM: 96 -> 256 -> 192 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.1
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 2: using manual_lambda = -0.1
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 0: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.1
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 2: using manual_lambda = -0.1
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 0: using manual_lambda = -0.1
SSM: 96 -> 256 -> 192 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.1
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 2: using manual_lambda = -0.1
SSM: 192 -> 256 -> 192
| epoch 1 | 1000/1179 batches | ms/batch 1044.43 | Performance/Training accuracy:  0.05 | Performance/Training loss:  3.55
-----------------------------------------------------------------------------------------
| end of epoch   1 | time per epoch: 1202.54s |
| Train Metrics | accuracy:  0.06 | loss:  3.50
[SequenceLayer] Layer 0: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.1
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 2: using manual_lambda = -0.1
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 0: using manual_lambda = -0.1
SSM: 96 -> 256 -> 192 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.1
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 2: using manual_lambda = -0.1
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 0: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.1
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 2: using manual_lambda = -0.1
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 0: using manual_lambda = -0.1
SSM: 96 -> 256 -> 192 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.1
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 2: using manual_lambda = -0.1
SSM: 192 -> 256 -> 192
| Eval  Metrics | accuracy:  0.17 | loss:  2.99
-----------------------------------------------------------------------------------------
[2025-02-24 16:32:28,086][absl][INFO] - Saving checkpoint at step: 1179
[2025-02-24 16:32:28,088][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 16:32:28,089][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 16:32:28,089][absl][INFO] - orbax-checkpoint version: 0.11.1
[2025-02-24 16:32:28,090][absl][INFO] - [thread=MainThread] Failed to get flag value for EXPERIMENTAL_ORBAX_USE_DISTRIBUTED_PROCESS_ID.
[2025-02-24 16:32:28,090][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_1179.
[2025-02-24 16:32:28,104][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 16:32:28,105][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_1179.orbax-checkpoint-tmp-0
[2025-02-24 16:32:28,112][absl][INFO] - Wrote Metadata={'item_handlers': None, 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1740432748108428684, 'commit_timestamp_nsecs': None, 'custom': {}}, json={"item_handlers": null, "metrics": {}, "performance_metrics": {}, "init_timestamp_nsecs": 1740432748108428684, "commit_timestamp_nsecs": null, "custom": {}} to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_1179.orbax-checkpoint-tmp-0/_CHECKPOINT_METADATA
[2025-02-24 16:32:28,112][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 16:32:28,138][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 16:32:28,164][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 177.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 51 milliseconds) (per-host)
[2025-02-24 16:32:28,384][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-24 16:32:28,384][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 271 milliseconds) (per-host)
[2025-02-24 16:32:28,386][absl][INFO] - Read Metadata={'item_handlers': None, 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1740432748108428684, 'commit_timestamp_nsecs': None, 'custom': {}} from /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_1179.orbax-checkpoint-tmp-0/_CHECKPOINT_METADATA
[2025-02-24 16:32:28,389][absl][INFO] - Updated Metadata={'item_handlers': 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler', 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1740432748108428684, 'commit_timestamp_nsecs': None, 'custom': {}} to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_1179.orbax-checkpoint-tmp-0/_CHECKPOINT_METADATA
[2025-02-24 16:32:28,389][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 16:32:28,419][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_1179.orbax-checkpoint-tmp-0 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_1179
[2025-02-24 16:32:28,424][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_1179`.
[2025-02-24 16:32:28,424][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
| epoch 2 | 1000/1179 batches | ms/batch 854.61 | Performance/Training accuracy:  0.15 | Performance/Training loss:  3.04
-----------------------------------------------------------------------------------------
| end of epoch   2 | time per epoch: 1007.11s |
| Train Metrics | accuracy:  0.16 | loss:  3.02
| Eval  Metrics | accuracy:  0.29 | loss:  2.57
-----------------------------------------------------------------------------------------
[2025-02-24 16:50:31,055][absl][INFO] - Saving checkpoint at step: 2358
[2025-02-24 16:50:31,056][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 16:50:31,057][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 16:50:31,058][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_2358.
[2025-02-24 16:50:31,065][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 16:50:31,066][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_2358.orbax-checkpoint-tmp-1
[2025-02-24 16:50:31,074][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 16:50:31,101][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 16:50:31,129][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 167.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-24 16:50:31,346][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-24 16:50:31,347][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 271 milliseconds) (per-host)
[2025-02-24 16:50:31,351][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 16:50:31,380][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_2358.orbax-checkpoint-tmp-1 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_2358
[2025-02-24 16:50:31,385][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_2358`.
[2025-02-24 16:50:31,385][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 16:50:31,386][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_1179
| epoch 3 | 1000/1179 batches | ms/batch 843.83 | Performance/Training accuracy:  0.22 | Performance/Training loss:  2.84
-----------------------------------------------------------------------------------------
| end of epoch   3 | time per epoch: 993.89s |
| Train Metrics | accuracy:  0.22 | loss:  2.82
| Eval  Metrics | accuracy:  0.35 | loss:  2.32
-----------------------------------------------------------------------------------------
[2025-02-24 17:08:21,089][absl][INFO] - Saving checkpoint at step: 3537
[2025-02-24 17:08:21,091][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 17:08:21,091][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 17:08:21,092][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_3537.
[2025-02-24 17:08:21,100][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 17:08:21,101][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_3537.orbax-checkpoint-tmp-2
[2025-02-24 17:08:21,107][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 17:08:21,133][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 17:08:21,169][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 148.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 61 milliseconds) (per-host)
[2025-02-24 17:08:21,372][absl][INFO] - ChainedFuture completed 1/1 futures in 0.20 seconds.
[2025-02-24 17:08:21,372][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 34.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 264 milliseconds) (per-host)
[2025-02-24 17:08:21,377][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 17:08:21,406][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_3537.orbax-checkpoint-tmp-2 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_3537
[2025-02-24 17:08:21,411][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_3537`.
[2025-02-24 17:08:21,411][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 17:08:21,413][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_2358
| epoch 4 | 1000/1179 batches | ms/batch 833.29 | Performance/Training accuracy:  0.27 | Performance/Training loss:  2.62
-----------------------------------------------------------------------------------------
| end of epoch   4 | time per epoch: 980.61s |
| Train Metrics | accuracy:  0.28 | loss:  2.61
| Eval  Metrics | accuracy:  0.44 | loss:  2.00
-----------------------------------------------------------------------------------------
[2025-02-24 17:25:57,600][absl][INFO] - Saving checkpoint at step: 4716
[2025-02-24 17:25:57,601][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 17:25:57,601][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 17:25:57,603][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_4716.
[2025-02-24 17:25:57,610][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 17:25:57,611][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_4716.orbax-checkpoint-tmp-3
[2025-02-24 17:25:57,618][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 17:25:57,643][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 17:25:57,672][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 169.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 53 milliseconds) (per-host)
[2025-02-24 17:25:57,891][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-24 17:25:57,891][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 272 milliseconds) (per-host)
[2025-02-24 17:25:57,897][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 17:25:57,925][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_4716.orbax-checkpoint-tmp-3 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_4716
[2025-02-24 17:25:57,931][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_4716`.
[2025-02-24 17:25:57,931][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 17:25:57,932][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_3537
| epoch 5 | 1000/1179 batches | ms/batch 772.65 | Performance/Training accuracy:  0.34 | Performance/Training loss:  2.39
-----------------------------------------------------------------------------------------
| end of epoch   5 | time per epoch: 909.98s |
| Train Metrics | accuracy:  0.34 | loss:  2.37
| Eval  Metrics | accuracy:  0.50 | loss:  1.72
-----------------------------------------------------------------------------------------
[2025-02-24 17:42:23,779][absl][INFO] - Saving checkpoint at step: 5895
[2025-02-24 17:42:23,780][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 17:42:23,780][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 17:42:23,781][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_5895.
[2025-02-24 17:42:23,788][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 17:42:23,789][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_5895.orbax-checkpoint-tmp-4
[2025-02-24 17:42:23,796][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 17:42:23,822][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 17:42:23,854][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 159.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 57 milliseconds) (per-host)
[2025-02-24 17:42:24,071][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-24 17:42:24,071][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 274 milliseconds) (per-host)
[2025-02-24 17:42:24,076][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 17:42:24,104][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_5895.orbax-checkpoint-tmp-4 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_5895
[2025-02-24 17:42:24,109][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_5895`.
[2025-02-24 17:42:24,109][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 17:42:24,110][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_4716
| epoch 6 | 1000/1179 batches | ms/batch 766.06 | Performance/Training accuracy:  0.40 | Performance/Training loss:  2.19
-----------------------------------------------------------------------------------------
| end of epoch   6 | time per epoch: 903.07s |
| Train Metrics | accuracy:  0.40 | loss:  2.18
| Eval  Metrics | accuracy:  0.55 | loss:  1.53
-----------------------------------------------------------------------------------------
[2025-02-24 17:58:44,107][absl][INFO] - Saving checkpoint at step: 7074
[2025-02-24 17:58:44,108][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 17:58:44,108][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 17:58:44,109][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_7074.
[2025-02-24 17:58:44,117][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 17:58:44,118][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_7074.orbax-checkpoint-tmp-5
[2025-02-24 17:58:44,124][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 17:58:44,150][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 17:58:44,180][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 166.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-24 17:58:44,387][absl][INFO] - ChainedFuture completed 1/1 futures in 0.21 seconds.
[2025-02-24 17:58:44,387][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 34.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 262 milliseconds) (per-host)
[2025-02-24 17:58:44,392][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 17:58:44,420][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_7074.orbax-checkpoint-tmp-5 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_7074
[2025-02-24 17:58:44,425][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_7074`.
[2025-02-24 17:58:44,425][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 17:58:44,426][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_5895
| epoch 7 | 1000/1179 batches | ms/batch 772.67 | Performance/Training accuracy:  0.43 | Performance/Training loss:  2.10
-----------------------------------------------------------------------------------------
| end of epoch   7 | time per epoch: 910.85s |
| Train Metrics | accuracy:  0.43 | loss:  2.09
| Eval  Metrics | accuracy:  0.57 | loss:  1.47
-----------------------------------------------------------------------------------------
[2025-02-24 18:15:11,395][absl][INFO] - Saving checkpoint at step: 8253
[2025-02-24 18:15:11,396][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 18:15:11,397][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 18:15:11,398][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_8253.
[2025-02-24 18:15:11,400][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 18:15:11,401][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_8253.orbax-checkpoint-tmp-6
[2025-02-24 18:15:11,409][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 18:15:11,434][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 18:15:11,752][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 26.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 342 milliseconds) (per-host)
[2025-02-24 18:15:11,971][absl][INFO] - ChainedFuture completed 1/1 futures in 0.21 seconds.
[2025-02-24 18:15:11,971][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 16.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 561 milliseconds) (per-host)
[2025-02-24 18:15:11,976][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 18:15:12,005][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_8253.orbax-checkpoint-tmp-6 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_8253
[2025-02-24 18:15:12,010][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_8253`.
[2025-02-24 18:15:12,010][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 18:15:12,012][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_7074
| epoch 8 | 1000/1179 batches | ms/batch 769.48 | Performance/Training accuracy:  0.47 | Performance/Training loss:  1.94
-----------------------------------------------------------------------------------------
| end of epoch   8 | time per epoch: 910.03s |
| Train Metrics | accuracy:  0.47 | loss:  1.94
| Eval  Metrics | accuracy:  0.61 | loss:  1.32
-----------------------------------------------------------------------------------------
[2025-02-24 18:31:39,052][absl][INFO] - Saving checkpoint at step: 9432
[2025-02-24 18:31:39,053][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 18:31:39,053][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 18:31:39,054][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_9432.
[2025-02-24 18:31:39,062][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 18:31:39,063][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_9432.orbax-checkpoint-tmp-7
[2025-02-24 18:31:39,069][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 18:31:39,093][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 18:31:39,124][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 168.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-24 18:31:39,321][absl][INFO] - ChainedFuture completed 1/1 futures in 0.20 seconds.
[2025-02-24 18:31:39,321][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 36.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 251 milliseconds) (per-host)
[2025-02-24 18:31:39,326][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 18:31:39,353][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_9432.orbax-checkpoint-tmp-7 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_9432
[2025-02-24 18:31:39,358][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_9432`.
[2025-02-24 18:31:39,358][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 18:31:39,359][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_8253
| epoch 9 | 1000/1179 batches | ms/batch 778.38 | Performance/Training accuracy:  0.49 | Performance/Training loss:  1.87
-----------------------------------------------------------------------------------------
| end of epoch   9 | time per epoch: 916.87s |
| Train Metrics | accuracy:  0.50 | loss:  1.87
| Eval  Metrics | accuracy:  0.64 | loss:  1.24
-----------------------------------------------------------------------------------------
[2025-02-24 18:48:12,698][absl][INFO] - Saving checkpoint at step: 10611
[2025-02-24 18:48:12,699][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 18:48:12,700][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 18:48:12,701][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_10611.
[2025-02-24 18:48:12,708][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 18:48:12,709][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_10611.orbax-checkpoint-tmp-8
[2025-02-24 18:48:12,715][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 18:48:12,740][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 18:48:12,756][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 222.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 41 milliseconds) (per-host)
[2025-02-24 18:48:12,986][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-24 18:48:12,987][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 271 milliseconds) (per-host)
[2025-02-24 18:48:12,992][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 18:48:13,019][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_10611.orbax-checkpoint-tmp-8 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_10611
[2025-02-24 18:48:13,024][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_10611`.
[2025-02-24 18:48:13,024][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 18:48:13,026][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_9432
| epoch 10 | 1000/1179 batches | ms/batch 779.51 | Performance/Training accuracy:  0.52 | Performance/Training loss:  1.77
-----------------------------------------------------------------------------------------
| end of epoch  10 | time per epoch: 920.12s |
| Train Metrics | accuracy:  0.52 | loss:  1.76
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.009523183107376099,
    "std": 0.11407002061605453,
    "var": 0.01301196962594986,
    "min": -0.17728492617607117,
    "max": 0.23814570903778076,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.928222119808197,
    "std": 0.09387975931167603,
    "var": 0.008813410066068172,
    "min": 0.728561520576477,
    "max": 1.1686145067214966,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.00015692452143412083,
    "std": 0.0897875726222992,
    "var": 0.008061808533966541,
    "min": -0.2530175745487213,
    "max": 0.22911827266216278,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.04948848485946655,
    "std": 0.04637126624584198,
    "var": 0.0021502943709492683,
    "min": -0.10073114186525345,
    "max": 0.15068647265434265,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.8029428720474243,
    "std": 0.08296877145767212,
    "var": 0.006883817724883556,
    "min": 0.6060432195663452,
    "max": 0.9909371137619019,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00046660215593874454,
    "std": 0.0894031971693039,
    "var": 0.007992932572960854,
    "min": -0.22709646821022034,
    "max": 0.225436270236969,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.04702833294868469,
    "std": 0.04295235872268677,
    "var": 0.0018449050839990377,
    "min": -0.06351318955421448,
    "max": 0.18298938870429993,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.745684802532196,
    "std": 0.08173985034227371,
    "var": 0.006681402679532766,
    "min": 0.5601018071174622,
    "max": 1.0103442668914795,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0008270707912743092,
    "std": 0.08906463533639908,
    "var": 0.007932508364319801,
    "min": -0.2223547399044037,
    "max": 0.22487477958202362,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.03718584030866623,
    "std": 0.046069420874118805,
    "var": 0.002122391713783145,
    "min": -0.0777239054441452,
    "max": 0.16346558928489685,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.8774230480194092,
    "std": 0.09586697816848755,
    "var": 0.009190477430820465,
    "min": 0.6257489919662476,
    "max": 1.1153887510299683,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.00011882461694767699,
    "std": 0.06370723247528076,
    "var": 0.0040586115792393684,
    "min": -0.18198956549167633,
    "max": 0.16656018793582916,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.043327510356903076,
    "std": 0.0469747856259346,
    "var": 0.0022066307719796896,
    "min": -0.0647178366780281,
    "max": 0.29879316687583923,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 1.0482853651046753,
    "std": 0.15231823921203613,
    "var": 0.02320084534585476,
    "min": 0.7876223921775818,
    "max": 1.659500241279602,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 5.814790347358212e-05,
    "std": 0.062371883541345596,
    "var": 0.0038902517408132553,
    "min": -0.1712438315153122,
    "max": 0.1826362907886505,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.025699203833937645,
    "std": 0.03441331535577774,
    "var": 0.0011842763051390648,
    "min": -0.053872089833021164,
    "max": 0.13815999031066895,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.1004929542541504,
    "std": 0.1552472710609436,
    "var": 0.02410171739757061,
    "min": 0.8577225208282471,
    "max": 1.7192637920379639,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0004344912595115602,
    "std": 0.06292633712291718,
    "var": 0.003959724213927984,
    "min": -0.17421427369117737,
    "max": 0.17123228311538696,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": 0.0011000372469425201,
    "std": 0.09623053669929504,
    "var": 0.00926031544804573,
    "min": -0.40212351083755493,
    "max": 0.3926650285720825,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 6.60023870295845e-05,
    "std": 0.09313995391130447,
    "var": 0.008675051853060722,
    "min": -0.3225003480911255,
    "max": 0.31060394644737244,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0022444650530815125,
    "std": 0.0930275022983551,
    "var": 0.008654115721583366,
    "min": -0.30472269654273987,
    "max": 0.3704625368118286,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": 2.584001049399376e-05,
    "std": 0.07293137162923813,
    "var": 0.005318985320627689,
    "min": -0.2713473439216614,
    "max": 0.3068174421787262,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 7.067753904266283e-05,
    "std": 0.0704287737607956,
    "var": 0.004960212390869856,
    "min": -0.26742857694625854,
    "max": 0.28020334243774414,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.00017229549121111631,
    "std": 0.07348558306694031,
    "var": 0.005400131456553936,
    "min": -0.3444167375564575,
    "max": 0.3289080262184143,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.11140894889831543,
    "std": 0.06236431747674942,
    "var": 0.003889308078214526,
    "min": -0.2993926703929901,
    "max": 0.04533316195011139,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.03504026681184769,
    "std": 0.13091443479061127,
    "var": 0.017138591036200523,
    "min": -0.6836923956871033,
    "max": 0.48058223724365234,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.036483604460954666,
    "std": 0.9042447209358215,
    "var": 0.817658543586731,
    "min": -1.8903616666793823,
    "max": 2.3055455684661865,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.12420760840177536,
    "std": 0.047661446034908295,
    "var": 0.002271613571792841,
    "min": -0.26097196340560913,
    "max": -0.008134875446557999,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.0766897052526474,
    "std": 0.09622079879045486,
    "var": 0.009258442558348179,
    "min": -0.41684991121292114,
    "max": 0.24558626115322113,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": -0.0010083516826853156,
    "std": 0.8264833688735962,
    "var": 0.6830747127532959,
    "min": -1.9704116582870483,
    "max": 2.4181020259857178,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.16491404175758362,
    "std": 0.04370788857340813,
    "var": 0.001910379622131586,
    "min": -0.26660555601119995,
    "max": -0.041628506034612656,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.07081840187311172,
    "std": 0.09738858789205551,
    "var": 0.00948453787714243,
    "min": -0.49454429745674133,
    "max": 0.2665965259075165,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.1473684161901474,
    "std": 0.7787929773330688,
    "var": 0.6065185070037842,
    "min": -1.4298079013824463,
    "max": 2.0795271396636963,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.06025698781013489,
    "std": 0.05059816688299179,
    "var": 0.002560174558311701,
    "min": -0.25286051630973816,
    "max": 0.05318208411335945,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.04584114998579025,
    "std": 0.08908747881650925,
    "var": 0.007936579175293446,
    "min": -0.5455964803695679,
    "max": 0.27751702070236206,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": 0.0010183148551732302,
    "std": 0.04397518187761307,
    "var": 0.001933816820383072,
    "min": -0.10685102641582489,
    "max": 0.13332302868366241,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.0003935297718271613,
    "std": 0.08749575167894363,
    "var": 0.0076555064879357815,
    "min": -0.35361260175704956,
    "max": 0.34438732266426086,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.005396679043769836,
    "std": 0.11427029222249985,
    "var": 0.013057698495686054,
    "min": -0.5536186695098877,
    "max": 0.4994713366031647,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.06589840352535248,
    "std": 0.052732232958078384,
    "var": 0.0027806886937469244,
    "min": -0.24467362463474274,
    "max": 0.09110100567340851,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.03290922939777374,
    "std": 0.10307761281728745,
    "var": 0.010624994523823261,
    "min": -0.617927074432373,
    "max": 0.5605374574661255,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": -0.05969482660293579,
    "std": 0.9580366015434265,
    "var": 0.9178341627120972,
    "min": -3.1661698818206787,
    "max": 2.410550594329834,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.029149113222956657,
    "std": 0.04740475118160248,
    "var": 0.002247210592031479,
    "min": -0.23426654934883118,
    "max": 0.0886990875005722,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.01832457073032856,
    "std": 0.10573594272136688,
    "var": 0.01118008978664875,
    "min": -0.510314404964447,
    "max": 0.5291070938110352,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.21831128001213074,
    "std": 0.9753479361534119,
    "var": 0.9513036012649536,
    "min": -2.209777593612671,
    "max": 3.0790810585021973,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.00479664234444499,
    "std": 0.03604194521903992,
    "var": 0.0012990218820050359,
    "min": -0.09991072863340378,
    "max": 0.05085347965359688,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0012549569364637136,
    "std": 0.09244254976511002,
    "var": 0.008545625023543835,
    "min": -0.4493675231933594,
    "max": 0.3149544298648834,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": 0.002533822786062956,
    "std": 0.15152741968631744,
    "var": 0.022960558533668518,
    "min": -0.660736620426178,
    "max": 0.7343237996101379,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -3.5710091590881348,
    "std": 1.0045323371887207,
    "var": 1.0090851783752441,
    "min": -5.174535751342773,
    "max": -1.4331599473953247,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -3.484499931335449,
    "std": 0.9337509870529175,
    "var": 0.8718909025192261,
    "min": -5.093738079071045,
    "max": -1.6654471158981323,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -3.686711549758911,
    "std": 0.9394243359565735,
    "var": 0.8825180530548096,
    "min": -5.123068332672119,
    "max": -1.7938470840454102,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -3.4494192600250244,
    "std": 0.9525250196456909,
    "var": 0.9073039293289185,
    "min": -5.079807758331299,
    "max": -1.7490606307983398,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -3.5633325576782227,
    "std": 0.9426444172859192,
    "var": 0.8885785341262817,
    "min": -5.214022636413574,
    "max": -1.505034327507019,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -3.488276958465576,
    "std": 0.8850598335266113,
    "var": 0.7833309173583984,
    "min": -5.105393409729004,
    "max": -1.7961680889129639,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.65 | loss:  1.19
-----------------------------------------------------------------------------------------
[2025-02-24 19:04:58,468][absl][INFO] - Saving checkpoint at step: 11790
[2025-02-24 19:04:58,469][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 19:04:58,469][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 19:04:58,470][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_11790.
[2025-02-24 19:04:58,478][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 19:04:58,479][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_11790.orbax-checkpoint-tmp-9
[2025-02-24 19:04:58,487][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 19:04:58,513][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 19:04:58,541][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 169.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 53 milliseconds) (per-host)
[2025-02-24 19:04:58,746][absl][INFO] - ChainedFuture completed 1/1 futures in 0.20 seconds.
[2025-02-24 19:04:58,746][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 35.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 258 milliseconds) (per-host)
[2025-02-24 19:04:58,751][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 19:04:58,780][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_11790.orbax-checkpoint-tmp-9 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_11790
[2025-02-24 19:04:58,785][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_11790`.
[2025-02-24 19:04:58,785][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 19:04:58,786][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_10611
| epoch 11 | 1000/1179 batches | ms/batch 786.41 | Performance/Training accuracy:  0.53 | Performance/Training loss:  1.75
-----------------------------------------------------------------------------------------
| end of epoch  11 | time per epoch: 928.50s |
| Train Metrics | accuracy:  0.53 | loss:  1.75
| Eval  Metrics | accuracy:  0.66 | loss:  1.14
-----------------------------------------------------------------------------------------
[2025-02-24 19:21:45,066][absl][INFO] - Saving checkpoint at step: 12969
[2025-02-24 19:21:45,067][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 19:21:45,067][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 19:21:45,069][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_12969.
[2025-02-24 19:21:45,070][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 19:21:45,071][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_12969.orbax-checkpoint-tmp-10
[2025-02-24 19:21:45,078][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 19:21:45,104][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 19:21:45,132][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 170.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 53 milliseconds) (per-host)
[2025-02-24 19:21:45,364][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-24 19:21:45,364][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 285 milliseconds) (per-host)
[2025-02-24 19:21:45,370][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 19:21:45,400][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_12969.orbax-checkpoint-tmp-10 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_12969
[2025-02-24 19:21:45,405][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_12969`.
[2025-02-24 19:21:45,405][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 19:21:45,407][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_11790
| epoch 12 | 1000/1179 batches | ms/batch 793.60 | Performance/Training accuracy:  0.55 | Performance/Training loss:  1.69
-----------------------------------------------------------------------------------------
| end of epoch  12 | time per epoch: 934.98s |
| Train Metrics | accuracy:  0.55 | loss:  1.68
| Eval  Metrics | accuracy:  0.68 | loss:  1.05
-----------------------------------------------------------------------------------------
[2025-02-24 19:38:38,479][absl][INFO] - Saving checkpoint at step: 14148
[2025-02-24 19:38:38,480][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 19:38:38,480][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 19:38:38,481][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_14148.
[2025-02-24 19:38:38,489][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 19:38:38,490][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_14148.orbax-checkpoint-tmp-11
[2025-02-24 19:38:38,496][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 19:38:38,523][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 19:38:38,565][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 134.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 68 milliseconds) (per-host)
[2025-02-24 19:38:38,772][absl][INFO] - ChainedFuture completed 1/1 futures in 0.21 seconds.
[2025-02-24 19:38:38,772][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 274 milliseconds) (per-host)
[2025-02-24 19:38:38,777][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 19:38:38,807][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_14148.orbax-checkpoint-tmp-11 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_14148
[2025-02-24 19:38:38,813][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_14148`.
[2025-02-24 19:38:38,813][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 19:38:38,814][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_12969
| epoch 13 | 1000/1179 batches | ms/batch 794.24 | Performance/Training accuracy:  0.56 | Performance/Training loss:  1.65
-----------------------------------------------------------------------------------------
| end of epoch  13 | time per epoch: 939.22s |
| Train Metrics | accuracy:  0.56 | loss:  1.65
| Eval  Metrics | accuracy:  0.66 | loss:  1.15
-----------------------------------------------------------------------------------------
| epoch 14 | 1000/1179 batches | ms/batch 793.56 | Performance/Training accuracy:  0.57 | Performance/Training loss:  1.60
-----------------------------------------------------------------------------------------
| end of epoch  14 | time per epoch: 935.47s |
| Train Metrics | accuracy:  0.57 | loss:  1.61
| Eval  Metrics | accuracy:  0.69 | loss:  1.02
-----------------------------------------------------------------------------------------
[2025-02-24 20:12:33,202][absl][INFO] - Saving checkpoint at step: 16506
[2025-02-24 20:12:33,204][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 20:12:33,204][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 20:12:33,205][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_16506.
[2025-02-24 20:12:33,219][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 20:12:33,220][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_16506.orbax-checkpoint-tmp-12
[2025-02-24 20:12:33,226][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 20:12:33,252][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 20:12:33,283][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 161.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 56 milliseconds) (per-host)
[2025-02-24 20:12:33,807][absl][INFO] - ChainedFuture completed 1/1 futures in 0.52 seconds.
[2025-02-24 20:12:33,807][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 15.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 580 milliseconds) (per-host)
[2025-02-24 20:12:33,812][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 20:12:33,841][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_16506.orbax-checkpoint-tmp-12 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_16506
[2025-02-24 20:12:33,846][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_16506`.
[2025-02-24 20:12:33,846][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 20:12:33,848][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_14148
| epoch 15 | 1000/1179 batches | ms/batch 807.37 | Performance/Training accuracy:  0.58 | Performance/Training loss:  1.56
-----------------------------------------------------------------------------------------
| end of epoch  15 | time per epoch: 951.17s |
| Train Metrics | accuracy:  0.58 | loss:  1.56
| Eval  Metrics | accuracy:  0.70 | loss:  1.02
-----------------------------------------------------------------------------------------
[2025-02-24 20:29:46,126][absl][INFO] - Saving checkpoint at step: 17685
[2025-02-24 20:29:46,127][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 20:29:46,127][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 20:29:46,129][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_17685.
[2025-02-24 20:29:46,136][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 20:29:46,137][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_17685.orbax-checkpoint-tmp-13
[2025-02-24 20:29:46,144][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 20:29:46,172][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 20:29:46,200][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 165.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 55 milliseconds) (per-host)
[2025-02-24 20:29:46,421][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-24 20:29:46,421][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 275 milliseconds) (per-host)
[2025-02-24 20:29:46,426][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 20:29:46,454][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_17685.orbax-checkpoint-tmp-13 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_17685
[2025-02-24 20:29:46,459][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_17685`.
[2025-02-24 20:29:46,459][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 20:29:46,460][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_16506
| epoch 16 | 1000/1179 batches | ms/batch 823.60 | Performance/Training accuracy:  0.59 | Performance/Training loss:  1.58
-----------------------------------------------------------------------------------------
| end of epoch  16 | time per epoch: 971.19s |
| Train Metrics | accuracy:  0.58 | loss:  1.58
| Eval  Metrics | accuracy:  0.71 | loss:  0.97
-----------------------------------------------------------------------------------------
[2025-02-24 20:47:19,692][absl][INFO] - Saving checkpoint at step: 18864
[2025-02-24 20:47:19,693][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 20:47:19,693][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 20:47:19,695][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_18864.
[2025-02-24 20:47:19,697][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 20:47:19,698][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_18864.orbax-checkpoint-tmp-14
[2025-02-24 20:47:19,704][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 20:47:19,730][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 20:47:19,758][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 172.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 53 milliseconds) (per-host)
[2025-02-24 20:47:19,981][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-24 20:47:19,981][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 275 milliseconds) (per-host)
[2025-02-24 20:47:19,986][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 20:47:20,013][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_18864.orbax-checkpoint-tmp-14 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_18864
[2025-02-24 20:47:20,018][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_18864`.
[2025-02-24 20:47:20,019][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 20:47:20,020][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_17685
| epoch 17 | 1000/1179 batches | ms/batch 810.07 | Performance/Training accuracy:  0.60 | Performance/Training loss:  1.54
-----------------------------------------------------------------------------------------
| end of epoch  17 | time per epoch: 954.86s |
| Train Metrics | accuracy:  0.60 | loss:  1.54
| Eval  Metrics | accuracy:  0.71 | loss:  0.97
-----------------------------------------------------------------------------------------
[2025-02-24 21:04:36,369][absl][INFO] - Saving checkpoint at step: 20043
[2025-02-24 21:04:36,371][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 21:04:36,371][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 21:04:36,372][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_20043.
[2025-02-24 21:04:36,379][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 21:04:36,380][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_20043.orbax-checkpoint-tmp-15
[2025-02-24 21:04:36,389][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 21:04:36,415][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 21:04:36,444][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 167.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-24 21:04:36,652][absl][INFO] - ChainedFuture completed 1/1 futures in 0.21 seconds.
[2025-02-24 21:04:36,652][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 34.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 261 milliseconds) (per-host)
[2025-02-24 21:04:36,657][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 21:04:36,687][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_20043.orbax-checkpoint-tmp-15 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_20043
[2025-02-24 21:04:36,692][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_20043`.
[2025-02-24 21:04:36,692][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 21:04:36,693][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_18864
| epoch 18 | 1000/1179 batches | ms/batch 816.13 | Performance/Training accuracy:  0.60 | Performance/Training loss:  1.51
-----------------------------------------------------------------------------------------
| end of epoch  18 | time per epoch: 961.69s |
| Train Metrics | accuracy:  0.60 | loss:  1.51
| Eval  Metrics | accuracy:  0.70 | loss:  1.00
-----------------------------------------------------------------------------------------
| epoch 19 | 1000/1179 batches | ms/batch 824.14 | Performance/Training accuracy:  0.60 | Performance/Training loss:  1.52
-----------------------------------------------------------------------------------------
| end of epoch  19 | time per epoch: 972.23s |
| Train Metrics | accuracy:  0.60 | loss:  1.51
| Eval  Metrics | accuracy:  0.72 | loss:  0.96
-----------------------------------------------------------------------------------------
[2025-02-24 21:39:37,641][absl][INFO] - Saving checkpoint at step: 22401
[2025-02-24 21:39:37,642][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 21:39:37,642][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 21:39:37,643][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_22401.
[2025-02-24 21:39:37,651][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 21:39:37,651][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_22401.orbax-checkpoint-tmp-16
[2025-02-24 21:39:37,659][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 21:39:37,685][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 21:39:37,721][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 149.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 61 milliseconds) (per-host)
[2025-02-24 21:39:37,910][absl][INFO] - ChainedFuture completed 1/1 futures in 0.19 seconds.
[2025-02-24 21:39:37,911][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 36.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 251 milliseconds) (per-host)
[2025-02-24 21:39:37,916][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 21:39:37,942][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_22401.orbax-checkpoint-tmp-16 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_22401
[2025-02-24 21:39:37,948][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_22401`.
[2025-02-24 21:39:37,948][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 21:39:37,949][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_20043
| epoch 20 | 1000/1179 batches | ms/batch 838.01 | Performance/Training accuracy:  0.62 | Performance/Training loss:  1.45
-----------------------------------------------------------------------------------------
| end of epoch  20 | time per epoch: 987.97s |
| Train Metrics | accuracy:  0.62 | loss:  1.44
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.02606137841939926,
    "std": 0.34822744131088257,
    "var": 0.12126235663890839,
    "min": -0.564083993434906,
    "max": 0.7404795289039612,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6177005767822266,
    "std": 0.14169371128082275,
    "var": 0.020077109336853027,
    "min": 0.34553927183151245,
    "max": 1.3619966506958008,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": 3.722356632351875e-05,
    "std": 0.09186587482690811,
    "var": 0.008439339697360992,
    "min": -0.32009169459342957,
    "max": 0.25812646746635437,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.1703050434589386,
    "std": 0.10263410955667496,
    "var": 0.010533761233091354,
    "min": -0.06890643388032913,
    "max": 0.4094240367412567,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6198941469192505,
    "std": 0.20400139689445496,
    "var": 0.04161657392978668,
    "min": 0.1080021783709526,
    "max": 0.9833735227584839,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 8.770963177084923e-05,
    "std": 0.09198922663927078,
    "var": 0.00846201740205288,
    "min": -0.28337523341178894,
    "max": 0.3083125352859497,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.1791810393333435,
    "std": 0.1261143833398819,
    "var": 0.01590484008193016,
    "min": -0.0290420763194561,
    "max": 0.5443487763404846,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.3959117829799652,
    "std": 0.16422823071479797,
    "var": 0.026970913633704185,
    "min": 0.13106513023376465,
    "max": 1.0164991617202759,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0009459704160690308,
    "std": 0.0925116091966629,
    "var": 0.008558398112654686,
    "min": -0.2887782156467438,
    "max": 0.2885383069515228,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.10467241704463959,
    "std": 0.10731684416532516,
    "var": 0.011516906321048737,
    "min": -0.11140544712543488,
    "max": 0.5558865666389465,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6459478735923767,
    "std": 0.21313804388046265,
    "var": 0.0454278290271759,
    "min": 0.1853361576795578,
    "max": 1.614452600479126,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 6.534842395922169e-05,
    "std": 0.06714661419391632,
    "var": 0.004508668091148138,
    "min": -0.23166364431381226,
    "max": 0.21243682503700256,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.0962352454662323,
    "std": 0.14929695427417755,
    "var": 0.0222895797342062,
    "min": -0.4458085596561432,
    "max": 0.6340277791023254,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.912988543510437,
    "std": 0.2943866550922394,
    "var": 0.08666350692510605,
    "min": 0.3826892077922821,
    "max": 2.3402597904205322,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00011780389468185604,
    "std": 0.059849828481674194,
    "var": 0.003582002129405737,
    "min": -0.2342558354139328,
    "max": 0.21899867057800293,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.01956385374069214,
    "std": 0.08452130854129791,
    "var": 0.0071438513696193695,
    "min": -0.2585175037384033,
    "max": 0.18322540819644928,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.0546073913574219,
    "std": 0.2962922751903534,
    "var": 0.08778911828994751,
    "min": 0.6391059756278992,
    "max": 2.681248903274536,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0003920409071724862,
    "std": 0.063517726957798,
    "var": 0.00403450196608901,
    "min": -0.20835255086421967,
    "max": 0.21265138685703278,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": 0.0008269698591902852,
    "std": 0.10151612013578415,
    "var": 0.010305522941052914,
    "min": -0.4912777543067932,
    "max": 0.6061511039733887,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0015119491145014763,
    "std": 0.10568174719810486,
    "var": 0.011168631725013256,
    "min": -0.4623851776123047,
    "max": 0.4499611556529999,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0029411809518933296,
    "std": 0.10554372519254684,
    "var": 0.011139477603137493,
    "min": -0.5034334659576416,
    "max": 0.4154801666736603,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0008392392192035913,
    "std": 0.1003170982003212,
    "var": 0.01006352063268423,
    "min": -0.4191400408744812,
    "max": 0.4570767283439636,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.000522900721989572,
    "std": 0.09377153217792511,
    "var": 0.008793100714683533,
    "min": -0.5079793334007263,
    "max": 0.49359652400016785,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0003961476613767445,
    "std": 0.0991821214556694,
    "var": 0.009837093763053417,
    "min": -0.4822418689727783,
    "max": 0.48423051834106445,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.26992177963256836,
    "std": 0.12232928723096848,
    "var": 0.014964453876018524,
    "min": -0.5673255324363708,
    "max": -0.0035104998387396336,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.06609968096017838,
    "std": 0.1998475193977356,
    "var": 0.0399390310049057,
    "min": -0.900626003742218,
    "max": 0.7484293580055237,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.26116761565208435,
    "std": 0.9846565127372742,
    "var": 0.9695484638214111,
    "min": -2.252293109893799,
    "max": 3.2740530967712402,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.2861142158508301,
    "std": 0.09206443279981613,
    "var": 0.008475860580801964,
    "min": -0.5013483762741089,
    "max": -0.04023444280028343,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.14840559661388397,
    "std": 0.12743492424488068,
    "var": 0.01623966172337532,
    "min": -0.6726701259613037,
    "max": 0.29155969619750977,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.5751153230667114,
    "std": 0.6565693616867065,
    "var": 0.4310833811759949,
    "min": -0.5795530676841736,
    "max": 2.573740005493164,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.3813267648220062,
    "std": 0.06224086880683899,
    "var": 0.003873925656080246,
    "min": -0.5392013192176819,
    "max": -0.22099418938159943,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.1324816346168518,
    "std": 0.12671424448490143,
    "var": 0.016056498512625694,
    "min": -0.6771349906921387,
    "max": 0.3546201288700104,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.4211992919445038,
    "std": 0.49932312965393066,
    "var": 0.24932357668876648,
    "min": -0.5206378698348999,
    "max": 1.6271569728851318,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.12814292311668396,
    "std": 0.08925153315067291,
    "var": 0.00796583667397499,
    "min": -0.40079084038734436,
    "max": 0.07188426703214645,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07949278503656387,
    "std": 0.1301213651895523,
    "var": 0.016931569203734398,
    "min": -0.927413821220398,
    "max": 0.4355618357658386,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.004586021415889263,
    "std": 0.02436050772666931,
    "var": 0.0005934343207627535,
    "min": -0.10043025016784668,
    "max": 0.06068631261587143,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.0006812732317484915,
    "std": 0.09814585000276566,
    "var": 0.009632606990635395,
    "min": -0.6328094601631165,
    "max": 0.7426501512527466,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.018091272562742233,
    "std": 0.24703849852085114,
    "var": 0.06102801859378815,
    "min": -1.1332262754440308,
    "max": 1.5020941495895386,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.1562478393316269,
    "std": 0.10711627453565598,
    "var": 0.01147389691323042,
    "min": -0.44351276755332947,
    "max": 0.19223453104496002,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.0646657794713974,
    "std": 0.13790519535541534,
    "var": 0.019017845392227173,
    "min": -1.2161409854888916,
    "max": 0.6337605118751526,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.012741251848638058,
    "std": 1.0800645351409912,
    "var": 1.1665394306182861,
    "min": -2.7491703033447266,
    "max": 2.558767795562744,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.032602209597826004,
    "std": 0.09372838586568832,
    "var": 0.008785010315477848,
    "min": -0.3701455891132355,
    "max": 0.16527047753334045,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.04017492011189461,
    "std": 0.14280422031879425,
    "var": 0.020393045619130135,
    "min": -0.7785624265670776,
    "max": 0.6167515516281128,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.40980154275894165,
    "std": 0.9970811605453491,
    "var": 0.9941709041595459,
    "min": -2.4850516319274902,
    "max": 3.106133460998535,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.011807424016296864,
    "std": 0.0806984156370163,
    "var": 0.006512234918773174,
    "min": -0.15925896167755127,
    "max": 0.13217349350452423,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0010518906638026237,
    "std": 0.15014855563640594,
    "var": 0.022544588893651962,
    "min": -0.675656795501709,
    "max": 0.5496171116828918,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.0005596449482254684,
    "std": 0.24263568222522736,
    "var": 0.058872077614068985,
    "min": -1.2516660690307617,
    "max": 1.3482545614242554,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -2.1780338287353516,
    "std": 0.6458832025527954,
    "var": 0.4171651005744934,
    "min": -3.3483967781066895,
    "max": -0.25104400515556335,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.8909008502960205,
    "std": 0.6773540377616882,
    "var": 0.4588085412979126,
    "min": -3.2162744998931885,
    "max": -0.6251596808433533,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -2.0593409538269043,
    "std": 0.5922729969024658,
    "var": 0.35078731179237366,
    "min": -3.190382242202759,
    "max": -0.6267780065536499,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -2.025282859802246,
    "std": 0.6005915999412537,
    "var": 0.3607102632522583,
    "min": -3.265305280685425,
    "max": -0.8689924478530884,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -2.3221755027770996,
    "std": 0.6118940711021423,
    "var": 0.3744143545627594,
    "min": -3.409437417984009,
    "max": -0.6716887354850769,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -2.1851084232330322,
    "std": 0.5609619617462158,
    "var": 0.3146783113479614,
    "min": -3.167083740234375,
    "max": -0.6988309025764465,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.72 | loss:  0.97
-----------------------------------------------------------------------------------------
[2025-02-24 21:57:28,587][absl][INFO] - Saving checkpoint at step: 23580
[2025-02-24 21:57:28,588][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 21:57:28,588][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 21:57:28,590][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_23580.
[2025-02-24 21:57:28,591][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 21:57:28,592][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_23580.orbax-checkpoint-tmp-17
[2025-02-24 21:57:28,599][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 21:57:28,625][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 21:57:28,654][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 168.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-24 21:57:28,858][absl][INFO] - ChainedFuture completed 1/1 futures in 0.20 seconds.
[2025-02-24 21:57:28,858][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 35.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 257 milliseconds) (per-host)
[2025-02-24 21:57:28,863][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 21:57:28,892][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_23580.orbax-checkpoint-tmp-17 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_23580
[2025-02-24 21:57:28,898][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_23580`.
[2025-02-24 21:57:28,898][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 21:57:28,899][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_22401
| epoch 21 | 1000/1179 batches | ms/batch 826.15 | Performance/Training accuracy:  0.61 | Performance/Training loss:  1.47
-----------------------------------------------------------------------------------------
| end of epoch  21 | time per epoch: 976.87s |
| Train Metrics | accuracy:  0.61 | loss:  1.47
| Eval  Metrics | accuracy:  0.69 | loss:  1.02
-----------------------------------------------------------------------------------------
| epoch 22 | 1000/1179 batches | ms/batch 835.69 | Performance/Training accuracy:  0.62 | Performance/Training loss:  1.43
-----------------------------------------------------------------------------------------
| end of epoch  22 | time per epoch: 985.38s |
| Train Metrics | accuracy:  0.62 | loss:  1.42
| Eval  Metrics | accuracy:  0.73 | loss:  0.89
-----------------------------------------------------------------------------------------
[2025-02-24 22:32:59,976][absl][INFO] - Saving checkpoint at step: 25938
[2025-02-24 22:32:59,978][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 22:32:59,978][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 22:32:59,979][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_25938.
[2025-02-24 22:32:59,987][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 22:32:59,988][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_25938.orbax-checkpoint-tmp-18
[2025-02-24 22:32:59,994][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 22:33:00,021][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 22:33:00,050][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 165.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 55 milliseconds) (per-host)
[2025-02-24 22:33:00,256][absl][INFO] - ChainedFuture completed 1/1 futures in 0.21 seconds.
[2025-02-24 22:33:00,256][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 34.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 261 milliseconds) (per-host)
[2025-02-24 22:33:00,262][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 22:33:00,291][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_25938.orbax-checkpoint-tmp-18 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_25938
[2025-02-24 22:33:00,297][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_25938`.
[2025-02-24 22:33:00,297][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 22:33:00,298][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_23580
| epoch 23 | 1000/1179 batches | ms/batch 841.14 | Performance/Training accuracy:  0.63 | Performance/Training loss:  1.43
-----------------------------------------------------------------------------------------
| end of epoch  23 | time per epoch: 992.24s |
| Train Metrics | accuracy:  0.63 | loss:  1.43
| Eval  Metrics | accuracy:  0.75 | loss:  0.88
-----------------------------------------------------------------------------------------
[2025-02-24 22:50:58,222][absl][INFO] - Saving checkpoint at step: 27117
[2025-02-24 22:50:58,223][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-24 22:50:58,224][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-24 22:50:58,225][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_27117.
[2025-02-24 22:50:58,233][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-24 22:50:58,234][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_27117.orbax-checkpoint-tmp-19
[2025-02-24 22:50:58,240][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-24 22:50:58,267][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-24 22:50:58,296][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 165.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 55 milliseconds) (per-host)
[2025-02-24 22:50:58,856][absl][INFO] - ChainedFuture completed 1/1 futures in 0.56 seconds.
[2025-02-24 22:50:58,857][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 14.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 616 milliseconds) (per-host)
[2025-02-24 22:50:58,862][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-24 22:50:58,891][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_27117.orbax-checkpoint-tmp-19 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_27117
[2025-02-24 22:50:58,896][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_27117`.
[2025-02-24 22:50:58,896][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-24 22:50:58,897][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_25938
| epoch 24 | 1000/1179 batches | ms/batch 859.33 | Performance/Training accuracy:  0.62 | Performance/Training loss:  1.45
-----------------------------------------------------------------------------------------
| end of epoch  24 | time per epoch: 1011.45s |
| Train Metrics | accuracy:  0.62 | loss:  1.45
| Eval  Metrics | accuracy:  0.75 | loss:  0.88
-----------------------------------------------------------------------------------------
| epoch 25 | 1000/1179 batches | ms/batch 861.76 | Performance/Training accuracy:  0.63 | Performance/Training loss:  1.41
-----------------------------------------------------------------------------------------
| end of epoch  25 | time per epoch: 1015.95s |
| Train Metrics | accuracy:  0.63 | loss:  1.40
| Eval  Metrics | accuracy:  0.74 | loss:  0.91
-----------------------------------------------------------------------------------------
| epoch 26 | 1000/1179 batches | ms/batch 871.75 | Performance/Training accuracy:  0.63 | Performance/Training loss:  1.41
-----------------------------------------------------------------------------------------
| end of epoch  26 | time per epoch: 1027.59s |
| Train Metrics | accuracy:  0.64 | loss:  1.41
| Eval  Metrics | accuracy:  0.73 | loss:  0.92
-----------------------------------------------------------------------------------------
| epoch 27 | 1000/1179 batches | ms/batch 882.17 | Performance/Training accuracy:  0.64 | Performance/Training loss:  1.37
-----------------------------------------------------------------------------------------
| end of epoch  27 | time per epoch: 1045.26s |
| Train Metrics | accuracy:  0.64 | loss:  1.38
| Eval  Metrics | accuracy:  0.74 | loss:  0.87
-----------------------------------------------------------------------------------------
| epoch 28 | 1000/1179 batches | ms/batch 924.59 | Performance/Training accuracy:  0.64 | Performance/Training loss:  1.38
-----------------------------------------------------------------------------------------
| end of epoch  28 | time per epoch: 1088.45s |
| Train Metrics | accuracy:  0.64 | loss:  1.37
| Eval  Metrics | accuracy:  0.75 | loss:  0.86
-----------------------------------------------------------------------------------------
| epoch 29 | 1000/1179 batches | ms/batch 904.59 | Performance/Training accuracy:  0.65 | Performance/Training loss:  1.38
-----------------------------------------------------------------------------------------
| end of epoch  29 | time per epoch: 1066.26s |
| Train Metrics | accuracy:  0.65 | loss:  1.37
| Eval  Metrics | accuracy:  0.75 | loss:  0.85
-----------------------------------------------------------------------------------------
[2025-02-25 00:44:24,577][absl][INFO] - Saving checkpoint at step: 34191
[2025-02-25 00:44:24,580][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 00:44:24,580][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 00:44:24,581][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_34191.
[2025-02-25 00:44:24,596][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 00:44:24,597][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_34191.orbax-checkpoint-tmp-20
[2025-02-25 00:44:24,604][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 00:44:24,632][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 00:44:24,661][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 162.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 56 milliseconds) (per-host)
[2025-02-25 00:44:24,869][absl][INFO] - ChainedFuture completed 1/1 futures in 0.21 seconds.
[2025-02-25 00:44:24,870][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 34.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 264 milliseconds) (per-host)
[2025-02-25 00:44:24,874][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 00:44:24,902][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_34191.orbax-checkpoint-tmp-20 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_34191
[2025-02-25 00:44:24,907][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_34191`.
[2025-02-25 00:44:24,907][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 00:44:24,908][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_27117
| epoch 30 | 1000/1179 batches | ms/batch 904.09 | Performance/Training accuracy:  0.65 | Performance/Training loss:  1.36
-----------------------------------------------------------------------------------------
| end of epoch  30 | time per epoch: 1066.87s |
| Train Metrics | accuracy:  0.65 | loss:  1.35
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.06628957390785217,
    "std": 0.30424901843070984,
    "var": 0.09256746619939804,
    "min": -0.438632994890213,
    "max": 0.6985148787498474,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.419465035200119,
    "std": 0.16320042312145233,
    "var": 0.026634380221366882,
    "min": 0.1487959623336792,
    "max": 1.414294719696045,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": 7.925012141640764e-06,
    "std": 0.09490256011486053,
    "var": 0.009006495587527752,
    "min": -0.3827861547470093,
    "max": 0.3390965461730957,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.23712269961833954,
    "std": 0.15955069661140442,
    "var": 0.025456426665186882,
    "min": -0.0451657772064209,
    "max": 0.7160481214523315,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.5444323420524597,
    "std": 0.2584269046783447,
    "var": 0.06678446382284164,
    "min": 0.024470612406730652,
    "max": 1.1855443716049194,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00023266032803803682,
    "std": 0.09726930409669876,
    "var": 0.009461317211389542,
    "min": -0.35038191080093384,
    "max": 0.33503463864326477,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.23237475752830505,
    "std": 0.23868058621883392,
    "var": 0.05696842074394226,
    "min": -0.03452855721116066,
    "max": 0.909883439540863,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.2634778618812561,
    "std": 0.15368857979774475,
    "var": 0.023620180785655975,
    "min": 0.05306076630949974,
    "max": 1.0117250680923462,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0009563976782374084,
    "std": 0.09843963384628296,
    "var": 0.0096903620287776,
    "min": -0.35817521810531616,
    "max": 0.4399275481700897,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.1482979953289032,
    "std": 0.14830999076366425,
    "var": 0.02199585549533367,
    "min": -0.11688526719808578,
    "max": 0.7987934947013855,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.5385270118713379,
    "std": 0.2475380003452301,
    "var": 0.06127506494522095,
    "min": 0.09666383266448975,
    "max": 2.1980810165405273,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.00034023632179014385,
    "std": 0.07332515716552734,
    "var": 0.005376578774303198,
    "min": -0.347772479057312,
    "max": 0.29841649532318115,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.12128123641014099,
    "std": 0.21335765719413757,
    "var": 0.04552149027585983,
    "min": -0.6300501823425293,
    "max": 0.7905236482620239,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.7978967428207397,
    "std": 0.31980180740356445,
    "var": 0.10227318853139877,
    "min": 0.24014228582382202,
    "max": 2.2270407676696777,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 5.423928814707324e-05,
    "std": 0.058496829122304916,
    "var": 0.0034218793734908104,
    "min": -0.3366861045360565,
    "max": 0.22940613329410553,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.008498081937432289,
    "std": 0.1029009073972702,
    "var": 0.010588596574962139,
    "min": -0.40849003195762634,
    "max": 0.25652462244033813,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.9867982864379883,
    "std": 0.3148971498012543,
    "var": 0.09916021674871445,
    "min": 0.46299681067466736,
    "max": 2.882077932357788,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0002945909509435296,
    "std": 0.06711353361606598,
    "var": 0.004504226613789797,
    "min": -0.27578866481781006,
    "max": 0.25773298740386963,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": 0.0004629245959222317,
    "std": 0.11187794804573059,
    "var": 0.01251667644828558,
    "min": -0.6162566542625427,
    "max": 0.9139283299446106,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0037144708912819624,
    "std": 0.12121482938528061,
    "var": 0.014693035744130611,
    "min": -0.5263006687164307,
    "max": 0.6084243655204773,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0011334295850247145,
    "std": 0.1216457411646843,
    "var": 0.014797687530517578,
    "min": -0.7430286407470703,
    "max": 0.5944893956184387,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0011127479374408722,
    "std": 0.11726520955562592,
    "var": 0.013751129619777203,
    "min": -0.816034197807312,
    "max": 1.2898708581924438,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00016887302626855671,
    "std": 0.10804338753223419,
    "var": 0.011673374101519585,
    "min": -0.6515733599662781,
    "max": 0.7487074732780457,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0009070287924259901,
    "std": 0.11492280662059784,
    "var": 0.013207251206040382,
    "min": -0.5743647813796997,
    "max": 0.6714219450950623,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.36069726943969727,
    "std": 0.16973818838596344,
    "var": 0.028811052441596985,
    "min": -0.8028793931007385,
    "max": -0.04069782793521881,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07569564878940582,
    "std": 0.2629733085632324,
    "var": 0.06915495544672012,
    "min": -1.103413462638855,
    "max": 0.9382633566856384,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.5673340559005737,
    "std": 0.8645865321159363,
    "var": 0.7475098967552185,
    "min": -1.6011403799057007,
    "max": 2.788064956665039,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.30315762758255005,
    "std": 0.11179352551698685,
    "var": 0.012497792020440102,
    "min": -0.6087180972099304,
    "max": -0.056841105222702026,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.16391699016094208,
    "std": 0.15803097188472748,
    "var": 0.024973787367343903,
    "min": -0.9817304015159607,
    "max": 0.4059430956840515,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.020058512687683,
    "std": 0.9074258208274841,
    "var": 0.8234216570854187,
    "min": -0.6683250665664673,
    "max": 4.21311092376709,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.4018990993499756,
    "std": 0.07057983428239822,
    "var": 0.0049815126694738865,
    "min": -0.576682448387146,
    "max": -0.20208045840263367,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.1450701355934143,
    "std": 0.1585584282875061,
    "var": 0.025140775367617607,
    "min": -0.7231608629226685,
    "max": 0.41400834918022156,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.5714894533157349,
    "std": 0.5062052011489868,
    "var": 0.2562437057495117,
    "min": -0.3677217364311218,
    "max": 2.3295199871063232,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.14277388155460358,
    "std": 0.09945961833000183,
    "var": 0.009892216883599758,
    "min": -0.48179197311401367,
    "max": 0.0858069509267807,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08823362737894058,
    "std": 0.1528867781162262,
    "var": 0.023374365642666817,
    "min": -0.9023098945617676,
    "max": 0.5596070289611816,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0005305185914039612,
    "std": 0.013672770000994205,
    "var": 0.00018694465688895434,
    "min": -0.0397893488407135,
    "max": 0.035775478929281235,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.000863189809024334,
    "std": 0.11697898805141449,
    "var": 0.013684083707630634,
    "min": -0.8612576127052307,
    "max": 0.9940528869628906,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.05030888691544533,
    "std": 0.35028624534606934,
    "var": 0.12270045280456543,
    "min": -2.2551705837249756,
    "max": 2.1109020709991455,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.18291369080543518,
    "std": 0.12425964325666428,
    "var": 0.015440458431839943,
    "min": -0.5076006650924683,
    "max": 0.1851867437362671,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.0780109167098999,
    "std": 0.1584867388010025,
    "var": 0.025118043646216393,
    "min": -1.2374144792556763,
    "max": 0.6614508628845215,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.11143483966588974,
    "std": 1.1472699642181396,
    "var": 1.3162285089492798,
    "min": -3.0818865299224854,
    "max": 2.836784839630127,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.007668661884963512,
    "std": 0.12511470913887024,
    "var": 0.015653690323233604,
    "min": -0.5088380575180054,
    "max": 0.24884843826293945,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.04698282852768898,
    "std": 0.16333727538585663,
    "var": 0.026679065078496933,
    "min": -0.9272885322570801,
    "max": 0.6040483713150024,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.5016487836837769,
    "std": 0.9559153914451599,
    "var": 0.9137741923332214,
    "min": -2.572075128555298,
    "max": 3.3310599327087402,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.014195458963513374,
    "std": 0.09246254712343216,
    "var": 0.008549323305487633,
    "min": -0.19487950205802917,
    "max": 0.1188870295882225,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.00013727106852456927,
    "std": 0.19089695811271667,
    "var": 0.03644165024161339,
    "min": -0.6907870769500732,
    "max": 0.7529504895210266,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.0014556834939867258,
    "std": 0.29079878330230713,
    "var": 0.08456393331289291,
    "min": -1.617020845413208,
    "max": 1.7116042375564575,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.4494743347167969,
    "std": 0.5428789854049683,
    "var": 0.29471760988235474,
    "min": -2.870908260345459,
    "max": 0.2478581666946411,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.1395387649536133,
    "std": 0.5868977904319763,
    "var": 0.3444490432739258,
    "min": -2.6782519817352295,
    "max": 0.08472815901041031,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.2862534523010254,
    "std": 0.5127110481262207,
    "var": 0.2628726363182068,
    "min": -2.9961564540863037,
    "max": -0.06159064546227455,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.4237319231033325,
    "std": 0.5566487312316895,
    "var": 0.3098578453063965,
    "min": -3.117818593978882,
    "max": -0.09729191660881042,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.717210292816162,
    "std": 0.5224232077598572,
    "var": 0.27292600274086,
    "min": -2.8235177993774414,
    "max": -0.10019931197166443,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.6006288528442383,
    "std": 0.5451619625091553,
    "var": 0.29720160365104675,
    "min": -2.6828670501708984,
    "max": -0.3813911974430084,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.75 | loss:  0.86
-----------------------------------------------------------------------------------------
| epoch 31 | 1000/1179 batches | ms/batch 915.99 | Performance/Training accuracy:  0.65 | Performance/Training loss:  1.36
-----------------------------------------------------------------------------------------
| end of epoch  31 | time per epoch: 1080.35s |
| Train Metrics | accuracy:  0.65 | loss:  1.35
| Eval  Metrics | accuracy:  0.76 | loss:  0.82
-----------------------------------------------------------------------------------------
[2025-02-25 01:23:25,760][absl][INFO] - Saving checkpoint at step: 36549
[2025-02-25 01:23:25,761][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 01:23:25,761][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 01:23:25,763][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_36549.
[2025-02-25 01:23:25,770][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 01:23:25,771][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_36549.orbax-checkpoint-tmp-21
[2025-02-25 01:23:25,777][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 01:23:25,804][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 01:23:25,833][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 166.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-25 01:23:26,056][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-25 01:23:26,056][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 278 milliseconds) (per-host)
[2025-02-25 01:23:26,061][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 01:23:26,087][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_36549.orbax-checkpoint-tmp-21 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_36549
[2025-02-25 01:23:26,092][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_36549`.
[2025-02-25 01:23:26,092][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 01:23:26,094][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_34191
| epoch 32 | 1000/1179 batches | ms/batch 934.04 | Performance/Training accuracy:  0.65 | Performance/Training loss:  1.38
-----------------------------------------------------------------------------------------
| end of epoch  32 | time per epoch: 1103.28s |
| Train Metrics | accuracy:  0.65 | loss:  1.38
| Eval  Metrics | accuracy:  0.76 | loss:  0.82
-----------------------------------------------------------------------------------------
[2025-02-25 01:43:29,336][absl][INFO] - Saving checkpoint at step: 37728
[2025-02-25 01:43:29,338][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 01:43:29,338][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 01:43:29,339][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_37728.
[2025-02-25 01:43:29,347][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 01:43:29,348][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_37728.orbax-checkpoint-tmp-22
[2025-02-25 01:43:29,354][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 01:43:29,381][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 01:43:29,411][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 163.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 56 milliseconds) (per-host)
[2025-02-25 01:43:29,644][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-25 01:43:29,644][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 288 milliseconds) (per-host)
[2025-02-25 01:43:29,649][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 01:43:29,676][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_37728.orbax-checkpoint-tmp-22 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_37728
[2025-02-25 01:43:29,682][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_37728`.
[2025-02-25 01:43:29,682][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 01:43:29,683][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_36549
| epoch 33 | 1000/1179 batches | ms/batch 939.74 | Performance/Training accuracy:  0.66 | Performance/Training loss:  1.33
-----------------------------------------------------------------------------------------
| end of epoch  33 | time per epoch: 1109.18s |
| Train Metrics | accuracy:  0.66 | loss:  1.33
| Eval  Metrics | accuracy:  0.75 | loss:  0.83
-----------------------------------------------------------------------------------------
| epoch 34 | 1000/1179 batches | ms/batch 947.78 | Performance/Training accuracy:  0.66 | Performance/Training loss:  1.31
-----------------------------------------------------------------------------------------
| end of epoch  34 | time per epoch: 1118.75s |
| Train Metrics | accuracy:  0.66 | loss:  1.32
| Eval  Metrics | accuracy:  0.76 | loss:  0.80
-----------------------------------------------------------------------------------------
| epoch 35 | 1000/1179 batches | ms/batch 959.65 | Performance/Training accuracy:  0.65 | Performance/Training loss:  1.36
-----------------------------------------------------------------------------------------
| end of epoch  35 | time per epoch: 1132.02s |
| Train Metrics | accuracy:  0.65 | loss:  1.36
| Eval  Metrics | accuracy:  0.77 | loss:  0.80
-----------------------------------------------------------------------------------------
[2025-02-25 02:44:40,098][absl][INFO] - Saving checkpoint at step: 41265
[2025-02-25 02:44:40,101][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 02:44:40,101][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 02:44:40,102][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_41265.
[2025-02-25 02:44:40,110][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 02:44:40,111][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_41265.orbax-checkpoint-tmp-23
[2025-02-25 02:44:40,119][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 02:44:40,145][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 02:44:40,173][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 170.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 53 milliseconds) (per-host)
[2025-02-25 02:44:47,364][absl][INFO] - ChainedFuture completed 1/1 futures in 7.19 seconds.
[2025-02-25 02:44:47,365][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 1.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 7 seconds) (per-host)
[2025-02-25 02:44:47,371][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 02:44:47,611][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_41265.orbax-checkpoint-tmp-23 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_41265
[2025-02-25 02:44:47,617][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_41265`.
[2025-02-25 02:44:47,617][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 02:44:47,618][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_37728
| epoch 36 | 1000/1179 batches | ms/batch 972.82 | Performance/Training accuracy:  0.66 | Performance/Training loss:  1.31
-----------------------------------------------------------------------------------------
| end of epoch  36 | time per epoch: 1147.65s |
| Train Metrics | accuracy:  0.67 | loss:  1.30
| Eval  Metrics | accuracy:  0.77 | loss:  0.77
-----------------------------------------------------------------------------------------
[2025-02-25 03:05:42,411][absl][INFO] - Saving checkpoint at step: 42444
[2025-02-25 03:05:42,413][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 03:05:42,413][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 03:05:42,414][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_42444.
[2025-02-25 03:05:42,422][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 03:05:42,423][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_42444.orbax-checkpoint-tmp-24
[2025-02-25 03:05:42,429][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 03:05:42,456][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 03:05:42,484][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 168.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-25 03:05:42,705][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-25 03:05:42,706][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 275 milliseconds) (per-host)
[2025-02-25 03:05:42,711][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 03:05:42,738][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_42444.orbax-checkpoint-tmp-24 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_42444
[2025-02-25 03:05:42,743][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_42444`.
[2025-02-25 03:05:42,743][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 03:05:42,744][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_41265
| epoch 37 | 1000/1179 batches | ms/batch 990.88 | Performance/Training accuracy:  0.66 | Performance/Training loss:  1.31
-----------------------------------------------------------------------------------------
| end of epoch  37 | time per epoch: 1168.71s |
| Train Metrics | accuracy:  0.66 | loss:  1.32
| Eval  Metrics | accuracy:  0.77 | loss:  0.79
-----------------------------------------------------------------------------------------
| epoch 38 | 1000/1179 batches | ms/batch 997.67 | Performance/Training accuracy:  0.66 | Performance/Training loss:  1.31
-----------------------------------------------------------------------------------------
| end of epoch  38 | time per epoch: 1177.20s |
| Train Metrics | accuracy:  0.66 | loss:  1.31
| Eval  Metrics | accuracy:  0.78 | loss:  0.76
-----------------------------------------------------------------------------------------
[2025-02-25 03:48:26,497][absl][INFO] - Saving checkpoint at step: 44802
[2025-02-25 03:48:26,498][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 03:48:26,498][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 03:48:26,500][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_44802.
[2025-02-25 03:48:26,507][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 03:48:26,508][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_44802.orbax-checkpoint-tmp-25
[2025-02-25 03:48:26,515][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 03:48:26,542][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 03:48:26,572][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 162.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 56 milliseconds) (per-host)
[2025-02-25 03:48:26,779][absl][INFO] - ChainedFuture completed 1/1 futures in 0.21 seconds.
[2025-02-25 03:48:26,779][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 34.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 263 milliseconds) (per-host)
[2025-02-25 03:48:26,783][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 03:48:26,810][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_44802.orbax-checkpoint-tmp-25 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_44802
[2025-02-25 03:48:26,815][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_44802`.
[2025-02-25 03:48:26,816][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 03:48:26,817][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_42444
| epoch 39 | 1000/1179 batches | ms/batch 1007.83 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.31
-----------------------------------------------------------------------------------------
| end of epoch  39 | time per epoch: 1189.81s |
| Train Metrics | accuracy:  0.67 | loss:  1.31
| Eval  Metrics | accuracy:  0.76 | loss:  0.81
-----------------------------------------------------------------------------------------
| epoch 40 | 1000/1179 batches | ms/batch 1019.81 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.30
-----------------------------------------------------------------------------------------
| end of epoch  40 | time per epoch: 1203.84s |
| Train Metrics | accuracy:  0.67 | loss:  1.30
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.10181733220815659,
    "std": 0.25873398780822754,
    "var": 0.06694327294826508,
    "min": -0.3287689983844757,
    "max": 0.7029904723167419,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.3331852853298187,
    "std": 0.16719822585582733,
    "var": 0.027955245226621628,
    "min": 0.10230980813503265,
    "max": 1.3261045217514038,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": 5.8209563576383516e-05,
    "std": 0.09813976287841797,
    "var": 0.009631412103772163,
    "min": -0.42931240797042847,
    "max": 0.4013148248195648,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.24474339187145233,
    "std": 0.18165001273155212,
    "var": 0.03299672529101372,
    "min": -0.11076442152261734,
    "max": 0.7720616459846497,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.4779958128929138,
    "std": 0.2791389226913452,
    "var": 0.07791852951049805,
    "min": 0.0654802918434143,
    "max": 1.412645936012268,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00036989874206483364,
    "std": 0.10140726715326309,
    "var": 0.010283434763550758,
    "min": -0.43909528851509094,
    "max": 0.3817133605480194,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2522341012954712,
    "std": 0.26449835300445557,
    "var": 0.06995938718318939,
    "min": -0.019423125311732292,
    "max": 0.9231564402580261,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.2470240294933319,
    "std": 0.16272391378879547,
    "var": 0.026479072868824005,
    "min": 0.06365534663200378,
    "max": 1.2685003280639648,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.000807068427093327,
    "std": 0.10381492972373962,
    "var": 0.010777540504932404,
    "min": -0.4443089962005615,
    "max": 0.5572600364685059,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.15732942521572113,
    "std": 0.1704876869916916,
    "var": 0.02906605415046215,
    "min": -0.20062148571014404,
    "max": 0.9124453663825989,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.5252889394760132,
    "std": 0.2544878125190735,
    "var": 0.06476404517889023,
    "min": 0.07785778492689133,
    "max": 2.2159101963043213,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0004782556788995862,
    "std": 0.07716207951307297,
    "var": 0.005953986197710037,
    "min": -0.5276678204536438,
    "max": 0.48722970485687256,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.12412363290786743,
    "std": 0.2401473969221115,
    "var": 0.057670772075653076,
    "min": -0.6460709571838379,
    "max": 0.9398930072784424,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.7470407485961914,
    "std": 0.31837162375450134,
    "var": 0.10136048495769501,
    "min": 0.19549232721328735,
    "max": 2.2801647186279297,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00017318273603450507,
    "std": 0.0582619309425354,
    "var": 0.0033944526221603155,
    "min": -0.38700950145721436,
    "max": 0.2749212980270386,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.024542026221752167,
    "std": 0.10654608905315399,
    "var": 0.01135206874459982,
    "min": -0.46808114647865295,
    "max": 0.22214607894420624,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.9959670901298523,
    "std": 0.29968705773353577,
    "var": 0.08981233835220337,
    "min": 0.45409926772117615,
    "max": 2.7395920753479004,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0002646201755851507,
    "std": 0.07130762934684753,
    "var": 0.005084778182208538,
    "min": -0.39347535371780396,
    "max": 0.3393750488758087,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": 0.0005157169653102756,
    "std": 0.11427950859069824,
    "var": 0.013059805147349834,
    "min": -0.7110021710395813,
    "max": 1.0037837028503418,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.003959274850785732,
    "std": 0.1212645173072815,
    "var": 0.014705082401633263,
    "min": -0.640317976474762,
    "max": 0.6011022329330444,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": -4.666063978220336e-05,
    "std": 0.12315680831670761,
    "var": 0.0151675995439291,
    "min": -0.6221025586128235,
    "max": 0.5483705997467041,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0002471804909873754,
    "std": 0.11595718562602997,
    "var": 0.01344607025384903,
    "min": -1.1706061363220215,
    "max": 1.4096957445144653,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0005329191335476935,
    "std": 0.10761779546737671,
    "var": 0.01158159039914608,
    "min": -0.6289461851119995,
    "max": 1.080264925956726,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0009937218856066465,
    "std": 0.11630679666996002,
    "var": 0.013527270406484604,
    "min": -0.6544843316078186,
    "max": 0.6339329481124878,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.40619683265686035,
    "std": 0.1823468953371048,
    "var": 0.033250391483306885,
    "min": -0.8135111331939697,
    "max": -0.014877327717840672,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.078417107462883,
    "std": 0.2976674437522888,
    "var": 0.08860591799020767,
    "min": -1.1883442401885986,
    "max": 1.1331710815429688,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.7585053443908691,
    "std": 0.8537262082099915,
    "var": 0.7288484573364258,
    "min": -1.2676749229431152,
    "max": 3.7803497314453125,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.2877761125564575,
    "std": 0.13613992929458618,
    "var": 0.018534081056714058,
    "min": -0.622092068195343,
    "max": 0.009456690400838852,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.1712578684091568,
    "std": 0.18036772310733795,
    "var": 0.03253251686692238,
    "min": -1.0607380867004395,
    "max": 0.5320326089859009,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.192022681236267,
    "std": 1.0830185413360596,
    "var": 1.1729291677474976,
    "min": -1.0756888389587402,
    "max": 3.9769949913024902,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.3705955445766449,
    "std": 0.08228942006826401,
    "var": 0.006771549116820097,
    "min": -0.5107347369194031,
    "max": -0.07870754599571228,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.14302046597003937,
    "std": 0.1797742396593094,
    "var": 0.032318778336048126,
    "min": -1.0511449575424194,
    "max": 0.5289995670318604,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.6127899885177612,
    "std": 0.5730586051940918,
    "var": 0.328396201133728,
    "min": -1.1751505136489868,
    "max": 2.4771595001220703,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.13375338912010193,
    "std": 0.09907085448503494,
    "var": 0.009815034456551075,
    "min": -0.47177955508232117,
    "max": 0.15626385807991028,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.0892954021692276,
    "std": 0.1625116914510727,
    "var": 0.026410052552819252,
    "min": -0.9237970113754272,
    "max": 0.5803912878036499,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": 1.2345592949714046e-05,
    "std": 0.010011378675699234,
    "var": 0.00010022771311923862,
    "min": -0.025171246379613876,
    "max": 0.024787049740552902,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.0015180909540504217,
    "std": 0.11828459799289703,
    "var": 0.013991246931254864,
    "min": -0.9364643692970276,
    "max": 1.129345417022705,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.05942531302571297,
    "std": 0.4039013385772705,
    "var": 0.1631363034248352,
    "min": -3.264439582824707,
    "max": 2.1653454303741455,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.17648617923259735,
    "std": 0.12825535237789154,
    "var": 0.01644943654537201,
    "min": -0.5875011086463928,
    "max": 0.1727251559495926,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07935719937086105,
    "std": 0.16578294336795807,
    "var": 0.02748398296535015,
    "min": -1.3544520139694214,
    "max": 0.6230754256248474,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.17411839962005615,
    "std": 1.1428306102752686,
    "var": 1.3060617446899414,
    "min": -3.2369401454925537,
    "max": 2.9549829959869385,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.0014362323563545942,
    "std": 0.13353678584098816,
    "var": 0.0178320724517107,
    "min": -0.4866037368774414,
    "max": 0.3433672785758972,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.04679858684539795,
    "std": 0.168705016374588,
    "var": 0.028461383655667305,
    "min": -0.9530487060546875,
    "max": 0.6274994015693665,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.5049469470977783,
    "std": 0.886201798915863,
    "var": 0.7853536605834961,
    "min": -2.0127573013305664,
    "max": 3.562786340713501,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.013698357157409191,
    "std": 0.08819448947906494,
    "var": 0.0077782683074474335,
    "min": -0.19041745364665985,
    "max": 0.1522371470928192,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": 0.0003371457278262824,
    "std": 0.20435528457164764,
    "var": 0.04176108166575432,
    "min": -0.7298464775085449,
    "max": 0.8147606253623962,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.001207041321322322,
    "std": 0.29756587743759155,
    "var": 0.08854545652866364,
    "min": -1.5573458671569824,
    "max": 1.5807297229766846,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.0446445941925049,
    "std": 0.5035132765769958,
    "var": 0.25352561473846436,
    "min": -2.5310542583465576,
    "max": 0.4433034658432007,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.8361981511116028,
    "std": 0.543883740901947,
    "var": 0.2958095073699951,
    "min": -2.2836999893188477,
    "max": 0.39737749099731445,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.9000076651573181,
    "std": 0.4741686284542084,
    "var": 0.22483590245246887,
    "min": -2.58829665184021,
    "max": 0.16351722180843353,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.1788082122802734,
    "std": 0.537320077419281,
    "var": 0.28871288895606995,
    "min": -3.018810510635376,
    "max": 0.36250272393226624,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.425988793373108,
    "std": 0.483090341091156,
    "var": 0.23337629437446594,
    "min": -2.5173394680023193,
    "max": 0.1123824417591095,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.3587725162506104,
    "std": 0.5475792288780212,
    "var": 0.2998430132865906,
    "min": -2.6175787448883057,
    "max": -0.2510494291782379,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.78 | loss:  0.77
-----------------------------------------------------------------------------------------
| epoch 41 | 1000/1179 batches | ms/batch 1030.85 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.31
-----------------------------------------------------------------------------------------
| end of epoch  41 | time per epoch: 1216.57s |
| Train Metrics | accuracy:  0.67 | loss:  1.32
| Eval  Metrics | accuracy:  0.76 | loss:  0.79
-----------------------------------------------------------------------------------------
| epoch 42 | 1000/1179 batches | ms/batch 1043.10 | Performance/Training accuracy:  0.66 | Performance/Training loss:  1.33
-----------------------------------------------------------------------------------------
| end of epoch  42 | time per epoch: 1232.69s |
| Train Metrics | accuracy:  0.66 | loss:  1.33
| Eval  Metrics | accuracy:  0.77 | loss:  0.78
-----------------------------------------------------------------------------------------
| epoch 43 | 1000/1179 batches | ms/batch 1059.03 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.27
-----------------------------------------------------------------------------------------
| end of epoch  43 | time per epoch: 1250.14s |
| Train Metrics | accuracy:  0.67 | loss:  1.28
| Eval  Metrics | accuracy:  0.76 | loss:  0.81
-----------------------------------------------------------------------------------------
| epoch 44 | 1000/1179 batches | ms/batch 1071.33 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.24
-----------------------------------------------------------------------------------------
| end of epoch  44 | time per epoch: 1264.49s |
| Train Metrics | accuracy:  0.68 | loss:  1.25
| Eval  Metrics | accuracy:  0.77 | loss:  0.79
-----------------------------------------------------------------------------------------
| epoch 45 | 1000/1179 batches | ms/batch 1094.01 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.25
-----------------------------------------------------------------------------------------
| end of epoch  45 | time per epoch: 1294.78s |
| Train Metrics | accuracy:  0.68 | loss:  1.27
| Eval  Metrics | accuracy:  0.78 | loss:  0.82
-----------------------------------------------------------------------------------------
| epoch 46 | 1000/1179 batches | ms/batch 1103.58 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.27
-----------------------------------------------------------------------------------------
| end of epoch  46 | time per epoch: 1301.27s |
| Train Metrics | accuracy:  0.68 | loss:  1.26
| Eval  Metrics | accuracy:  0.77 | loss:  0.78
-----------------------------------------------------------------------------------------
| epoch 47 | 1000/1179 batches | ms/batch 1115.12 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.22
-----------------------------------------------------------------------------------------
| end of epoch  47 | time per epoch: 1316.06s |
| Train Metrics | accuracy:  0.68 | loss:  1.22
| Eval  Metrics | accuracy:  0.79 | loss:  0.72
-----------------------------------------------------------------------------------------
[2025-02-25 07:14:16,540][absl][INFO] - Saving checkpoint at step: 55413
[2025-02-25 07:14:16,542][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 07:14:16,542][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 07:14:16,543][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_55413.
[2025-02-25 07:14:16,694][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 07:14:16,696][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_55413.orbax-checkpoint-tmp-26
[2025-02-25 07:14:16,703][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 07:14:16,729][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 07:14:16,746][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 219.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 41 milliseconds) (per-host)
[2025-02-25 07:14:17,281][absl][INFO] - ChainedFuture completed 1/1 futures in 0.52 seconds.
[2025-02-25 07:14:17,281][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 15.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 576 milliseconds) (per-host)
[2025-02-25 07:14:17,286][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 07:14:17,313][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_55413.orbax-checkpoint-tmp-26 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_55413
[2025-02-25 07:14:17,319][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_55413`.
[2025-02-25 07:14:17,319][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 07:14:17,320][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_44802
| epoch 48 | 1000/1179 batches | ms/batch 1125.39 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.23
-----------------------------------------------------------------------------------------
| end of epoch  48 | time per epoch: 1326.91s |
| Train Metrics | accuracy:  0.68 | loss:  1.23
| Eval  Metrics | accuracy:  0.78 | loss:  0.74
-----------------------------------------------------------------------------------------
| epoch 49 | 1000/1179 batches | ms/batch 1141.65 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.24
-----------------------------------------------------------------------------------------
| end of epoch  49 | time per epoch: 1345.92s |
| Train Metrics | accuracy:  0.68 | loss:  1.24
| Eval  Metrics | accuracy:  0.78 | loss:  0.77
-----------------------------------------------------------------------------------------
| epoch 50 | 1000/1179 batches | ms/batch 1118.46 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.27
-----------------------------------------------------------------------------------------
| end of epoch  50 | time per epoch: 1319.80s |
| Train Metrics | accuracy:  0.68 | loss:  1.27
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.13326139748096466,
    "std": 0.24447393417358398,
    "var": 0.05976750701665878,
    "min": -0.2537827491760254,
    "max": 0.8221849799156189,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.30865418910980225,
    "std": 0.17735067009925842,
    "var": 0.03145326301455498,
    "min": 0.07306066155433655,
    "max": 1.2913057804107666,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.00012493404210545123,
    "std": 0.10130105167627335,
    "var": 0.010261903516948223,
    "min": -0.4647607207298279,
    "max": 0.44480153918266296,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.2352636754512787,
    "std": 0.1787910759449005,
    "var": 0.03196625038981438,
    "min": -0.10454698652029037,
    "max": 0.772793173789978,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.44501373171806335,
    "std": 0.2887974977493286,
    "var": 0.08340400457382202,
    "min": 0.052384648472070694,
    "max": 1.5179859399795532,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0002545099123381078,
    "std": 0.10507936030626297,
    "var": 0.0110416729003191,
    "min": -0.5132383108139038,
    "max": 0.41086506843566895,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.25590136647224426,
    "std": 0.27055177092552185,
    "var": 0.07319825887680054,
    "min": -0.01904711127281189,
    "max": 0.9565237760543823,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.2617155909538269,
    "std": 0.18855133652687073,
    "var": 0.03555160388350487,
    "min": 0.05839693546295166,
    "max": 1.464776873588562,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0010915833991020918,
    "std": 0.10854916274547577,
    "var": 0.011782921850681305,
    "min": -0.5772159695625305,
    "max": 0.6949859857559204,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.15544423460960388,
    "std": 0.18128785490989685,
    "var": 0.032865285873413086,
    "min": -0.18100158870220184,
    "max": 0.9677361845970154,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.5297350883483887,
    "std": 0.261287122964859,
    "var": 0.0682709664106369,
    "min": 0.07455964386463165,
    "max": 2.2111778259277344,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0007207276648841798,
    "std": 0.07930856943130493,
    "var": 0.006289849057793617,
    "min": -0.6912532448768616,
    "max": 0.6186736226081848,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.12572284042835236,
    "std": 0.24665507674217224,
    "var": 0.0608387254178524,
    "min": -0.642199695110321,
    "max": 0.9790777564048767,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.7226287722587585,
    "std": 0.3208155333995819,
    "var": 0.10292260348796844,
    "min": 0.16703493893146515,
    "max": 2.2748541831970215,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00014864745025988668,
    "std": 0.05811137706041336,
    "var": 0.0033769323490560055,
    "min": -0.4139384627342224,
    "max": 0.3261823356151581,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.03718292713165283,
    "std": 0.10739141702651978,
    "var": 0.011532916687428951,
    "min": -0.48599180579185486,
    "max": 0.2120458483695984,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.0128498077392578,
    "std": 0.29616832733154297,
    "var": 0.08771568536758423,
    "min": 0.5447232723236084,
    "max": 2.653555393218994,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00023101740225683898,
    "std": 0.07526135444641113,
    "var": 0.005664272233843803,
    "min": -0.5058346390724182,
    "max": 0.4213857054710388,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": 0.0006066667265258729,
    "std": 0.11278782039880753,
    "var": 0.012721093371510506,
    "min": -0.77415531873703,
    "max": 0.9517056345939636,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0033340868540108204,
    "std": 0.11784143000841141,
    "var": 0.013886602595448494,
    "min": -0.598936915397644,
    "max": 0.6355352997779846,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.00029036420164629817,
    "std": 0.12100154161453247,
    "var": 0.014641372486948967,
    "min": -0.6053358912467957,
    "max": 0.6542817950248718,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0003840888384729624,
    "std": 0.11036822944879532,
    "var": 0.012181146070361137,
    "min": -1.139401912689209,
    "max": 1.2151408195495605,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.000692394794896245,
    "std": 0.10416329652070999,
    "var": 0.010849992744624615,
    "min": -0.6814205646514893,
    "max": 0.9809067249298096,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0005662874900735915,
    "std": 0.11442074924707413,
    "var": 0.013092108070850372,
    "min": -0.6915973424911499,
    "max": 0.6717473268508911,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.42066246271133423,
    "std": 0.1630655825138092,
    "var": 0.026590384542942047,
    "min": -0.788636326789856,
    "max": -0.057061102241277695,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08090422302484512,
    "std": 0.31656256318092346,
    "var": 0.10021185874938965,
    "min": -1.5556186437606812,
    "max": 1.3191620111465454,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.858285129070282,
    "std": 0.9076122641563416,
    "var": 0.8237600326538086,
    "min": -1.572209358215332,
    "max": 3.8372302055358887,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.2732256054878235,
    "std": 0.1579415500164032,
    "var": 0.024945532903075218,
    "min": -0.6529185175895691,
    "max": 0.16043661534786224,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.18170879781246185,
    "std": 0.1991003453731537,
    "var": 0.03964094817638397,
    "min": -1.1513108015060425,
    "max": 0.5467735528945923,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.2194788455963135,
    "std": 1.1300562620162964,
    "var": 1.2770271301269531,
    "min": -1.3295408487319946,
    "max": 4.616265773773193,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.3459802567958832,
    "std": 0.09299904108047485,
    "var": 0.008648821152746677,
    "min": -0.5415157675743103,
    "max": -0.08777697384357452,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.1410573571920395,
    "std": 0.19078728556632996,
    "var": 0.03639978915452957,
    "min": -1.037318229675293,
    "max": 0.5613740682601929,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.6018736958503723,
    "std": 0.6336358189582825,
    "var": 0.4014943540096283,
    "min": -1.454002022743225,
    "max": 2.6998848915100098,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.12704145908355713,
    "std": 0.09896435588598251,
    "var": 0.009793943725526333,
    "min": -0.4650249779224396,
    "max": 0.12818343937397003,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08809497952461243,
    "std": 0.16633859276771545,
    "var": 0.027668530121445656,
    "min": -0.9649011492729187,
    "max": 0.5455085635185242,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0006546314107254148,
    "std": 0.009477884508669376,
    "var": 8.983029692899436e-05,
    "min": -0.029661988839507103,
    "max": 0.02429444156587124,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.0009641649667173624,
    "std": 0.11863766610622406,
    "var": 0.014074895530939102,
    "min": -0.9967424869537354,
    "max": 1.0898419618606567,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.054361432790756226,
    "std": 0.42856499552726746,
    "var": 0.18366797268390656,
    "min": -3.970632314682007,
    "max": 2.5266060829162598,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.17031101882457733,
    "std": 0.12338092923164368,
    "var": 0.015222853049635887,
    "min": -0.5674018859863281,
    "max": 0.11157386004924774,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07850706577301025,
    "std": 0.16774341464042664,
    "var": 0.02813785709440708,
    "min": -1.4234176874160767,
    "max": 0.6192922592163086,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.2135922610759735,
    "std": 1.1304975748062134,
    "var": 1.278024673461914,
    "min": -3.3999409675598145,
    "max": 3.0668530464172363,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.011647619307041168,
    "std": 0.13122130930423737,
    "var": 0.01721903309226036,
    "min": -0.4730115830898285,
    "max": 0.31747615337371826,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.04657582566142082,
    "std": 0.1680939495563507,
    "var": 0.028255576267838478,
    "min": -0.9159948825836182,
    "max": 0.5750073790550232,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.48866724967956543,
    "std": 0.8186281323432922,
    "var": 0.6701520681381226,
    "min": -1.3558688163757324,
    "max": 3.5564522743225098,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.013860461302101612,
    "std": 0.08407838642597198,
    "var": 0.007069175597280264,
    "min": -0.17330381274223328,
    "max": 0.13665658235549927,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": 0.00022918242029845715,
    "std": 0.21060216426849365,
    "var": 0.04435327276587486,
    "min": -0.8067895770072937,
    "max": 0.8892732858657837,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.0017161176074296236,
    "std": 0.29423847794532776,
    "var": 0.08657628297805786,
    "min": -1.5510293245315552,
    "max": 1.5828437805175781,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.7851341962814331,
    "std": 0.48791611194610596,
    "var": 0.23806214332580566,
    "min": -2.1629536151885986,
    "max": 0.5839040279388428,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.665712833404541,
    "std": 0.5127666592597961,
    "var": 0.26292967796325684,
    "min": -2.091911554336548,
    "max": 0.5431264042854309,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.7012665271759033,
    "std": 0.4455311894416809,
    "var": 0.19849804043769836,
    "min": -2.2845523357391357,
    "max": 0.24214640259742737,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.058365821838379,
    "std": 0.5125157833099365,
    "var": 0.26267245411872864,
    "min": -2.738917589187622,
    "max": 0.47496122121810913,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.2868709564208984,
    "std": 0.46462833881378174,
    "var": 0.21587949991226196,
    "min": -2.410459518432617,
    "max": 0.23340097069740295,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.227222204208374,
    "std": 0.555250883102417,
    "var": 0.308303564786911,
    "min": -2.535433053970337,
    "max": -0.1637541949748993,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.78 | loss:  0.77
-----------------------------------------------------------------------------------------
| epoch 51 | 1000/1179 batches | ms/batch 1164.44 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.29
-----------------------------------------------------------------------------------------
| end of epoch  51 | time per epoch: 1374.28s |
| Train Metrics | accuracy:  0.68 | loss:  1.27
| Eval  Metrics | accuracy:  0.79 | loss:  0.73
-----------------------------------------------------------------------------------------
[2025-02-25 08:52:30,180][absl][INFO] - Saving checkpoint at step: 60129
[2025-02-25 08:52:30,182][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 08:52:30,182][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 08:52:30,184][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_60129.
[2025-02-25 08:52:30,191][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 08:52:30,192][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_60129.orbax-checkpoint-tmp-27
[2025-02-25 08:52:30,198][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 08:52:30,225][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 08:52:30,263][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 143.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 63 milliseconds) (per-host)
[2025-02-25 08:52:30,472][absl][INFO] - ChainedFuture completed 1/1 futures in 0.20 seconds.
[2025-02-25 08:52:30,472][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 273 milliseconds) (per-host)
[2025-02-25 08:52:30,477][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 08:52:30,505][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_60129.orbax-checkpoint-tmp-27 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_60129
[2025-02-25 08:52:30,511][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_60129`.
[2025-02-25 08:52:30,511][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 08:52:30,512][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_55413
| epoch 52 | 1000/1179 batches | ms/batch 1175.60 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.26
-----------------------------------------------------------------------------------------
| end of epoch  52 | time per epoch: 1387.27s |
| Train Metrics | accuracy:  0.68 | loss:  1.26
| Eval  Metrics | accuracy:  0.77 | loss:  0.79
-----------------------------------------------------------------------------------------
| epoch 53 | 1000/1179 batches | ms/batch 1193.12 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.24
-----------------------------------------------------------------------------------------
| end of epoch  53 | time per epoch: 1407.29s |
| Train Metrics | accuracy:  0.68 | loss:  1.25
| Eval  Metrics | accuracy:  0.77 | loss:  0.75
-----------------------------------------------------------------------------------------
| epoch 54 | 1000/1179 batches | ms/batch 1211.00 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.22
-----------------------------------------------------------------------------------------
| end of epoch  54 | time per epoch: 1430.73s |
| Train Metrics | accuracy:  0.69 | loss:  1.22
| Eval  Metrics | accuracy:  0.79 | loss:  0.72
-----------------------------------------------------------------------------------------
[2025-02-25 10:09:53,918][absl][INFO] - Saving checkpoint at step: 63666
[2025-02-25 10:09:53,920][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 10:09:53,921][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 10:09:53,922][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_63666.
[2025-02-25 10:09:53,930][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 10:09:53,931][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_63666.orbax-checkpoint-tmp-28
[2025-02-25 10:09:53,938][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 10:09:53,964][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 10:09:53,984][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 200.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 45 milliseconds) (per-host)
[2025-02-25 10:09:54,208][absl][INFO] - ChainedFuture completed 1/1 futures in 0.21 seconds.
[2025-02-25 10:09:54,208][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 269 milliseconds) (per-host)
[2025-02-25 10:09:54,214][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 10:09:54,248][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_63666.orbax-checkpoint-tmp-28 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_63666
[2025-02-25 10:09:54,253][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_63666`.
[2025-02-25 10:09:54,253][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 10:09:54,255][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_60129
| epoch 55 | 1000/1179 batches | ms/batch 1218.80 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.26
-----------------------------------------------------------------------------------------
| end of epoch  55 | time per epoch: 1438.00s |
| Train Metrics | accuracy:  0.68 | loss:  1.26
| Eval  Metrics | accuracy:  0.77 | loss:  0.78
-----------------------------------------------------------------------------------------
| epoch 56 | 1000/1179 batches | ms/batch 1235.88 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.24
-----------------------------------------------------------------------------------------
| end of epoch  56 | time per epoch: 1458.05s |
| Train Metrics | accuracy:  0.68 | loss:  1.25
| Eval  Metrics | accuracy:  0.78 | loss:  0.78
-----------------------------------------------------------------------------------------
| epoch 57 | 1000/1179 batches | ms/batch 1244.10 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.26
-----------------------------------------------------------------------------------------
| end of epoch  57 | time per epoch: 1468.40s |
| Train Metrics | accuracy:  0.68 | loss:  1.25
| Eval  Metrics | accuracy:  0.77 | loss:  0.80
-----------------------------------------------------------------------------------------
| epoch 58 | 1000/1179 batches | ms/batch 1263.53 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.24
-----------------------------------------------------------------------------------------
| end of epoch  58 | time per epoch: 1489.04s |
| Train Metrics | accuracy:  0.68 | loss:  1.23
| Eval  Metrics | accuracy:  0.78 | loss:  0.75
-----------------------------------------------------------------------------------------
| epoch 59 | 1000/1179 batches | ms/batch 1279.29 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.21
-----------------------------------------------------------------------------------------
| end of epoch  59 | time per epoch: 1510.54s |
| Train Metrics | accuracy:  0.69 | loss:  1.22
| Eval  Metrics | accuracy:  0.79 | loss:  0.72
-----------------------------------------------------------------------------------------
[2025-02-25 12:24:59,758][absl][INFO] - Saving checkpoint at step: 69561
[2025-02-25 12:24:59,760][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 12:24:59,760][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 12:24:59,762][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_69561.
[2025-02-25 12:24:59,769][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 12:24:59,770][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_69561.orbax-checkpoint-tmp-29
[2025-02-25 12:24:59,779][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 12:24:59,804][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 12:24:59,834][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 166.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-25 12:25:00,045][absl][INFO] - ChainedFuture completed 1/1 futures in 0.21 seconds.
[2025-02-25 12:25:00,045][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 34.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 265 milliseconds) (per-host)
[2025-02-25 12:25:00,052][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 12:25:00,079][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_69561.orbax-checkpoint-tmp-29 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_69561
[2025-02-25 12:25:00,084][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_69561`.
[2025-02-25 12:25:00,084][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 12:25:00,086][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_63666
| epoch 60 | 1000/1179 batches | ms/batch 1350.40 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.23
-----------------------------------------------------------------------------------------
| end of epoch  60 | time per epoch: 1589.12s |
| Train Metrics | accuracy:  0.69 | loss:  1.22
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.15752388536930084,
    "std": 0.24977563321590424,
    "var": 0.062387868762016296,
    "min": -0.23590517044067383,
    "max": 0.8864606618881226,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.3054642677307129,
    "std": 0.18870313465595245,
    "var": 0.03560887277126312,
    "min": 0.0947679802775383,
    "max": 1.251973271369934,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -6.694707553833723e-05,
    "std": 0.10418401658535004,
    "var": 0.010854309424757957,
    "min": -0.5253225564956665,
    "max": 0.48821353912353516,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.22994807362556458,
    "std": 0.16847726702690125,
    "var": 0.028384588658809662,
    "min": -0.12735435366630554,
    "max": 0.746029794216156,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.42160481214523315,
    "std": 0.29678085446357727,
    "var": 0.08807888627052307,
    "min": 0.06311724334955215,
    "max": 1.523006796836853,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00028613998438231647,
    "std": 0.10858262330293655,
    "var": 0.011790186166763306,
    "min": -0.5654630661010742,
    "max": 0.41600102186203003,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2589195668697357,
    "std": 0.27825623750686646,
    "var": 0.07742653042078018,
    "min": -0.04132430627942085,
    "max": 0.9632031917572021,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.27551382780075073,
    "std": 0.20540617406368256,
    "var": 0.04219169542193413,
    "min": 0.04190363362431526,
    "max": 1.565264105796814,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0012066768249496818,
    "std": 0.11265424638986588,
    "var": 0.012690979056060314,
    "min": -0.6570715308189392,
    "max": 0.7637429237365723,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.15709051489830017,
    "std": 0.19176267087459564,
    "var": 0.036772921681404114,
    "min": -0.21153125166893005,
    "max": 0.9616695046424866,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.5467159152030945,
    "std": 0.2628105878829956,
    "var": 0.06906940788030624,
    "min": 0.07819511741399765,
    "max": 2.124037265777588,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0008238991722464561,
    "std": 0.08054028451442719,
    "var": 0.006486737634986639,
    "min": -0.7904266715049744,
    "max": 0.7163929343223572,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.12977874279022217,
    "std": 0.25014713406562805,
    "var": 0.06257359683513641,
    "min": -0.6294938921928406,
    "max": 0.9850606322288513,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.7045187950134277,
    "std": 0.3154151141643524,
    "var": 0.09948669373989105,
    "min": 0.13864582777023315,
    "max": 2.122775077819824,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00015156407607719302,
    "std": 0.058135878294706345,
    "var": 0.0033797803334891796,
    "min": -0.4263320863246918,
    "max": 0.4657324552536011,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.040667228400707245,
    "std": 0.1139104813337326,
    "var": 0.012975598685443401,
    "min": -0.6161087155342102,
    "max": 0.24430948495864868,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.0374003648757935,
    "std": 0.29358646273612976,
    "var": 0.0861930102109909,
    "min": 0.5719753503799438,
    "max": 2.654042959213257,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0003315610811114311,
    "std": 0.07875072956085205,
    "var": 0.0062016770243644714,
    "min": -0.6052976250648499,
    "max": 0.5059778094291687,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0007302546291612089,
    "std": 0.11198268830776215,
    "var": 0.012540123425424099,
    "min": -0.7695195078849792,
    "max": 0.8314240574836731,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.002770100487396121,
    "std": 0.11565197259187698,
    "var": 0.013375379145145416,
    "min": -0.6357209086418152,
    "max": 0.6345423460006714,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0007057732436805964,
    "std": 0.1173969954252243,
    "var": 0.01378205418586731,
    "min": -0.6017879843711853,
    "max": 0.6486678719520569,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00023513943597208709,
    "std": 0.10528873652219772,
    "var": 0.011085718870162964,
    "min": -1.0466945171356201,
    "max": 0.9705567955970764,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0007546168635599315,
    "std": 0.1005350798368454,
    "var": 0.010107303038239479,
    "min": -0.6454448103904724,
    "max": 0.8036874532699585,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.000647661043331027,
    "std": 0.11127462238073349,
    "var": 0.012382041662931442,
    "min": -0.7615453004837036,
    "max": 0.6413661241531372,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.41762876510620117,
    "std": 0.15233097970485687,
    "var": 0.023204727098345757,
    "min": -0.8811229467391968,
    "max": -0.07351042330265045,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.09132370352745056,
    "std": 0.3150540590286255,
    "var": 0.09925905615091324,
    "min": -1.4683336019515991,
    "max": 1.2082995176315308,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.8832542300224304,
    "std": 0.9733091592788696,
    "var": 0.9473307132720947,
    "min": -1.8875521421432495,
    "max": 3.883460760116577,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.2735539674758911,
    "std": 0.1701418161392212,
    "var": 0.028948236256837845,
    "min": -0.6645734906196594,
    "max": 0.21912074089050293,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19036780297756195,
    "std": 0.21459823846817017,
    "var": 0.04605240747332573,
    "min": -1.170223355293274,
    "max": 0.6097557544708252,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.2110532522201538,
    "std": 1.1154510974884033,
    "var": 1.2442312240600586,
    "min": -1.314092993736267,
    "max": 4.555777072906494,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.33296477794647217,
    "std": 0.1039704978466034,
    "var": 0.010809863917529583,
    "min": -0.5782126784324646,
    "max": -0.06814412027597427,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.14127908647060394,
    "std": 0.197548508644104,
    "var": 0.03902541100978851,
    "min": -1.2277992963790894,
    "max": 0.5995250344276428,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.5571081042289734,
    "std": 0.6584489941596985,
    "var": 0.43355506658554077,
    "min": -1.5000503063201904,
    "max": 2.869635820388794,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.12461303174495697,
    "std": 0.09956429898738861,
    "var": 0.009913049638271332,
    "min": -0.4801565706729889,
    "max": 0.12320512533187866,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08704648166894913,
    "std": 0.16675437986850739,
    "var": 0.027807023376226425,
    "min": -1.0355134010314941,
    "max": 0.5696930289268494,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0004892107099294662,
    "std": 0.008842775598168373,
    "var": 7.819468009984121e-05,
    "min": -0.02997097559273243,
    "max": 0.03242989629507065,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.0006749866879545152,
    "std": 0.11818120628595352,
    "var": 0.013966796919703484,
    "min": -0.9843726754188538,
    "max": 1.0667617321014404,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.04795104265213013,
    "std": 0.43851906061172485,
    "var": 0.19229896366596222,
    "min": -4.228204250335693,
    "max": 2.789703845977783,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.16638606786727905,
    "std": 0.11641824245452881,
    "var": 0.013553207740187645,
    "min": -0.5482061505317688,
    "max": 0.08651533722877502,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07783801108598709,
    "std": 0.16757121682167053,
    "var": 0.028080115094780922,
    "min": -1.349312663078308,
    "max": 0.750485360622406,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.23139719665050507,
    "std": 1.1001932621002197,
    "var": 1.2104253768920898,
    "min": -3.184882402420044,
    "max": 3.0258536338806152,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.018139313906431198,
    "std": 0.13485440611839294,
    "var": 0.018185710534453392,
    "min": -0.4996137320995331,
    "max": 0.3383069932460785,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.04554269090294838,
    "std": 0.16595055162906647,
    "var": 0.027539588510990143,
    "min": -0.9568830132484436,
    "max": 0.6487320065498352,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.4871925711631775,
    "std": 0.766973614692688,
    "var": 0.5882484912872314,
    "min": -1.0817126035690308,
    "max": 3.2657151222229004,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.01365573052316904,
    "std": 0.08220414072275162,
    "var": 0.006757520604878664,
    "min": -0.17500586807727814,
    "max": 0.13452774286270142,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": 0.00018241781799588352,
    "std": 0.21348567306995392,
    "var": 0.04557613283395767,
    "min": -0.8772929310798645,
    "max": 0.8591693639755249,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.0015005292370915413,
    "std": 0.28903719782829285,
    "var": 0.08354251086711884,
    "min": -1.5389727354049683,
    "max": 1.4696470499038696,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.6081511378288269,
    "std": 0.4795173406600952,
    "var": 0.229936882853508,
    "min": -1.8229278326034546,
    "max": 0.7134478092193604,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.5685757994651794,
    "std": 0.5010899901390076,
    "var": 0.2510911822319031,
    "min": -2.0308046340942383,
    "max": 0.6334139704704285,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.5857998728752136,
    "std": 0.4391970932483673,
    "var": 0.1928940862417221,
    "min": -2.0685927867889404,
    "max": 0.3399885594844818,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.0048617124557495,
    "std": 0.5002102851867676,
    "var": 0.25021037459373474,
    "min": -2.4848968982696533,
    "max": 0.5132534503936768,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.2101197242736816,
    "std": 0.4526442885398865,
    "var": 0.20488685369491577,
    "min": -2.3002288341522217,
    "max": 0.3142475187778473,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.1490641832351685,
    "std": 0.5603536367416382,
    "var": 0.31399619579315186,
    "min": -2.5183334350585938,
    "max": -0.05158666893839836,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.80 | loss:  0.69
-----------------------------------------------------------------------------------------
[2025-02-25 12:54:04,528][absl][INFO] - Saving checkpoint at step: 70740
[2025-02-25 12:54:04,529][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 12:54:04,529][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 12:54:04,531][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_70740.
[2025-02-25 12:54:04,538][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 12:54:04,539][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_70740.orbax-checkpoint-tmp-30
[2025-02-25 12:54:04,545][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 12:54:04,571][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 12:54:04,587][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 222.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 41 milliseconds) (per-host)
[2025-02-25 12:54:04,823][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-25 12:54:04,823][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 276 milliseconds) (per-host)
[2025-02-25 12:54:04,828][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 12:54:04,855][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_70740.orbax-checkpoint-tmp-30 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_70740
[2025-02-25 12:54:04,861][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_70740`.
[2025-02-25 12:54:04,861][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 12:54:04,862][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_69561
| epoch 61 | 1000/1179 batches | ms/batch 1310.73 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.20
-----------------------------------------------------------------------------------------
| end of epoch  61 | time per epoch: 1546.34s |
| Train Metrics | accuracy:  0.69 | loss:  1.21
| Eval  Metrics | accuracy:  0.77 | loss:  0.80
-----------------------------------------------------------------------------------------
| epoch 62 | 1000/1179 batches | ms/batch 1322.75 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.24
-----------------------------------------------------------------------------------------
| end of epoch  62 | time per epoch: 1559.87s |
| Train Metrics | accuracy:  0.69 | loss:  1.23
| Eval  Metrics | accuracy:  0.79 | loss:  0.70
-----------------------------------------------------------------------------------------
| epoch 63 | 1000/1179 batches | ms/batch 1333.48 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.20
-----------------------------------------------------------------------------------------
| end of epoch  63 | time per epoch: 1575.23s |
| Train Metrics | accuracy:  0.69 | loss:  1.21
| Eval  Metrics | accuracy:  0.78 | loss:  0.74
-----------------------------------------------------------------------------------------
| epoch 64 | 1000/1179 batches | ms/batch 1348.71 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.25
-----------------------------------------------------------------------------------------
| end of epoch  64 | time per epoch: 1592.83s |
| Train Metrics | accuracy:  0.69 | loss:  1.25
| Eval  Metrics | accuracy:  0.80 | loss:  0.70
-----------------------------------------------------------------------------------------
| epoch 65 | 1000/1179 batches | ms/batch 1358.21 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.21
-----------------------------------------------------------------------------------------
| end of epoch  65 | time per epoch: 1602.22s |
| Train Metrics | accuracy:  0.69 | loss:  1.22
| Eval  Metrics | accuracy:  0.80 | loss:  0.69
-----------------------------------------------------------------------------------------
| epoch 66 | 1000/1179 batches | ms/batch 1378.31 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.25
-----------------------------------------------------------------------------------------
| end of epoch  66 | time per epoch: 1625.44s |
| Train Metrics | accuracy:  0.69 | loss:  1.25
| Eval  Metrics | accuracy:  0.80 | loss:  0.71
-----------------------------------------------------------------------------------------
| epoch 67 | 1000/1179 batches | ms/batch 1379.79 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.18
-----------------------------------------------------------------------------------------
| end of epoch  67 | time per epoch: 1627.67s |
| Train Metrics | accuracy:  0.70 | loss:  1.19
| Eval  Metrics | accuracy:  0.79 | loss:  0.74
-----------------------------------------------------------------------------------------
| epoch 68 | 1000/1179 batches | ms/batch 1394.76 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.18
-----------------------------------------------------------------------------------------
| end of epoch  68 | time per epoch: 1644.99s |
| Train Metrics | accuracy:  0.70 | loss:  1.19
| Eval  Metrics | accuracy:  0.78 | loss:  0.74
-----------------------------------------------------------------------------------------
| epoch 69 | 1000/1179 batches | ms/batch 1400.63 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.19
-----------------------------------------------------------------------------------------
| end of epoch  69 | time per epoch: 1652.13s |
| Train Metrics | accuracy:  0.70 | loss:  1.19
| Eval  Metrics | accuracy:  0.78 | loss:  0.76
-----------------------------------------------------------------------------------------
| epoch 70 | 1000/1179 batches | ms/batch 1413.36 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.19
-----------------------------------------------------------------------------------------
| end of epoch  70 | time per epoch: 1667.36s |
| Train Metrics | accuracy:  0.70 | loss:  1.19
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.1747037172317505,
    "std": 0.2667950391769409,
    "var": 0.07117959856987,
    "min": -0.2092353105545044,
    "max": 0.9826397895812988,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.31425467133522034,
    "std": 0.20214514434337616,
    "var": 0.04086265712976456,
    "min": 0.0779634341597557,
    "max": 1.2453193664550781,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.00022857668227516115,
    "std": 0.10657374560832977,
    "var": 0.01135796308517456,
    "min": -0.5581144690513611,
    "max": 0.5150775909423828,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.22642426192760468,
    "std": 0.17201213538646698,
    "var": 0.02958817407488823,
    "min": -0.14533472061157227,
    "max": 0.7343493103981018,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.40973135828971863,
    "std": 0.29902467131614685,
    "var": 0.08941575139760971,
    "min": 0.08852037042379379,
    "max": 1.4476317167282104,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0004066461406182498,
    "std": 0.11179033666849136,
    "var": 0.012497080489993095,
    "min": -0.611858069896698,
    "max": 0.4793359339237213,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2667730450630188,
    "std": 0.28236067295074463,
    "var": 0.07972754538059235,
    "min": -0.02766897715628147,
    "max": 0.9842454195022583,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.2879254221916199,
    "std": 0.22295445203781128,
    "var": 0.049708686769008636,
    "min": 0.06419206410646439,
    "max": 1.624297022819519,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.001106788171455264,
    "std": 0.11612540483474731,
    "var": 0.013485110364854336,
    "min": -0.710055410861969,
    "max": 0.829197883605957,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.15939539670944214,
    "std": 0.19773836433887482,
    "var": 0.039100464433431625,
    "min": -0.2493928223848343,
    "max": 0.9462170004844666,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.5558955073356628,
    "std": 0.26408737897872925,
    "var": 0.06974214315414429,
    "min": 0.0784248486161232,
    "max": 2.0718894004821777,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0008597054402343929,
    "std": 0.08109771460294724,
    "var": 0.006576838903129101,
    "min": -0.8645874261856079,
    "max": 0.7978783249855042,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.1346791684627533,
    "std": 0.2506743371486664,
    "var": 0.0628376305103302,
    "min": -0.6245942115783691,
    "max": 1.0819694995880127,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6990548372268677,
    "std": 0.3164713680744171,
    "var": 0.10015412420034409,
    "min": 0.1520141363143921,
    "max": 2.0599989891052246,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0001237044489243999,
    "std": 0.058113496750593185,
    "var": 0.0033771784510463476,
    "min": -0.4372051954269409,
    "max": 0.5442463159561157,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.04275272786617279,
    "std": 0.11604020744562149,
    "var": 0.013465330004692078,
    "min": -0.6953719258308411,
    "max": 0.28237274289131165,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.0591801404953003,
    "std": 0.3033616542816162,
    "var": 0.09202830493450165,
    "min": 0.5957245230674744,
    "max": 2.6523454189300537,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00037826396874152124,
    "std": 0.08167775720357895,
    "var": 0.006671256851404905,
    "min": -0.6933477520942688,
    "max": 0.5816850066184998,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00038567636511288583,
    "std": 0.10851482301950455,
    "var": 0.011775466613471508,
    "min": -0.6951180696487427,
    "max": 0.7191140651702881,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0008746427483856678,
    "std": 0.11174507439136505,
    "var": 0.012486962601542473,
    "min": -0.5675727725028992,
    "max": 0.6215230822563171,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0003094589337706566,
    "std": 0.1141420230269432,
    "var": 0.0130284009501338,
    "min": -0.6579033732414246,
    "max": 0.6008972525596619,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00047476307372562587,
    "std": 0.10015926510095596,
    "var": 0.01003187894821167,
    "min": -0.950854480266571,
    "max": 0.8970397114753723,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00036476642708294094,
    "std": 0.09685958921909332,
    "var": 0.00938178040087223,
    "min": -0.5853405594825745,
    "max": 0.7389641404151917,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0006272384198382497,
    "std": 0.10752083361148834,
    "var": 0.011560729704797268,
    "min": -0.7479663491249084,
    "max": 0.6406491994857788,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.40953510999679565,
    "std": 0.13937188684940338,
    "var": 0.019424524158239365,
    "min": -0.790090799331665,
    "max": -0.09908771514892578,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.09421992301940918,
    "std": 0.3123463988304138,
    "var": 0.09756027907133102,
    "min": -1.6924386024475098,
    "max": 1.2597947120666504,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.8302482962608337,
    "std": 0.9912939667701721,
    "var": 0.9826637506484985,
    "min": -2.2390635013580322,
    "max": 3.448383331298828,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.2748274803161621,
    "std": 0.16846902668476105,
    "var": 0.028381813317537308,
    "min": -0.6670626997947693,
    "max": 0.19839416444301605,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19570404291152954,
    "std": 0.2199801504611969,
    "var": 0.04839127138257027,
    "min": -1.4052159786224365,
    "max": 0.6679962873458862,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.2024548053741455,
    "std": 1.071593999862671,
    "var": 1.1483137607574463,
    "min": -1.3727977275848389,
    "max": 4.710357666015625,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.32826900482177734,
    "std": 0.10750148445367813,
    "var": 0.011556568555533886,
    "min": -0.5705782771110535,
    "max": -0.04820927232503891,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.14163358509540558,
    "std": 0.20104186236858368,
    "var": 0.040417831391096115,
    "min": -1.5259572267532349,
    "max": 0.6091625094413757,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.5031220316886902,
    "std": 0.6799858212471008,
    "var": 0.4623807370662689,
    "min": -1.3034576177597046,
    "max": 3.045650005340576,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.12288078665733337,
    "std": 0.09887557476758957,
    "var": 0.00977637991309166,
    "min": -0.45938020944595337,
    "max": 0.09434138238430023,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08525703847408295,
    "std": 0.1653561145067215,
    "var": 0.027342643588781357,
    "min": -1.1057040691375732,
    "max": 0.5055881142616272,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -5.401971793617122e-05,
    "std": 0.008798041380941868,
    "var": 7.740553701296449e-05,
    "min": -0.02915135584771633,
    "max": 0.03923580050468445,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.0002905841392930597,
    "std": 0.11716475337743759,
    "var": 0.013727580197155476,
    "min": -1.0184071063995361,
    "max": 1.0920096635818481,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.04277168959379196,
    "std": 0.4354921579360962,
    "var": 0.1896534264087677,
    "min": -4.020700454711914,
    "max": 2.6429951190948486,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.16385221481323242,
    "std": 0.11157316714525223,
    "var": 0.012448571622371674,
    "min": -0.5594600439071655,
    "max": 0.07334007322788239,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07581644505262375,
    "std": 0.16698023676872253,
    "var": 0.027882400900125504,
    "min": -1.205642819404602,
    "max": 0.7081308960914612,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.23763231933116913,
    "std": 1.0717978477478027,
    "var": 1.14875066280365,
    "min": -3.215761661529541,
    "max": 2.952054977416992,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.02268805354833603,
    "std": 0.1354917585849762,
    "var": 0.01835801638662815,
    "min": -0.5102319717407227,
    "max": 0.31562328338623047,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.04461201652884483,
    "std": 0.16300030052661896,
    "var": 0.026569096371531487,
    "min": -0.9741595387458801,
    "max": 0.5744860768318176,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.479331910610199,
    "std": 0.7254441976547241,
    "var": 0.5262693166732788,
    "min": -1.0543255805969238,
    "max": 3.0947484970092773,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.01277270819991827,
    "std": 0.0785127729177475,
    "var": 0.006164255551993847,
    "min": -0.1836801916360855,
    "max": 0.1410415917634964,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0003834501840174198,
    "std": 0.21473155915737152,
    "var": 0.0461096465587616,
    "min": -0.8491791486740112,
    "max": 0.9262111186981201,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.0005255758296698332,
    "std": 0.2825813293457031,
    "var": 0.07985220849514008,
    "min": -1.3983640670776367,
    "max": 1.4077861309051514,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.5027651190757751,
    "std": 0.4606751501560211,
    "var": 0.21222159266471863,
    "min": -1.5524299144744873,
    "max": 0.7707115411758423,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.5022871494293213,
    "std": 0.48159459233283997,
    "var": 0.2319333553314209,
    "min": -1.9462273120880127,
    "max": 0.6888140439987183,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.5010751485824585,
    "std": 0.42491966485977173,
    "var": 0.18055671453475952,
    "min": -2.0256783962249756,
    "max": 0.4435320794582367,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.971637487411499,
    "std": 0.49230387806892395,
    "var": 0.2423631250858307,
    "min": -2.4575207233428955,
    "max": 0.5098235607147217,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.158017635345459,
    "std": 0.442037433385849,
    "var": 0.19539709389209747,
    "min": -2.229642629623413,
    "max": 0.34421205520629883,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.0864585638046265,
    "std": 0.5594674348831177,
    "var": 0.3130038380622864,
    "min": -2.46769380569458,
    "max": 0.038776885718107224,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.79 | loss:  0.70
-----------------------------------------------------------------------------------------
| epoch 71 | 1000/1179 batches | ms/batch 1431.88 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.21
-----------------------------------------------------------------------------------------
| end of epoch  71 | time per epoch: 1687.22s |
| Train Metrics | accuracy:  0.69 | loss:  1.21
| Eval  Metrics | accuracy:  0.78 | loss:  0.80
-----------------------------------------------------------------------------------------
| epoch 72 | 1000/1179 batches | ms/batch 1439.09 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.17
-----------------------------------------------------------------------------------------
| end of epoch  72 | time per epoch: 1697.11s |
| Train Metrics | accuracy:  0.70 | loss:  1.18
| Eval  Metrics | accuracy:  0.80 | loss:  0.70
-----------------------------------------------------------------------------------------
| epoch 73 | 1000/1179 batches | ms/batch 1453.73 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.21
-----------------------------------------------------------------------------------------
| end of epoch  73 | time per epoch: 1713.95s |
| Train Metrics | accuracy:  0.70 | loss:  1.20
| Eval  Metrics | accuracy:  0.80 | loss:  0.67
-----------------------------------------------------------------------------------------
| epoch 74 | 1000/1179 batches | ms/batch 1464.39 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.17
-----------------------------------------------------------------------------------------
| end of epoch  74 | time per epoch: 1726.47s |
| Train Metrics | accuracy:  0.70 | loss:  1.17
| Eval  Metrics | accuracy:  0.80 | loss:  0.69
-----------------------------------------------------------------------------------------
| epoch 75 | 1000/1179 batches | ms/batch 1509.22 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.20
-----------------------------------------------------------------------------------------
| end of epoch  75 | time per epoch: 1777.61s |
| Train Metrics | accuracy:  0.70 | loss:  1.19
| Eval  Metrics | accuracy:  0.80 | loss:  0.67
-----------------------------------------------------------------------------------------
| epoch 76 | 1000/1179 batches | ms/batch 1497.98 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.23
-----------------------------------------------------------------------------------------
| end of epoch  76 | time per epoch: 1763.62s |
| Train Metrics | accuracy:  0.69 | loss:  1.22
| Eval  Metrics | accuracy:  0.80 | loss:  0.68
-----------------------------------------------------------------------------------------
[2025-02-25 21:00:55,348][absl][INFO] - Saving checkpoint at step: 89604
[2025-02-25 21:00:55,350][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 21:00:55,351][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 21:00:55,352][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_89604.
[2025-02-25 21:00:55,368][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 21:00:55,369][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_89604.orbax-checkpoint-tmp-31
[2025-02-25 21:00:55,380][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 21:00:55,406][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 21:00:55,436][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 166.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-25 21:00:55,638][absl][INFO] - ChainedFuture completed 1/1 futures in 0.20 seconds.
[2025-02-25 21:00:55,638][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 35.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 256 milliseconds) (per-host)
[2025-02-25 21:00:55,643][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 21:00:55,671][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_89604.orbax-checkpoint-tmp-31 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_89604
[2025-02-25 21:00:55,676][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_89604`.
[2025-02-25 21:00:55,676][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 21:00:55,678][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_70740
| epoch 77 | 1000/1179 batches | ms/batch 1503.37 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.18
-----------------------------------------------------------------------------------------
| end of epoch  77 | time per epoch: 1772.07s |
| Train Metrics | accuracy:  0.70 | loss:  1.18
| Eval  Metrics | accuracy:  0.78 | loss:  0.74
-----------------------------------------------------------------------------------------
| epoch 78 | 1000/1179 batches | ms/batch 1519.63 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.16
-----------------------------------------------------------------------------------------
| end of epoch  78 | time per epoch: 1790.56s |
| Train Metrics | accuracy:  0.70 | loss:  1.16
| Eval  Metrics | accuracy:  0.80 | loss:  0.69
-----------------------------------------------------------------------------------------
| epoch 79 | 1000/1179 batches | ms/batch 1542.69 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.19
-----------------------------------------------------------------------------------------
| end of epoch  79 | time per epoch: 1817.20s |
| Train Metrics | accuracy:  0.70 | loss:  1.18
| Eval  Metrics | accuracy:  0.80 | loss:  0.68
-----------------------------------------------------------------------------------------
| epoch 80 | 1000/1179 batches | ms/batch 1540.01 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.19
-----------------------------------------------------------------------------------------
| end of epoch  80 | time per epoch: 1817.89s |
| Train Metrics | accuracy:  0.70 | loss:  1.19
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.18959426879882812,
    "std": 0.2729912996292114,
    "var": 0.07452425360679626,
    "min": -0.2069590538740158,
    "max": 1.0110645294189453,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.3233979642391205,
    "std": 0.20765948295593262,
    "var": 0.043122462928295135,
    "min": 0.07235938310623169,
    "max": 1.2075574398040771,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0003731875622179359,
    "std": 0.10842683166265488,
    "var": 0.01175637822598219,
    "min": -0.5877060294151306,
    "max": 0.5575752258300781,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.22642672061920166,
    "std": 0.17152465879917145,
    "var": 0.02942070923745632,
    "min": -0.147225484251976,
    "max": 0.7421244382858276,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.4033212661743164,
    "std": 0.299889475107193,
    "var": 0.08993370831012726,
    "min": 0.08025266230106354,
    "max": 1.4409282207489014,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0004750762600451708,
    "std": 0.11450282484292984,
    "var": 0.01311089750379324,
    "min": -0.6621545553207397,
    "max": 0.5235015749931335,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2723345160484314,
    "std": 0.28359559178352356,
    "var": 0.08042646199464798,
    "min": -0.022580387070775032,
    "max": 1.0010091066360474,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.2981739938259125,
    "std": 0.2362276166677475,
    "var": 0.055803488940000534,
    "min": 0.04397495463490486,
    "max": 1.6848198175430298,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0010037256870418787,
    "std": 0.11886414140462875,
    "var": 0.014128684997558594,
    "min": -0.7608869671821594,
    "max": 0.8905377388000488,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.1607942432165146,
    "std": 0.2033950686454773,
    "var": 0.04136955738067627,
    "min": -0.29361581802368164,
    "max": 0.9443232417106628,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.561924159526825,
    "std": 0.27405938506126404,
    "var": 0.07510855048894882,
    "min": 0.06027067452669144,
    "max": 2.1864209175109863,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0008829593425616622,
    "std": 0.08120487630367279,
    "var": 0.006594232749193907,
    "min": -0.9117533564567566,
    "max": 0.8598209023475647,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.13764894008636475,
    "std": 0.24873007833957672,
    "var": 0.061866652220487595,
    "min": -0.6204034090042114,
    "max": 1.0785846710205078,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6959185600280762,
    "std": 0.3149612843990326,
    "var": 0.09920060634613037,
    "min": 0.12262418121099472,
    "max": 2.0250563621520996,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00012361837434582412,
    "std": 0.058182839304208755,
    "var": 0.0033852425403892994,
    "min": -0.4913484454154968,
    "max": 0.5832521915435791,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.04582870006561279,
    "std": 0.11360201239585876,
    "var": 0.012905417010188103,
    "min": -0.6566023230552673,
    "max": 0.22901961207389832,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.0792561769485474,
    "std": 0.30316081643104553,
    "var": 0.09190648794174194,
    "min": 0.5809049606323242,
    "max": 2.522602081298828,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.000297021702863276,
    "std": 0.08406604826450348,
    "var": 0.007067101076245308,
    "min": -0.7703147530555725,
    "max": 0.670234739780426,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00046498895972035825,
    "std": 0.10514365136623383,
    "var": 0.01105518825352192,
    "min": -0.7051222920417786,
    "max": 0.8072471618652344,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0007277670665644109,
    "std": 0.10772161930799484,
    "var": 0.011603946797549725,
    "min": -0.5412582159042358,
    "max": 0.5346899628639221,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0008682509651407599,
    "std": 0.10949311405420303,
    "var": 0.011988742277026176,
    "min": -0.6377183794975281,
    "max": 0.6419031620025635,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00011915628419956192,
    "std": 0.09511122107505798,
    "var": 0.009046144783496857,
    "min": -0.8392425179481506,
    "max": 0.8143451809883118,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00033477082615718246,
    "std": 0.09309221059083939,
    "var": 0.008666159585118294,
    "min": -0.6075490117073059,
    "max": 0.7095702886581421,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0005265586078166962,
    "std": 0.10320956259965897,
    "var": 0.010652214288711548,
    "min": -0.7092446684837341,
    "max": 0.640760064125061,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3900769352912903,
    "std": 0.12865692377090454,
    "var": 0.016552602872252464,
    "min": -0.7552461624145508,
    "max": -0.09703721851110458,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.09480440616607666,
    "std": 0.3061651885509491,
    "var": 0.09373712539672852,
    "min": -1.5133568048477173,
    "max": 1.2757316827774048,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.766312301158905,
    "std": 1.0410398244857788,
    "var": 1.0837639570236206,
    "min": -2.388808250427246,
    "max": 3.107530117034912,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.27703067660331726,
    "std": 0.16634880006313324,
    "var": 0.027671923860907555,
    "min": -0.6526917219161987,
    "max": 0.16459216177463531,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19981993734836578,
    "std": 0.22019383311271667,
    "var": 0.04848532751202583,
    "min": -1.5731205940246582,
    "max": 0.5915505290031433,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.1760661602020264,
    "std": 1.0491349697113037,
    "var": 1.1006842851638794,
    "min": -1.472672939300537,
    "max": 4.834375381469727,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.3212270736694336,
    "std": 0.10913947224617004,
    "var": 0.011911424808204174,
    "min": -0.6252358555793762,
    "max": -0.07591865956783295,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.141073539853096,
    "std": 0.20108675956726074,
    "var": 0.04043588414788246,
    "min": -1.5129265785217285,
    "max": 0.5934479832649231,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.4648352861404419,
    "std": 0.6771671175956726,
    "var": 0.45855531096458435,
    "min": -1.3012104034423828,
    "max": 3.1188786029815674,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.12564948201179504,
    "std": 0.0937192365527153,
    "var": 0.008783294819295406,
    "min": -0.4262816309928894,
    "max": 0.1170685812830925,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08423858135938644,
    "std": 0.1629900485277176,
    "var": 0.026565756648778915,
    "min": -1.0348272323608398,
    "max": 0.5212411284446716,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.00018907288904301822,
    "std": 0.007944600656628609,
    "var": 6.311669130809605e-05,
    "min": -0.026166189461946487,
    "max": 0.02558181993663311,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.0007454921142198145,
    "std": 0.11547954380512238,
    "var": 0.01333552598953247,
    "min": -1.0084011554718018,
    "max": 1.006301999092102,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.03817983344197273,
    "std": 0.4283628761768341,
    "var": 0.18349474668502808,
    "min": -3.949712038040161,
    "max": 2.5065367221832275,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15906579792499542,
    "std": 0.10753608494997025,
    "var": 0.011564008891582489,
    "min": -0.547724723815918,
    "max": 0.07148681581020355,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07563938200473785,
    "std": 0.16400328278541565,
    "var": 0.02689707651734352,
    "min": -1.4509291648864746,
    "max": 0.6991643309593201,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.22785863280296326,
    "std": 1.033389925956726,
    "var": 1.0678948163986206,
    "min": -3.1377270221710205,
    "max": 2.8281776905059814,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.026050563901662827,
    "std": 0.13677506148815155,
    "var": 0.01870741881430149,
    "min": -0.48758527636528015,
    "max": 0.31410419940948486,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.04266900196671486,
    "std": 0.15981976687908173,
    "var": 0.025542359799146652,
    "min": -0.997525155544281,
    "max": 0.6140040755271912,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.4626309275627136,
    "std": 0.6937081813812256,
    "var": 0.48123109340667725,
    "min": -1.2959986925125122,
    "max": 3.0136451721191406,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.01279746275395155,
    "std": 0.07853621244430542,
    "var": 0.006167937070131302,
    "min": -0.18751965463161469,
    "max": 0.14005319774150848,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0005992913502268493,
    "std": 0.21516530215740204,
    "var": 0.04629610851407051,
    "min": -0.8796039819717407,
    "max": 0.9615548253059387,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": 3.720027962117456e-05,
    "std": 0.2731141448020935,
    "var": 0.07459133863449097,
    "min": -1.3444675207138062,
    "max": 1.3499277830123901,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.4187358021736145,
    "std": 0.44821467995643616,
    "var": 0.20089641213417053,
    "min": -1.405664324760437,
    "max": 0.8953570127487183,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.44747933745384216,
    "std": 0.46520060300827026,
    "var": 0.21641160547733307,
    "min": -1.8698264360427856,
    "max": 0.7083606123924255,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.4367046058177948,
    "std": 0.4198811948299408,
    "var": 0.17630021274089813,
    "min": -1.9283920526504517,
    "max": 0.504615068435669,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.9590463042259216,
    "std": 0.4977802634239197,
    "var": 0.24778521060943604,
    "min": -2.4397785663604736,
    "max": 0.5130401253700256,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.1106282472610474,
    "std": 0.44401639699935913,
    "var": 0.1971505582332611,
    "min": -2.2007930278778076,
    "max": 0.40023112297058105,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.037975549697876,
    "std": 0.5586723685264587,
    "var": 0.31211477518081665,
    "min": -2.439124822616577,
    "max": 0.15937580168247223,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.80 | loss:  0.69
-----------------------------------------------------------------------------------------
| epoch 81 | 1000/1179 batches | ms/batch 1554.25 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.20
-----------------------------------------------------------------------------------------
| end of epoch  81 | time per epoch: 1836.21s |
| Train Metrics | accuracy:  0.70 | loss:  1.19
| Eval  Metrics | accuracy:  0.79 | loss:  0.70
-----------------------------------------------------------------------------------------
| epoch 82 | 1000/1179 batches | ms/batch 1570.59 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.19
-----------------------------------------------------------------------------------------
| end of epoch  82 | time per epoch: 1851.84s |
| Train Metrics | accuracy:  0.71 | loss:  1.17
| Eval  Metrics | accuracy:  0.79 | loss:  0.70
-----------------------------------------------------------------------------------------
| epoch 83 | 1000/1179 batches | ms/batch 1579.88 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.17
-----------------------------------------------------------------------------------------
| end of epoch  83 | time per epoch: 1864.18s |
| Train Metrics | accuracy:  0.70 | loss:  1.17
| Eval  Metrics | accuracy:  0.79 | loss:  0.72
-----------------------------------------------------------------------------------------
| epoch 84 | 1000/1179 batches | ms/batch 1590.58 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.14
-----------------------------------------------------------------------------------------
| end of epoch  84 | time per epoch: 1876.09s |
| Train Metrics | accuracy:  0.71 | loss:  1.13
| Eval  Metrics | accuracy:  0.80 | loss:  0.65
-----------------------------------------------------------------------------------------
[2025-02-26 01:30:50,219][absl][INFO] - Saving checkpoint at step: 99036
[2025-02-26 01:30:50,222][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 01:30:50,222][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 01:30:50,223][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_99036.
[2025-02-26 01:30:50,450][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 01:30:50,451][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_99036.orbax-checkpoint-tmp-32
[2025-02-26 01:30:50,460][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 01:30:50,486][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 01:30:50,514][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 169.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 53 milliseconds) (per-host)
[2025-02-26 01:30:50,720][absl][INFO] - ChainedFuture completed 1/1 futures in 0.21 seconds.
[2025-02-26 01:30:50,720][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 35.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 259 milliseconds) (per-host)
[2025-02-26 01:30:50,725][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 01:30:50,754][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_99036.orbax-checkpoint-tmp-32 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_99036
[2025-02-26 01:30:50,759][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_99036`.
[2025-02-26 01:30:50,759][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 01:30:50,761][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_89604
| epoch 85 | 1000/1179 batches | ms/batch 1605.80 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.16
-----------------------------------------------------------------------------------------
| end of epoch  85 | time per epoch: 1893.96s |
| Train Metrics | accuracy:  0.70 | loss:  1.17
| Eval  Metrics | accuracy:  0.79 | loss:  0.74
-----------------------------------------------------------------------------------------
| epoch 86 | 1000/1179 batches | ms/batch 1616.73 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.16
-----------------------------------------------------------------------------------------
| end of epoch  86 | time per epoch: 1906.00s |
| Train Metrics | accuracy:  0.71 | loss:  1.17
| Eval  Metrics | accuracy:  0.80 | loss:  0.69
-----------------------------------------------------------------------------------------
| epoch 87 | 1000/1179 batches | ms/batch 1638.04 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.18
-----------------------------------------------------------------------------------------
| end of epoch  87 | time per epoch: 1930.32s |
| Train Metrics | accuracy:  0.70 | loss:  1.18
| Eval  Metrics | accuracy:  0.80 | loss:  0.69
-----------------------------------------------------------------------------------------
| epoch 88 | 1000/1179 batches | ms/batch 1639.28 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.16
-----------------------------------------------------------------------------------------
| end of epoch  88 | time per epoch: 1931.67s |
| Train Metrics | accuracy:  0.71 | loss:  1.16
| Eval  Metrics | accuracy:  0.81 | loss:  0.69
-----------------------------------------------------------------------------------------
[2025-02-26 03:52:19,591][absl][INFO] - Saving checkpoint at step: 103752
[2025-02-26 03:52:19,594][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 03:52:19,594][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 03:52:19,595][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_103752.
[2025-02-26 03:52:19,603][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 03:52:19,605][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_103752.orbax-checkpoint-tmp-33
[2025-02-26 03:52:19,614][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 03:52:19,640][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 03:52:19,670][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 166.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-26 03:52:19,888][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-26 03:52:19,888][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 273 milliseconds) (per-host)
[2025-02-26 03:52:19,894][absl][INFO] - Wrote Metadata={'item_handlers': 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler', 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1740559939611026352, 'commit_timestamp_nsecs': None, 'custom': {}}, json={"item_handlers": "orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler", "metrics": {}, "performance_metrics": {}, "init_timestamp_nsecs": 1740559939611026352, "commit_timestamp_nsecs": null, "custom": {}} to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_103752.orbax-checkpoint-tmp-33/_CHECKPOINT_METADATA
[2025-02-26 03:52:19,894][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 03:52:19,922][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_103752.orbax-checkpoint-tmp-33 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_103752
[2025-02-26 03:52:19,928][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_103752`.
[2025-02-26 03:52:19,928][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 03:52:19,930][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_99036
| epoch 89 | 1000/1179 batches | ms/batch 1654.72 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.13
-----------------------------------------------------------------------------------------
| end of epoch  89 | time per epoch: 1953.96s |
| Train Metrics | accuracy:  0.71 | loss:  1.13
| Eval  Metrics | accuracy:  0.80 | loss:  0.66
-----------------------------------------------------------------------------------------
| epoch 90 | 1000/1179 batches | ms/batch 1666.72 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.16
-----------------------------------------------------------------------------------------
| end of epoch  90 | time per epoch: 1968.83s |
| Train Metrics | accuracy:  0.71 | loss:  1.17
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.2067178189754486,
    "std": 0.2833375930786133,
    "var": 0.08028019964694977,
    "min": -0.21820662915706635,
    "max": 1.017482876777649,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.33135780692100525,
    "std": 0.21903373301029205,
    "var": 0.047975778579711914,
    "min": 0.06567495316267014,
    "max": 1.2269560098648071,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0006704190745949745,
    "std": 0.10976152122020721,
    "var": 0.012047591619193554,
    "min": -0.6144317984580994,
    "max": 0.5848957300186157,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.22963647544384003,
    "std": 0.17711761593818665,
    "var": 0.031370650976896286,
    "min": -0.10345321893692017,
    "max": 0.7853158712387085,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.4009532928466797,
    "std": 0.31345200538635254,
    "var": 0.09825216233730316,
    "min": 0.08031217008829117,
    "max": 1.4892092943191528,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0006108393426984549,
    "std": 0.11664389818906784,
    "var": 0.013605799525976181,
    "min": -0.6779997944831848,
    "max": 0.5564345717430115,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.27461427450180054,
    "std": 0.28331565856933594,
    "var": 0.0802677720785141,
    "min": -0.028497008606791496,
    "max": 1.0161292552947998,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.3092637360095978,
    "std": 0.2460210919380188,
    "var": 0.06052638217806816,
    "min": 0.028078561648726463,
    "max": 1.6344434022903442,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0007949296268634498,
    "std": 0.12113526463508606,
    "var": 0.014673752710223198,
    "min": -0.792289674282074,
    "max": 0.9258995056152344,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.161260724067688,
    "std": 0.20397143065929413,
    "var": 0.04160434752702713,
    "min": -0.2844570577144623,
    "max": 0.9702053666114807,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.5715115070343018,
    "std": 0.2836209535598755,
    "var": 0.08044084906578064,
    "min": 0.07011418789625168,
    "max": 2.331756114959717,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0008164059836417437,
    "std": 0.08108110725879669,
    "var": 0.0065741464495658875,
    "min": -0.9391367435455322,
    "max": 0.9020308256149292,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.14737576246261597,
    "std": 0.24780386686325073,
    "var": 0.061406753957271576,
    "min": -0.568382740020752,
    "max": 1.0644794702529907,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6869608759880066,
    "std": 0.3093456029891968,
    "var": 0.09569470584392548,
    "min": 0.13841764628887177,
    "max": 1.8989735841751099,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0001804994826670736,
    "std": 0.05811426043510437,
    "var": 0.0033772671595215797,
    "min": -0.5324345231056213,
    "max": 0.6077566742897034,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.042388468980789185,
    "std": 0.11462074518203735,
    "var": 0.01313791610300541,
    "min": -0.6594606041908264,
    "max": 0.2666471302509308,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.1006605625152588,
    "std": 0.30620649456977844,
    "var": 0.09376242011785507,
    "min": 0.6185624599456787,
    "max": 2.53997802734375,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00027901289286091924,
    "std": 0.08596369624137878,
    "var": 0.007389756850898266,
    "min": -0.839952826499939,
    "max": 0.7434694170951843,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0008213394321501255,
    "std": 0.10037925094366074,
    "var": 0.01007599476724863,
    "min": -0.611956775188446,
    "max": 0.7267764210700989,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00021421629935503006,
    "std": 0.10311222076416016,
    "var": 0.010632130317389965,
    "min": -0.4837389290332794,
    "max": 0.5072396397590637,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0003299026284366846,
    "std": 0.10451695322990417,
    "var": 0.010923793539404869,
    "min": -0.5368160009384155,
    "max": 0.5691709518432617,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00023470322776120156,
    "std": 0.08963045477867126,
    "var": 0.008033618330955505,
    "min": -0.8063485622406006,
    "max": 0.7550550103187561,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0005285479128360748,
    "std": 0.08868488669395447,
    "var": 0.00786500982940197,
    "min": -0.5485878586769104,
    "max": 0.7100303173065186,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0004846260999329388,
    "std": 0.09850703179836273,
    "var": 0.00970363523811102,
    "min": -0.7226414680480957,
    "max": 0.6391228437423706,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3782491683959961,
    "std": 0.11603958904743195,
    "var": 0.013465186581015587,
    "min": -0.6906677484512329,
    "max": -0.11665522307157516,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.0970647856593132,
    "std": 0.2988865077495575,
    "var": 0.08933314681053162,
    "min": -1.3539594411849976,
    "max": 1.2843114137649536,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.6915530562400818,
    "std": 1.063370704650879,
    "var": 1.1307573318481445,
    "min": -2.532470464706421,
    "max": 2.921107769012451,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.2784535586833954,
    "std": 0.16113808751106262,
    "var": 0.025965481996536255,
    "min": -0.6824513077735901,
    "max": 0.09595870971679688,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19986997544765472,
    "std": 0.21842773258686066,
    "var": 0.04771067574620247,
    "min": -1.6480703353881836,
    "max": 0.5520163178443909,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.121181845664978,
    "std": 1.0148063898086548,
    "var": 1.029831886291504,
    "min": -1.5341781377792358,
    "max": 4.654779434204102,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.3177028298377991,
    "std": 0.1120900958776474,
    "var": 0.012564189732074738,
    "min": -0.6434298157691956,
    "max": -0.07537464052438736,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.14100250601768494,
    "std": 0.20009642839431763,
    "var": 0.0400385782122612,
    "min": -1.3612301349639893,
    "max": 0.7198717594146729,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.4215822219848633,
    "std": 0.6681430339813232,
    "var": 0.44641512632369995,
    "min": -1.2480748891830444,
    "max": 3.147969961166382,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.12704329192638397,
    "std": 0.09775403887033463,
    "var": 0.00955585204064846,
    "min": -0.4823296070098877,
    "max": 0.11386021226644516,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08355595171451569,
    "std": 0.16029949486255646,
    "var": 0.025695929303765297,
    "min": -1.081813931465149,
    "max": 0.5096979141235352,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.00043971449485979974,
    "std": 0.006573409307748079,
    "var": 4.320970765547827e-05,
    "min": -0.025775248184800148,
    "max": 0.021676983684301376,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.0005939154070802033,
    "std": 0.1142636314034462,
    "var": 0.013056177645921707,
    "min": -1.0030450820922852,
    "max": 0.9320414662361145,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.03761214762926102,
    "std": 0.41524067521095276,
    "var": 0.17242483794689178,
    "min": -3.779850721359253,
    "max": 2.2923972606658936,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15473124384880066,
    "std": 0.10278966277837753,
    "var": 0.010565714910626411,
    "min": -0.5441873073577881,
    "max": 0.07136683911085129,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07416558265686035,
    "std": 0.16126659512519836,
    "var": 0.02600691467523575,
    "min": -1.4866772890090942,
    "max": 0.7510101795196533,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.22857658565044403,
    "std": 0.9936137199401855,
    "var": 0.9872682094573975,
    "min": -3.012861490249634,
    "max": 2.8083319664001465,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.029953375458717346,
    "std": 0.1353505402803421,
    "var": 0.01831977069377899,
    "min": -0.44827499985694885,
    "max": 0.3180152177810669,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.041736774146556854,
    "std": 0.1557123363018036,
    "var": 0.024246331304311752,
    "min": -1.014793872833252,
    "max": 0.6167886257171631,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.44723284244537354,
    "std": 0.6566593647003174,
    "var": 0.4312015473842621,
    "min": -0.931373655796051,
    "max": 2.9618825912475586,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.011994263157248497,
    "std": 0.07460159063339233,
    "var": 0.0055653974413871765,
    "min": -0.18871258199214935,
    "max": 0.12392210960388184,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.001083725830540061,
    "std": 0.21512584388256073,
    "var": 0.04627912864089012,
    "min": -0.859595000743866,
    "max": 0.9155963063240051,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.0006371336639858782,
    "std": 0.2634965777397156,
    "var": 0.06943044811487198,
    "min": -1.3220089673995972,
    "max": 1.348183274269104,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.35668763518333435,
    "std": 0.44307300448417664,
    "var": 0.19631367921829224,
    "min": -1.2414238452911377,
    "max": 1.081775426864624,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.40526247024536133,
    "std": 0.4467167556285858,
    "var": 0.1995558738708496,
    "min": -1.7888410091400146,
    "max": 0.73455810546875,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.3914881944656372,
    "std": 0.4131726324558258,
    "var": 0.17071163654327393,
    "min": -1.8635594844818115,
    "max": 0.5425305962562561,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.9540073871612549,
    "std": 0.5036818385124207,
    "var": 0.25369542837142944,
    "min": -2.446700096130371,
    "max": 0.47598230838775635,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.080574870109558,
    "std": 0.4462597966194153,
    "var": 0.19914782047271729,
    "min": -2.1718597412109375,
    "max": 0.4059436619281769,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.9886540174484253,
    "std": 0.5581981539726257,
    "var": 0.3115851879119873,
    "min": -2.4319021701812744,
    "max": 0.25812646746635437,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.78 | loss:  0.76
-----------------------------------------------------------------------------------------
| epoch 91 | 1000/1179 batches | ms/batch 1678.30 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.19
-----------------------------------------------------------------------------------------
| end of epoch  91 | time per epoch: 1978.75s |
| Train Metrics | accuracy:  0.70 | loss:  1.19
| Eval  Metrics | accuracy:  0.81 | loss:  0.68
-----------------------------------------------------------------------------------------
| epoch 92 | 1000/1179 batches | ms/batch 1690.30 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.14
-----------------------------------------------------------------------------------------
| end of epoch  92 | time per epoch: 1991.91s |
| Train Metrics | accuracy:  0.71 | loss:  1.14
| Eval  Metrics | accuracy:  0.80 | loss:  0.66
-----------------------------------------------------------------------------------------
| epoch 93 | 1000/1179 batches | ms/batch 1706.65 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.16
-----------------------------------------------------------------------------------------
| end of epoch  93 | time per epoch: 2012.03s |
| Train Metrics | accuracy:  0.71 | loss:  1.17
| Eval  Metrics | accuracy:  0.80 | loss:  0.69
-----------------------------------------------------------------------------------------
| epoch 94 | 1000/1179 batches | ms/batch 1721.26 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.15
-----------------------------------------------------------------------------------------
| end of epoch  94 | time per epoch: 2030.70s |
| Train Metrics | accuracy:  0.71 | loss:  1.16
| Eval  Metrics | accuracy:  0.81 | loss:  0.70
-----------------------------------------------------------------------------------------
[2025-02-26 07:32:58,557][absl][INFO] - Saving checkpoint at step: 110826
[2025-02-26 07:32:58,559][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 07:32:58,560][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 07:32:58,561][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_110826.
[2025-02-26 07:32:58,728][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 07:32:58,729][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_110826.orbax-checkpoint-tmp-34
[2025-02-26 07:32:58,738][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 07:32:58,764][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 07:32:58,780][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 219.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 41 milliseconds) (per-host)
[2025-02-26 07:32:59,325][absl][INFO] - ChainedFuture completed 1/1 futures in 0.54 seconds.
[2025-02-26 07:32:59,325][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 15.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 586 milliseconds) (per-host)
[2025-02-26 07:32:59,330][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 07:32:59,358][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_110826.orbax-checkpoint-tmp-34 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_110826
[2025-02-26 07:32:59,363][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_110826`.
[2025-02-26 07:32:59,363][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 07:32:59,365][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_103752
| epoch 95 | 1000/1179 batches | ms/batch 1726.37 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.15
-----------------------------------------------------------------------------------------
| end of epoch  95 | time per epoch: 2036.48s |
| Train Metrics | accuracy:  0.71 | loss:  1.15
| Eval  Metrics | accuracy:  0.81 | loss:  0.65
-----------------------------------------------------------------------------------------
[2025-02-26 08:10:37,504][absl][INFO] - Saving checkpoint at step: 112005
[2025-02-26 08:10:37,506][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 08:10:37,506][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 08:10:37,507][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_112005.
[2025-02-26 08:10:37,515][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 08:10:37,516][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_112005.orbax-checkpoint-tmp-35
[2025-02-26 08:10:37,522][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 08:10:37,549][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 08:10:37,579][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 164.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 55 milliseconds) (per-host)
[2025-02-26 08:10:37,787][absl][INFO] - ChainedFuture completed 1/1 futures in 0.21 seconds.
[2025-02-26 08:10:37,787][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 34.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 264 milliseconds) (per-host)
[2025-02-26 08:10:37,792][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 08:10:37,821][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_112005.orbax-checkpoint-tmp-35 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_112005
[2025-02-26 08:10:37,826][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_112005`.
[2025-02-26 08:10:37,826][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 08:10:37,827][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_110826
| epoch 96 | 1000/1179 batches | ms/batch 1738.16 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.16
-----------------------------------------------------------------------------------------
| end of epoch  96 | time per epoch: 2052.66s |
| Train Metrics | accuracy:  0.71 | loss:  1.16
| Eval  Metrics | accuracy:  0.81 | loss:  0.66
-----------------------------------------------------------------------------------------
| epoch 97 | 1000/1179 batches | ms/batch 1774.69 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.13
-----------------------------------------------------------------------------------------
| end of epoch  97 | time per epoch: 2088.76s |
| Train Metrics | accuracy:  0.72 | loss:  1.13
| Eval  Metrics | accuracy:  0.81 | loss:  0.65
-----------------------------------------------------------------------------------------
| epoch 98 | 1000/1179 batches | ms/batch 1761.37 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.13
-----------------------------------------------------------------------------------------
| end of epoch  98 | time per epoch: 2077.41s |
| Train Metrics | accuracy:  0.72 | loss:  1.13
| Eval  Metrics | accuracy:  0.81 | loss:  0.68
-----------------------------------------------------------------------------------------
| epoch 99 | 1000/1179 batches | ms/batch 1706.34 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.13
-----------------------------------------------------------------------------------------
| end of epoch  99 | time per epoch: 1975.58s |
| Train Metrics | accuracy:  0.72 | loss:  1.12
| Eval  Metrics | accuracy:  0.81 | loss:  0.64
-----------------------------------------------------------------------------------------
| epoch 100 | 1000/1179 batches | ms/batch 1756.03 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.16
-----------------------------------------------------------------------------------------
| end of epoch 100 | time per epoch: 2076.43s |
| Train Metrics | accuracy:  0.71 | loss:  1.16
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.222126767039299,
    "std": 0.2983129024505615,
    "var": 0.08899058401584625,
    "min": -0.21254171431064606,
    "max": 1.1016690731048584,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.3344728946685791,
    "std": 0.2303728312253952,
    "var": 0.05307164043188095,
    "min": 0.06650731712579727,
    "max": 1.290005087852478,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.000734807166736573,
    "std": 0.11061091721057892,
    "var": 0.012234775349497795,
    "min": -0.6364043354988098,
    "max": 0.611629843711853,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.2364509552717209,
    "std": 0.18241092562675476,
    "var": 0.03327374532818794,
    "min": -0.09998282790184021,
    "max": 0.8176192045211792,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.3994755148887634,
    "std": 0.32085490226745605,
    "var": 0.10294787585735321,
    "min": 0.07973457127809525,
    "max": 1.5004059076309204,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00048510864144191146,
    "std": 0.1182723194360733,
    "var": 0.013988341204822063,
    "min": -0.6985551714897156,
    "max": 0.5723957419395447,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.28088051080703735,
    "std": 0.2893063724040985,
    "var": 0.08369817584753036,
    "min": -0.020627088844776154,
    "max": 1.0066243410110474,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.3176511526107788,
    "std": 0.2634018063545227,
    "var": 0.06938052177429199,
    "min": 0.05462735518813133,
    "max": 1.6572613716125488,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00079623784404248,
    "std": 0.12296560406684875,
    "var": 0.01512053981423378,
    "min": -0.8037911653518677,
    "max": 0.9480705261230469,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.1719483733177185,
    "std": 0.20833106338977814,
    "var": 0.04340182989835739,
    "min": -0.27071473002433777,
    "max": 1.0183366537094116,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.5700861215591431,
    "std": 0.2878338396549225,
    "var": 0.08284832537174225,
    "min": 0.07189072668552399,
    "max": 2.299586296081543,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0007486280519515276,
    "std": 0.08070465177297592,
    "var": 0.006513240747153759,
    "min": -0.9591407775878906,
    "max": 0.9276847839355469,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.1540038287639618,
    "std": 0.24566394090652466,
    "var": 0.060350771993398666,
    "min": -0.5209341645240784,
    "max": 1.0956517457962036,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6796362400054932,
    "std": 0.30620408058166504,
    "var": 0.09376095235347748,
    "min": 0.12787793576717377,
    "max": 1.8572447299957275,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0001465886307414621,
    "std": 0.05804057791829109,
    "var": 0.0033687090035527945,
    "min": -0.5696423053741455,
    "max": 0.6315498352050781,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.04297028109431267,
    "std": 0.11029516905546188,
    "var": 0.012165024876594543,
    "min": -0.6772572994232178,
    "max": 0.26252520084381104,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.1208595037460327,
    "std": 0.30806511640548706,
    "var": 0.09490412473678589,
    "min": 0.6591793298721313,
    "max": 2.575791358947754,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0003371232596691698,
    "std": 0.08738696575164795,
    "var": 0.007636481896042824,
    "min": -0.8946986198425293,
    "max": 0.8046414256095886,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0004262676811777055,
    "std": 0.09386444091796875,
    "var": 0.00881053414195776,
    "min": -0.5831564664840698,
    "max": 0.6968328952789307,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.0003876677656080574,
    "std": 0.09755894541740417,
    "var": 0.009517748840153217,
    "min": -0.46178290247917175,
    "max": 0.49533915519714355,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.00041531468741595745,
    "std": 0.09876483678817749,
    "var": 0.009754492901265621,
    "min": -0.5396180748939514,
    "max": 0.542206346988678,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0001977225037990138,
    "std": 0.08414669334888458,
    "var": 0.007080665789544582,
    "min": -0.7449743151664734,
    "max": 0.718902587890625,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0005748533876612782,
    "std": 0.08419084548950195,
    "var": 0.007088098209351301,
    "min": -0.5163988471031189,
    "max": 0.6614734530448914,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.00026823635562323034,
    "std": 0.09337916970252991,
    "var": 0.0087196696549654,
    "min": -0.6725891828536987,
    "max": 0.6126992106437683,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.36995622515678406,
    "std": 0.11732270568609238,
    "var": 0.013764617964625359,
    "min": -0.7484214901924133,
    "max": -0.08793003857135773,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.09817536920309067,
    "std": 0.2905983626842499,
    "var": 0.08444741368293762,
    "min": -1.4587111473083496,
    "max": 1.2012090682983398,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.6417475938796997,
    "std": 1.0634554624557495,
    "var": 1.1309374570846558,
    "min": -2.5432615280151367,
    "max": 2.818883180618286,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.27889418601989746,
    "std": 0.15871737897396088,
    "var": 0.025191206485033035,
    "min": -0.7776069045066833,
    "max": 0.08180385828018188,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.20015016198158264,
    "std": 0.21784809231758118,
    "var": 0.04745779559016228,
    "min": -1.4661662578582764,
    "max": 0.6269362568855286,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.071105718612671,
    "std": 0.9911978840827942,
    "var": 0.9824732542037964,
    "min": -1.6157249212265015,
    "max": 4.4134650230407715,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.3131380081176758,
    "std": 0.11242856085300446,
    "var": 0.012640180997550488,
    "min": -0.6151580214500427,
    "max": -0.0819062888622284,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.14118368923664093,
    "std": 0.1980762630701065,
    "var": 0.039234209805727005,
    "min": -1.2630486488342285,
    "max": 0.7815484404563904,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.3967406749725342,
    "std": 0.6581962704658508,
    "var": 0.43322235345840454,
    "min": -1.2174936532974243,
    "max": 3.076813220977783,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.12929533421993256,
    "std": 0.09262319654226303,
    "var": 0.008579056710004807,
    "min": -0.44137975573539734,
    "max": 0.07548443228006363,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08218968659639359,
    "std": 0.15630441904067993,
    "var": 0.024431070312857628,
    "min": -1.0858666896820068,
    "max": 0.5419846177101135,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0008217570721171796,
    "std": 0.006369061768054962,
    "var": 4.056494799442589e-05,
    "min": -0.029913362115621567,
    "max": 0.01595843955874443,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.0003301553661003709,
    "std": 0.11189352720975876,
    "var": 0.01252016145735979,
    "min": -0.9646556973457336,
    "max": 0.8540323972702026,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.034663304686546326,
    "std": 0.39614734053611755,
    "var": 0.15693272650241852,
    "min": -3.577416181564331,
    "max": 2.02679705619812,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15256091952323914,
    "std": 0.09736748784780502,
    "var": 0.009480427950620651,
    "min": -0.5325495004653931,
    "max": 0.06448806822299957,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07341761142015457,
    "std": 0.15740111470222473,
    "var": 0.024775110185146332,
    "min": -1.4963021278381348,
    "max": 0.6896224617958069,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.23116068542003632,
    "std": 0.949330747127533,
    "var": 0.9012289047241211,
    "min": -2.939286947250366,
    "max": 2.6862103939056396,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.03959942236542702,
    "std": 0.13492251932621002,
    "var": 0.018204087391495705,
    "min": -0.41322407126426697,
    "max": 0.3310042917728424,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.03997955843806267,
    "std": 0.15084227919578552,
    "var": 0.022753393277525902,
    "min": -0.9524514675140381,
    "max": 0.6014698147773743,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.4287692904472351,
    "std": 0.6204749941825867,
    "var": 0.3849892318248749,
    "min": -0.9126912951469421,
    "max": 2.8010923862457275,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.012052973732352257,
    "std": 0.07524839788675308,
    "var": 0.005662321578711271,
    "min": -0.19005519151687622,
    "max": 0.13120315968990326,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0013900576159358025,
    "std": 0.21540845930576324,
    "var": 0.046400804072618484,
    "min": -0.8516709208488464,
    "max": 0.873146653175354,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.0011460819514468312,
    "std": 0.253428190946579,
    "var": 0.06422585248947144,
    "min": -1.2587714195251465,
    "max": 1.2315016984939575,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.31615549325942993,
    "std": 0.4333614110946655,
    "var": 0.18780212104320526,
    "min": -1.1845805644989014,
    "max": 1.1669533252716064,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.36785024404525757,
    "std": 0.44243037700653076,
    "var": 0.19574463367462158,
    "min": -1.7581260204315186,
    "max": 0.7774671316146851,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.35728326439857483,
    "std": 0.4062764048576355,
    "var": 0.16506052017211914,
    "min": -1.7669622898101807,
    "max": 0.6128793358802795,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.9395079612731934,
    "std": 0.5071938633918762,
    "var": 0.25724563002586365,
    "min": -2.3574376106262207,
    "max": 0.4671485126018524,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.0417006015777588,
    "std": 0.45002397894859314,
    "var": 0.20252159237861633,
    "min": -2.130819082260132,
    "max": 0.43328627943992615,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.951774001121521,
    "std": 0.5543529391288757,
    "var": 0.3073071837425232,
    "min": -2.3640570640563965,
    "max": 0.21557889878749847,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.82 | loss:  0.62
-----------------------------------------------------------------------------------------
[2025-02-26 11:20:18,198][absl][INFO] - Saving checkpoint at step: 117900
[2025-02-26 11:20:18,201][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 11:20:18,201][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 11:20:18,203][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_117900.
[2025-02-26 11:20:18,211][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 11:20:18,212][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_117900.orbax-checkpoint-tmp-36
[2025-02-26 11:20:18,218][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 11:20:18,246][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 11:20:18,276][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 159.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 57 milliseconds) (per-host)
[2025-02-26 11:20:18,493][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-26 11:20:18,493][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 273 milliseconds) (per-host)
[2025-02-26 11:20:18,498][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 11:20:18,528][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_117900.orbax-checkpoint-tmp-36 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_117900
[2025-02-26 11:20:18,533][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_117900`.
[2025-02-26 11:20:18,533][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 11:20:18,535][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_112005
| epoch 101 | 1000/1179 batches | ms/batch 1805.72 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.08
-----------------------------------------------------------------------------------------
| end of epoch 101 | time per epoch: 2131.71s |
| Train Metrics | accuracy:  0.73 | loss:  1.08
| Eval  Metrics | accuracy:  0.82 | loss:  0.64
-----------------------------------------------------------------------------------------
[2025-02-26 11:59:43,684][absl][INFO] - Saving checkpoint at step: 119079
[2025-02-26 11:59:43,685][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 11:59:43,685][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 11:59:43,686][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_119079.
[2025-02-26 11:59:43,701][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 11:59:43,702][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_119079.orbax-checkpoint-tmp-37
[2025-02-26 11:59:43,709][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 11:59:43,736][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 11:59:43,768][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 155.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 58 milliseconds) (per-host)
[2025-02-26 11:59:44,028][absl][INFO] - ChainedFuture completed 1/1 futures in 0.26 seconds.
[2025-02-26 11:59:44,028][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 28.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 318 milliseconds) (per-host)
[2025-02-26 11:59:44,033][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 11:59:44,061][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_119079.orbax-checkpoint-tmp-37 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_119079
[2025-02-26 11:59:44,066][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_119079`.
[2025-02-26 11:59:44,066][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 11:59:44,067][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_117900
| epoch 102 | 1000/1179 batches | ms/batch 1822.05 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.11
-----------------------------------------------------------------------------------------
| end of epoch 102 | time per epoch: 2147.24s |
| Train Metrics | accuracy:  0.72 | loss:  1.11
| Eval  Metrics | accuracy:  0.81 | loss:  0.65
-----------------------------------------------------------------------------------------
| epoch 103 | 1000/1179 batches | ms/batch 1826.15 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.11
-----------------------------------------------------------------------------------------
| end of epoch 103 | time per epoch: 2154.44s |
| Train Metrics | accuracy:  0.72 | loss:  1.12
| Eval  Metrics | accuracy:  0.81 | loss:  0.67
-----------------------------------------------------------------------------------------
| epoch 104 | 1000/1179 batches | ms/batch 1837.18 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.08
-----------------------------------------------------------------------------------------
| end of epoch 104 | time per epoch: 2169.71s |
| Train Metrics | accuracy:  0.73 | loss:  1.08
| Eval  Metrics | accuracy:  0.81 | loss:  0.63
-----------------------------------------------------------------------------------------
| epoch 105 | 1000/1179 batches | ms/batch 1857.44 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.09
-----------------------------------------------------------------------------------------
| end of epoch 105 | time per epoch: 2188.10s |
| Train Metrics | accuracy:  0.72 | loss:  1.10
| Eval  Metrics | accuracy:  0.80 | loss:  0.71
-----------------------------------------------------------------------------------------
| epoch 106 | 1000/1179 batches | ms/batch 1853.25 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.12
-----------------------------------------------------------------------------------------
| end of epoch 106 | time per epoch: 2185.76s |
| Train Metrics | accuracy:  0.72 | loss:  1.11
| Eval  Metrics | accuracy:  0.82 | loss:  0.61
-----------------------------------------------------------------------------------------
[2025-02-26 15:20:30,099][absl][INFO] - Saving checkpoint at step: 124974
[2025-02-26 15:20:30,101][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 15:20:30,101][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 15:20:30,102][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_124974.
[2025-02-26 15:20:30,111][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 15:20:30,112][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_124974.orbax-checkpoint-tmp-38
[2025-02-26 15:20:30,119][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 15:20:30,145][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 15:20:30,175][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 164.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 55 milliseconds) (per-host)
[2025-02-26 15:20:30,395][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-26 15:20:30,395][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 275 milliseconds) (per-host)
[2025-02-26 15:20:30,400][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 15:20:30,426][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_124974.orbax-checkpoint-tmp-38 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_124974
[2025-02-26 15:20:30,430][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_124974`.
[2025-02-26 15:20:30,431][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 15:20:30,432][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_119079
| epoch 107 | 1000/1179 batches | ms/batch 1865.15 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.08
-----------------------------------------------------------------------------------------
| end of epoch 107 | time per epoch: 2200.98s |
| Train Metrics | accuracy:  0.72 | loss:  1.09
| Eval  Metrics | accuracy:  0.81 | loss:  0.65
-----------------------------------------------------------------------------------------
| epoch 108 | 1000/1179 batches | ms/batch 1883.63 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.13
-----------------------------------------------------------------------------------------
| end of epoch 108 | time per epoch: 2220.39s |
| Train Metrics | accuracy:  0.72 | loss:  1.12
| Eval  Metrics | accuracy:  0.81 | loss:  0.66
-----------------------------------------------------------------------------------------
| epoch 109 | 1000/1179 batches | ms/batch 1896.11 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.11
-----------------------------------------------------------------------------------------
| end of epoch 109 | time per epoch: 2238.53s |
| Train Metrics | accuracy:  0.72 | loss:  1.11
| Eval  Metrics | accuracy:  0.81 | loss:  0.61
-----------------------------------------------------------------------------------------
| epoch 110 | 1000/1179 batches | ms/batch 1909.36 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.10
-----------------------------------------------------------------------------------------
| end of epoch 110 | time per epoch: 2253.63s |
| Train Metrics | accuracy:  0.73 | loss:  1.09
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.23083218932151794,
    "std": 0.30603426694869995,
    "var": 0.0936569795012474,
    "min": -0.20528067648410797,
    "max": 1.0961380004882812,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.33894801139831543,
    "std": 0.2408239245414734,
    "var": 0.05799616500735283,
    "min": 0.07369239628314972,
    "max": 1.3576254844665527,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0007229880429804325,
    "std": 0.11122239381074905,
    "var": 0.012370421551167965,
    "min": -0.6411763429641724,
    "max": 0.6239085793495178,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.23996597528457642,
    "std": 0.18547919392585754,
    "var": 0.03440253436565399,
    "min": -0.09886734932661057,
    "max": 0.8458772301673889,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.39764755964279175,
    "std": 0.33110636472702026,
    "var": 0.10963141918182373,
    "min": 0.06283418834209442,
    "max": 1.5512853860855103,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0005521186976693571,
    "std": 0.11948854476213455,
    "var": 0.014277513138949871,
    "min": -0.7049808502197266,
    "max": 0.610740602016449,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.28583455085754395,
    "std": 0.2973575294017792,
    "var": 0.08842150866985321,
    "min": -0.017397401854395866,
    "max": 1.0315327644348145,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.3177824318408966,
    "std": 0.27092245221138,
    "var": 0.07339897751808167,
    "min": 0.04893151670694351,
    "max": 1.6374629735946655,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0007075656903907657,
    "std": 0.12436803430318832,
    "var": 0.015467408113181591,
    "min": -0.8196342587471008,
    "max": 0.9675611853599548,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.17752455174922943,
    "std": 0.20718736946582794,
    "var": 0.0429266020655632,
    "min": -0.2675655782222748,
    "max": 0.9912572503089905,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.5762559771537781,
    "std": 0.28925639390945435,
    "var": 0.0836692675948143,
    "min": 0.0749230608344078,
    "max": 2.3503737449645996,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0007218117825686932,
    "std": 0.08025448769330978,
    "var": 0.0064407829195261,
    "min": -0.9689048528671265,
    "max": 0.9378042221069336,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.16263717412948608,
    "std": 0.24597474932670593,
    "var": 0.060503579676151276,
    "min": -0.5086708068847656,
    "max": 1.0978654623031616,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6722297668457031,
    "std": 0.3001706004142761,
    "var": 0.09010239690542221,
    "min": 0.1150718554854393,
    "max": 1.7837921380996704,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00015716080088168383,
    "std": 0.05791379138827324,
    "var": 0.003354007378220558,
    "min": -0.5807186365127563,
    "max": 0.6399099826812744,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.04075689613819122,
    "std": 0.1083555743098259,
    "var": 0.011740930378437042,
    "min": -0.6676577925682068,
    "max": 0.2498566210269928,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.1418006420135498,
    "std": 0.3066704571247101,
    "var": 0.09404677152633667,
    "min": 0.6927496790885925,
    "max": 2.5914788246154785,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00033369241282343864,
    "std": 0.08839923143386841,
    "var": 0.007814424112439156,
    "min": -0.9368041753768921,
    "max": 0.8536292910575867,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0005652533145621419,
    "std": 0.08856470882892609,
    "var": 0.007843708619475365,
    "min": -0.4661131203174591,
    "max": 0.6059023141860962,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.00021205819211900234,
    "std": 0.09258688986301422,
    "var": 0.008572332561016083,
    "min": -0.4705234467983246,
    "max": 0.5293159484863281,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0005495191435329616,
    "std": 0.09353315830230713,
    "var": 0.008748451247811317,
    "min": -0.4933364689350128,
    "max": 0.5233202576637268,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00024566042702645063,
    "std": 0.07877416908740997,
    "var": 0.006205370184034109,
    "min": -0.7145467400550842,
    "max": 0.6854112148284912,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0005152532830834389,
    "std": 0.07982257753610611,
    "var": 0.006371644791215658,
    "min": -0.504692018032074,
    "max": 0.5951916575431824,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0002918152022175491,
    "std": 0.08783666789531708,
    "var": 0.007715281099081039,
    "min": -0.6084873676300049,
    "max": 0.6144938468933105,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.36211198568344116,
    "std": 0.11548848450183868,
    "var": 0.013337589800357819,
    "min": -0.6915274858474731,
    "max": -0.06772856414318085,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.09864024072885513,
    "std": 0.2877131700515747,
    "var": 0.08277886360883713,
    "min": -1.633806824684143,
    "max": 1.210563063621521,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.5984278917312622,
    "std": 1.0573716163635254,
    "var": 1.1180347204208374,
    "min": -2.6148931980133057,
    "max": 2.6723310947418213,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.28222721815109253,
    "std": 0.1526932418346405,
    "var": 0.023315226659178734,
    "min": -0.7208155393600464,
    "max": 0.06087932363152504,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.20159806311130524,
    "std": 0.21616826951503754,
    "var": 0.046728719025850296,
    "min": -1.49628484249115,
    "max": 0.6620258688926697,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.0248160362243652,
    "std": 0.9562628865242004,
    "var": 0.9144387245178223,
    "min": -1.563296914100647,
    "max": 4.282201290130615,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.30961644649505615,
    "std": 0.1102471873164177,
    "var": 0.012154443189501762,
    "min": -0.6020839810371399,
    "max": -0.07376812398433685,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.1405591070652008,
    "std": 0.19553525745868683,
    "var": 0.03823403641581535,
    "min": -1.2583024501800537,
    "max": 0.8033199310302734,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.3693103790283203,
    "std": 0.6403191685676575,
    "var": 0.41000866889953613,
    "min": -1.2872179746627808,
    "max": 2.87949275970459,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.1295844316482544,
    "std": 0.09014112502336502,
    "var": 0.008125422522425652,
    "min": -0.4393019676208496,
    "max": 0.08365315943956375,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08082132041454315,
    "std": 0.15319180488586426,
    "var": 0.02346772886812687,
    "min": -1.1273506879806519,
    "max": 0.5332562327384949,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0006053248653188348,
    "std": 0.006341562140733004,
    "var": 4.021541099064052e-05,
    "min": -0.025626111775636673,
    "max": 0.018665188923478127,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.00034336320823058486,
    "std": 0.10918688774108887,
    "var": 0.0119217773899436,
    "min": -0.963782012462616,
    "max": 0.8467327356338501,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.03230522945523262,
    "std": 0.37617188692092896,
    "var": 0.14150528609752655,
    "min": -3.3935797214508057,
    "max": 1.8629021644592285,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15377956628799438,
    "std": 0.0926876962184906,
    "var": 0.008591009303927422,
    "min": -0.5082221627235413,
    "max": 0.05606698617339134,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.0724937692284584,
    "std": 0.15366722643375397,
    "var": 0.023613618686795235,
    "min": -1.448587417602539,
    "max": 0.6487244367599487,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.22541958093643188,
    "std": 0.9032571911811829,
    "var": 0.8158736228942871,
    "min": -2.7764339447021484,
    "max": 2.5548064708709717,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.04302648454904556,
    "std": 0.13472649455070496,
    "var": 0.01815122738480568,
    "min": -0.41954824328422546,
    "max": 0.3236883580684662,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.03728630021214485,
    "std": 0.14576531946659088,
    "var": 0.021247530356049538,
    "min": -1.007394552230835,
    "max": 0.588555634021759,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.4155290126800537,
    "std": 0.5947647094726562,
    "var": 0.35374510288238525,
    "min": -0.8080253601074219,
    "max": 2.6985127925872803,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.01186449360102415,
    "std": 0.07271640002727509,
    "var": 0.005287674721330404,
    "min": -0.18127740919589996,
    "max": 0.12307178229093552,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0018463680753484368,
    "std": 0.21475328505039215,
    "var": 0.046118978410959244,
    "min": -0.8417903184890747,
    "max": 0.9290026426315308,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.0014936237130314112,
    "std": 0.24252678453922272,
    "var": 0.0588192418217659,
    "min": -1.2109020948410034,
    "max": 1.226008653640747,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.2608872056007385,
    "std": 0.42916375398635864,
    "var": 0.18418154120445251,
    "min": -1.1495990753173828,
    "max": 1.1947420835494995,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.3260290026664734,
    "std": 0.43486469984054565,
    "var": 0.18910729885101318,
    "min": -1.6443392038345337,
    "max": 0.7822946310043335,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.3323896825313568,
    "std": 0.40306147933006287,
    "var": 0.16245856881141663,
    "min": -1.725027322769165,
    "max": 0.6871475577354431,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.9351720809936523,
    "std": 0.5138106346130371,
    "var": 0.26400139927864075,
    "min": -2.2931337356567383,
    "max": 0.5163574814796448,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.0044504404067993,
    "std": 0.4509643614292145,
    "var": 0.2033688724040985,
    "min": -2.1112606525421143,
    "max": 0.42415863275527954,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.9158612489700317,
    "std": 0.5495390295982361,
    "var": 0.301993191242218,
    "min": -2.3308374881744385,
    "max": 0.240224227309227,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.81 | loss:  0.65
-----------------------------------------------------------------------------------------
| epoch 111 | 1000/1179 batches | ms/batch 1926.55 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.11
-----------------------------------------------------------------------------------------
| end of epoch 111 | time per epoch: 2272.94s |
| Train Metrics | accuracy:  0.72 | loss:  1.10
| Eval  Metrics | accuracy:  0.81 | loss:  0.64
-----------------------------------------------------------------------------------------
| epoch 112 | 1000/1179 batches | ms/batch 1958.54 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.06
-----------------------------------------------------------------------------------------
| end of epoch 112 | time per epoch: 2306.66s |
| Train Metrics | accuracy:  0.73 | loss:  1.07
| Eval  Metrics | accuracy:  0.82 | loss:  0.61
-----------------------------------------------------------------------------------------
| epoch 113 | 1000/1179 batches | ms/batch 1944.55 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.07
-----------------------------------------------------------------------------------------
| end of epoch 113 | time per epoch: 2294.95s |
| Train Metrics | accuracy:  0.73 | loss:  1.07
| Eval  Metrics | accuracy:  0.82 | loss:  0.61
-----------------------------------------------------------------------------------------
[2025-02-26 20:12:58,139][absl][INFO] - Saving checkpoint at step: 133227
[2025-02-26 20:12:58,141][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 20:12:58,141][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 20:12:58,143][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_133227.
[2025-02-26 20:12:58,145][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 20:12:58,146][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_133227.orbax-checkpoint-tmp-39
[2025-02-26 20:12:58,200][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 20:12:58,227][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 20:12:58,249][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 191.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 47 milliseconds) (per-host)
[2025-02-26 20:12:58,490][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-26 20:12:58,490][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 289 milliseconds) (per-host)
[2025-02-26 20:12:58,496][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 20:12:58,526][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_133227.orbax-checkpoint-tmp-39 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_133227
[2025-02-26 20:12:58,531][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_133227`.
[2025-02-26 20:12:58,532][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 20:12:58,533][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_124974
| epoch 114 | 1000/1179 batches | ms/batch 1966.58 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.11
-----------------------------------------------------------------------------------------
| end of epoch 114 | time per epoch: 2319.26s |
| Train Metrics | accuracy:  0.72 | loss:  1.12
| Eval  Metrics | accuracy:  0.82 | loss:  0.64
-----------------------------------------------------------------------------------------
| epoch 115 | 1000/1179 batches | ms/batch 1975.04 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.08
-----------------------------------------------------------------------------------------
| end of epoch 115 | time per epoch: 2328.79s |
| Train Metrics | accuracy:  0.73 | loss:  1.09
| Eval  Metrics | accuracy:  0.82 | loss:  0.63
-----------------------------------------------------------------------------------------
| epoch 116 | 1000/1179 batches | ms/batch 1983.51 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.10
-----------------------------------------------------------------------------------------
| end of epoch 116 | time per epoch: 2339.06s |
| Train Metrics | accuracy:  0.73 | loss:  1.10
| Eval  Metrics | accuracy:  0.82 | loss:  0.67
-----------------------------------------------------------------------------------------
| epoch 117 | 1000/1179 batches | ms/batch 1995.00 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.08
-----------------------------------------------------------------------------------------
| end of epoch 117 | time per epoch: 2353.91s |
| Train Metrics | accuracy:  0.73 | loss:  1.09
| Eval  Metrics | accuracy:  0.82 | loss:  0.63
-----------------------------------------------------------------------------------------
| epoch 118 | 1000/1179 batches | ms/batch 2005.79 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.11
-----------------------------------------------------------------------------------------
| end of epoch 118 | time per epoch: 2366.46s |
| Train Metrics | accuracy:  0.73 | loss:  1.11
| Eval  Metrics | accuracy:  0.81 | loss:  0.69
-----------------------------------------------------------------------------------------
| epoch 119 | 1000/1179 batches | ms/batch 2022.36 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.08
-----------------------------------------------------------------------------------------
| end of epoch 119 | time per epoch: 2385.50s |
| Train Metrics | accuracy:  0.73 | loss:  1.08
| Eval  Metrics | accuracy:  0.82 | loss:  0.60
-----------------------------------------------------------------------------------------
| epoch 120 | 1000/1179 batches | ms/batch 2036.81 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.04
-----------------------------------------------------------------------------------------
| end of epoch 120 | time per epoch: 2420.01s |
| Train Metrics | accuracy:  0.74 | loss:  1.04
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.23777779936790466,
    "std": 0.31308314204216003,
    "var": 0.09802105277776718,
    "min": -0.21108299493789673,
    "max": 1.0870033502578735,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.34312281012535095,
    "std": 0.25257763266563416,
    "var": 0.06379546970129013,
    "min": 0.07285768538713455,
    "max": 1.3291165828704834,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0006406407337635756,
    "std": 0.11161474138498306,
    "var": 0.012457850389182568,
    "min": -0.6442657709121704,
    "max": 0.634366512298584,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.24429838359355927,
    "std": 0.1892310082912445,
    "var": 0.03580837324261665,
    "min": -0.08815830945968628,
    "max": 0.8796401619911194,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.39544445276260376,
    "std": 0.3392714262008667,
    "var": 0.11510509252548218,
    "min": 0.06299502402544022,
    "max": 1.5997793674468994,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0005906374426558614,
    "std": 0.12040825188159943,
    "var": 0.014498148113489151,
    "min": -0.708079993724823,
    "max": 0.6314435005187988,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.29146119952201843,
    "std": 0.3065013885498047,
    "var": 0.09394311159849167,
    "min": -0.01831672713160515,
    "max": 1.0697240829467773,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.3239797353744507,
    "std": 0.2810221016407013,
    "var": 0.0789734274148941,
    "min": 0.050594400614500046,
    "max": 1.6236485242843628,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0006132021080702543,
    "std": 0.1254558563232422,
    "var": 0.01573917269706726,
    "min": -0.825370728969574,
    "max": 0.9886685609817505,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.18327975273132324,
    "std": 0.2064678817987442,
    "var": 0.04262898489832878,
    "min": -0.2526637315750122,
    "max": 1.008816123008728,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.5773023962974548,
    "std": 0.29643017053604126,
    "var": 0.08787085115909576,
    "min": 0.05827433243393898,
    "max": 2.43811297416687,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0007522289524786174,
    "std": 0.07978168874979019,
    "var": 0.006365118082612753,
    "min": -0.9773289561271667,
    "max": 0.9489604830741882,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.17417535185813904,
    "std": 0.24187132716178894,
    "var": 0.05850174278020859,
    "min": -0.46689608693122864,
    "max": 1.0883636474609375,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6667094230651855,
    "std": 0.29445141553878784,
    "var": 0.08670163154602051,
    "min": 0.1400698721408844,
    "max": 1.7450251579284668,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00017064274288713932,
    "std": 0.0577981173992157,
    "var": 0.0033406224101781845,
    "min": -0.6030820608139038,
    "max": 0.6463714241981506,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.03753672540187836,
    "std": 0.10550659894943237,
    "var": 0.011131643317639828,
    "min": -0.6125737428665161,
    "max": 0.2436586320400238,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.1672953367233276,
    "std": 0.30853164196014404,
    "var": 0.09519177675247192,
    "min": 0.719336748123169,
    "max": 2.661807060241699,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00036180377355776727,
    "std": 0.08909287303686142,
    "var": 0.007937540300190449,
    "min": -0.9638757109642029,
    "max": 0.8877547383308411,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0007967079291120172,
    "std": 0.08252192288637161,
    "var": 0.0068098679184913635,
    "min": -0.4746592044830322,
    "max": 0.5960455536842346,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.0006413475493900478,
    "std": 0.08652888983488083,
    "var": 0.007487248629331589,
    "min": -0.4441300630569458,
    "max": 0.548466682434082,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.00030147976940497756,
    "std": 0.08743691444396973,
    "var": 0.007645214907824993,
    "min": -0.45696955919265747,
    "max": 0.4622822701931,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0003930760722141713,
    "std": 0.07322949916124344,
    "var": 0.005362559109926224,
    "min": -0.6492102742195129,
    "max": 0.614177942276001,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00024624529760330915,
    "std": 0.0752035528421402,
    "var": 0.0056555746123194695,
    "min": -0.4568043351173401,
    "max": 0.52744060754776,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.00032349288812838495,
    "std": 0.08219493180513382,
    "var": 0.0067560067400336266,
    "min": -0.5666865110397339,
    "max": 0.5498650074005127,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3550388813018799,
    "std": 0.1157214418053627,
    "var": 0.013391452841460705,
    "min": -0.6835446357727051,
    "max": -0.06396505236625671,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.09987453371286392,
    "std": 0.2844747006893158,
    "var": 0.08092585951089859,
    "min": -1.6172510385513306,
    "max": 1.276031732559204,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.5571989417076111,
    "std": 1.0378849506378174,
    "var": 1.0772051811218262,
    "min": -2.545137405395508,
    "max": 2.625300645828247,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.2842826247215271,
    "std": 0.14913451671600342,
    "var": 0.022241106256842613,
    "min": -0.7099515795707703,
    "max": 0.05242709442973137,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.20059223473072052,
    "std": 0.21484656631946564,
    "var": 0.0461590476334095,
    "min": -1.4225168228149414,
    "max": 0.7353394627571106,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.9699551463127136,
    "std": 0.9278480410575867,
    "var": 0.8609020113945007,
    "min": -1.561385989189148,
    "max": 4.051985263824463,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.3054552376270294,
    "std": 0.11059563606977463,
    "var": 0.012231394648551941,
    "min": -0.6529306173324585,
    "max": -0.0828045979142189,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.13897378742694855,
    "std": 0.1932217925786972,
    "var": 0.037334661930799484,
    "min": -1.2910611629486084,
    "max": 0.6367272138595581,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.34713014960289,
    "std": 0.616033136844635,
    "var": 0.37949681282043457,
    "min": -1.2254533767700195,
    "max": 2.737384557723999,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.13251203298568726,
    "std": 0.08538073301315308,
    "var": 0.007289869245141745,
    "min": -0.4372396469116211,
    "max": 0.06527158617973328,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08005625009536743,
    "std": 0.1497790515422821,
    "var": 0.02243376336991787,
    "min": -1.1182142496109009,
    "max": 0.544901430606842,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0006316453800536692,
    "std": 0.005530180875211954,
    "var": 3.058290167246014e-05,
    "min": -0.023798678070306778,
    "max": 0.021160295233130455,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.00041005900129675865,
    "std": 0.10649814456701279,
    "var": 0.011341854929924011,
    "min": -0.9014281034469604,
    "max": 0.8385488390922546,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.03053266555070877,
    "std": 0.35377341508865356,
    "var": 0.12515562772750854,
    "min": -3.0765585899353027,
    "max": 1.641304612159729,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15276852250099182,
    "std": 0.08808763325214386,
    "var": 0.0077594309113919735,
    "min": -0.47752487659454346,
    "max": 0.03564140200614929,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07122152298688889,
    "std": 0.14949385821819305,
    "var": 0.02234841324388981,
    "min": -1.3723094463348389,
    "max": 0.6268683075904846,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.21684575080871582,
    "std": 0.8496435880661011,
    "var": 0.7218942046165466,
    "min": -2.6183178424835205,
    "max": 2.4697062969207764,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.04738088697195053,
    "std": 0.13312740623950958,
    "var": 0.017722908407449722,
    "min": -0.37368330359458923,
    "max": 0.3493119180202484,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.03584785386919975,
    "std": 0.1408255696296692,
    "var": 0.019831843674182892,
    "min": -0.9707413911819458,
    "max": 0.5562924742698669,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.3919510245323181,
    "std": 0.5602070093154907,
    "var": 0.3138318955898285,
    "min": -0.6793289184570312,
    "max": 2.523876190185547,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.011355329304933548,
    "std": 0.06994075328111649,
    "var": 0.004891708958894014,
    "min": -0.16070422530174255,
    "max": 0.12489761412143707,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.002092776820063591,
    "std": 0.21469613909721375,
    "var": 0.04609443247318268,
    "min": -0.836816668510437,
    "max": 0.869527280330658,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.0013685323065146804,
    "std": 0.231032595038414,
    "var": 0.05337606370449066,
    "min": -1.12015962600708,
    "max": 1.1498669385910034,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.22298301756381989,
    "std": 0.41787150502204895,
    "var": 0.17461660504341125,
    "min": -1.0760893821716309,
    "max": 1.2304136753082275,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.30354613065719604,
    "std": 0.4325164556503296,
    "var": 0.18707048892974854,
    "min": -1.6187025308609009,
    "max": 0.7719742059707642,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.30456048250198364,
    "std": 0.3974539339542389,
    "var": 0.1579696238040924,
    "min": -1.6908574104309082,
    "max": 0.7009711265563965,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.9176515936851501,
    "std": 0.5147198438644409,
    "var": 0.26493650674819946,
    "min": -2.228557586669922,
    "max": 0.5596044659614563,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.9649721384048462,
    "std": 0.45103830099105835,
    "var": 0.20343557000160217,
    "min": -2.0950515270233154,
    "max": 0.4125332832336426,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.8877944946289062,
    "std": 0.5458521246910095,
    "var": 0.2979545593261719,
    "min": -2.28194260597229,
    "max": 0.25156185030937195,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.82 | loss:  0.61
-----------------------------------------------------------------------------------------
| epoch 121 | 1000/1179 batches | ms/batch 2047.39 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.11
-----------------------------------------------------------------------------------------
| end of epoch 121 | time per epoch: 2413.89s |
| Train Metrics | accuracy:  0.73 | loss:  1.11
| Eval  Metrics | accuracy:  0.81 | loss:  0.66
-----------------------------------------------------------------------------------------
| epoch 122 | 1000/1179 batches | ms/batch 2058.63 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.08
-----------------------------------------------------------------------------------------
| end of epoch 122 | time per epoch: 2428.95s |
| Train Metrics | accuracy:  0.73 | loss:  1.07
| Eval  Metrics | accuracy:  0.82 | loss:  0.59
-----------------------------------------------------------------------------------------
| epoch 123 | 1000/1179 batches | ms/batch 2064.03 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.09
-----------------------------------------------------------------------------------------
| end of epoch 123 | time per epoch: 2434.03s |
| Train Metrics | accuracy:  0.73 | loss:  1.07
| Eval  Metrics | accuracy:  0.83 | loss:  0.59
-----------------------------------------------------------------------------------------
[2025-02-27 03:34:08,137][absl][INFO] - Saving checkpoint at step: 145017
[2025-02-27 03:34:08,140][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 03:34:08,141][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 03:34:08,142][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_145017.
[2025-02-27 03:34:08,297][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 03:34:08,299][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_145017.orbax-checkpoint-tmp-40
[2025-02-27 03:34:08,330][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 03:34:08,356][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 03:34:08,386][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 166.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-27 03:34:08,607][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-27 03:34:08,607][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 275 milliseconds) (per-host)
[2025-02-27 03:34:08,612][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 03:34:08,641][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_145017.orbax-checkpoint-tmp-40 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_145017
[2025-02-27 03:34:08,647][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_145017`.
[2025-02-27 03:34:08,647][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 03:34:08,648][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_133227
| epoch 124 | 1000/1179 batches | ms/batch 2077.18 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.07
-----------------------------------------------------------------------------------------
| end of epoch 124 | time per epoch: 2450.77s |
| Train Metrics | accuracy:  0.73 | loss:  1.08
| Eval  Metrics | accuracy:  0.82 | loss:  0.61
-----------------------------------------------------------------------------------------
| epoch 125 | 1000/1179 batches | ms/batch 2092.24 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.07
-----------------------------------------------------------------------------------------
| end of epoch 125 | time per epoch: 2466.47s |
| Train Metrics | accuracy:  0.74 | loss:  1.07
| Eval  Metrics | accuracy:  0.83 | loss:  0.60
-----------------------------------------------------------------------------------------
| epoch 126 | 1000/1179 batches | ms/batch 2099.29 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.07
-----------------------------------------------------------------------------------------
| end of epoch 126 | time per epoch: 2477.80s |
| Train Metrics | accuracy:  0.73 | loss:  1.07
| Eval  Metrics | accuracy:  0.83 | loss:  0.59
-----------------------------------------------------------------------------------------
| epoch 127 | 1000/1179 batches | ms/batch 2119.55 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.05
-----------------------------------------------------------------------------------------
| end of epoch 127 | time per epoch: 2500.08s |
| Train Metrics | accuracy:  0.74 | loss:  1.04
| Eval  Metrics | accuracy:  0.82 | loss:  0.64
-----------------------------------------------------------------------------------------
| epoch 128 | 1000/1179 batches | ms/batch 2133.68 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.02
-----------------------------------------------------------------------------------------
| end of epoch 128 | time per epoch: 2515.40s |
| Train Metrics | accuracy:  0.74 | loss:  1.03
| Eval  Metrics | accuracy:  0.83 | loss:  0.60
-----------------------------------------------------------------------------------------
| epoch 129 | 1000/1179 batches | ms/batch 2136.26 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.01
-----------------------------------------------------------------------------------------
| end of epoch 129 | time per epoch: 2521.13s |
| Train Metrics | accuracy:  0.74 | loss:  1.03
| Eval  Metrics | accuracy:  0.82 | loss:  0.63
-----------------------------------------------------------------------------------------
| epoch 130 | 1000/1179 batches | ms/batch 2151.55 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.06
-----------------------------------------------------------------------------------------
| end of epoch 130 | time per epoch: 2536.33s |
| Train Metrics | accuracy:  0.74 | loss:  1.04
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.24583427608013153,
    "std": 0.3171283006668091,
    "var": 0.10057035088539124,
    "min": -0.19101011753082275,
    "max": 1.0949592590332031,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.34912359714508057,
    "std": 0.2680739462375641,
    "var": 0.07186364382505417,
    "min": 0.05785989388823509,
    "max": 1.401344895362854,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0006608852418139577,
    "std": 0.11180757731199265,
    "var": 0.012500934302806854,
    "min": -0.6441143751144409,
    "max": 0.6402138471603394,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.24811291694641113,
    "std": 0.19491657614707947,
    "var": 0.03799247369170189,
    "min": -0.09122419357299805,
    "max": 0.9027198553085327,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.39427971839904785,
    "std": 0.34601011872291565,
    "var": 0.11972300708293915,
    "min": 0.05643973499536514,
    "max": 1.658257007598877,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0005753347650170326,
    "std": 0.12103378027677536,
    "var": 0.014649176970124245,
    "min": -0.7096111178398132,
    "max": 0.6543028354644775,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.29664912819862366,
    "std": 0.3112418055534363,
    "var": 0.09687145799398422,
    "min": -0.016518935561180115,
    "max": 1.0923209190368652,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.3224881887435913,
    "std": 0.2884563207626343,
    "var": 0.08320704847574234,
    "min": 0.028777003288269043,
    "max": 1.637529730796814,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0005488495226018131,
    "std": 0.12618526816368103,
    "var": 0.015922721475362778,
    "min": -0.8242220878601074,
    "max": 1.003371238708496,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.18987970054149628,
    "std": 0.2062462419271469,
    "var": 0.04253751039505005,
    "min": -0.24682660400867462,
    "max": 1.0319664478302002,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.5771709084510803,
    "std": 0.29730111360549927,
    "var": 0.08838795870542526,
    "min": 0.0635695680975914,
    "max": 2.4372570514678955,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0006637043552473187,
    "std": 0.07937921583652496,
    "var": 0.006301059853285551,
    "min": -0.9754211902618408,
    "max": 0.9546645283699036,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.18165859580039978,
    "std": 0.24076689779758453,
    "var": 0.05796869844198227,
    "min": -0.4528486728668213,
    "max": 1.13242506980896,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6623446941375732,
    "std": 0.2876792848110199,
    "var": 0.08275936543941498,
    "min": 0.1257621794939041,
    "max": 1.7443469762802124,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00014862357056699693,
    "std": 0.05762457847595215,
    "var": 0.003320591989904642,
    "min": -0.6154776215553284,
    "max": 0.6495400667190552,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.03230513259768486,
    "std": 0.10154709219932556,
    "var": 0.010311812162399292,
    "min": -0.5800580382347107,
    "max": 0.252358078956604,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.1903287172317505,
    "std": 0.3050810694694519,
    "var": 0.09307446330785751,
    "min": 0.7572605609893799,
    "max": 2.650142192840576,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0003273322363384068,
    "std": 0.0895235687494278,
    "var": 0.008014469407498837,
    "min": -0.9890292882919312,
    "max": 0.9085736274719238,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0008418707875534892,
    "std": 0.0766839012503624,
    "var": 0.005880420561879873,
    "min": -0.4390225112438202,
    "max": 0.528154730796814,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.0007765071932226419,
    "std": 0.0807022750377655,
    "var": 0.006512857042253017,
    "min": -0.40315911173820496,
    "max": 0.556980311870575,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.00017145270248875022,
    "std": 0.08163471519947052,
    "var": 0.00666422676295042,
    "min": -0.42718738317489624,
    "max": 0.457520455121994,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0002250253746751696,
    "std": 0.06806226819753647,
    "var": 0.004632472526282072,
    "min": -0.6032041907310486,
    "max": 0.5593332648277283,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 6.750957982148975e-05,
    "std": 0.07012103497982025,
    "var": 0.0049169594421982765,
    "min": -0.46483299136161804,
    "max": 0.4895003139972687,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0003831496578641236,
    "std": 0.0764937773346901,
    "var": 0.005851298570632935,
    "min": -0.5073210597038269,
    "max": 0.5079711079597473,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.34799546003341675,
    "std": 0.11264164745807648,
    "var": 0.012688140384852886,
    "min": -0.6624152064323425,
    "max": -0.06565553694963455,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.09947074949741364,
    "std": 0.281284898519516,
    "var": 0.0791211947798729,
    "min": -1.620142936706543,
    "max": 1.3120882511138916,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.5188533663749695,
    "std": 1.0233553647994995,
    "var": 1.047256350517273,
    "min": -2.518442392349243,
    "max": 2.7072484493255615,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.2853007912635803,
    "std": 0.14635218679904938,
    "var": 0.021418964490294456,
    "min": -0.7464281320571899,
    "max": 0.03576687350869179,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19984641671180725,
    "std": 0.21241170167922974,
    "var": 0.04511873051524162,
    "min": -1.4745932817459106,
    "max": 0.7172812223434448,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.9176632761955261,
    "std": 0.8889663815498352,
    "var": 0.7902612686157227,
    "min": -1.5774956941604614,
    "max": 3.8774821758270264,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.3028247058391571,
    "std": 0.11036039888858795,
    "var": 0.012179417535662651,
    "min": -0.6229889988899231,
    "max": -0.07683547586202621,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.13641251623630524,
    "std": 0.19110770523548126,
    "var": 0.03652215376496315,
    "min": -1.3093304634094238,
    "max": 0.595142126083374,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.3244785964488983,
    "std": 0.5872267484664917,
    "var": 0.3448352813720703,
    "min": -1.2017383575439453,
    "max": 2.6230294704437256,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.13427117466926575,
    "std": 0.08220838755369186,
    "var": 0.006758218631148338,
    "min": -0.43005234003067017,
    "max": 0.07415296882390976,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07909957319498062,
    "std": 0.1460934430360794,
    "var": 0.021343296393752098,
    "min": -1.1428263187408447,
    "max": 0.509338915348053,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0006084521301090717,
    "std": 0.004863889422267675,
    "var": 2.365742329857312e-05,
    "min": -0.02394469827413559,
    "max": 0.014226571656763554,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.000572967401240021,
    "std": 0.10295166820287704,
    "var": 0.01059904508292675,
    "min": -0.8571549654006958,
    "max": 0.8110018968582153,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.027654211968183517,
    "std": 0.3340093493461609,
    "var": 0.11156225204467773,
    "min": -2.809631109237671,
    "max": 1.47108793258667,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15393686294555664,
    "std": 0.08420169353485107,
    "var": 0.0070899249985814095,
    "min": -0.46895140409469604,
    "max": 0.039767857640981674,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07068880647420883,
    "std": 0.14563316106796265,
    "var": 0.02120901830494404,
    "min": -1.290954351425171,
    "max": 0.580588698387146,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.21224668622016907,
    "std": 0.7967934608459473,
    "var": 0.6348798274993896,
    "min": -2.4497830867767334,
    "max": 2.381669044494629,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.0534028634428978,
    "std": 0.13101132214069366,
    "var": 0.017163965851068497,
    "min": -0.3514953851699829,
    "max": 0.344433456659317,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.03372958302497864,
    "std": 0.13584773242473602,
    "var": 0.01845460757613182,
    "min": -0.9049345850944519,
    "max": 0.5891827344894409,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.37868356704711914,
    "std": 0.5261192321777344,
    "var": 0.2768014669418335,
    "min": -0.600017786026001,
    "max": 2.39041805267334,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.011290992610156536,
    "std": 0.06977460533380508,
    "var": 0.0048684957437217236,
    "min": -0.16737937927246094,
    "max": 0.13389039039611816,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0021780238021165133,
    "std": 0.21443597972393036,
    "var": 0.04598278924822807,
    "min": -0.7942277193069458,
    "max": 0.8869357705116272,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.0019707074388861656,
    "std": 0.22013184428215027,
    "var": 0.048458032310009,
    "min": -1.069029450416565,
    "max": 1.123328447341919,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.18531163036823273,
    "std": 0.4111136496067047,
    "var": 0.16901442408561707,
    "min": -1.0183489322662354,
    "max": 1.247936487197876,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.2755022644996643,
    "std": 0.42096832394599915,
    "var": 0.1772143393754959,
    "min": -1.5403980016708374,
    "max": 0.7817708253860474,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.2824575901031494,
    "std": 0.3914435803890228,
    "var": 0.15322808921337128,
    "min": -1.6322345733642578,
    "max": 0.7369892001152039,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.8927933573722839,
    "std": 0.5078494548797607,
    "var": 0.2579110860824585,
    "min": -2.178260564804077,
    "max": 0.586613118648529,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.9210318922996521,
    "std": 0.44842055439949036,
    "var": 0.20108100771903992,
    "min": -2.069648027420044,
    "max": 0.44227781891822815,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.8597594499588013,
    "std": 0.5425966382026672,
    "var": 0.2944111227989197,
    "min": -2.260460376739502,
    "max": 0.2602699100971222,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.83 | loss:  0.57
-----------------------------------------------------------------------------------------
[2025-02-27 08:58:19,954][absl][INFO] - Saving checkpoint at step: 153270
[2025-02-27 08:58:19,957][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 08:58:19,957][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 08:58:19,958][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_153270.
[2025-02-27 08:58:20,131][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 08:58:20,132][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_153270.orbax-checkpoint-tmp-41
[2025-02-27 08:58:20,139][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 08:58:20,167][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 08:58:20,209][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 131.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 69 milliseconds) (per-host)
[2025-02-27 08:58:20,408][absl][INFO] - ChainedFuture completed 1/1 futures in 0.20 seconds.
[2025-02-27 08:58:20,408][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 34.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 267 milliseconds) (per-host)
[2025-02-27 08:58:20,413][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 08:58:20,442][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_153270.orbax-checkpoint-tmp-41 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_153270
[2025-02-27 08:58:20,447][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_153270`.
[2025-02-27 08:58:20,447][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 08:58:20,448][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_145017
| epoch 131 | 1000/1179 batches | ms/batch 2166.82 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.04
-----------------------------------------------------------------------------------------
| end of epoch 131 | time per epoch: 2556.13s |
| Train Metrics | accuracy:  0.74 | loss:  1.05
| Eval  Metrics | accuracy:  0.83 | loss:  0.64
-----------------------------------------------------------------------------------------
| epoch 132 | 1000/1179 batches | ms/batch 2179.24 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.06
-----------------------------------------------------------------------------------------
| end of epoch 132 | time per epoch: 2569.78s |
| Train Metrics | accuracy:  0.74 | loss:  1.06
| Eval  Metrics | accuracy:  0.82 | loss:  0.63
-----------------------------------------------------------------------------------------
| epoch 133 | 1000/1179 batches | ms/batch 2198.40 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.06
-----------------------------------------------------------------------------------------
| end of epoch 133 | time per epoch: 2600.08s |
| Train Metrics | accuracy:  0.74 | loss:  1.05
| Eval  Metrics | accuracy:  0.83 | loss:  0.59
-----------------------------------------------------------------------------------------
| epoch 134 | 1000/1179 batches | ms/batch 2217.41 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.03
-----------------------------------------------------------------------------------------
| end of epoch 134 | time per epoch: 2615.68s |
| Train Metrics | accuracy:  0.75 | loss:  1.03
| Eval  Metrics | accuracy:  0.83 | loss:  0.61
-----------------------------------------------------------------------------------------
| epoch 135 | 1000/1179 batches | ms/batch 2235.88 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.06
-----------------------------------------------------------------------------------------
| end of epoch 135 | time per epoch: 2637.07s |
| Train Metrics | accuracy:  0.74 | loss:  1.05
| Eval  Metrics | accuracy:  0.83 | loss:  0.59
-----------------------------------------------------------------------------------------
[2025-02-27 12:59:22,220][absl][INFO] - Saving checkpoint at step: 159165
[2025-02-27 12:59:22,223][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 12:59:22,223][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 12:59:22,225][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_159165.
[2025-02-27 12:59:22,241][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 12:59:22,242][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_159165.orbax-checkpoint-tmp-42
[2025-02-27 12:59:22,251][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 12:59:22,277][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 12:59:22,307][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 166.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-27 12:59:22,863][absl][INFO] - ChainedFuture completed 1/1 futures in 0.56 seconds.
[2025-02-27 12:59:22,863][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 14.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 611 milliseconds) (per-host)
[2025-02-27 12:59:22,869][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 12:59:22,902][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_159165.orbax-checkpoint-tmp-42 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_159165
[2025-02-27 12:59:22,908][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_159165`.
[2025-02-27 12:59:22,908][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 12:59:22,909][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_153270
| epoch 136 | 1000/1179 batches | ms/batch 2251.45 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.06
-----------------------------------------------------------------------------------------
| end of epoch 136 | time per epoch: 2653.91s |
| Train Metrics | accuracy:  0.74 | loss:  1.06
| Eval  Metrics | accuracy:  0.82 | loss:  0.61
-----------------------------------------------------------------------------------------
| epoch 137 | 1000/1179 batches | ms/batch 2255.41 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.01
-----------------------------------------------------------------------------------------
| end of epoch 137 | time per epoch: 2659.52s |
| Train Metrics | accuracy:  0.75 | loss:  1.01
| Eval  Metrics | accuracy:  0.82 | loss:  0.62
-----------------------------------------------------------------------------------------
| epoch 138 | 1000/1179 batches | ms/batch 2273.36 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.01
-----------------------------------------------------------------------------------------
| end of epoch 138 | time per epoch: 2681.20s |
| Train Metrics | accuracy:  0.75 | loss:  1.02
| Eval  Metrics | accuracy:  0.83 | loss:  0.58
-----------------------------------------------------------------------------------------
| epoch 139 | 1000/1179 batches | ms/batch 2287.46 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.05
-----------------------------------------------------------------------------------------
| end of epoch 139 | time per epoch: 2696.76s |
| Train Metrics | accuracy:  0.75 | loss:  1.04
| Eval  Metrics | accuracy:  0.83 | loss:  0.58
-----------------------------------------------------------------------------------------
| epoch 140 | 1000/1179 batches | ms/batch 2300.54 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 140 | time per epoch: 2712.19s |
| Train Metrics | accuracy:  0.75 | loss:  1.00
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.25144603848457336,
    "std": 0.3212429881095886,
    "var": 0.10319705307483673,
    "min": -0.21249541640281677,
    "max": 1.0981624126434326,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.3559662103652954,
    "std": 0.28946182131767273,
    "var": 0.08378814905881882,
    "min": 0.05083577334880829,
    "max": 1.4764622449874878,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0006162661593407393,
    "std": 0.11195701360702515,
    "var": 0.012534372508525848,
    "min": -0.6453812122344971,
    "max": 0.6435141563415527,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.2511255741119385,
    "std": 0.1979828178882599,
    "var": 0.039197199046611786,
    "min": -0.08302262425422668,
    "max": 0.929484486579895,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.395005464553833,
    "std": 0.3573775887489319,
    "var": 0.1277187466621399,
    "min": 0.05194227024912834,
    "max": 1.7239587306976318,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0005975458188913763,
    "std": 0.12136784940958023,
    "var": 0.01473015546798706,
    "min": -0.7144683003425598,
    "max": 0.6751972436904907,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.3017994463443756,
    "std": 0.31786373257637024,
    "var": 0.10103735327720642,
    "min": -0.0107802152633667,
    "max": 1.1085768938064575,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.324241578578949,
    "std": 0.29518887400627136,
    "var": 0.08713646978139877,
    "min": 0.041173554956912994,
    "max": 1.6000616550445557,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0005729577387683094,
    "std": 0.12666861712932587,
    "var": 0.016044937074184418,
    "min": -0.825807511806488,
    "max": 1.007591724395752,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.1977141797542572,
    "std": 0.20677466690540314,
    "var": 0.04275576397776604,
    "min": -0.23252061009407043,
    "max": 1.0601412057876587,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.57527756690979,
    "std": 0.2975611090660095,
    "var": 0.08854261040687561,
    "min": 0.07151226699352264,
    "max": 2.439997434616089,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0006524394266307354,
    "std": 0.07907352596521378,
    "var": 0.006252622231841087,
    "min": -0.9751027822494507,
    "max": 0.9568770527839661,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.1917707324028015,
    "std": 0.2399665266275406,
    "var": 0.05758393928408623,
    "min": -0.42307138442993164,
    "max": 1.1347030401229858,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6580567359924316,
    "std": 0.28238505125045776,
    "var": 0.07974132150411606,
    "min": 0.09563446044921875,
    "max": 1.7136378288269043,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00016183887782972306,
    "std": 0.0575254000723362,
    "var": 0.00330917164683342,
    "min": -0.6214284896850586,
    "max": 0.6467906832695007,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.027708079665899277,
    "std": 0.09876175969839096,
    "var": 0.009753884747624397,
    "min": -0.5383175015449524,
    "max": 0.2516895830631256,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.2110414505004883,
    "std": 0.3060978949069977,
    "var": 0.09369592368602753,
    "min": 0.761168360710144,
    "max": 2.664625406265259,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0002890686737373471,
    "std": 0.08977307379245758,
    "var": 0.008059205487370491,
    "min": -1.005363941192627,
    "max": 0.9170905351638794,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0010642701527103782,
    "std": 0.0711245983839035,
    "var": 0.005058708600699902,
    "min": -0.41354456543922424,
    "max": 0.44269028306007385,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.0002475197543390095,
    "std": 0.07475744932889938,
    "var": 0.005588676314800978,
    "min": -0.3364543616771698,
    "max": 0.52618408203125,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0005111577338539064,
    "std": 0.07543297857046127,
    "var": 0.005690134130418301,
    "min": -0.3771968483924866,
    "max": 0.41484788060188293,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00017296720761805773,
    "std": 0.06333458423614502,
    "var": 0.00401126965880394,
    "min": -0.5516585111618042,
    "max": 0.5120382905006409,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00010389895760454237,
    "std": 0.06556147336959839,
    "var": 0.004298307001590729,
    "min": -0.3904971480369568,
    "max": 0.4403350055217743,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0003442445886321366,
    "std": 0.07100175321102142,
    "var": 0.0050412495620548725,
    "min": -0.4537322521209717,
    "max": 0.4675385057926178,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.34327125549316406,
    "std": 0.1132807806134224,
    "var": 0.012832535430788994,
    "min": -0.6587697267532349,
    "max": -0.06735951453447342,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.10047772526741028,
    "std": 0.2783728539943695,
    "var": 0.07749145478010178,
    "min": -1.5535461902618408,
    "max": 1.2560386657714844,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.485887736082077,
    "std": 1.0091878175735474,
    "var": 1.0184601545333862,
    "min": -2.4311959743499756,
    "max": 2.7679665088653564,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.286782443523407,
    "std": 0.14360854029655457,
    "var": 0.02062341570854187,
    "min": -0.7572214603424072,
    "max": 0.05386495590209961,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19962207973003387,
    "std": 0.21058081090450287,
    "var": 0.044344279915094376,
    "min": -1.4400380849838257,
    "max": 0.6674105525016785,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.8686529397964478,
    "std": 0.8537570238113403,
    "var": 0.7289010882377625,
    "min": -1.5715943574905396,
    "max": 3.7287206649780273,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.30134135484695435,
    "std": 0.10973091423511505,
    "var": 0.012040873989462852,
    "min": -0.6465427875518799,
    "max": -0.05955187603831291,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.13599589467048645,
    "std": 0.18855175375938416,
    "var": 0.0355517603456974,
    "min": -1.2940679788589478,
    "max": 0.549170732498169,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.3036687970161438,
    "std": 0.5612415671348572,
    "var": 0.31499212980270386,
    "min": -1.156628131866455,
    "max": 2.4613900184631348,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.13777166604995728,
    "std": 0.07933052629232407,
    "var": 0.006293333135545254,
    "min": -0.4287250339984894,
    "max": 0.05805791914463043,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07896704971790314,
    "std": 0.14254888892173767,
    "var": 0.020320188254117966,
    "min": -1.0939406156539917,
    "max": 0.472435861825943,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0004514993051998317,
    "std": 0.00425683194771409,
    "var": 1.812061782402452e-05,
    "min": -0.021023349836468697,
    "max": 0.011431936174631119,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.00038461873191408813,
    "std": 0.09927000105381012,
    "var": 0.009854533709585667,
    "min": -0.8222597241401672,
    "max": 0.8327667117118835,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.026205474510788918,
    "std": 0.3134041726589203,
    "var": 0.09822218120098114,
    "min": -2.565544843673706,
    "max": 1.3942004442214966,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15363386273384094,
    "std": 0.08012722432613373,
    "var": 0.006420372053980827,
    "min": -0.4511733055114746,
    "max": 0.02777021937072277,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07003066688776016,
    "std": 0.14178188145160675,
    "var": 0.020102104172110558,
    "min": -1.2292495965957642,
    "max": 0.563630998134613,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.19967269897460938,
    "std": 0.7437283992767334,
    "var": 0.5531318783760071,
    "min": -2.3067128658294678,
    "max": 2.2993662357330322,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.05740725249052048,
    "std": 0.12852010130882263,
    "var": 0.016517415642738342,
    "min": -0.35906481742858887,
    "max": 0.3375239372253418,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.03169736638665199,
    "std": 0.1309807449579239,
    "var": 0.017155954614281654,
    "min": -0.9135608077049255,
    "max": 0.5971055030822754,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.36324167251586914,
    "std": 0.49144262075424194,
    "var": 0.2415158450603485,
    "min": -0.5264642238616943,
    "max": 2.236448049545288,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.011324354447424412,
    "std": 0.07011143863201141,
    "var": 0.004915613681077957,
    "min": -0.16840139031410217,
    "max": 0.12559521198272705,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.002498449059203267,
    "std": 0.21392977237701416,
    "var": 0.0457659475505352,
    "min": -0.8159772157669067,
    "max": 0.8981326818466187,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.002212344668805599,
    "std": 0.2082778364419937,
    "var": 0.04337965324521065,
    "min": -1.0231972932815552,
    "max": 1.0565592050552368,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.14108411967754364,
    "std": 0.4028133153915405,
    "var": 0.1622585654258728,
    "min": -0.9780603051185608,
    "max": 1.244346261024475,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.24688313901424408,
    "std": 0.41485968232154846,
    "var": 0.17210856080055237,
    "min": -1.4686706066131592,
    "max": 0.7850469350814819,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.2599886655807495,
    "std": 0.38027796149253845,
    "var": 0.14461134374141693,
    "min": -1.5596364736557007,
    "max": 0.6996186375617981,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.8607143759727478,
    "std": 0.5017330050468445,
    "var": 0.251736044883728,
    "min": -2.1370129585266113,
    "max": 0.5983536839485168,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.8737162351608276,
    "std": 0.4433610439300537,
    "var": 0.19656902551651,
    "min": -2.0252749919891357,
    "max": 0.4493122398853302,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.8331906795501709,
    "std": 0.5352407693862915,
    "var": 0.28648269176483154,
    "min": -2.2353100776672363,
    "max": 0.25103744864463806,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.83 | loss:  0.56
-----------------------------------------------------------------------------------------
[2025-02-27 17:08:23,352][absl][INFO] - Saving checkpoint at step: 165060
[2025-02-27 17:08:23,354][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 17:08:23,354][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 17:08:23,356][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_165060.
[2025-02-27 17:08:23,371][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 17:08:23,372][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_165060.orbax-checkpoint-tmp-43
[2025-02-27 17:08:23,379][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 17:08:23,406][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 17:08:23,435][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 164.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 55 milliseconds) (per-host)
[2025-02-27 17:08:23,651][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-27 17:08:23,651][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 270 milliseconds) (per-host)
[2025-02-27 17:08:23,656][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 17:08:23,686][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_165060.orbax-checkpoint-tmp-43 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_165060
[2025-02-27 17:08:23,691][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_165060`.
[2025-02-27 17:08:23,691][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 17:08:23,693][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_159165
| epoch 141 | 1000/1179 batches | ms/batch 2306.64 | Performance/Training accuracy:  0.75 | Performance/Training loss:  0.99
-----------------------------------------------------------------------------------------
| end of epoch 141 | time per epoch: 2721.23s |
| Train Metrics | accuracy:  0.75 | loss:  1.00
| Eval  Metrics | accuracy:  0.83 | loss:  0.59
-----------------------------------------------------------------------------------------
| epoch 142 | 1000/1179 batches | ms/batch 2328.09 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.01
-----------------------------------------------------------------------------------------
| end of epoch 142 | time per epoch: 2746.73s |
| Train Metrics | accuracy:  0.75 | loss:  1.01
| Eval  Metrics | accuracy:  0.83 | loss:  0.57
-----------------------------------------------------------------------------------------
| epoch 143 | 1000/1179 batches | ms/batch 2339.32 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 143 | time per epoch: 2759.84s |
| Train Metrics | accuracy:  0.75 | loss:  1.01
| Eval  Metrics | accuracy:  0.83 | loss:  0.61
-----------------------------------------------------------------------------------------
| epoch 144 | 1000/1179 batches | ms/batch 2367.63 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.02
-----------------------------------------------------------------------------------------
| end of epoch 144 | time per epoch: 2791.07s |
| Train Metrics | accuracy:  0.75 | loss:  1.02
| Eval  Metrics | accuracy:  0.83 | loss:  0.58
-----------------------------------------------------------------------------------------
[2025-02-27 20:33:09,361][absl][INFO] - Saving checkpoint at step: 169776
[2025-02-27 20:33:09,364][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 20:33:09,364][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 20:33:09,365][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_169776.
[2025-02-27 20:33:09,373][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 20:33:09,374][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_169776.orbax-checkpoint-tmp-44
[2025-02-27 20:33:09,382][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 20:33:09,408][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 20:33:09,437][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 167.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-27 20:33:09,654][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-27 20:33:09,654][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 271 milliseconds) (per-host)
[2025-02-27 20:33:09,659][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 20:33:09,688][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_169776.orbax-checkpoint-tmp-44 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_169776
[2025-02-27 20:33:09,694][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_169776`.
[2025-02-27 20:33:09,694][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 20:33:09,695][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_165060
| epoch 145 | 1000/1179 batches | ms/batch 2358.68 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.01
-----------------------------------------------------------------------------------------
| end of epoch 145 | time per epoch: 2777.95s |
| Train Metrics | accuracy:  0.75 | loss:  1.02
| Eval  Metrics | accuracy:  0.83 | loss:  0.57
-----------------------------------------------------------------------------------------
| epoch 146 | 1000/1179 batches | ms/batch 2353.35 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.99
-----------------------------------------------------------------------------------------
| end of epoch 146 | time per epoch: 2774.42s |
| Train Metrics | accuracy:  0.76 | loss:  0.99
| Eval  Metrics | accuracy:  0.83 | loss:  0.56
-----------------------------------------------------------------------------------------
[2025-02-27 22:16:22,512][absl][INFO] - Saving checkpoint at step: 172134
[2025-02-27 22:16:22,517][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 22:16:22,517][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 22:16:22,518][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_172134.
[2025-02-27 22:16:22,533][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 22:16:22,534][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_172134.orbax-checkpoint-tmp-45
[2025-02-27 22:16:22,584][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 22:16:22,610][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 22:16:22,641][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 162.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 56 milliseconds) (per-host)
[2025-02-27 22:16:22,859][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-27 22:16:22,859][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 274 milliseconds) (per-host)
[2025-02-27 22:16:22,864][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 22:16:22,891][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_172134.orbax-checkpoint-tmp-45 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_172134
[2025-02-27 22:16:22,898][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_172134`.
[2025-02-27 22:16:22,899][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 22:16:22,900][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_169776
| epoch 147 | 1000/1179 batches | ms/batch 2370.48 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.03
-----------------------------------------------------------------------------------------
| end of epoch 147 | time per epoch: 2795.17s |
| Train Metrics | accuracy:  0.75 | loss:  1.03
| Eval  Metrics | accuracy:  0.84 | loss:  0.57
-----------------------------------------------------------------------------------------
[2025-02-27 23:08:19,335][absl][INFO] - Saving checkpoint at step: 173313
[2025-02-27 23:08:19,337][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 23:08:19,337][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 23:08:19,338][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_173313.
[2025-02-27 23:08:19,346][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 23:08:19,346][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_173313.orbax-checkpoint-tmp-46
[2025-02-27 23:08:19,354][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 23:08:19,380][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 23:08:19,411][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 160.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 56 milliseconds) (per-host)
[2025-02-27 23:08:19,629][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-27 23:08:19,629][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 274 milliseconds) (per-host)
[2025-02-27 23:08:19,634][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 23:08:19,661][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_173313.orbax-checkpoint-tmp-46 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_173313
[2025-02-27 23:08:19,666][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_173313`.
[2025-02-27 23:08:19,666][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 23:08:19,667][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_172134
| epoch 148 | 1000/1179 batches | ms/batch 2387.15 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.01
-----------------------------------------------------------------------------------------
| end of epoch 148 | time per epoch: 2816.09s |
| Train Metrics | accuracy:  0.75 | loss:  1.01
| Eval  Metrics | accuracy:  0.84 | loss:  0.56
-----------------------------------------------------------------------------------------
| epoch 149 | 1000/1179 batches | ms/batch 2390.49 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.98
-----------------------------------------------------------------------------------------
| end of epoch 149 | time per epoch: 2820.81s |
| Train Metrics | accuracy:  0.76 | loss:  0.99
| Eval  Metrics | accuracy:  0.83 | loss:  0.58
-----------------------------------------------------------------------------------------
| epoch 150 | 1000/1179 batches | ms/batch 2409.91 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.99
-----------------------------------------------------------------------------------------
| end of epoch 150 | time per epoch: 2841.07s |
| Train Metrics | accuracy:  0.76 | loss:  0.98
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.25904959440231323,
    "std": 0.32824429869651794,
    "var": 0.10774432122707367,
    "min": -0.2126014530658722,
    "max": 1.1005618572235107,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.35949191451072693,
    "std": 0.30512359738349915,
    "var": 0.0931004211306572,
    "min": 0.04612228274345398,
    "max": 1.5133280754089355,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0006089513190090656,
    "std": 0.11202719062566757,
    "var": 0.012550092302262783,
    "min": -0.6431353688240051,
    "max": 0.6444510817527771,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.2537603974342346,
    "std": 0.20448875427246094,
    "var": 0.04181564971804619,
    "min": -0.09084554761648178,
    "max": 0.9398431181907654,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.397705614566803,
    "std": 0.37061870098114014,
    "var": 0.13735821843147278,
    "min": 0.04485723748803139,
    "max": 1.8310703039169312,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0006046458147466183,
    "std": 0.12157180905342102,
    "var": 0.014779704622924328,
    "min": -0.7126287817955017,
    "max": 0.6803220510482788,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.30720269680023193,
    "std": 0.3243722915649414,
    "var": 0.10521738231182098,
    "min": -0.01466372050344944,
    "max": 1.1306551694869995,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.32540932297706604,
    "std": 0.3009846806526184,
    "var": 0.09059177339076996,
    "min": 0.04145092889666557,
    "max": 1.58646821975708,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0005461584078148007,
    "std": 0.12694260478019714,
    "var": 0.016114424914121628,
    "min": -0.8226009011268616,
    "max": 1.0056819915771484,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.2048305720090866,
    "std": 0.20542104542255402,
    "var": 0.042197804898023605,
    "min": -0.2265568971633911,
    "max": 1.0442365407943726,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.5725942254066467,
    "std": 0.2995328903198242,
    "var": 0.08971995115280151,
    "min": 0.05812113732099533,
    "max": 2.47922945022583,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0006553995190188289,
    "std": 0.07884089648723602,
    "var": 0.00621588621288538,
    "min": -0.9702737927436829,
    "max": 0.955959141254425,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.20141613483428955,
    "std": 0.23887264728546143,
    "var": 0.05706014484167099,
    "min": -0.40637585520744324,
    "max": 1.127970576286316,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6549434065818787,
    "std": 0.2767479419708252,
    "var": 0.0765894204378128,
    "min": 0.10383839905261993,
    "max": 1.7174047231674194,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00014803354861214757,
    "std": 0.05744495615363121,
    "var": 0.003299923148006201,
    "min": -0.6233424544334412,
    "max": 0.6467159390449524,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.02389398217201233,
    "std": 0.09622440487146378,
    "var": 0.009259135462343693,
    "min": -0.5049024820327759,
    "max": 0.24900628626346588,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.2319743633270264,
    "std": 0.304217129945755,
    "var": 0.09254806488752365,
    "min": 0.763672411441803,
    "max": 2.691227674484253,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00034259591484442353,
    "std": 0.08990731090307236,
    "var": 0.008083324879407883,
    "min": -1.0126571655273438,
    "max": 0.9262063503265381,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0012150700204074383,
    "std": 0.0661998838186264,
    "var": 0.004382424987852573,
    "min": -0.40192970633506775,
    "max": 0.39111730456352234,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.00044130912283435464,
    "std": 0.06944248080253601,
    "var": 0.004822258837521076,
    "min": -0.32875749468803406,
    "max": 0.48925477266311646,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.00024662018404342234,
    "std": 0.0701523870229721,
    "var": 0.004921357147395611,
    "min": -0.3653639853000641,
    "max": 0.40247002243995667,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00019144584075547755,
    "std": 0.0587986595928669,
    "var": 0.0034572824370115995,
    "min": -0.49753427505493164,
    "max": 0.4565226435661316,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00010633950296323746,
    "std": 0.061194341629743576,
    "var": 0.0037447474896907806,
    "min": -0.3659161329269409,
    "max": 0.3891276717185974,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.00021090370137244463,
    "std": 0.06595336645841599,
    "var": 0.004349846392869949,
    "min": -0.4226723313331604,
    "max": 0.4451417624950409,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.340079128742218,
    "std": 0.11445609480142593,
    "var": 0.013100198470056057,
    "min": -0.6558876633644104,
    "max": -0.0736621543765068,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.10057089477777481,
    "std": 0.276187539100647,
    "var": 0.07627955824136734,
    "min": -1.5423797369003296,
    "max": 1.2440921068191528,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.45812806487083435,
    "std": 0.9954973459243774,
    "var": 0.9910149574279785,
    "min": -2.3910651206970215,
    "max": 2.770110607147217,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.28847822546958923,
    "std": 0.14111199975013733,
    "var": 0.0199125986546278,
    "min": -0.770426332950592,
    "max": 0.029352379962801933,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.1994915008544922,
    "std": 0.20884576439857483,
    "var": 0.04361655190587044,
    "min": -1.4517436027526855,
    "max": 0.6961230039596558,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.8246964812278748,
    "std": 0.8179150223731995,
    "var": 0.6689850091934204,
    "min": -1.56350839138031,
    "max": 3.5856988430023193,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.3007534444332123,
    "std": 0.11060558259487152,
    "var": 0.012233595363795757,
    "min": -0.6735256314277649,
    "max": -0.0500602088868618,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.13546544313430786,
    "std": 0.1866178810596466,
    "var": 0.034826237708330154,
    "min": -1.236376404762268,
    "max": 0.5336517691612244,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.2865005433559418,
    "std": 0.5389940142631531,
    "var": 0.29051458835601807,
    "min": -1.1212513446807861,
    "max": 2.3371758460998535,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.14092832803726196,
    "std": 0.07634571194648743,
    "var": 0.0058286674320697784,
    "min": -0.43284744024276733,
    "max": 0.05587037280201912,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.0787237212061882,
    "std": 0.13944943249225616,
    "var": 0.01944614201784134,
    "min": -1.0371345281600952,
    "max": 0.449651837348938,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0003632960724644363,
    "std": 0.003929317928850651,
    "var": 1.5439540220540948e-05,
    "min": -0.02030787244439125,
    "max": 0.01165780983865261,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.00030334843904711306,
    "std": 0.09547525644302368,
    "var": 0.009115524590015411,
    "min": -0.7897613048553467,
    "max": 0.8077543377876282,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.023745927959680557,
    "std": 0.2947431206703186,
    "var": 0.08687350153923035,
    "min": -2.376617908477783,
    "max": 1.3406522274017334,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15504170954227448,
    "std": 0.07693272829055786,
    "var": 0.005918644368648529,
    "min": -0.4565523564815521,
    "max": 0.015654422342777252,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.06986204534769058,
    "std": 0.13864578306674957,
    "var": 0.019222652539610863,
    "min": -1.21907377243042,
    "max": 0.5531948804855347,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.18942755460739136,
    "std": 0.6949738264083862,
    "var": 0.4829885959625244,
    "min": -2.161975860595703,
    "max": 2.1816446781158447,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.061678897589445114,
    "std": 0.12618054449558258,
    "var": 0.01592153124511242,
    "min": -0.3399960994720459,
    "max": 0.3378700613975525,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.02991434559226036,
    "std": 0.12692584097385406,
    "var": 0.016110168769955635,
    "min": -0.9081664681434631,
    "max": 0.5969281196594238,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.34953293204307556,
    "std": 0.4610764682292938,
    "var": 0.2125915139913559,
    "min": -0.5032854080200195,
    "max": 2.1135647296905518,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.011647871695458889,
    "std": 0.0707051083445549,
    "var": 0.004999212455004454,
    "min": -0.16309744119644165,
    "max": 0.12459473311901093,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0026134252548217773,
    "std": 0.21388070285320282,
    "var": 0.04574495553970337,
    "min": -0.8561500906944275,
    "max": 0.8812188506126404,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.0028545879758894444,
    "std": 0.19755685329437256,
    "var": 0.03902871161699295,
    "min": -1.0091397762298584,
    "max": 1.0090603828430176,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.10447054356336594,
    "std": 0.3947288990020752,
    "var": 0.1558109074831009,
    "min": -0.9369766712188721,
    "max": 1.2272027730941772,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.2229101061820984,
    "std": 0.4051421582698822,
    "var": 0.16414017975330353,
    "min": -1.3886324167251587,
    "max": 0.770492672920227,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.2465078979730606,
    "std": 0.37101438641548157,
    "var": 0.13765168190002441,
    "min": -1.494837999343872,
    "max": 0.7136712670326233,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.8263492584228516,
    "std": 0.49080178141593933,
    "var": 0.240886390209198,
    "min": -2.0767834186553955,
    "max": 0.6064401865005493,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.8321717977523804,
    "std": 0.44063884019851685,
    "var": 0.19416260719299316,
    "min": -1.9888066053390503,
    "max": 0.45291605591773987,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.8124479055404663,
    "std": 0.5281153917312622,
    "var": 0.2789058983325958,
    "min": -2.191141128540039,
    "max": 0.24245084822177887,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.84 | loss:  0.53
-----------------------------------------------------------------------------------------
[2025-02-28 01:45:58,150][absl][INFO] - Saving checkpoint at step: 176850
[2025-02-28 01:45:58,152][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-28 01:45:58,153][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-28 01:45:58,154][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_176850.
[2025-02-28 01:45:58,162][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-28 01:45:58,163][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_176850.orbax-checkpoint-tmp-47
[2025-02-28 01:45:58,199][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-28 01:45:58,226][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-28 01:45:58,258][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 156.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 58 milliseconds) (per-host)
[2025-02-28 01:45:58,484][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-28 01:45:58,484][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 284 milliseconds) (per-host)
[2025-02-28 01:45:58,489][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-28 01:45:58,515][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_176850.orbax-checkpoint-tmp-47 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_176850
[2025-02-28 01:45:58,520][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_176850`.
[2025-02-28 01:45:58,520][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-28 01:45:58,521][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_173313
| epoch 151 | 1000/1179 batches | ms/batch 2412.55 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.99
-----------------------------------------------------------------------------------------
| end of epoch 151 | time per epoch: 2854.63s |
| Train Metrics | accuracy:  0.76 | loss:  0.99
| Eval  Metrics | accuracy:  0.83 | loss:  0.58
-----------------------------------------------------------------------------------------
| epoch 152 | 1000/1179 batches | ms/batch 2442.04 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.98
-----------------------------------------------------------------------------------------
| end of epoch 152 | time per epoch: 2876.46s |
| Train Metrics | accuracy:  0.76 | loss:  0.98
| Eval  Metrics | accuracy:  0.84 | loss:  0.56
-----------------------------------------------------------------------------------------
| epoch 153 | 1000/1179 batches | ms/batch 2436.77 | Performance/Training accuracy:  0.76 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 153 | time per epoch: 2875.28s |
| Train Metrics | accuracy:  0.76 | loss:  1.00
| Eval  Metrics | accuracy:  0.83 | loss:  0.59
-----------------------------------------------------------------------------------------
| epoch 154 | 1000/1179 batches | ms/batch 2452.31 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.99
-----------------------------------------------------------------------------------------
| end of epoch 154 | time per epoch: 2890.94s |
| Train Metrics | accuracy:  0.76 | loss:  0.99
| Eval  Metrics | accuracy:  0.83 | loss:  0.57
-----------------------------------------------------------------------------------------
| epoch 155 | 1000/1179 batches | ms/batch 2456.62 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.95
-----------------------------------------------------------------------------------------
| end of epoch 155 | time per epoch: 2899.27s |
| Train Metrics | accuracy:  0.76 | loss:  0.98
| Eval  Metrics | accuracy:  0.84 | loss:  0.59
-----------------------------------------------------------------------------------------
| epoch 156 | 1000/1179 batches | ms/batch 2476.84 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.97
-----------------------------------------------------------------------------------------
| end of epoch 156 | time per epoch: 2921.69s |
| Train Metrics | accuracy:  0.76 | loss:  0.98
| Eval  Metrics | accuracy:  0.84 | loss:  0.55
-----------------------------------------------------------------------------------------
| epoch 157 | 1000/1179 batches | ms/batch 2489.18 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.97
-----------------------------------------------------------------------------------------
| end of epoch 157 | time per epoch: 2936.90s |
| Train Metrics | accuracy:  0.77 | loss:  0.97
| Eval  Metrics | accuracy:  0.84 | loss:  0.58
-----------------------------------------------------------------------------------------
| epoch 158 | 1000/1179 batches | ms/batch 2502.10 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.99
-----------------------------------------------------------------------------------------
| end of epoch 158 | time per epoch: 2954.39s |
| Train Metrics | accuracy:  0.76 | loss:  0.99
| Eval  Metrics | accuracy:  0.84 | loss:  0.55
-----------------------------------------------------------------------------------------
| epoch 159 | 1000/1179 batches | ms/batch 2508.90 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.99
-----------------------------------------------------------------------------------------
| end of epoch 159 | time per epoch: 2959.48s |
| Train Metrics | accuracy:  0.76 | loss:  0.99
| Eval  Metrics | accuracy:  0.84 | loss:  0.57
-----------------------------------------------------------------------------------------
| epoch 160 | 1000/1179 batches | ms/batch 2527.65 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.97
-----------------------------------------------------------------------------------------
| end of epoch 160 | time per epoch: 2984.76s |
| Train Metrics | accuracy:  0.77 | loss:  0.97
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.2628844678401947,
    "std": 0.3303185701370239,
    "var": 0.10911034792661667,
    "min": -0.19357696175575256,
    "max": 1.1137548685073853,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.36160463094711304,
    "std": 0.3132167160511017,
    "var": 0.09810471534729004,
    "min": 0.0415932834148407,
    "max": 1.5183184146881104,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0005717743188142776,
    "std": 0.112044557929039,
    "var": 0.012553982436656952,
    "min": -0.643027663230896,
    "max": 0.6457287669181824,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.25543034076690674,
    "std": 0.20931220054626465,
    "var": 0.04381159693002701,
    "min": -0.08000453561544418,
    "max": 0.9652068018913269,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.3990698754787445,
    "std": 0.3799690008163452,
    "var": 0.14437642693519592,
    "min": 0.03913393244147301,
    "max": 1.8905302286148071,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0006196348695084453,
    "std": 0.12168756872415543,
    "var": 0.014807865023612976,
    "min": -0.7133256196975708,
    "max": 0.680540919303894,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.3098962604999542,
    "std": 0.32758986949920654,
    "var": 0.10731511563062668,
    "min": -0.01728961244225502,
    "max": 1.1296656131744385,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.3248833417892456,
    "std": 0.30543312430381775,
    "var": 0.09328939020633698,
    "min": 0.03133102506399155,
    "max": 1.5789512395858765,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0005519735859706998,
    "std": 0.127080500125885,
    "var": 0.016149453818798065,
    "min": -0.8200580477714539,
    "max": 1.0055477619171143,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.21086333692073822,
    "std": 0.2046310007572174,
    "var": 0.04187384992837906,
    "min": -0.22146037220954895,
    "max": 1.0503969192504883,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.5698034167289734,
    "std": 0.30054232478141785,
    "var": 0.09032569825649261,
    "min": 0.05594351887702942,
    "max": 2.490504741668701,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0006632643635384738,
    "std": 0.07871964573860168,
    "var": 0.006196782924234867,
    "min": -0.9669650197029114,
    "max": 0.9575929641723633,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.20853590965270996,
    "std": 0.2374485284090042,
    "var": 0.05638180300593376,
    "min": -0.3888710141181946,
    "max": 1.1347424983978271,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.648585855960846,
    "std": 0.2717472016811371,
    "var": 0.07384654879570007,
    "min": 0.09395166486501694,
    "max": 1.6891744136810303,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00014797752373851836,
    "std": 0.05739559605717659,
    "var": 0.00329425442032516,
    "min": -0.6250781416893005,
    "max": 0.642092764377594,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.01968551054596901,
    "std": 0.09318092465400696,
    "var": 0.00868268497288227,
    "min": -0.47993314266204834,
    "max": 0.24581460654735565,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.249140739440918,
    "std": 0.30383846163749695,
    "var": 0.09231781959533691,
    "min": 0.7833922505378723,
    "max": 2.6914355754852295,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00036252508289180696,
    "std": 0.08997207134962082,
    "var": 0.008094973862171173,
    "min": -1.0167657136917114,
    "max": 0.9259348511695862,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0013336509000509977,
    "std": 0.06185102462768555,
    "var": 0.003825549501925707,
    "min": -0.3839177191257477,
    "max": 0.3624925911426544,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.0002157367707695812,
    "std": 0.06497660279273987,
    "var": 0.004221959039568901,
    "min": -0.3204645812511444,
    "max": 0.46372196078300476,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0003275515919085592,
    "std": 0.0655924454331398,
    "var": 0.0043023694306612015,
    "min": -0.32483556866645813,
    "max": 0.38664448261260986,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0002950995694845915,
    "std": 0.05508522316813469,
    "var": 0.003034382127225399,
    "min": -0.46778255701065063,
    "max": 0.4311155080795288,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0001017076283460483,
    "std": 0.05749139189720154,
    "var": 0.003305260092020035,
    "min": -0.34737104177474976,
    "max": 0.3612361550331116,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.00021440352429635823,
    "std": 0.06157376989722252,
    "var": 0.0037913292180746794,
    "min": -0.3917473554611206,
    "max": 0.4087430238723755,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.33774298429489136,
    "std": 0.11379913985729218,
    "var": 0.01295024435967207,
    "min": -0.6689016222953796,
    "max": -0.07031848281621933,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.10018103569746017,
    "std": 0.27416980266571045,
    "var": 0.07516907900571823,
    "min": -1.4855387210845947,
    "max": 1.2575527429580688,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.43875402212142944,
    "std": 0.9796041250228882,
    "var": 0.9596242308616638,
    "min": -2.331075429916382,
    "max": 2.7624423503875732,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.29006344079971313,
    "std": 0.14005792140960693,
    "var": 0.019616222009062767,
    "min": -0.7838379144668579,
    "max": 0.020558029413223267,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.1991356760263443,
    "std": 0.20751960575580597,
    "var": 0.04306438937783241,
    "min": -1.4485565423965454,
    "max": 0.6828128099441528,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.7855353355407715,
    "std": 0.7864822745323181,
    "var": 0.618554413318634,
    "min": -1.5757025480270386,
    "max": 3.437713384628296,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.2989078760147095,
    "std": 0.11114256083965302,
    "var": 0.01235266961157322,
    "min": -0.6869840025901794,
    "max": -0.055480554699897766,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.13424284756183624,
    "std": 0.18493865430355072,
    "var": 0.03420230746269226,
    "min": -1.2441755533218384,
    "max": 0.5356124043464661,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.27173465490341187,
    "std": 0.5185110569000244,
    "var": 0.26885369420051575,
    "min": -1.1175435781478882,
    "max": 2.214620351791382,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.14360235631465912,
    "std": 0.07419221848249435,
    "var": 0.005504485219717026,
    "min": -0.4364109933376312,
    "max": 0.043660521507263184,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07856019586324692,
    "std": 0.13696742057800293,
    "var": 0.01876007579267025,
    "min": -1.0426207780838013,
    "max": 0.4357164800167084,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0006161660421639681,
    "std": 0.00352243660017848,
    "var": 1.2407559552229941e-05,
    "min": -0.017657598480582237,
    "max": 0.011781207285821438,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.00034924401552416384,
    "std": 0.09225467592477798,
    "var": 0.008510924875736237,
    "min": -0.7578561902046204,
    "max": 0.7623959183692932,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.02249964512884617,
    "std": 0.2791314423084259,
    "var": 0.07791435718536377,
    "min": -2.2183146476745605,
    "max": 1.2650883197784424,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15569670498371124,
    "std": 0.07520963996648788,
    "var": 0.0056564901024103165,
    "min": -0.44649961590766907,
    "max": 0.014308150857686996,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.06921648234128952,
    "std": 0.1356082260608673,
    "var": 0.018389590084552765,
    "min": -1.2030034065246582,
    "max": 0.5363441109657288,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.1799508035182953,
    "std": 0.6523109674453735,
    "var": 0.42550963163375854,
    "min": -2.0238876342773438,
    "max": 2.050513505935669,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.06491762399673462,
    "std": 0.12397915124893188,
    "var": 0.015370829962193966,
    "min": -0.32133978605270386,
    "max": 0.332708477973938,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.028251396492123604,
    "std": 0.12349613755941391,
    "var": 0.015251295641064644,
    "min": -0.8991735577583313,
    "max": 0.6092797517776489,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.33755040168762207,
    "std": 0.435869425535202,
    "var": 0.18998216092586517,
    "min": -0.4750331938266754,
    "max": 1.998525857925415,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.011654130183160305,
    "std": 0.07060915976762772,
    "var": 0.004985653329640627,
    "min": -0.16128049790859222,
    "max": 0.12453082203865051,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0026814762968569994,
    "std": 0.2136499136686325,
    "var": 0.04564628750085831,
    "min": -0.8172178864479065,
    "max": 0.9006239175796509,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.002894738921895623,
    "std": 0.18827854096889496,
    "var": 0.03544881194829941,
    "min": -0.9630106687545776,
    "max": 0.9643803834915161,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.07205080986022949,
    "std": 0.3890397846698761,
    "var": 0.1513519585132599,
    "min": -0.8964102268218994,
    "max": 1.216173529624939,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.20612558722496033,
    "std": 0.3953648507595062,
    "var": 0.15631335973739624,
    "min": -1.342740535736084,
    "max": 0.7555832266807556,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.23622462153434753,
    "std": 0.3644079267978668,
    "var": 0.132793128490448,
    "min": -1.4591172933578491,
    "max": 0.7311463952064514,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.7975019812583923,
    "std": 0.4813362658023834,
    "var": 0.2316845953464508,
    "min": -2.0182299613952637,
    "max": 0.5921631455421448,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.7946286201477051,
    "std": 0.4364674985408783,
    "var": 0.19050389528274536,
    "min": -1.9518084526062012,
    "max": 0.4416223168373108,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.7926405668258667,
    "std": 0.52149897813797,
    "var": 0.2719612121582031,
    "min": -2.158294677734375,
    "max": 0.24037055671215057,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.85 | loss:  0.53
-----------------------------------------------------------------------------------------
[2025-02-28 10:48:18,826][absl][INFO] - Saving checkpoint at step: 188640
[2025-02-28 10:48:18,828][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-28 10:48:18,828][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-28 10:48:18,830][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_188640.
[2025-02-28 10:48:18,839][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-28 10:48:18,840][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_188640.orbax-checkpoint-tmp-48
[2025-02-28 10:48:18,849][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-28 10:48:18,875][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-28 10:48:18,904][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 166.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 54 milliseconds) (per-host)
[2025-02-28 10:48:19,113][absl][INFO] - ChainedFuture completed 1/1 futures in 0.21 seconds.
[2025-02-28 10:48:19,113][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 34.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 263 milliseconds) (per-host)
[2025-02-28 10:48:19,118][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-28 10:48:19,147][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_188640.orbax-checkpoint-tmp-48 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_188640
[2025-02-28 10:48:19,152][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_188640`.
[2025-02-28 10:48:19,152][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-28 10:48:19,154][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_176850
| epoch 161 | 1000/1179 batches | ms/batch 2527.69 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.96
-----------------------------------------------------------------------------------------
| end of epoch 161 | time per epoch: 2984.69s |
| Train Metrics | accuracy:  0.77 | loss:  0.96
| Eval  Metrics | accuracy:  0.84 | loss:  0.56
-----------------------------------------------------------------------------------------
| epoch 162 | 1000/1179 batches | ms/batch 2555.25 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.94
-----------------------------------------------------------------------------------------
| end of epoch 162 | time per epoch: 3029.80s |
| Train Metrics | accuracy:  0.77 | loss:  0.94
| Eval  Metrics | accuracy:  0.84 | loss:  0.54
-----------------------------------------------------------------------------------------
| epoch 163 | 1000/1179 batches | ms/batch 2739.52 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.97
-----------------------------------------------------------------------------------------
| end of epoch 163 | time per epoch: 3249.44s |
| Train Metrics | accuracy:  0.77 | loss:  0.98
| Eval  Metrics | accuracy:  0.84 | loss:  0.55
-----------------------------------------------------------------------------------------
| epoch 164 | 1000/1179 batches | ms/batch 2713.16 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.93
-----------------------------------------------------------------------------------------
| end of epoch 164 | time per epoch: 3190.82s |
| Train Metrics | accuracy:  0.77 | loss:  0.93
| Eval  Metrics | accuracy:  0.84 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 165 | 1000/1179 batches | ms/batch 2733.46 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.98
-----------------------------------------------------------------------------------------
| end of epoch 165 | time per epoch: 3231.93s |
| Train Metrics | accuracy:  0.76 | loss:  0.98
| Eval  Metrics | accuracy:  0.85 | loss:  0.55
-----------------------------------------------------------------------------------------
| epoch 166 | 1000/1179 batches | ms/batch 2758.69 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.96
-----------------------------------------------------------------------------------------
| end of epoch 166 | time per epoch: 3231.75s |
| Train Metrics | accuracy:  0.77 | loss:  0.96
| Eval  Metrics | accuracy:  0.84 | loss:  0.54
-----------------------------------------------------------------------------------------
| epoch 167 | 1000/1179 batches | ms/batch 2834.54 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.96
-----------------------------------------------------------------------------------------
| end of epoch 167 | time per epoch: 3343.67s |
| Train Metrics | accuracy:  0.77 | loss:  0.95
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 168 | 1000/1179 batches | ms/batch 2740.49 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.91
-----------------------------------------------------------------------------------------
| end of epoch 168 | time per epoch: 3222.94s |
| Train Metrics | accuracy:  0.78 | loss:  0.93
| Eval  Metrics | accuracy:  0.84 | loss:  0.54
-----------------------------------------------------------------------------------------
| epoch 169 | 1000/1179 batches | ms/batch 2777.91 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.91
-----------------------------------------------------------------------------------------
| end of epoch 169 | time per epoch: 3255.52s |
| Train Metrics | accuracy:  0.77 | loss:  0.94
| Eval  Metrics | accuracy:  0.85 | loss:  0.53
-----------------------------------------------------------------------------------------
| epoch 170 | 1000/1179 batches | ms/batch 2744.96 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.93
-----------------------------------------------------------------------------------------
| end of epoch 170 | time per epoch: 3267.61s |
| Train Metrics | accuracy:  0.77 | loss:  0.94
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.26540130376815796,
    "std": 0.33247676491737366,
    "var": 0.11054079979658127,
    "min": -0.18694333732128143,
    "max": 1.1157945394515991,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.36282527446746826,
    "std": 0.3216921389102936,
    "var": 0.1034858375787735,
    "min": 0.03761182725429535,
    "max": 1.5270287990570068,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0005630968953482807,
    "std": 0.11208884418010712,
    "var": 0.012563908472657204,
    "min": -0.6424225568771362,
    "max": 0.6454616189002991,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.257991760969162,
    "std": 0.2125629335641861,
    "var": 0.04518299922347069,
    "min": -0.07563379406929016,
    "max": 0.9707613587379456,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.3987733721733093,
    "std": 0.3848142921924591,
    "var": 0.14808204770088196,
    "min": 0.037369947880506516,
    "max": 1.9051222801208496,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0006269083824008703,
    "std": 0.12173717468976974,
    "var": 0.01481994055211544,
    "min": -0.7142466306686401,
    "max": 0.6798804402351379,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.31120043992996216,
    "std": 0.33002421259880066,
    "var": 0.10891597718000412,
    "min": -0.015369927510619164,
    "max": 1.1369762420654297,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.32417023181915283,
    "std": 0.30542317032814026,
    "var": 0.09328331053256989,
    "min": 0.029792843386530876,
    "max": 1.5507349967956543,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0005398214561864734,
    "std": 0.12715303897857666,
    "var": 0.01616789773106575,
    "min": -0.8196114301681519,
    "max": 1.0055668354034424,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.21530525386333466,
    "std": 0.2040640413761139,
    "var": 0.04164213314652443,
    "min": -0.20845845341682434,
    "max": 1.0568307638168335,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.5666162371635437,
    "std": 0.30217450857162476,
    "var": 0.09130944311618805,
    "min": 0.048451170325279236,
    "max": 2.51924467086792,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0006645001703873277,
    "std": 0.07866887003183365,
    "var": 0.006188791245222092,
    "min": -0.9658902883529663,
    "max": 0.9583423733711243,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.21279045939445496,
    "std": 0.23620586097240448,
    "var": 0.05579320713877678,
    "min": -0.3678382933139801,
    "max": 1.1453609466552734,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6450640559196472,
    "std": 0.26852306723594666,
    "var": 0.07210463285446167,
    "min": 0.09669369459152222,
    "max": 1.6864070892333984,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00014201115118339658,
    "std": 0.057378046214580536,
    "var": 0.0032922402024269104,
    "min": -0.6265398263931274,
    "max": 0.6389783024787903,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.01688019186258316,
    "std": 0.09148816019296646,
    "var": 0.008370082825422287,
    "min": -0.45697376132011414,
    "max": 0.2595466375350952,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.2632194757461548,
    "std": 0.30418872833251953,
    "var": 0.09253077954053879,
    "min": 0.7888540029525757,
    "max": 2.705819845199585,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0003514988347887993,
    "std": 0.08999641239643097,
    "var": 0.008099354803562164,
    "min": -1.0204377174377441,
    "max": 0.926035463809967,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0012958820443600416,
    "std": 0.05886417254805565,
    "var": 0.003464990993961692,
    "min": -0.353034645318985,
    "max": 0.3380775451660156,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.00030817350489087403,
    "std": 0.06154728680849075,
    "var": 0.0037880686577409506,
    "min": -0.30024778842926025,
    "max": 0.42870962619781494,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0003069107769988477,
    "std": 0.06204880774021149,
    "var": 0.003850054694339633,
    "min": -0.3138684630393982,
    "max": 0.37302473187446594,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0003006304905284196,
    "std": 0.05237202346324921,
    "var": 0.0027428288012742996,
    "min": -0.4267614483833313,
    "max": 0.4011971056461334,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 8.07613178039901e-05,
    "std": 0.05467630550265312,
    "var": 0.002989498432725668,
    "min": -0.32164499163627625,
    "max": 0.3304775357246399,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.00021235013264231384,
    "std": 0.05832209065556526,
    "var": 0.0034014664124697447,
    "min": -0.3681742548942566,
    "max": 0.3852598965167999,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.33568471670150757,
    "std": 0.11282601952552795,
    "var": 0.012729711830615997,
    "min": -0.6663538217544556,
    "max": -0.07621023803949356,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.09966564923524857,
    "std": 0.2718549072742462,
    "var": 0.0739050954580307,
    "min": -1.4466336965560913,
    "max": 1.2531838417053223,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.42447346448898315,
    "std": 0.9684683680534363,
    "var": 0.9379310011863708,
    "min": -2.2869114875793457,
    "max": 2.7378313541412354,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.29077649116516113,
    "std": 0.1394200623035431,
    "var": 0.01943795196712017,
    "min": -0.7718373537063599,
    "max": 0.02388853020966053,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19844844937324524,
    "std": 0.2061379998922348,
    "var": 0.04249287396669388,
    "min": -1.4419268369674683,
    "max": 0.6785904169082642,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.7554180026054382,
    "std": 0.7649041414260864,
    "var": 0.5850783586502075,
    "min": -1.5829468965530396,
    "max": 3.3427202701568604,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.29731065034866333,
    "std": 0.10904999077320099,
    "var": 0.01189190149307251,
    "min": -0.6837833523750305,
    "max": -0.055587273091077805,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.13338515162467957,
    "std": 0.18349312245845795,
    "var": 0.03366972878575325,
    "min": -1.234380841255188,
    "max": 0.542497992515564,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.2597389817237854,
    "std": 0.5033907294273376,
    "var": 0.2534022331237793,
    "min": -1.0873922109603882,
    "max": 2.1058685779571533,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.14585067331790924,
    "std": 0.0723300352692604,
    "var": 0.00523163378238678,
    "min": -0.43761947751045227,
    "max": 0.04156498983502388,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07853929698467255,
    "std": 0.13480506837368011,
    "var": 0.018172407522797585,
    "min": -1.028704047203064,
    "max": 0.4254145920276642,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0006122306222096086,
    "std": 0.0030725542455911636,
    "var": 9.440589565201662e-06,
    "min": -0.017194846644997597,
    "max": 0.007208159659057856,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.00041973163024522364,
    "std": 0.08965566754341125,
    "var": 0.008038138039410114,
    "min": -0.7225608825683594,
    "max": 0.7323707342147827,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.021237840875983238,
    "std": 0.26724475622177124,
    "var": 0.07141976803541183,
    "min": -2.1044504642486572,
    "max": 1.2250951528549194,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.1566413938999176,
    "std": 0.07364285737276077,
    "var": 0.005423270165920258,
    "min": -0.44856104254722595,
    "max": 0.005912134889513254,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.06923609972000122,
    "std": 0.13329792022705078,
    "var": 0.017768334597349167,
    "min": -1.194932460784912,
    "max": 0.509685754776001,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.17039620876312256,
    "std": 0.620486319065094,
    "var": 0.3850032687187195,
    "min": -1.9096583127975464,
    "max": 1.9607943296432495,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.06705738604068756,
    "std": 0.12237607687711716,
    "var": 0.014975903555750847,
    "min": -0.3032325506210327,
    "max": 0.33471012115478516,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.02705838903784752,
    "std": 0.121150441467762,
    "var": 0.014677430503070354,
    "min": -0.8713874816894531,
    "max": 0.6237427592277527,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.326824426651001,
    "std": 0.41641029715538025,
    "var": 0.17339754104614258,
    "min": -0.46666979789733887,
    "max": 1.9232197999954224,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.01171363890171051,
    "std": 0.0701313242316246,
    "var": 0.004918402526527643,
    "min": -0.16036321222782135,
    "max": 0.12282517552375793,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.002783420728519559,
    "std": 0.21371078491210938,
    "var": 0.045672304928302765,
    "min": -0.8207191824913025,
    "max": 0.8924609422683716,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.0031063382048159838,
    "std": 0.18123967945575714,
    "var": 0.032847821712493896,
    "min": -0.9383543133735657,
    "max": 0.938816487789154,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.04533465951681137,
    "std": 0.3846833109855652,
    "var": 0.14798125624656677,
    "min": -0.8581430315971375,
    "max": 1.2037570476531982,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.19113533198833466,
    "std": 0.38692232966423035,
    "var": 0.14970888197422028,
    "min": -1.3083910942077637,
    "max": 0.7367837429046631,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.22794221341609955,
    "std": 0.3561323881149292,
    "var": 0.12683027982711792,
    "min": -1.4306951761245728,
    "max": 0.7163121104240417,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.7733333706855774,
    "std": 0.4722028076648712,
    "var": 0.22297550737857819,
    "min": -1.9786694049835205,
    "max": 0.5768346786499023,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.7659561634063721,
    "std": 0.432095468044281,
    "var": 0.18670649826526642,
    "min": -1.9248042106628418,
    "max": 0.4371183216571808,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.7797085642814636,
    "std": 0.5147664546966553,
    "var": 0.26498451828956604,
    "min": -2.1320087909698486,
    "max": 0.23968064785003662,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 171 | 1000/1179 batches | ms/batch 2746.87 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.95
-----------------------------------------------------------------------------------------
| end of epoch 171 | time per epoch: 3234.06s |
| Train Metrics | accuracy:  0.78 | loss:  0.94
| Eval  Metrics | accuracy:  0.85 | loss:  0.53
-----------------------------------------------------------------------------------------
| epoch 172 | 1000/1179 batches | ms/batch 2802.19 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.93
-----------------------------------------------------------------------------------------
| end of epoch 172 | time per epoch: 3303.23s |
| Train Metrics | accuracy:  0.78 | loss:  0.93
| Eval  Metrics | accuracy:  0.85 | loss:  0.53
-----------------------------------------------------------------------------------------
[2025-02-28 22:46:20,419][absl][INFO] - Saving checkpoint at step: 202788
[2025-02-28 22:46:20,422][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-28 22:46:20,422][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-28 22:46:20,423][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_202788.
[2025-02-28 22:46:20,431][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-28 22:46:20,432][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_202788.orbax-checkpoint-tmp-49
[2025-02-28 22:46:20,440][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-28 22:46:20,467][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-28 22:46:20,498][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 159.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 57 milliseconds) (per-host)
[2025-02-28 22:46:20,723][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-28 22:46:20,723][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 282 milliseconds) (per-host)
[2025-02-28 22:46:20,728][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-28 22:46:20,759][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_202788.orbax-checkpoint-tmp-49 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_202788
[2025-02-28 22:46:20,765][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_202788`.
[2025-02-28 22:46:20,765][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-28 22:46:20,767][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_188640
| epoch 173 | 1000/1179 batches | ms/batch 2797.52 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.97
-----------------------------------------------------------------------------------------
| end of epoch 173 | time per epoch: 3298.54s |
| Train Metrics | accuracy:  0.77 | loss:  0.96
| Eval  Metrics | accuracy:  0.85 | loss:  0.53
-----------------------------------------------------------------------------------------
| epoch 174 | 1000/1179 batches | ms/batch 2652.69 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.97
-----------------------------------------------------------------------------------------
| end of epoch 174 | time per epoch: 3128.08s |
| Train Metrics | accuracy:  0.77 | loss:  0.96
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
[2025-03-01 00:45:36,337][absl][INFO] - Saving checkpoint at step: 205146
[2025-03-01 00:45:36,339][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-03-01 00:45:36,339][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-03-01 00:45:36,340][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_205146.
[2025-03-01 00:45:36,348][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-03-01 00:45:36,349][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_205146.orbax-checkpoint-tmp-50
[2025-03-01 00:45:36,356][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-03-01 00:45:36,382][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-03-01 00:45:36,725][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 24.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 367 milliseconds) (per-host)
[2025-03-01 00:45:36,935][absl][INFO] - ChainedFuture completed 1/1 futures in 0.21 seconds.
[2025-03-01 00:45:36,936][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 15.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 578 milliseconds) (per-host)
[2025-03-01 00:45:36,941][absl][INFO] - Updated Metadata={'item_handlers': 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler', 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1740807936353553771, 'commit_timestamp_nsecs': None, 'custom': {}} to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_205146.orbax-checkpoint-tmp-50/_CHECKPOINT_METADATA
[2025-03-01 00:45:36,941][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-03-01 00:45:36,968][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_205146.orbax-checkpoint-tmp-50 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_205146
[2025-03-01 00:45:36,973][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_205146`.
[2025-03-01 00:45:36,973][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-03-01 00:45:36,975][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_202788
| epoch 175 | 1000/1179 batches | ms/batch 2827.17 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.91
-----------------------------------------------------------------------------------------
| end of epoch 175 | time per epoch: 3333.53s |
| Train Metrics | accuracy:  0.78 | loss:  0.91
| Eval  Metrics | accuracy:  0.85 | loss:  0.51
-----------------------------------------------------------------------------------------
[2025-03-01 01:47:28,943][absl][INFO] - Saving checkpoint at step: 206325
[2025-03-01 01:47:28,945][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-03-01 01:47:28,945][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-03-01 01:47:28,946][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_206325.
[2025-03-01 01:47:28,954][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-03-01 01:47:28,955][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_206325.orbax-checkpoint-tmp-51
[2025-03-01 01:47:28,961][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-03-01 01:47:28,987][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-03-01 01:47:29,015][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 172.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 52 milliseconds) (per-host)
[2025-03-01 01:47:29,226][absl][INFO] - ChainedFuture completed 1/1 futures in 0.21 seconds.
[2025-03-01 01:47:29,226][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 34.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 264 milliseconds) (per-host)
[2025-03-01 01:47:29,231][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-03-01 01:47:29,257][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_206325.orbax-checkpoint-tmp-51 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_206325
[2025-03-01 01:47:29,261][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_206325`.
[2025-03-01 01:47:29,261][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-03-01 01:47:29,263][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_205146
| epoch 176 | 1000/1179 batches | ms/batch 2768.29 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.91
-----------------------------------------------------------------------------------------
| end of epoch 176 | time per epoch: 3251.13s |
| Train Metrics | accuracy:  0.78 | loss:  0.92
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 177 | 1000/1179 batches | ms/batch 2763.57 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.92
-----------------------------------------------------------------------------------------
| end of epoch 177 | time per epoch: 3256.90s |
| Train Metrics | accuracy:  0.78 | loss:  0.91
| Eval  Metrics | accuracy:  0.85 | loss:  0.50
-----------------------------------------------------------------------------------------
| epoch 178 | 1000/1179 batches | ms/batch 2690.46 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.91
-----------------------------------------------------------------------------------------
| end of epoch 178 | time per epoch: 3171.65s |
| Train Metrics | accuracy:  0.78 | loss:  0.91
| Eval  Metrics | accuracy:  0.85 | loss:  0.54
-----------------------------------------------------------------------------------------
| epoch 179 | 1000/1179 batches | ms/batch 2709.52 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.93
-----------------------------------------------------------------------------------------
| end of epoch 179 | time per epoch: 3192.86s |
| Train Metrics | accuracy:  0.78 | loss:  0.92
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 180 | 1000/1179 batches | ms/batch 2747.12 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.91
-----------------------------------------------------------------------------------------
| end of epoch 180 | time per epoch: 3242.06s |
| Train Metrics | accuracy:  0.78 | loss:  0.90
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.2683032751083374,
    "std": 0.3357454836368561,
    "var": 0.11272504180669785,
    "min": -0.1790992021560669,
    "max": 1.1239192485809326,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.3630097806453705,
    "std": 0.32630103826522827,
    "var": 0.10647237300872803,
    "min": 0.03429804742336273,
    "max": 1.5420345067977905,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.000545772141776979,
    "std": 0.11209660768508911,
    "var": 0.01256564911454916,
    "min": -0.6421278119087219,
    "max": 0.6455171704292297,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.25816580653190613,
    "std": 0.21395769715309143,
    "var": 0.04577789828181267,
    "min": -0.07740835845470428,
    "max": 0.9782773852348328,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.3993929624557495,
    "std": 0.3878158926963806,
    "var": 0.15040117502212524,
    "min": 0.03195201978087425,
    "max": 1.9234894514083862,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0006114802090451121,
    "std": 0.121753990650177,
    "var": 0.014824035577476025,
    "min": -0.7147163152694702,
    "max": 0.6786144375801086,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.3130201995372772,
    "std": 0.3324921727180481,
    "var": 0.11055104434490204,
    "min": -0.013485862873494625,
    "max": 1.1437368392944336,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.32327505946159363,
    "std": 0.3063502907752991,
    "var": 0.0938505157828331,
    "min": 0.030800342559814453,
    "max": 1.5390064716339111,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0005603378522209823,
    "std": 0.12716402113437653,
    "var": 0.016170687973499298,
    "min": -0.8203625679016113,
    "max": 1.0054736137390137,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.21787337958812714,
    "std": 0.204513281583786,
    "var": 0.041825681924819946,
    "min": -0.2031506448984146,
    "max": 1.0646175146102905,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.5655616521835327,
    "std": 0.3025861084461212,
    "var": 0.09155835956335068,
    "min": 0.04604911059141159,
    "max": 2.5254340171813965,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.000654855219181627,
    "std": 0.07864224910736084,
    "var": 0.006184603087604046,
    "min": -0.9649896025657654,
    "max": 0.9581348299980164,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.2162242829799652,
    "std": 0.2355564385652542,
    "var": 0.05548683926463127,
    "min": -0.3602750897407532,
    "max": 1.1477503776550293,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.643102765083313,
    "std": 0.26640477776527405,
    "var": 0.07097150385379791,
    "min": 0.09310120344161987,
    "max": 1.6866421699523926,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00013870038674212992,
    "std": 0.05737946555018425,
    "var": 0.003292403183877468,
    "min": -0.6273135542869568,
    "max": 0.6394520401954651,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.015150880441069603,
    "std": 0.09035252779722214,
    "var": 0.008163578808307648,
    "min": -0.44385212659835815,
    "max": 0.2638449966907501,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.2718384265899658,
    "std": 0.30447378754615784,
    "var": 0.09270428866147995,
    "min": 0.7990707159042358,
    "max": 2.7173891067504883,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0003574569127522409,
    "std": 0.09000439196825027,
    "var": 0.008100790902972221,
    "min": -1.02153742313385,
    "max": 0.9256595373153687,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.001333335880190134,
    "std": 0.056944288313388824,
    "var": 0.0032426519319415092,
    "min": -0.3426786959171295,
    "max": 0.3251836895942688,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.00019875371071975678,
    "std": 0.059458471834659576,
    "var": 0.0035353098064661026,
    "min": -0.29440727829933167,
    "max": 0.41104888916015625,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0003922464675270021,
    "std": 0.05991677567362785,
    "var": 0.0035900201182812452,
    "min": -0.30334004759788513,
    "max": 0.3640233278274536,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0003169687115587294,
    "std": 0.05066726356744766,
    "var": 0.002567171584814787,
    "min": -0.41455283761024475,
    "max": 0.38961005210876465,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 5.89521077927202e-05,
    "std": 0.05295507237315178,
    "var": 0.002804239746183157,
    "min": -0.31398627161979675,
    "max": 0.3172103464603424,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.00020223524188622832,
    "std": 0.056344885379076004,
    "var": 0.003174746409058571,
    "min": -0.351916640996933,
    "max": 0.3679957985877991,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.33557090163230896,
    "std": 0.11309616267681122,
    "var": 0.012790742330253124,
    "min": -0.6653696298599243,
    "max": -0.07176751643419266,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.09985794126987457,
    "std": 0.27073782682418823,
    "var": 0.07329897582530975,
    "min": -1.4155570268630981,
    "max": 1.236218810081482,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.41578173637390137,
    "std": 0.9593913555145264,
    "var": 0.9204317927360535,
    "min": -2.248161792755127,
    "max": 2.715437650680542,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.29161474108695984,
    "std": 0.13784591853618622,
    "var": 0.019001498818397522,
    "min": -0.768907904624939,
    "max": 0.012742613442242146,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19833461940288544,
    "std": 0.20508824288845062,
    "var": 0.04206119105219841,
    "min": -1.4278017282485962,
    "max": 0.6747176051139832,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.7368977069854736,
    "std": 0.7521911859512329,
    "var": 0.5657916069030762,
    "min": -1.5794352293014526,
    "max": 3.2876033782958984,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.29659730195999146,
    "std": 0.1080094501376152,
    "var": 0.011666040867567062,
    "min": -0.6763867735862732,
    "max": -0.05835102126002312,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.13292795419692993,
    "std": 0.18270838260650635,
    "var": 0.0333823561668396,
    "min": -1.2295767068862915,
    "max": 0.5478755235671997,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.25205954909324646,
    "std": 0.49350738525390625,
    "var": 0.24354955554008484,
    "min": -1.0747230052947998,
    "max": 2.0429515838623047,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.14747947454452515,
    "std": 0.07137824594974518,
    "var": 0.005094854161143303,
    "min": -0.44113385677337646,
    "max": 0.03700060397386551,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07871370762586594,
    "std": 0.13353639841079712,
    "var": 0.017831970006227493,
    "min": -1.0257632732391357,
    "max": 0.439462274312973,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0006518850568681955,
    "std": 0.002827909542247653,
    "var": 7.997072316356935e-06,
    "min": -0.014591640792787075,
    "max": 0.008576941676437855,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 0.00039421222754754126,
    "std": 0.08790349215269089,
    "var": 0.007727024611085653,
    "min": -0.702572226524353,
    "max": 0.7144006490707397,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.020476924255490303,
    "std": 0.2601413428783417,
    "var": 0.06767352670431137,
    "min": -2.0334856510162354,
    "max": 1.19431734085083,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15735091269016266,
    "std": 0.07291129231452942,
    "var": 0.005316057242453098,
    "min": -0.4487846791744232,
    "max": 0.004086244385689497,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.06917606294155121,
    "std": 0.13200537860393524,
    "var": 0.017425421625375748,
    "min": -1.1929030418395996,
    "max": 0.510776698589325,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.16515976190567017,
    "std": 0.6004630923271179,
    "var": 0.3605559766292572,
    "min": -1.8436139822006226,
    "max": 1.89795982837677,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.06883301585912704,
    "std": 0.12162762135267258,
    "var": 0.014793278649449348,
    "min": -0.29875537753105164,
    "max": 0.3362642824649811,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.02624848484992981,
    "std": 0.11976421624422073,
    "var": 0.01434346754103899,
    "min": -0.8590289354324341,
    "max": 0.6260556578636169,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.3204827308654785,
    "std": 0.40439870953559875,
    "var": 0.16353830695152283,
    "min": -0.46371376514434814,
    "max": 1.8732895851135254,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.01173045951873064,
    "std": 0.07041306793689728,
    "var": 0.004958000499755144,
    "min": -0.15796633064746857,
    "max": 0.12261458486318588,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0027938683051615953,
    "std": 0.21387167274951935,
    "var": 0.045741092413663864,
    "min": -0.8165969848632812,
    "max": 0.8919501304626465,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.0032920411322265863,
    "std": 0.17683416604995728,
    "var": 0.03127032145857811,
    "min": -0.9210008978843689,
    "max": 0.9098275899887085,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.028456170111894608,
    "std": 0.3802952468395233,
    "var": 0.1446244716644287,
    "min": -0.8344323039054871,
    "max": 1.1962202787399292,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.18249468505382538,
    "std": 0.38090938329696655,
    "var": 0.1450919657945633,
    "min": -1.2844727039337158,
    "max": 0.7198635339736938,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.22392027080059052,
    "std": 0.3510530889034271,
    "var": 0.12323828041553497,
    "min": -1.4102306365966797,
    "max": 0.704216718673706,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.7589553594589233,
    "std": 0.46469414234161377,
    "var": 0.2159406542778015,
    "min": -1.947735071182251,
    "max": 0.5657344460487366,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.7478100657463074,
    "std": 0.42922598123550415,
    "var": 0.18423494696617126,
    "min": -1.905254602432251,
    "max": 0.43200626969337463,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.7711526155471802,
    "std": 0.5101247429847717,
    "var": 0.2602272927761078,
    "min": -2.1159424781799316,
    "max": 0.23499026894569397,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 181 | 1000/1179 batches | ms/batch 2729.90 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.90
-----------------------------------------------------------------------------------------
| end of epoch 181 | time per epoch: 3219.36s |
| Train Metrics | accuracy:  0.78 | loss:  0.91
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 182 | 1000/1179 batches | ms/batch 2750.13 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.92
-----------------------------------------------------------------------------------------
| end of epoch 182 | time per epoch: 3246.89s |
| Train Metrics | accuracy:  0.78 | loss:  0.91
| Eval  Metrics | accuracy:  0.85 | loss:  0.51
-----------------------------------------------------------------------------------------
[2025-03-01 08:47:47,751][absl][INFO] - Saving checkpoint at step: 214578
[2025-03-01 08:47:47,753][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-03-01 08:47:47,754][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-03-01 08:47:47,755][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_214578.
[2025-03-01 08:47:47,925][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-03-01 08:47:47,926][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_214578.orbax-checkpoint-tmp-52
[2025-03-01 08:47:47,934][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-03-01 08:47:47,961][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-03-01 08:47:47,992][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 158.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 57 milliseconds) (per-host)
[2025-03-01 08:47:48,210][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-03-01 08:47:48,211][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 276 milliseconds) (per-host)
[2025-03-01 08:47:48,215][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-03-01 08:47:48,244][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_214578.orbax-checkpoint-tmp-52 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_214578
[2025-03-01 08:47:48,249][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_214578`.
[2025-03-01 08:47:48,249][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-03-01 08:47:48,251][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_206325
| epoch 183 | 1000/1179 batches | ms/batch 2784.56 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.91
-----------------------------------------------------------------------------------------
| end of epoch 183 | time per epoch: 3283.19s |
| Train Metrics | accuracy:  0.78 | loss:  0.91
| Eval  Metrics | accuracy:  0.85 | loss:  0.50
-----------------------------------------------------------------------------------------
| epoch 184 | 1000/1179 batches | ms/batch 2798.14 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.92
-----------------------------------------------------------------------------------------
| end of epoch 184 | time per epoch: 3299.13s |
| Train Metrics | accuracy:  0.78 | loss:  0.92
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 185 | 1000/1179 batches | ms/batch 2810.33 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.88
-----------------------------------------------------------------------------------------
| end of epoch 185 | time per epoch: 3313.49s |
| Train Metrics | accuracy:  0.79 | loss:  0.89
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 186 | 1000/1179 batches | ms/batch 3014.35 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.85
-----------------------------------------------------------------------------------------
| end of epoch 186 | time per epoch: 3551.42s |
| Train Metrics | accuracy:  0.79 | loss:  0.85
| Eval  Metrics | accuracy:  0.85 | loss:  0.50
-----------------------------------------------------------------------------------------
| epoch 187 | 1000/1179 batches | ms/batch 3024.88 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.90
-----------------------------------------------------------------------------------------
| end of epoch 187 | time per epoch: 3542.24s |
| Train Metrics | accuracy:  0.79 | loss:  0.90
| Eval  Metrics | accuracy:  0.85 | loss:  0.51
-----------------------------------------------------------------------------------------
[2025-03-01 14:04:22,241][absl][INFO] - Saving checkpoint at step: 220473
[2025-03-01 14:04:22,243][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-03-01 14:04:22,243][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-03-01 14:04:22,244][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_220473.
[2025-03-01 14:04:22,247][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-03-01 14:04:22,248][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_220473.orbax-checkpoint-tmp-53
[2025-03-01 14:04:22,276][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-03-01 14:04:22,303][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-03-01 14:04:22,320][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 214.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 42 milliseconds) (per-host)
[2025-03-01 14:04:22,550][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-03-01 14:04:22,550][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 33.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 273 milliseconds) (per-host)
[2025-03-01 14:04:22,556][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-03-01 14:04:22,585][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_220473.orbax-checkpoint-tmp-53 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_220473
[2025-03-01 14:04:22,590][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_220473`.
[2025-03-01 14:04:22,590][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-03-01 14:04:22,592][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_214578
| epoch 188 | 1000/1179 batches | ms/batch 2959.49 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.89
-----------------------------------------------------------------------------------------
| end of epoch 188 | time per epoch: 3478.74s |
| Train Metrics | accuracy:  0.79 | loss:  0.90
| Eval  Metrics | accuracy:  0.85 | loss:  0.50
-----------------------------------------------------------------------------------------
[2025-03-01 15:09:15,037][absl][INFO] - Saving checkpoint at step: 221652
[2025-03-01 15:09:15,039][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-03-01 15:09:15,039][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-03-01 15:09:15,041][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_221652.
[2025-03-01 15:09:15,050][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-03-01 15:09:15,051][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_221652.orbax-checkpoint-tmp-54
[2025-03-01 15:09:15,058][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-03-01 15:09:15,087][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-03-01 15:09:15,116][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 158.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 57 milliseconds) (per-host)
[2025-03-01 15:09:15,324][absl][INFO] - ChainedFuture completed 1/1 futures in 0.21 seconds.
[2025-03-01 15:09:15,324][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 34.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 265 milliseconds) (per-host)
[2025-03-01 15:09:15,329][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-03-01 15:09:15,360][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_221652.orbax-checkpoint-tmp-54 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_221652
[2025-03-01 15:09:15,365][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_221652`.
[2025-03-01 15:09:15,365][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-03-01 15:09:15,367][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-24-16-09-54/checkpoints/checkpoint_220473
slurmstepd: error: *** JOB 21696406 ON gl1515 CANCELLED AT 2025-03-01T16:09:55 DUE TO TIME LIMIT ***
