WARNING:absl:Tensorflow library not found, tensorflow.io.gfile operations will use native shim calls. GCS paths (i.e. 'gs://...') cannot be accessed.
INFO:2025-02-25 17:52:09,784:jax._src.xla_bridge:945: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
seed: 1234
checkpoint: null
data_dir: ./data
output_dir: ./outputs/${now:%Y-%m-%d-%H-%M-%S}
checkpoint_dir: ./checkpoints
model:
  ssm_init:
    C_init: lecun_normal
    dt_min: 0.0015
    dt_max: 0.1
    conj_sym: true
    clip_eigs: false
  ssm:
    discretization: async
    d_model: 96
    d_ssm: 128
    ssm_block_size: 16
    num_stages: 2
    num_layers_per_stage: 3
    dropout: 0.23
    classification_mode: pool
    prenorm: true
    batchnorm: true
    bn_momentum: 0.95
    pooling_stride: 8
    pooling_mode: avgpool
    state_expansion_factor: 2
task:
  name: ssc-classification
training:
  num_epochs: 200
  per_device_batch_size: 32
  per_device_eval_batch_size: 64
  num_workers: 2
  time_jitter: 3
  spatial_jitter: 1.0
  noise: 100
  drop_event: 0.1
  max_drop_chunk: 0.02
  cut_mix: 0.3
  time_skew: 1.05
  pad_unit: 8192
optimizer:
  ssm_base_lr: 5.0e-06
  lr_factor: 5
  warmup_epochs: 20
  ssm_weight_decay: 0.0
  weight_decay: 0.05
  schedule: cosine
  accumulation_steps: 1
logging:
  log_dir: ${output_dir}
  interval: 1000
  wandb: false
  summary_metric: Performance/Validation accuracy
  project: ???
  entity: ???

[2025-02-25 17:52:09,784][jax._src.xla_bridge][INFO] - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
INFO:2025-02-25 17:52:09,785:jax._src.xla_bridge:945: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-02-25 17:52:09,785][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[*] Loading dataset...
[*] Generating Spiking Speech Commands Classification Dataset
[*] Creating model...
[*] Initializing model state...
/sw/pkgs/arc/python/3.12.1/lib/python3.12/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
[SequenceLayer] Layer 0: using manual_lambda = -0.3
SSM: 96 -> 128 -> 96 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 2: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 0: using manual_lambda = -0.2
SSM: 96 -> 256 -> 192 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.2
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 2: using manual_lambda = -0.2
SSM: 192 -> 256 -> 192
[*] Model parameter count: 597731
[*] Using gradient accumulation with 1 steps
[*] Running training on 2 GPUs
[*] Logging to ./outputs/2025-02-25-17-52-09
[*] Number of model parameters: 597731
[*] Running training...
[SequenceLayer] Layer 0: using manual_lambda = -0.3
SSM: 96 -> 128 -> 96 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 2: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 0: using manual_lambda = -0.2
SSM: 96 -> 256 -> 192 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.2
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 2: using manual_lambda = -0.2
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 0: using manual_lambda = -0.3
SSM: 96 -> 128 -> 96 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 2: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 0: using manual_lambda = -0.2
SSM: 96 -> 256 -> 192 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.2
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 2: using manual_lambda = -0.2
SSM: 192 -> 256 -> 192
| epoch 1 | 1000/1179 batches | ms/batch 1064.70 | Performance/Training accuracy:  0.05 | Performance/Training loss:  3.54
-----------------------------------------------------------------------------------------
| end of epoch   1 | time per epoch: 1217.07s |
| Train Metrics | accuracy:  0.06 | loss:  3.50
[SequenceLayer] Layer 0: using manual_lambda = -0.3
SSM: 96 -> 128 -> 96 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 2: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 0: using manual_lambda = -0.2
SSM: 96 -> 256 -> 192 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.2
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 2: using manual_lambda = -0.2
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 0: using manual_lambda = -0.3
SSM: 96 -> 128 -> 96 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 2: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 0: using manual_lambda = -0.2
SSM: 96 -> 256 -> 192 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.2
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 2: using manual_lambda = -0.2
SSM: 192 -> 256 -> 192
| Eval  Metrics | accuracy:  0.16 | loss:  3.03
-----------------------------------------------------------------------------------------
[2025-02-25 18:14:57,578][absl][INFO] - Saving checkpoint at step: 1179
[2025-02-25 18:14:57,579][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 18:14:57,580][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 18:14:57,580][absl][INFO] - orbax-checkpoint version: 0.11.1
[2025-02-25 18:14:57,581][absl][INFO] - [thread=MainThread] Failed to get flag value for EXPERIMENTAL_ORBAX_USE_DISTRIBUTED_PROCESS_ID.
[2025-02-25 18:14:57,582][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_1179.
[2025-02-25 18:14:57,593][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 18:14:57,593][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_1179.orbax-checkpoint-tmp-0
[2025-02-25 18:14:57,602][absl][INFO] - Wrote Metadata={'item_handlers': None, 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1740525297598406405, 'commit_timestamp_nsecs': None, 'custom': {}}, json={"item_handlers": null, "metrics": {}, "performance_metrics": {}, "init_timestamp_nsecs": 1740525297598406405, "commit_timestamp_nsecs": null, "custom": {}} to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_1179.orbax-checkpoint-tmp-0/_CHECKPOINT_METADATA
[2025-02-25 18:14:57,602][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 18:14:57,628][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 18:14:57,661][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 154.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 58 milliseconds) (per-host)
[2025-02-25 18:14:57,883][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-25 18:14:57,883][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 280 milliseconds) (per-host)
[2025-02-25 18:14:57,885][absl][INFO] - Read Metadata={'item_handlers': None, 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1740525297598406405, 'commit_timestamp_nsecs': None, 'custom': {}} from /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_1179.orbax-checkpoint-tmp-0/_CHECKPOINT_METADATA
[2025-02-25 18:14:57,889][absl][INFO] - Updated Metadata={'item_handlers': 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler', 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1740525297598406405, 'commit_timestamp_nsecs': None, 'custom': {}} to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_1179.orbax-checkpoint-tmp-0/_CHECKPOINT_METADATA
[2025-02-25 18:14:57,889][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 18:14:57,920][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_1179.orbax-checkpoint-tmp-0 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_1179
[2025-02-25 18:14:57,926][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_1179`.
[2025-02-25 18:14:57,926][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
| epoch 2 | 1000/1179 batches | ms/batch 767.69 | Performance/Training accuracy:  0.15 | Performance/Training loss:  3.06
-----------------------------------------------------------------------------------------
| end of epoch   2 | time per epoch: 928.14s |
| Train Metrics | accuracy:  0.15 | loss:  3.04
| Eval  Metrics | accuracy:  0.29 | loss:  2.60
-----------------------------------------------------------------------------------------
[2025-02-25 18:31:47,278][absl][INFO] - Saving checkpoint at step: 2358
[2025-02-25 18:31:47,279][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 18:31:47,280][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 18:31:47,281][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_2358.
[2025-02-25 18:31:47,283][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 18:31:47,284][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_2358.orbax-checkpoint-tmp-1
[2025-02-25 18:31:47,290][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 18:31:47,319][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 18:31:47,359][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 133.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 68 milliseconds) (per-host)
[2025-02-25 18:31:47,578][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-25 18:31:47,579][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 287 milliseconds) (per-host)
[2025-02-25 18:31:47,585][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 18:31:47,617][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_2358.orbax-checkpoint-tmp-1 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_2358
[2025-02-25 18:31:47,626][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_2358`.
[2025-02-25 18:31:47,626][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 18:31:47,627][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_1179
| epoch 3 | 1000/1179 batches | ms/batch 722.97 | Performance/Training accuracy:  0.21 | Performance/Training loss:  2.83
-----------------------------------------------------------------------------------------
| end of epoch   3 | time per epoch: 874.40s |
| Train Metrics | accuracy:  0.22 | loss:  2.81
| Eval  Metrics | accuracy:  0.36 | loss:  2.30
-----------------------------------------------------------------------------------------
[2025-02-25 18:47:25,279][absl][INFO] - Saving checkpoint at step: 3537
[2025-02-25 18:47:25,280][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 18:47:25,281][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 18:47:25,282][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_3537.
[2025-02-25 18:47:25,284][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 18:47:25,285][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_3537.orbax-checkpoint-tmp-2
[2025-02-25 18:47:25,293][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 18:47:25,321][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 18:47:25,356][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 146.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 62 milliseconds) (per-host)
[2025-02-25 18:47:25,668][absl][INFO] - ChainedFuture completed 1/1 futures in 0.31 seconds.
[2025-02-25 18:47:25,668][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 24.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 374 milliseconds) (per-host)
[2025-02-25 18:47:25,721][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 18:47:25,783][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_3537.orbax-checkpoint-tmp-2 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_3537
[2025-02-25 18:47:25,821][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_3537`.
[2025-02-25 18:47:25,821][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 18:47:25,822][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_2358
| epoch 4 | 1000/1179 batches | ms/batch 714.26 | Performance/Training accuracy:  0.28 | Performance/Training loss:  2.60
-----------------------------------------------------------------------------------------
| end of epoch   4 | time per epoch: 846.30s |
| Train Metrics | accuracy:  0.28 | loss:  2.58
| Eval  Metrics | accuracy:  0.45 | loss:  1.92
-----------------------------------------------------------------------------------------
[2025-02-25 19:02:37,400][absl][INFO] - Saving checkpoint at step: 4716
[2025-02-25 19:02:37,401][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 19:02:37,401][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 19:02:37,402][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_4716.
[2025-02-25 19:02:37,405][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 19:02:37,406][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_4716.orbax-checkpoint-tmp-3
[2025-02-25 19:02:37,413][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 19:02:37,443][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 19:02:37,477][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 144.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 63 milliseconds) (per-host)
[2025-02-25 19:02:37,720][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-25 19:02:37,721][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 29.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 306 milliseconds) (per-host)
[2025-02-25 19:02:37,727][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 19:02:37,757][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_4716.orbax-checkpoint-tmp-3 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_4716
[2025-02-25 19:02:37,763][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_4716`.
[2025-02-25 19:02:37,763][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 19:02:37,765][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_3537
| epoch 5 | 1000/1179 batches | ms/batch 766.87 | Performance/Training accuracy:  0.34 | Performance/Training loss:  2.38
-----------------------------------------------------------------------------------------
| end of epoch   5 | time per epoch: 896.51s |
| Train Metrics | accuracy:  0.35 | loss:  2.36
| Eval  Metrics | accuracy:  0.50 | loss:  1.72
-----------------------------------------------------------------------------------------
[2025-02-25 19:19:16,219][absl][INFO] - Saving checkpoint at step: 5895
[2025-02-25 19:19:16,220][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 19:19:16,220][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 19:19:16,222][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_5895.
[2025-02-25 19:19:16,224][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 19:19:16,225][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_5895.orbax-checkpoint-tmp-4
[2025-02-25 19:19:16,231][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 19:19:16,259][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 19:19:16,294][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 145.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 62 milliseconds) (per-host)
[2025-02-25 19:19:16,523][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-25 19:19:16,524][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 292 milliseconds) (per-host)
[2025-02-25 19:19:16,529][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 19:19:16,559][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_5895.orbax-checkpoint-tmp-4 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_5895
[2025-02-25 19:19:16,565][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_5895`.
[2025-02-25 19:19:16,565][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 19:19:16,566][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_4716
| epoch 6 | 1000/1179 batches | ms/batch 887.90 | Performance/Training accuracy:  0.40 | Performance/Training loss:  2.19
-----------------------------------------------------------------------------------------
| end of epoch   6 | time per epoch: 1070.15s |
| Train Metrics | accuracy:  0.40 | loss:  2.18
| Eval  Metrics | accuracy:  0.55 | loss:  1.54
-----------------------------------------------------------------------------------------
[2025-02-25 19:38:41,231][absl][INFO] - Saving checkpoint at step: 7074
[2025-02-25 19:38:41,233][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 19:38:41,233][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 19:38:41,234][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_7074.
[2025-02-25 19:38:41,237][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 19:38:41,238][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_7074.orbax-checkpoint-tmp-5
[2025-02-25 19:38:41,245][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 19:38:41,272][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 19:38:41,304][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 155.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 58 milliseconds) (per-host)
[2025-02-25 19:38:41,899][absl][INFO] - ChainedFuture completed 1/1 futures in 0.59 seconds.
[2025-02-25 19:38:41,899][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 14.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 653 milliseconds) (per-host)
[2025-02-25 19:38:41,905][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 19:38:41,938][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_7074.orbax-checkpoint-tmp-5 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_7074
[2025-02-25 19:38:41,945][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_7074`.
[2025-02-25 19:38:41,945][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 19:38:41,947][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_5895
| epoch 7 | 1000/1179 batches | ms/batch 919.51 | Performance/Training accuracy:  0.44 | Performance/Training loss:  2.04
-----------------------------------------------------------------------------------------
| end of epoch   7 | time per epoch: 1101.43s |
| Train Metrics | accuracy:  0.45 | loss:  2.03
| Eval  Metrics | accuracy:  0.59 | loss:  1.41
-----------------------------------------------------------------------------------------
[2025-02-25 19:58:42,268][absl][INFO] - Saving checkpoint at step: 8253
[2025-02-25 19:58:42,269][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 19:58:42,270][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 19:58:42,271][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_8253.
[2025-02-25 19:58:42,273][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 19:58:42,274][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_8253.orbax-checkpoint-tmp-6
[2025-02-25 19:58:42,284][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 19:58:42,311][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 19:58:42,330][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 198.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 45 milliseconds) (per-host)
[2025-02-25 19:58:42,583][absl][INFO] - ChainedFuture completed 1/1 futures in 0.25 seconds.
[2025-02-25 19:58:42,583][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 299 milliseconds) (per-host)
[2025-02-25 19:58:42,589][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 19:58:42,623][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_8253.orbax-checkpoint-tmp-6 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_8253
[2025-02-25 19:58:42,629][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_8253`.
[2025-02-25 19:58:42,629][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 19:58:42,631][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_7074
| epoch 8 | 1000/1179 batches | ms/batch 855.67 | Performance/Training accuracy:  0.48 | Performance/Training loss:  1.95
-----------------------------------------------------------------------------------------
| end of epoch   8 | time per epoch: 1011.62s |
| Train Metrics | accuracy:  0.48 | loss:  1.93
| Eval  Metrics | accuracy:  0.63 | loss:  1.26
-----------------------------------------------------------------------------------------
[2025-02-25 20:17:21,014][absl][INFO] - Saving checkpoint at step: 9432
[2025-02-25 20:17:21,015][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 20:17:21,015][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 20:17:21,017][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_9432.
[2025-02-25 20:17:21,019][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 20:17:21,020][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_9432.orbax-checkpoint-tmp-7
[2025-02-25 20:17:21,028][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 20:17:21,056][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 20:17:21,088][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 152.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 59 milliseconds) (per-host)
[2025-02-25 20:17:21,324][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-25 20:17:21,324][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 295 milliseconds) (per-host)
[2025-02-25 20:17:21,331][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 20:17:21,365][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_9432.orbax-checkpoint-tmp-7 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_9432
[2025-02-25 20:17:21,376][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_9432`.
[2025-02-25 20:17:21,376][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 20:17:21,377][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_8253
| epoch 9 | 1000/1179 batches | ms/batch 836.29 | Performance/Training accuracy:  0.51 | Performance/Training loss:  1.83
-----------------------------------------------------------------------------------------
| end of epoch   9 | time per epoch: 1000.51s |
| Train Metrics | accuracy:  0.51 | loss:  1.83
| Eval  Metrics | accuracy:  0.65 | loss:  1.22
-----------------------------------------------------------------------------------------
[2025-02-25 20:35:54,008][absl][INFO] - Saving checkpoint at step: 10611
[2025-02-25 20:35:54,009][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 20:35:54,010][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 20:35:54,011][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_10611.
[2025-02-25 20:35:54,013][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 20:35:54,014][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_10611.orbax-checkpoint-tmp-8
[2025-02-25 20:35:54,021][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 20:35:54,049][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 20:35:54,069][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 192.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 47 milliseconds) (per-host)
[2025-02-25 20:35:54,327][absl][INFO] - ChainedFuture completed 1/1 futures in 0.25 seconds.
[2025-02-25 20:35:54,327][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 29.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 305 milliseconds) (per-host)
[2025-02-25 20:35:54,334][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 20:35:54,368][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_10611.orbax-checkpoint-tmp-8 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_10611
[2025-02-25 20:35:54,375][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_10611`.
[2025-02-25 20:35:54,375][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 20:35:54,376][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_9432
| epoch 10 | 1000/1179 batches | ms/batch 839.54 | Performance/Training accuracy:  0.53 | Performance/Training loss:  1.74
-----------------------------------------------------------------------------------------
| end of epoch  10 | time per epoch: 985.21s |
| Train Metrics | accuracy:  0.53 | loss:  1.75
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.005763612687587738,
    "std": 0.12323155999183655,
    "var": 0.015186017379164696,
    "min": -0.2670597434043884,
    "max": 0.24352744221687317,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.8409370183944702,
    "std": 0.08217989653348923,
    "var": 0.006753535009920597,
    "min": 0.6434023380279541,
    "max": 1.0696758031845093,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.00016839806630741805,
    "std": 0.08993951231241226,
    "var": 0.008089115843176842,
    "min": -0.22845923900604248,
    "max": 0.22812359035015106,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.07454538345336914,
    "std": 0.06810519844293594,
    "var": 0.004638318438082933,
    "min": -0.09695739299058914,
    "max": 0.30907660722732544,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.8349013328552246,
    "std": 0.09444587677717209,
    "var": 0.008920024149119854,
    "min": 0.6176391243934631,
    "max": 1.0795226097106934,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0001640613190829754,
    "std": 0.08905103802680969,
    "var": 0.007930086925625801,
    "min": -0.23939001560211182,
    "max": 0.23436862230300903,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.06747636198997498,
    "std": 0.06008797138929367,
    "var": 0.0036105643957853317,
    "min": -0.04853374883532524,
    "max": 0.25969743728637695,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.7804478406906128,
    "std": 0.09705467522144318,
    "var": 0.009419609792530537,
    "min": 0.5994650721549988,
    "max": 1.0245606899261475,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0010705608874559402,
    "std": 0.08907833695411682,
    "var": 0.007934950292110443,
    "min": -0.22733892500400543,
    "max": 0.22893376648426056,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.053206801414489746,
    "std": 0.05175923928618431,
    "var": 0.002679018769413233,
    "min": -0.04825182259082794,
    "max": 0.2135503739118576,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.9016178846359253,
    "std": 0.09652439504861832,
    "var": 0.009316958487033844,
    "min": 0.6594571471214294,
    "max": 1.166070818901062,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.00019941094797104597,
    "std": 0.06349728256464005,
    "var": 0.004031905438750982,
    "min": -0.17274963855743408,
    "max": 0.1754649579524994,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.05730908736586571,
    "std": 0.050502803176641464,
    "var": 0.0025505332741886377,
    "min": -0.07123445719480515,
    "max": 0.2308637797832489,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 1.0730974674224854,
    "std": 0.1561746448278427,
    "var": 0.02439052239060402,
    "min": 0.783495306968689,
    "max": 1.6428465843200684,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 8.275478467112407e-05,
    "std": 0.06249329820275307,
    "var": 0.003905412508174777,
    "min": -0.16835635900497437,
    "max": 0.1666516214609146,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.028104368597269058,
    "std": 0.03937742859125137,
    "var": 0.0015505817718803883,
    "min": -0.05068236216902733,
    "max": 0.15104041993618011,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.1459836959838867,
    "std": 0.16479462385177612,
    "var": 0.027157267555594444,
    "min": 0.8691778779029846,
    "max": 1.7346837520599365,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00041172662167809904,
    "std": 0.06316763907670975,
    "var": 0.003990150988101959,
    "min": -0.17872737348079681,
    "max": 0.17709898948669434,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": 0.0008521784911863506,
    "std": 0.09651059657335281,
    "var": 0.009314294904470444,
    "min": -0.4706319570541382,
    "max": 0.46821677684783936,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0002846510033123195,
    "std": 0.09170664846897125,
    "var": 0.008410109207034111,
    "min": -0.30858588218688965,
    "max": 0.3185933828353882,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0013225128641352057,
    "std": 0.0932731181383133,
    "var": 0.008699875324964523,
    "min": -0.3500317633152008,
    "max": 0.31786224246025085,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0007139198714867234,
    "std": 0.07253583520650864,
    "var": 0.0052614472806453705,
    "min": -0.2915034890174866,
    "max": 0.3132622241973877,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00014932124759070575,
    "std": 0.07059405744075775,
    "var": 0.004983521066606045,
    "min": -0.27696430683135986,
    "max": 0.25381046533584595,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.00045314719318412244,
    "std": 0.07421065866947174,
    "var": 0.005507222376763821,
    "min": -0.3120972514152527,
    "max": 0.3284277021884918,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.13202761113643646,
    "std": 0.05089394748210907,
    "var": 0.002590194111689925,
    "min": -0.23836641013622284,
    "max": -0.011463482864201069,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.03394375741481781,
    "std": 0.12252648174762726,
    "var": 0.015012738294899464,
    "min": -0.5589701533317566,
    "max": 0.468291699886322,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.014151116833090782,
    "std": 0.8667236566543579,
    "var": 0.7512099146842957,
    "min": -1.7198219299316406,
    "max": 2.221604108810425,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.12612198293209076,
    "std": 0.05253824219107628,
    "var": 0.0027602668851614,
    "min": -0.26616019010543823,
    "max": 0.008485985919833183,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07952447980642319,
    "std": 0.10216222703456879,
    "var": 0.01043712068349123,
    "min": -0.4859090745449066,
    "max": 0.2788233458995819,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": -0.018686100840568542,
    "std": 0.8336740136146545,
    "var": 0.6950123310089111,
    "min": -2.0262629985809326,
    "max": 2.222665309906006,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.14701418578624725,
    "std": 0.04241592809557915,
    "var": 0.00179911102168262,
    "min": -0.2260560244321823,
    "max": -0.044721297919750214,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.07691621035337448,
    "std": 0.09849649667739868,
    "var": 0.009701560251414776,
    "min": -0.5155406594276428,
    "max": 0.23069708049297333,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.08775778859853745,
    "std": 0.776869535446167,
    "var": 0.6035262942314148,
    "min": -1.4550105333328247,
    "max": 1.935093641281128,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.06728844344615936,
    "std": 0.04680650308728218,
    "var": 0.0021908488124608994,
    "min": -0.22674663364887238,
    "max": 0.047302257269620895,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.050810787826776505,
    "std": 0.09081827849149704,
    "var": 0.008247960358858109,
    "min": -0.49143460392951965,
    "max": 0.29800841212272644,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0025164815597236156,
    "std": 0.04133783280849457,
    "var": 0.0017088165041059256,
    "min": -0.09263027459383011,
    "max": 0.11686746031045914,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -3.960159665439278e-05,
    "std": 0.08268453180789948,
    "var": 0.006836731918156147,
    "min": -0.3533306419849396,
    "max": 0.3583858907222748,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.005363962147384882,
    "std": 0.1198107898235321,
    "var": 0.014354624785482883,
    "min": -0.7998415231704712,
    "max": 0.6002888679504395,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.0787665843963623,
    "std": 0.05209360644221306,
    "var": 0.0027137435972690582,
    "min": -0.21498429775238037,
    "max": 0.03137214481830597,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.03698844462633133,
    "std": 0.10421262681484222,
    "var": 0.010860271751880646,
    "min": -0.7196797728538513,
    "max": 0.5454289317131042,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": -0.07676500082015991,
    "std": 0.9409475326538086,
    "var": 0.8853822946548462,
    "min": -3.0240182876586914,
    "max": 2.3563389778137207,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.031410858035087585,
    "std": 0.04813758656382561,
    "var": 0.0023172274231910706,
    "min": -0.19636815786361694,
    "max": 0.0794248953461647,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.0181938074529171,
    "std": 0.10880157351493835,
    "var": 0.011837782338261604,
    "min": -0.5934579968452454,
    "max": 0.4269842505455017,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.18642453849315643,
    "std": 0.9586207866668701,
    "var": 0.9189537763595581,
    "min": -2.2597620487213135,
    "max": 2.890774726867676,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.004134334158152342,
    "std": 0.03170444443821907,
    "var": 0.001005171681754291,
    "min": -0.08467237651348114,
    "max": 0.04506849870085716,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0013988266000524163,
    "std": 0.0929480567574501,
    "var": 0.008639341220259666,
    "min": -0.4529922902584076,
    "max": 0.34840133786201477,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.0003936775610782206,
    "std": 0.15266256034374237,
    "var": 0.023305857554078102,
    "min": -0.7532618641853333,
    "max": 0.7496509552001953,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -3.5661745071411133,
    "std": 0.9903129935264587,
    "var": 0.980719804763794,
    "min": -5.173593521118164,
    "max": -1.5200538635253906,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -3.4808664321899414,
    "std": 0.9427942633628845,
    "var": 0.8888610601425171,
    "min": -5.156405925750732,
    "max": -1.620058536529541,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -3.678907632827759,
    "std": 0.9231765270233154,
    "var": 0.8522549271583557,
    "min": -5.116715908050537,
    "max": -1.6905988454818726,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -3.4749855995178223,
    "std": 0.936004638671875,
    "var": 0.8761047720909119,
    "min": -5.125897407531738,
    "max": -1.7747858762741089,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -3.56447696685791,
    "std": 0.9191840291023254,
    "var": 0.8448993563652039,
    "min": -5.1902570724487305,
    "max": -1.4984396696090698,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -3.5096240043640137,
    "std": 0.8494107723236084,
    "var": 0.7214987277984619,
    "min": -5.074463367462158,
    "max": -1.9275131225585938,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.66 | loss:  1.14
-----------------------------------------------------------------------------------------
[2025-02-25 20:54:03,064][absl][INFO] - Saving checkpoint at step: 11790
[2025-02-25 20:54:03,065][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 20:54:03,065][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 20:54:03,066][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_11790.
[2025-02-25 20:54:03,069][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 20:54:03,070][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_11790.orbax-checkpoint-tmp-9
[2025-02-25 20:54:03,076][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 20:54:03,103][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 20:54:03,134][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 159.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 57 milliseconds) (per-host)
[2025-02-25 20:54:03,362][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-25 20:54:03,362][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 284 milliseconds) (per-host)
[2025-02-25 20:54:03,368][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 20:54:03,402][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_11790.orbax-checkpoint-tmp-9 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_11790
[2025-02-25 20:54:03,408][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_11790`.
[2025-02-25 20:54:03,409][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 20:54:03,410][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_10611
| epoch 11 | 1000/1179 batches | ms/batch 737.06 | Performance/Training accuracy:  0.55 | Performance/Training loss:  1.68
-----------------------------------------------------------------------------------------
| end of epoch  11 | time per epoch: 906.74s |
| Train Metrics | accuracy:  0.55 | loss:  1.68
| Eval  Metrics | accuracy:  0.66 | loss:  1.15
-----------------------------------------------------------------------------------------
[2025-02-25 21:11:11,046][absl][INFO] - Saving checkpoint at step: 12969
[2025-02-25 21:11:11,048][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 21:11:11,048][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 21:11:11,049][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_12969.
[2025-02-25 21:11:11,051][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 21:11:11,052][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_12969.orbax-checkpoint-tmp-10
[2025-02-25 21:11:11,060][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 21:11:11,087][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 21:11:11,119][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 156.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 58 milliseconds) (per-host)
[2025-02-25 21:11:11,378][absl][INFO] - ChainedFuture completed 1/1 futures in 0.26 seconds.
[2025-02-25 21:11:11,378][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 28.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 317 milliseconds) (per-host)
[2025-02-25 21:11:11,384][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 21:11:11,419][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_12969.orbax-checkpoint-tmp-10 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_12969
[2025-02-25 21:11:11,426][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_12969`.
[2025-02-25 21:11:11,426][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 21:11:11,427][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_11790
| epoch 12 | 1000/1179 batches | ms/batch 842.89 | Performance/Training accuracy:  0.56 | Performance/Training loss:  1.64
-----------------------------------------------------------------------------------------
| end of epoch  12 | time per epoch: 994.44s |
| Train Metrics | accuracy:  0.56 | loss:  1.64
| Eval  Metrics | accuracy:  0.68 | loss:  1.07
-----------------------------------------------------------------------------------------
[2025-02-25 21:29:17,377][absl][INFO] - Saving checkpoint at step: 14148
[2025-02-25 21:29:17,379][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 21:29:17,379][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 21:29:17,380][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_14148.
[2025-02-25 21:29:17,382][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 21:29:17,383][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_14148.orbax-checkpoint-tmp-11
[2025-02-25 21:29:17,390][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 21:29:17,418][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 21:29:17,449][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 158.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 57 milliseconds) (per-host)
[2025-02-25 21:29:18,041][absl][INFO] - ChainedFuture completed 1/1 futures in 0.59 seconds.
[2025-02-25 21:29:18,041][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 14.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 650 milliseconds) (per-host)
[2025-02-25 21:29:18,048][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 21:29:18,078][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_14148.orbax-checkpoint-tmp-11 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_14148
[2025-02-25 21:29:18,085][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_14148`.
[2025-02-25 21:29:18,085][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 21:29:18,086][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_12969
| epoch 13 | 1000/1179 batches | ms/batch 912.39 | Performance/Training accuracy:  0.57 | Performance/Training loss:  1.61
-----------------------------------------------------------------------------------------
| end of epoch  13 | time per epoch: 1043.87s |
| Train Metrics | accuracy:  0.58 | loss:  1.60
| Eval  Metrics | accuracy:  0.69 | loss:  1.04
-----------------------------------------------------------------------------------------
[2025-02-25 21:48:19,892][absl][INFO] - Saving checkpoint at step: 15327
[2025-02-25 21:48:19,893][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 21:48:19,893][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 21:48:19,894][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_15327.
[2025-02-25 21:48:19,896][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 21:48:19,897][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_15327.orbax-checkpoint-tmp-12
[2025-02-25 21:48:19,907][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 21:48:19,933][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 21:48:19,966][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 155.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 58 milliseconds) (per-host)
[2025-02-25 21:48:20,208][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-25 21:48:20,209][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 300 milliseconds) (per-host)
[2025-02-25 21:48:20,217][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 21:48:20,257][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_15327.orbax-checkpoint-tmp-12 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_15327
[2025-02-25 21:48:20,264][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_15327`.
[2025-02-25 21:48:20,264][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 21:48:20,266][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_14148
| epoch 14 | 1000/1179 batches | ms/batch 776.37 | Performance/Training accuracy:  0.59 | Performance/Training loss:  1.54
-----------------------------------------------------------------------------------------
| end of epoch  14 | time per epoch: 926.25s |
| Train Metrics | accuracy:  0.59 | loss:  1.54
| Eval  Metrics | accuracy:  0.70 | loss:  1.00
-----------------------------------------------------------------------------------------
[2025-02-25 22:05:08,881][absl][INFO] - Saving checkpoint at step: 16506
[2025-02-25 22:05:08,882][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 22:05:08,882][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 22:05:08,883][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_16506.
[2025-02-25 22:05:08,885][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 22:05:08,886][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_16506.orbax-checkpoint-tmp-13
[2025-02-25 22:05:08,894][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 22:05:08,920][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 22:05:08,952][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 157.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 58 milliseconds) (per-host)
[2025-02-25 22:05:09,196][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-25 22:05:09,196][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 302 milliseconds) (per-host)
[2025-02-25 22:05:09,203][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 22:05:09,233][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_16506.orbax-checkpoint-tmp-13 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_16506
[2025-02-25 22:05:09,239][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_16506`.
[2025-02-25 22:05:09,239][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 22:05:09,241][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_15327
| epoch 15 | 1000/1179 batches | ms/batch 792.68 | Performance/Training accuracy:  0.59 | Performance/Training loss:  1.55
-----------------------------------------------------------------------------------------
| end of epoch  15 | time per epoch: 938.72s |
| Train Metrics | accuracy:  0.59 | loss:  1.56
| Eval  Metrics | accuracy:  0.70 | loss:  1.01
-----------------------------------------------------------------------------------------
[2025-02-25 22:22:17,987][absl][INFO] - Saving checkpoint at step: 17685
[2025-02-25 22:22:17,989][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 22:22:17,989][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 22:22:17,990][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_17685.
[2025-02-25 22:22:17,992][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 22:22:17,993][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_17685.orbax-checkpoint-tmp-14
[2025-02-25 22:22:18,001][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 22:22:18,029][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 22:22:18,050][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 187.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 48 milliseconds) (per-host)
[2025-02-25 22:22:18,307][absl][INFO] - ChainedFuture completed 1/1 futures in 0.25 seconds.
[2025-02-25 22:22:18,308][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 29.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 305 milliseconds) (per-host)
[2025-02-25 22:22:18,314][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 22:22:18,345][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_17685.orbax-checkpoint-tmp-14 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_17685
[2025-02-25 22:22:18,357][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_17685`.
[2025-02-25 22:22:18,358][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 22:22:18,359][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_16506
| epoch 16 | 1000/1179 batches | ms/batch 788.29 | Performance/Training accuracy:  0.60 | Performance/Training loss:  1.54
-----------------------------------------------------------------------------------------
| end of epoch  16 | time per epoch: 936.30s |
| Train Metrics | accuracy:  0.60 | loss:  1.54
| Eval  Metrics | accuracy:  0.72 | loss:  0.98
-----------------------------------------------------------------------------------------
[2025-02-25 22:39:52,592][absl][INFO] - Saving checkpoint at step: 18864
[2025-02-25 22:39:52,593][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 22:39:52,593][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 22:39:52,594][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_18864.
[2025-02-25 22:39:52,596][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 22:39:52,597][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_18864.orbax-checkpoint-tmp-15
[2025-02-25 22:39:52,604][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 22:39:52,631][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 22:39:52,682][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 117.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 77 milliseconds) (per-host)
[2025-02-25 22:39:52,905][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-25 22:39:52,906][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 300 milliseconds) (per-host)
[2025-02-25 22:39:52,911][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 22:39:52,943][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_18864.orbax-checkpoint-tmp-15 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_18864
[2025-02-25 22:39:52,949][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_18864`.
[2025-02-25 22:39:52,949][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 22:39:52,950][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_17685
| epoch 17 | 1000/1179 batches | ms/batch 875.78 | Performance/Training accuracy:  0.60 | Performance/Training loss:  1.51
-----------------------------------------------------------------------------------------
| end of epoch  17 | time per epoch: 1021.52s |
| Train Metrics | accuracy:  0.61 | loss:  1.50
| Eval  Metrics | accuracy:  0.72 | loss:  0.93
-----------------------------------------------------------------------------------------
[2025-02-25 22:58:38,881][absl][INFO] - Saving checkpoint at step: 20043
[2025-02-25 22:58:38,882][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 22:58:38,882][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 22:58:38,883][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_20043.
[2025-02-25 22:58:38,885][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 22:58:38,886][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_20043.orbax-checkpoint-tmp-16
[2025-02-25 22:58:38,892][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 22:58:38,919][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 22:58:38,953][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 151.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 60 milliseconds) (per-host)
[2025-02-25 22:58:39,170][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-25 22:58:39,170][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 277 milliseconds) (per-host)
[2025-02-25 22:58:39,179][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 22:58:39,211][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_20043.orbax-checkpoint-tmp-16 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_20043
[2025-02-25 22:58:39,218][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_20043`.
[2025-02-25 22:58:39,218][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 22:58:39,220][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_18864
| epoch 18 | 1000/1179 batches | ms/batch 931.19 | Performance/Training accuracy:  0.61 | Performance/Training loss:  1.47
-----------------------------------------------------------------------------------------
| end of epoch  18 | time per epoch: 1081.28s |
| Train Metrics | accuracy:  0.61 | loss:  1.48
| Eval  Metrics | accuracy:  0.72 | loss:  0.93
-----------------------------------------------------------------------------------------
| epoch 19 | 1000/1179 batches | ms/batch 773.11 | Performance/Training accuracy:  0.61 | Performance/Training loss:  1.49
-----------------------------------------------------------------------------------------
| end of epoch  19 | time per epoch: 898.97s |
| Train Metrics | accuracy:  0.62 | loss:  1.48
| Eval  Metrics | accuracy:  0.71 | loss:  0.96
-----------------------------------------------------------------------------------------
| epoch 20 | 1000/1179 batches | ms/batch 837.27 | Performance/Training accuracy:  0.61 | Performance/Training loss:  1.51
-----------------------------------------------------------------------------------------
| end of epoch  20 | time per epoch: 975.48s |
| Train Metrics | accuracy:  0.61 | loss:  1.50
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.03061981499195099,
    "std": 0.32810041308403015,
    "var": 0.10764987766742706,
    "min": -0.5048486590385437,
    "max": 0.720811665058136,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.5066410303115845,
    "std": 0.11987441033124924,
    "var": 0.014369875192642212,
    "min": 0.26971766352653503,
    "max": 1.022810935974121,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.00029997696401551366,
    "std": 0.09314897656440735,
    "var": 0.008676731958985329,
    "min": -0.3050087094306946,
    "max": 0.2826231122016907,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.21135416626930237,
    "std": 0.1418088674545288,
    "var": 0.02010975405573845,
    "min": -0.08678402751684189,
    "max": 0.6456807255744934,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.5687664151191711,
    "std": 0.18496905267238617,
    "var": 0.03421355038881302,
    "min": 0.12355613708496094,
    "max": 1.1636016368865967,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0002916304802056402,
    "std": 0.09138434380292892,
    "var": 0.008351098746061325,
    "min": -0.34128496050834656,
    "max": 0.2739260494709015,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.21125781536102295,
    "std": 0.15289901196956635,
    "var": 0.02337810769677162,
    "min": -0.08191324025392532,
    "max": 0.6780506372451782,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.47254371643066406,
    "std": 0.20859764516353607,
    "var": 0.0435129813849926,
    "min": 0.08617573976516724,
    "max": 1.128735899925232,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0012830288615077734,
    "std": 0.09245739877223969,
    "var": 0.008548370562493801,
    "min": -0.296038955450058,
    "max": 0.28455328941345215,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.13931553065776825,
    "std": 0.1285984069108963,
    "var": 0.01653755083680153,
    "min": -0.11599695682525635,
    "max": 0.5682041645050049,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.7164379358291626,
    "std": 0.22311843931674957,
    "var": 0.04978184029459953,
    "min": 0.19086594879627228,
    "max": 1.4665559530258179,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0003144379588775337,
    "std": 0.06362584978342056,
    "var": 0.004048248752951622,
    "min": -0.22487597167491913,
    "max": 0.2338893860578537,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.12115459144115448,
    "std": 0.15338116884231567,
    "var": 0.02352578192949295,
    "min": -0.28284507989883423,
    "max": 0.6139953136444092,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.9174653887748718,
    "std": 0.26729026436805725,
    "var": 0.07144409418106079,
    "min": 0.25617891550064087,
    "max": 1.9665803909301758,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 9.096116991713643e-05,
    "std": 0.060745641589164734,
    "var": 0.0036900329869240522,
    "min": -0.21442686021327972,
    "max": 0.22708533704280853,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.01160459965467453,
    "std": 0.08687886595726013,
    "var": 0.0075479368679225445,
    "min": -0.32853108644485474,
    "max": 0.24592606723308563,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.0719337463378906,
    "std": 0.2675109803676605,
    "var": 0.07156212627887726,
    "min": 0.6021958589553833,
    "max": 2.2415435314178467,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00040443544276058674,
    "std": 0.06421804428100586,
    "var": 0.004123957362025976,
    "min": -0.2189415544271469,
    "max": 0.2226373255252838,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": 0.0014893593033775687,
    "std": 0.10523629933595657,
    "var": 0.011074678972363472,
    "min": -0.48283571004867554,
    "max": 0.4951969385147095,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0012036970583721995,
    "std": 0.10341199487447739,
    "var": 0.010694040916860104,
    "min": -0.48469072580337524,
    "max": 0.3971380591392517,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0004031265852972865,
    "std": 0.10691114515066147,
    "var": 0.011429993435740471,
    "min": -0.4464035928249359,
    "max": 0.4650721549987793,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": 0.0003980813780799508,
    "std": 0.09523024410009384,
    "var": 0.009068799205124378,
    "min": -0.5675713419914246,
    "max": 0.5856605172157288,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0009255489567294717,
    "std": 0.09393512457609177,
    "var": 0.008823808282613754,
    "min": -0.4736047089099884,
    "max": 0.5535637140274048,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0010846757795661688,
    "std": 0.09751693159341812,
    "var": 0.009509552270174026,
    "min": -0.5311344265937805,
    "max": 0.560693085193634,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3345624804496765,
    "std": 0.11278543621301651,
    "var": 0.012720555067062378,
    "min": -0.7534103393554688,
    "max": -0.026253173127770424,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.0553264394402504,
    "std": 0.20724785327911377,
    "var": 0.04295167326927185,
    "min": -0.9778832793235779,
    "max": 0.8222149610519409,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.4569801092147827,
    "std": 0.8594319820404053,
    "var": 0.738623321056366,
    "min": -1.6767501831054688,
    "max": 2.853626251220703,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.287731409072876,
    "std": 0.09028781205415726,
    "var": 0.008151888847351074,
    "min": -0.5277376770973206,
    "max": -0.07968650758266449,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.1461857259273529,
    "std": 0.12366971373558044,
    "var": 0.015294198878109455,
    "min": -0.6344142556190491,
    "max": 0.26330259442329407,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.6609914302825928,
    "std": 0.6529272794723511,
    "var": 0.4263140559196472,
    "min": -0.7150828242301941,
    "max": 2.3915059566497803,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.3275950253009796,
    "std": 0.08188820630311966,
    "var": 0.006705678068101406,
    "min": -0.4952124357223511,
    "max": -0.08717017620801926,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.13428837060928345,
    "std": 0.13246122002601624,
    "var": 0.017545975744724274,
    "min": -0.6728686690330505,
    "max": 0.3443185091018677,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.4849950671195984,
    "std": 0.5779449343681335,
    "var": 0.33402037620544434,
    "min": -0.5684927105903625,
    "max": 2.116018533706665,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.1171363890171051,
    "std": 0.07956872135400772,
    "var": 0.006331180687993765,
    "min": -0.3477247953414917,
    "max": 0.06690942496061325,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.0855647623538971,
    "std": 0.13032421469688416,
    "var": 0.016984399408102036,
    "min": -0.784389078617096,
    "max": 0.3999648690223694,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0035935374908149242,
    "std": 0.016568878665566444,
    "var": 0.0002745277597568929,
    "min": -0.04465196281671524,
    "max": 0.035187605768442154,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.0008868369041010737,
    "std": 0.093417689204216,
    "var": 0.00872686505317688,
    "min": -0.5774040818214417,
    "max": 0.5579642057418823,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.033660639077425,
    "std": 0.2699972689151764,
    "var": 0.07289852201938629,
    "min": -1.5279295444488525,
    "max": 1.371842622756958,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.16055648028850555,
    "std": 0.09519180655479431,
    "var": 0.009061479941010475,
    "min": -0.4422801434993744,
    "max": 0.1195286214351654,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.06727331131696701,
    "std": 0.1389143466949463,
    "var": 0.019297197461128235,
    "min": -1.025924563407898,
    "max": 0.5697906613349915,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.0034234202466905117,
    "std": 1.0167748928070068,
    "var": 1.0338313579559326,
    "min": -2.4525041580200195,
    "max": 2.0920238494873047,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.033399488776922226,
    "std": 0.09302925318479538,
    "var": 0.008654441684484482,
    "min": -0.3422028720378876,
    "max": 0.1890699714422226,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.03791820630431175,
    "std": 0.14242438971996307,
    "var": 0.020284706726670265,
    "min": -0.9759740829467773,
    "max": 0.5736228227615356,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.34967154264450073,
    "std": 0.927753746509552,
    "var": 0.8607270121574402,
    "min": -2.4606738090515137,
    "max": 2.684497356414795,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.011522926390171051,
    "std": 0.07829786837100983,
    "var": 0.00613055657595396,
    "min": -0.17730677127838135,
    "max": 0.11981367319822311,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0019907443784177303,
    "std": 0.1508120745420456,
    "var": 0.022744284942746162,
    "min": -0.7705813646316528,
    "max": 0.6185457706451416,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.00687185674905777,
    "std": 0.24763265252113342,
    "var": 0.0613219328224659,
    "min": -1.3367502689361572,
    "max": 1.2331629991531372,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -2.191434860229492,
    "std": 0.6345493793487549,
    "var": 0.40265291929244995,
    "min": -3.4785244464874268,
    "max": -0.43032127618789673,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.9746265411376953,
    "std": 0.6759910583496094,
    "var": 0.4569639265537262,
    "min": -3.4523916244506836,
    "max": -0.6663115620613098,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -2.166840076446533,
    "std": 0.6346222758293152,
    "var": 0.40274548530578613,
    "min": -3.5552473068237305,
    "max": -0.8080845475196838,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -2.2419118881225586,
    "std": 0.6382649540901184,
    "var": 0.40738219022750854,
    "min": -3.8089563846588135,
    "max": -0.6584899425506592,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -2.374207019805908,
    "std": 0.638435423374176,
    "var": 0.4075997769832611,
    "min": -3.6205053329467773,
    "max": -0.6539254188537598,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -2.3231968879699707,
    "std": 0.5883557796478271,
    "var": 0.3461625576019287,
    "min": -3.385958671569824,
    "max": -1.0142405033111572,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.72 | loss:  0.94
-----------------------------------------------------------------------------------------
[2025-02-25 23:52:20,592][absl][INFO] - Saving checkpoint at step: 23580
[2025-02-25 23:52:20,593][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-25 23:52:20,593][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-25 23:52:20,595][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_23580.
[2025-02-25 23:52:20,597][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-25 23:52:20,598][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_23580.orbax-checkpoint-tmp-17
[2025-02-25 23:52:20,604][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-25 23:52:20,631][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-25 23:52:20,664][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 156.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 58 milliseconds) (per-host)
[2025-02-25 23:52:20,901][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-25 23:52:20,901][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 295 milliseconds) (per-host)
[2025-02-25 23:52:20,906][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-25 23:52:20,937][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_23580.orbax-checkpoint-tmp-17 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_23580
[2025-02-25 23:52:20,943][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_23580`.
[2025-02-25 23:52:20,943][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-25 23:52:20,945][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_20043
| epoch 21 | 1000/1179 batches | ms/batch 892.23 | Performance/Training accuracy:  0.63 | Performance/Training loss:  1.43
-----------------------------------------------------------------------------------------
| end of epoch  21 | time per epoch: 1020.41s |
| Train Metrics | accuracy:  0.62 | loss:  1.44
| Eval  Metrics | accuracy:  0.73 | loss:  0.95
-----------------------------------------------------------------------------------------
[2025-02-26 00:11:13,179][absl][INFO] - Saving checkpoint at step: 24759
[2025-02-26 00:11:13,180][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 00:11:13,180][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 00:11:13,182][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_24759.
[2025-02-26 00:11:13,184][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 00:11:13,185][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_24759.orbax-checkpoint-tmp-18
[2025-02-26 00:11:13,200][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 00:11:13,226][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 00:11:13,257][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 162.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 56 milliseconds) (per-host)
[2025-02-26 00:11:13,821][absl][INFO] - ChainedFuture completed 1/1 futures in 0.56 seconds.
[2025-02-26 00:11:13,821][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 14.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 619 milliseconds) (per-host)
[2025-02-26 00:11:13,827][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 00:11:13,860][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_24759.orbax-checkpoint-tmp-18 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_24759
[2025-02-26 00:11:13,866][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_24759`.
[2025-02-26 00:11:13,866][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 00:11:13,868][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_23580
| epoch 22 | 1000/1179 batches | ms/batch 910.24 | Performance/Training accuracy:  0.63 | Performance/Training loss:  1.40
-----------------------------------------------------------------------------------------
| end of epoch  22 | time per epoch: 1088.92s |
| Train Metrics | accuracy:  0.63 | loss:  1.41
| Eval  Metrics | accuracy:  0.75 | loss:  0.84
-----------------------------------------------------------------------------------------
[2025-02-26 00:31:23,375][absl][INFO] - Saving checkpoint at step: 25938
[2025-02-26 00:31:23,377][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 00:31:23,377][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 00:31:23,378][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_25938.
[2025-02-26 00:31:23,380][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 00:31:23,381][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_25938.orbax-checkpoint-tmp-19
[2025-02-26 00:31:23,388][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 00:31:23,415][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 00:31:23,449][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 151.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 60 milliseconds) (per-host)
[2025-02-26 00:31:23,696][absl][INFO] - ChainedFuture completed 1/1 futures in 0.25 seconds.
[2025-02-26 00:31:23,697][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 29.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 307 milliseconds) (per-host)
[2025-02-26 00:31:23,702][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 00:31:23,754][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_25938.orbax-checkpoint-tmp-19 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_25938
[2025-02-26 00:31:23,761][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_25938`.
[2025-02-26 00:31:23,761][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 00:31:23,762][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_24759
| epoch 23 | 1000/1179 batches | ms/batch 785.38 | Performance/Training accuracy:  0.63 | Performance/Training loss:  1.42
-----------------------------------------------------------------------------------------
| end of epoch  23 | time per epoch: 943.35s |
| Train Metrics | accuracy:  0.63 | loss:  1.42
| Eval  Metrics | accuracy:  0.75 | loss:  0.83
-----------------------------------------------------------------------------------------
[2025-02-26 00:48:25,145][absl][INFO] - Saving checkpoint at step: 27117
[2025-02-26 00:48:25,146][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 00:48:25,146][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 00:48:25,147][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_27117.
[2025-02-26 00:48:25,149][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 00:48:25,150][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_27117.orbax-checkpoint-tmp-20
[2025-02-26 00:48:25,157][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 00:48:25,184][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 00:48:25,222][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 142.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 63 milliseconds) (per-host)
[2025-02-26 00:48:25,479][absl][INFO] - ChainedFuture completed 1/1 futures in 0.26 seconds.
[2025-02-26 00:48:25,480][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 28.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 321 milliseconds) (per-host)
[2025-02-26 00:48:25,486][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 00:48:25,517][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_27117.orbax-checkpoint-tmp-20 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_27117
[2025-02-26 00:48:25,524][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_27117`.
[2025-02-26 00:48:25,524][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 00:48:25,526][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_25938
| epoch 24 | 1000/1179 batches | ms/batch 845.60 | Performance/Training accuracy:  0.64 | Performance/Training loss:  1.41
-----------------------------------------------------------------------------------------
| end of epoch  24 | time per epoch: 1045.38s |
| Train Metrics | accuracy:  0.64 | loss:  1.41
| Eval  Metrics | accuracy:  0.75 | loss:  0.82
-----------------------------------------------------------------------------------------
[2025-02-26 01:07:12,944][absl][INFO] - Saving checkpoint at step: 28296
[2025-02-26 01:07:12,945][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 01:07:12,946][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 01:07:12,947][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_28296.
[2025-02-26 01:07:12,949][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 01:07:12,950][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_28296.orbax-checkpoint-tmp-21
[2025-02-26 01:07:12,957][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 01:07:12,983][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 01:07:13,018][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 151.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 60 milliseconds) (per-host)
[2025-02-26 01:07:13,236][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-26 01:07:13,236][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 278 milliseconds) (per-host)
[2025-02-26 01:07:13,242][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 01:07:13,273][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_28296.orbax-checkpoint-tmp-21 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_28296
[2025-02-26 01:07:13,279][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_28296`.
[2025-02-26 01:07:13,279][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 01:07:13,280][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_27117
| epoch 25 | 1000/1179 batches | ms/batch 805.31 | Performance/Training accuracy:  0.64 | Performance/Training loss:  1.39
-----------------------------------------------------------------------------------------
| end of epoch  25 | time per epoch: 949.90s |
| Train Metrics | accuracy:  0.64 | loss:  1.38
| Eval  Metrics | accuracy:  0.76 | loss:  0.82
-----------------------------------------------------------------------------------------
[2025-02-26 01:24:07,263][absl][INFO] - Saving checkpoint at step: 29475
[2025-02-26 01:24:07,264][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 01:24:07,264][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 01:24:07,265][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_29475.
[2025-02-26 01:24:07,267][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 01:24:07,268][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_29475.orbax-checkpoint-tmp-22
[2025-02-26 01:24:07,275][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 01:24:07,301][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 01:24:07,333][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 157.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 57 milliseconds) (per-host)
[2025-02-26 01:24:07,552][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-26 01:24:07,553][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 277 milliseconds) (per-host)
[2025-02-26 01:24:07,563][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 01:24:07,595][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_29475.orbax-checkpoint-tmp-22 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_29475
[2025-02-26 01:24:07,602][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_29475`.
[2025-02-26 01:24:07,602][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 01:24:07,603][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_28296
| epoch 26 | 1000/1179 batches | ms/batch 806.02 | Performance/Training accuracy:  0.65 | Performance/Training loss:  1.36
-----------------------------------------------------------------------------------------
| end of epoch  26 | time per epoch: 940.88s |
| Train Metrics | accuracy:  0.65 | loss:  1.36
| Eval  Metrics | accuracy:  0.75 | loss:  0.87
-----------------------------------------------------------------------------------------
| epoch 27 | 1000/1179 batches | ms/batch 728.74 | Performance/Training accuracy:  0.65 | Performance/Training loss:  1.37
-----------------------------------------------------------------------------------------
| end of epoch  27 | time per epoch: 882.77s |
| Train Metrics | accuracy:  0.65 | loss:  1.38
| Eval  Metrics | accuracy:  0.76 | loss:  0.82
-----------------------------------------------------------------------------------------
[2025-02-26 01:57:49,264][absl][INFO] - Saving checkpoint at step: 31833
[2025-02-26 01:57:49,265][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 01:57:49,265][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 01:57:49,266][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_31833.
[2025-02-26 01:57:49,276][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 01:57:49,277][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_31833.orbax-checkpoint-tmp-23
[2025-02-26 01:57:49,284][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 01:57:49,310][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 01:57:49,343][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 154.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 59 milliseconds) (per-host)
[2025-02-26 01:57:49,564][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-26 01:57:49,564][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 279 milliseconds) (per-host)
[2025-02-26 01:57:49,571][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 01:57:49,602][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_31833.orbax-checkpoint-tmp-23 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_31833
[2025-02-26 01:57:49,608][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_31833`.
[2025-02-26 01:57:49,609][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 01:57:49,610][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_29475
| epoch 28 | 1000/1179 batches | ms/batch 842.47 | Performance/Training accuracy:  0.66 | Performance/Training loss:  1.35
-----------------------------------------------------------------------------------------
| end of epoch  28 | time per epoch: 992.90s |
| Train Metrics | accuracy:  0.65 | loss:  1.36
| Eval  Metrics | accuracy:  0.76 | loss:  0.84
-----------------------------------------------------------------------------------------
| epoch 29 | 1000/1179 batches | ms/batch 800.96 | Performance/Training accuracy:  0.65 | Performance/Training loss:  1.38
-----------------------------------------------------------------------------------------
| end of epoch  29 | time per epoch: 948.70s |
| Train Metrics | accuracy:  0.65 | loss:  1.38
| Eval  Metrics | accuracy:  0.76 | loss:  0.83
-----------------------------------------------------------------------------------------
[2025-02-26 02:33:05,275][absl][INFO] - Saving checkpoint at step: 34191
[2025-02-26 02:33:05,276][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 02:33:05,277][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 02:33:05,278][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_34191.
[2025-02-26 02:33:05,280][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 02:33:05,281][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_34191.orbax-checkpoint-tmp-24
[2025-02-26 02:33:05,290][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 02:33:05,317][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 02:33:05,354][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 143.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 63 milliseconds) (per-host)
[2025-02-26 02:33:05,569][absl][INFO] - ChainedFuture completed 1/1 futures in 0.21 seconds.
[2025-02-26 02:33:05,569][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 278 milliseconds) (per-host)
[2025-02-26 02:33:05,575][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 02:33:05,605][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_34191.orbax-checkpoint-tmp-24 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_34191
[2025-02-26 02:33:05,611][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_34191`.
[2025-02-26 02:33:05,611][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 02:33:05,612][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_31833
| epoch 30 | 1000/1179 batches | ms/batch 880.63 | Performance/Training accuracy:  0.66 | Performance/Training loss:  1.34
-----------------------------------------------------------------------------------------
| end of epoch  30 | time per epoch: 1022.00s |
| Train Metrics | accuracy:  0.66 | loss:  1.34
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.07082977890968323,
    "std": 0.2808583974838257,
    "var": 0.07888143509626389,
    "min": -0.3502483069896698,
    "max": 0.6404810547828674,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.32848235964775085,
    "std": 0.11718814820051193,
    "var": 0.013733062893152237,
    "min": 0.14440520107746124,
    "max": 0.8849089741706848,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.00028010920505039394,
    "std": 0.09765483438968658,
    "var": 0.00953646656125784,
    "min": -0.36707520484924316,
    "max": 0.33553358912467957,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.25557130575180054,
    "std": 0.18384619057178497,
    "var": 0.0337994247674942,
    "min": -0.043557051569223404,
    "max": 0.6963942646980286,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.4293147027492523,
    "std": 0.19325324892997742,
    "var": 0.037346821278333664,
    "min": 0.04130767285823822,
    "max": 1.2795307636260986,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 3.833649680018425e-05,
    "std": 0.09679263830184937,
    "var": 0.009368814527988434,
    "min": -0.38487866520881653,
    "max": 0.32201674580574036,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2610169053077698,
    "std": 0.20028753578662872,
    "var": 0.04011509567499161,
    "min": -0.023953422904014587,
    "max": 0.7871613502502441,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.38268062472343445,
    "std": 0.22556625306606293,
    "var": 0.05088013410568237,
    "min": 0.05772674083709717,
    "max": 1.3362469673156738,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0008026704890653491,
    "std": 0.09816085547208786,
    "var": 0.009635552763938904,
    "min": -0.39394164085388184,
    "max": 0.37326565384864807,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.15753772854804993,
    "std": 0.17604540288448334,
    "var": 0.030991986393928528,
    "min": -0.17921262979507446,
    "max": 0.7712724804878235,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6265631914138794,
    "std": 0.24256238341331482,
    "var": 0.05883651226758957,
    "min": 0.07983995974063873,
    "max": 1.4785258769989014,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.00016368390060961246,
    "std": 0.06478054076433182,
    "var": 0.00419651810079813,
    "min": -0.33207786083221436,
    "max": 0.3319739103317261,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.13757334649562836,
    "std": 0.20576368272304535,
    "var": 0.042338691651821136,
    "min": -0.41861358284950256,
    "max": 0.8374055027961731,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.789573073387146,
    "std": 0.2787899076938629,
    "var": 0.07772380858659744,
    "min": 0.11774292588233948,
    "max": 2.0677030086517334,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00015098886797204614,
    "std": 0.06013384461402893,
    "var": 0.0036160792224109173,
    "min": -0.28444018959999084,
    "max": 0.3151152729988098,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.019194580614566803,
    "std": 0.09594685584306717,
    "var": 0.009205798618495464,
    "min": -0.5452495813369751,
    "max": 0.19284506142139435,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.9936606287956238,
    "std": 0.25838103890419006,
    "var": 0.06676076352596283,
    "min": 0.4855037033557892,
    "max": 2.2188034057617188,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.000524266972206533,
    "std": 0.0678870752453804,
    "var": 0.004608655348420143,
    "min": -0.30817458033561707,
    "max": 0.31225353479385376,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": 0.001899121212773025,
    "std": 0.11541847884654999,
    "var": 0.013321424834430218,
    "min": -0.5524186491966248,
    "max": 0.6183230876922607,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.002316058613359928,
    "std": 0.12032719701528549,
    "var": 0.014478634111583233,
    "min": -0.5255435109138489,
    "max": 0.5055714249610901,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0011863326653838158,
    "std": 0.12267713993787766,
    "var": 0.015049681067466736,
    "min": -0.6333374977111816,
    "max": 0.6406072378158569,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": 0.0004618372768163681,
    "std": 0.10758377611637115,
    "var": 0.011574268341064453,
    "min": -0.7116824984550476,
    "max": 0.8370176553726196,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00015945301856845617,
    "std": 0.10616089403629303,
    "var": 0.011270135641098022,
    "min": -0.615276038646698,
    "max": 0.7723025679588318,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.001183953951112926,
    "std": 0.11298508942127228,
    "var": 0.012765630148351192,
    "min": -0.6096879243850708,
    "max": 0.6261243224143982,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.45761018991470337,
    "std": 0.1650265008211136,
    "var": 0.027233747765421867,
    "min": -0.9022972583770752,
    "max": -0.07511186599731445,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.06808658689260483,
    "std": 0.2905043959617615,
    "var": 0.08439280837774277,
    "min": -1.168757677078247,
    "max": 1.156023383140564,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.7574273347854614,
    "std": 0.9207228422164917,
    "var": 0.8477305769920349,
    "min": -1.3667775392532349,
    "max": 3.51823353767395,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.3122042119503021,
    "std": 0.11728660017251968,
    "var": 0.01375614758580923,
    "min": -0.6408969759941101,
    "max": -0.046247128397226334,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.17287413775920868,
    "std": 0.1620468646287918,
    "var": 0.02625918574631214,
    "min": -0.915279746055603,
    "max": 0.354806512594223,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.0514044761657715,
    "std": 0.8503955006599426,
    "var": 0.7231725454330444,
    "min": -0.556526243686676,
    "max": 4.044229030609131,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.3375406861305237,
    "std": 0.12579113245010376,
    "var": 0.01582340896129608,
    "min": -0.5674771666526794,
    "max": -0.02311418391764164,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.1532105654478073,
    "std": 0.17854659259319305,
    "var": 0.031878888607025146,
    "min": -1.1551313400268555,
    "max": 0.5596321821212769,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.7229388952255249,
    "std": 0.7267419099807739,
    "var": 0.5281537771224976,
    "min": -0.5588609576225281,
    "max": 3.1026222705841064,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.11711111664772034,
    "std": 0.08370667695999146,
    "var": 0.0070068081840872765,
    "min": -0.3824334740638733,
    "max": 0.054503604769706726,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.09367644041776657,
    "std": 0.15433569252490997,
    "var": 0.02381950616836548,
    "min": -0.9730539321899414,
    "max": 0.42237600684165955,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0015080049633979797,
    "std": 0.010401208885014057,
    "var": 0.00010818515147548169,
    "min": -0.030300477519631386,
    "max": 0.030015069991350174,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": 7.990282028913498e-06,
    "std": 0.11029812693595886,
    "var": 0.012165676802396774,
    "min": -0.7569419741630554,
    "max": 0.7647939324378967,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.041288524866104126,
    "std": 0.3486422300338745,
    "var": 0.12155140936374664,
    "min": -1.8865734338760376,
    "max": 1.6085634231567383,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.17727017402648926,
    "std": 0.10802394151687622,
    "var": 0.01166917197406292,
    "min": -0.4840725362300873,
    "max": 0.1117914617061615,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07756946235895157,
    "std": 0.15912644565105438,
    "var": 0.025321222841739655,
    "min": -1.256041169166565,
    "max": 0.6135067343711853,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.06522275507450104,
    "std": 1.0851231813430786,
    "var": 1.1774922609329224,
    "min": -2.689429998397827,
    "max": 2.3816256523132324,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.006573257967829704,
    "std": 0.12085284292697906,
    "var": 0.014605410397052765,
    "min": -0.3445993661880493,
    "max": 0.26214510202407837,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.04487495869398117,
    "std": 0.16208724677562714,
    "var": 0.026272276416420937,
    "min": -1.1482584476470947,
    "max": 0.5962249040603638,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.4083254337310791,
    "std": 0.859078049659729,
    "var": 0.7380151748657227,
    "min": -2.5145328044891357,
    "max": 2.358461618423462,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.013248438015580177,
    "std": 0.08761002123355865,
    "var": 0.007675515953451395,
    "min": -0.2090424746274948,
    "max": 0.1486017107963562,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0021937137935310602,
    "std": 0.1873668134212494,
    "var": 0.03510632365942001,
    "min": -0.8564310669898987,
    "max": 0.7683585286140442,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.005811734590679407,
    "std": 0.2967697083950043,
    "var": 0.0880722627043724,
    "min": -1.5740424394607544,
    "max": 1.612385869026184,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.3763788938522339,
    "std": 0.5488681197166443,
    "var": 0.3012562394142151,
    "min": -2.78678560256958,
    "max": 0.11266658455133438,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.2582919597625732,
    "std": 0.5898417830467224,
    "var": 0.34791332483291626,
    "min": -2.796553373336792,
    "max": -0.1513526737689972,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.4284332990646362,
    "std": 0.6191040277481079,
    "var": 0.38328981399536133,
    "min": -3.159529685974121,
    "max": -0.21692553162574768,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.7133835554122925,
    "std": 0.5802332758903503,
    "var": 0.3366706967353821,
    "min": -3.313689708709717,
    "max": -0.13664278388023376,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.7861180305480957,
    "std": 0.5223572254180908,
    "var": 0.27285706996917725,
    "min": -3.225297212600708,
    "max": -0.20803211629390717,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.8113677501678467,
    "std": 0.5895511507987976,
    "var": 0.34757059812545776,
    "min": -3.047093391418457,
    "max": -0.5431051254272461,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.77 | loss:  0.79
-----------------------------------------------------------------------------------------
[2025-02-26 02:51:55,267][absl][INFO] - Saving checkpoint at step: 35370
[2025-02-26 02:51:55,269][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 02:51:55,269][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 02:51:55,270][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_35370.
[2025-02-26 02:51:55,272][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 02:51:55,273][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_35370.orbax-checkpoint-tmp-25
[2025-02-26 02:51:55,282][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 02:51:55,308][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 02:51:55,341][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 154.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 58 milliseconds) (per-host)
[2025-02-26 02:51:55,581][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-26 02:51:55,581][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 298 milliseconds) (per-host)
[2025-02-26 02:51:55,588][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 02:51:55,621][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_35370.orbax-checkpoint-tmp-25 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_35370
[2025-02-26 02:51:55,627][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_35370`.
[2025-02-26 02:51:55,627][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 02:51:55,629][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_34191
| epoch 31 | 1000/1179 batches | ms/batch 851.24 | Performance/Training accuracy:  0.66 | Performance/Training loss:  1.35
-----------------------------------------------------------------------------------------
| end of epoch  31 | time per epoch: 1008.86s |
| Train Metrics | accuracy:  0.66 | loss:  1.35
| Eval  Metrics | accuracy:  0.75 | loss:  0.83
-----------------------------------------------------------------------------------------
| epoch 32 | 1000/1179 batches | ms/batch 750.49 | Performance/Training accuracy:  0.66 | Performance/Training loss:  1.33
-----------------------------------------------------------------------------------------
| end of epoch  32 | time per epoch: 904.15s |
| Train Metrics | accuracy:  0.66 | loss:  1.33
| Eval  Metrics | accuracy:  0.76 | loss:  0.82
-----------------------------------------------------------------------------------------
| epoch 33 | 1000/1179 batches | ms/batch 761.85 | Performance/Training accuracy:  0.66 | Performance/Training loss:  1.32
-----------------------------------------------------------------------------------------
| end of epoch  33 | time per epoch: 923.22s |
| Train Metrics | accuracy:  0.67 | loss:  1.31
| Eval  Metrics | accuracy:  0.77 | loss:  0.77
-----------------------------------------------------------------------------------------
| epoch 34 | 1000/1179 batches | ms/batch 831.71 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.29
-----------------------------------------------------------------------------------------
| end of epoch  34 | time per epoch: 1008.71s |
| Train Metrics | accuracy:  0.67 | loss:  1.29
| Eval  Metrics | accuracy:  0.77 | loss:  0.79
-----------------------------------------------------------------------------------------
| epoch 35 | 1000/1179 batches | ms/batch 892.15 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.31
-----------------------------------------------------------------------------------------
| end of epoch  35 | time per epoch: 1039.35s |
| Train Metrics | accuracy:  0.66 | loss:  1.32
| Eval  Metrics | accuracy:  0.76 | loss:  0.85
-----------------------------------------------------------------------------------------
| epoch 36 | 1000/1179 batches | ms/batch 816.08 | Performance/Training accuracy:  0.66 | Performance/Training loss:  1.31
-----------------------------------------------------------------------------------------
| end of epoch  36 | time per epoch: 949.87s |
| Train Metrics | accuracy:  0.67 | loss:  1.30
| Eval  Metrics | accuracy:  0.77 | loss:  0.81
-----------------------------------------------------------------------------------------
| epoch 37 | 1000/1179 batches | ms/batch 792.02 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.31
-----------------------------------------------------------------------------------------
| end of epoch  37 | time per epoch: 923.73s |
| Train Metrics | accuracy:  0.66 | loss:  1.32
| Eval  Metrics | accuracy:  0.78 | loss:  0.77
-----------------------------------------------------------------------------------------
[2025-02-26 04:56:16,076][absl][INFO] - Saving checkpoint at step: 43623
[2025-02-26 04:56:16,078][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 04:56:16,078][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 04:56:16,079][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_43623.
[2025-02-26 04:56:16,082][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 04:56:16,083][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_43623.orbax-checkpoint-tmp-26
[2025-02-26 04:56:16,091][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 04:56:16,532][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 04:56:16,561][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 19.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 469 milliseconds) (per-host)
[2025-02-26 04:56:16,786][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-26 04:56:16,787][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 13.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 695 milliseconds) (per-host)
[2025-02-26 04:56:16,793][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 04:56:16,826][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_43623.orbax-checkpoint-tmp-26 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_43623
[2025-02-26 04:56:16,833][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_43623`.
[2025-02-26 04:56:16,833][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 04:56:16,834][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_35370
| epoch 38 | 1000/1179 batches | ms/batch 773.04 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.28
-----------------------------------------------------------------------------------------
| end of epoch  38 | time per epoch: 944.63s |
| Train Metrics | accuracy:  0.67 | loss:  1.29
| Eval  Metrics | accuracy:  0.77 | loss:  0.76
-----------------------------------------------------------------------------------------
| epoch 39 | 1000/1179 batches | ms/batch 866.43 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.27
-----------------------------------------------------------------------------------------
| end of epoch  39 | time per epoch: 990.39s |
| Train Metrics | accuracy:  0.67 | loss:  1.28
| Eval  Metrics | accuracy:  0.78 | loss:  0.79
-----------------------------------------------------------------------------------------
| epoch 40 | 1000/1179 batches | ms/batch 845.17 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.29
-----------------------------------------------------------------------------------------
| end of epoch  40 | time per epoch: 987.17s |
| Train Metrics | accuracy:  0.67 | loss:  1.28
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.10900132358074188,
    "std": 0.2556819021701813,
    "var": 0.0653732419013977,
    "min": -0.2628113627433777,
    "max": 0.8802440166473389,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.27914193272590637,
    "std": 0.12421030551195145,
    "var": 0.015428200364112854,
    "min": 0.10300818085670471,
    "max": 0.79264897108078,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -7.472699508070946e-06,
    "std": 0.10161475092172623,
    "var": 0.010325557552278042,
    "min": -0.4528134763240814,
    "max": 0.3940190076828003,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.2455195188522339,
    "std": 0.17999441921710968,
    "var": 0.03239799290895462,
    "min": -0.052047595381736755,
    "max": 0.8411653637886047,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.37707018852233887,
    "std": 0.19503702223300934,
    "var": 0.0380394384264946,
    "min": 0.06700050085783005,
    "max": 1.318170428276062,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 3.288942389190197e-05,
    "std": 0.10177435725927353,
    "var": 0.010358019731938839,
    "min": -0.3953438103199005,
    "max": 0.3550707697868347,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.25268086791038513,
    "std": 0.19566968083381653,
    "var": 0.03828662633895874,
    "min": -0.03786642849445343,
    "max": 0.7815310955047607,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.381160706281662,
    "std": 0.24505026638507843,
    "var": 0.0600496344268322,
    "min": 0.05597482621669769,
    "max": 1.4545300006866455,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.000352341216057539,
    "std": 0.10297207534313202,
    "var": 0.010603247210383415,
    "min": -0.4896852970123291,
    "max": 0.4863913357257843,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.15078121423721313,
    "std": 0.2006731927394867,
    "var": 0.04026972874999046,
    "min": -0.32160940766334534,
    "max": 0.9079018831253052,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6175017356872559,
    "std": 0.24225562810897827,
    "var": 0.058687787503004074,
    "min": 0.09741239249706268,
    "max": 1.565941572189331,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0005509617039933801,
    "std": 0.06472685933113098,
    "var": 0.004189566243439913,
    "min": -0.42920586466789246,
    "max": 0.42605817317962646,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.14129382371902466,
    "std": 0.23079754412174225,
    "var": 0.05326750874519348,
    "min": -0.4445333778858185,
    "max": 1.023584246635437,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.7424895167350769,
    "std": 0.2730303704738617,
    "var": 0.07454559206962585,
    "min": 0.14853402972221375,
    "max": 1.9369665384292603,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00016648029850330204,
    "std": 0.06002349779009819,
    "var": 0.0036028202157467604,
    "min": -0.36217591166496277,
    "max": 0.3525196313858032,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.031918372958898544,
    "std": 0.10034959018230438,
    "var": 0.01007003989070654,
    "min": -0.6423275470733643,
    "max": 0.21120941638946533,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.9956731796264648,
    "std": 0.252983033657074,
    "var": 0.06400041282176971,
    "min": 0.5412308573722839,
    "max": 2.2154173851013184,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0005158616113476455,
    "std": 0.07184397429227829,
    "var": 0.005161557346582413,
    "min": -0.39762648940086365,
    "max": 0.38023442029953003,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": 0.000886370602529496,
    "std": 0.1167425811290741,
    "var": 0.013628831133246422,
    "min": -0.631931722164154,
    "max": 0.7573599219322205,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0014200611039996147,
    "std": 0.12295182794332504,
    "var": 0.015117151662707329,
    "min": -0.5503751635551453,
    "max": 0.5968176126480103,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0013066364917904139,
    "std": 0.12287089973688126,
    "var": 0.015097258612513542,
    "min": -0.687261700630188,
    "max": 0.7012724876403809,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": 0.0004251080099493265,
    "std": 0.10359793156385422,
    "var": 0.010732531547546387,
    "min": -0.7170121669769287,
    "max": 0.85074383020401,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0005551268113777041,
    "std": 0.10545673221349716,
    "var": 0.011121122166514397,
    "min": -0.6900429725646973,
    "max": 0.9532032012939453,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0007591204484924674,
    "std": 0.11467015743255615,
    "var": 0.013149244710803032,
    "min": -0.6939929723739624,
    "max": 0.7121071219444275,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.475583016872406,
    "std": 0.1617455780506134,
    "var": 0.02616163343191147,
    "min": -0.8341884613037109,
    "max": -0.08471677452325821,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07115837186574936,
    "std": 0.3189912736415863,
    "var": 0.10175543278455734,
    "min": -1.2830655574798584,
    "max": 1.3499895334243774,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.9157158732414246,
    "std": 0.9919010996818542,
    "var": 0.9838678240776062,
    "min": -1.5698347091674805,
    "max": 3.959469795227051,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.3120986521244049,
    "std": 0.13362905383110046,
    "var": 0.017856724560260773,
    "min": -0.572773277759552,
    "max": 0.0278975497931242,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.18430045247077942,
    "std": 0.19096842408180237,
    "var": 0.03646894171833992,
    "min": -1.0928473472595215,
    "max": 0.6535516381263733,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.1597509384155273,
    "std": 1.0081202983856201,
    "var": 1.0163066387176514,
    "min": -0.8129652142524719,
    "max": 4.2688446044921875,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.3084888458251953,
    "std": 0.1492352932691574,
    "var": 0.02227117493748665,
    "min": -0.6682984828948975,
    "max": 0.02944866567850113,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.16432258486747742,
    "std": 0.2074509710073471,
    "var": 0.04303590953350067,
    "min": -1.3232953548431396,
    "max": 0.6760277152061462,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.8157288432121277,
    "std": 0.8468844890594482,
    "var": 0.7172133326530457,
    "min": -0.5962933897972107,
    "max": 3.2235145568847656,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.11182263493537903,
    "std": 0.09159106016159058,
    "var": 0.008388921618461609,
    "min": -0.42274951934814453,
    "max": 0.09202568978071213,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.09341684728860855,
    "std": 0.16517245769500732,
    "var": 0.02728193998336792,
    "min": -0.9844892024993896,
    "max": 0.5047928690910339,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0015737991780042648,
    "std": 0.008983056992292404,
    "var": 8.069531759247184e-05,
    "min": -0.030020834878087044,
    "max": 0.021887416020035744,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.000576090591493994,
    "std": 0.11060235649347305,
    "var": 0.012232881970703602,
    "min": -0.7335883975028992,
    "max": 0.8274470567703247,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.030255159363150597,
    "std": 0.37856683135032654,
    "var": 0.14331284165382385,
    "min": -2.581672430038452,
    "max": 2.040208578109741,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.17186999320983887,
    "std": 0.1129763126373291,
    "var": 0.012763647362589836,
    "min": -0.4907609224319458,
    "max": 0.09634888917207718,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07689535617828369,
    "std": 0.16666662693023682,
    "var": 0.027777764946222305,
    "min": -1.334737777709961,
    "max": 0.6110243201255798,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.10942154377698898,
    "std": 1.091832160949707,
    "var": 1.192097544670105,
    "min": -3.0001299381256104,
    "max": 2.583770275115967,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.008554732427001,
    "std": 0.13144728541374207,
    "var": 0.017278388142585754,
    "min": -0.3671109676361084,
    "max": 0.31419065594673157,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.046974413096904755,
    "std": 0.16771039366722107,
    "var": 0.028126776218414307,
    "min": -1.0374265909194946,
    "max": 0.6149662733078003,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.399783194065094,
    "std": 0.7991361021995544,
    "var": 0.6386184692382812,
    "min": -2.314027786254883,
    "max": 2.4836959838867188,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.013282389380037785,
    "std": 0.08699832856655121,
    "var": 0.007568709552288055,
    "min": -0.1932772547006607,
    "max": 0.14398272335529327,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0022393933031708,
    "std": 0.19967277348041534,
    "var": 0.039869219064712524,
    "min": -0.8045499324798584,
    "max": 0.8203296661376953,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.0040678707882761955,
    "std": 0.30557551980018616,
    "var": 0.09337639808654785,
    "min": -1.5424052476882935,
    "max": 1.8224843740463257,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.9676823616027832,
    "std": 0.49899110198020935,
    "var": 0.24899211525917053,
    "min": -2.3157176971435547,
    "max": 0.3398281931877136,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.9565714597702026,
    "std": 0.5426585674285889,
    "var": 0.2944783568382263,
    "min": -2.580263137817383,
    "max": 0.01922461949288845,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.1387789249420166,
    "std": 0.581177830696106,
    "var": 0.33776769042015076,
    "min": -2.9223499298095703,
    "max": 0.03315265476703644,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.4975157976150513,
    "std": 0.5332249402999878,
    "var": 0.284328818321228,
    "min": -3.2714128494262695,
    "max": 0.002504992764443159,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.5355455875396729,
    "std": 0.4733528792858124,
    "var": 0.2240629494190216,
    "min": -2.937370777130127,
    "max": -0.017142612487077713,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.591638445854187,
    "std": 0.6007835268974304,
    "var": 0.3609408736228943,
    "min": -2.918983221054077,
    "max": -0.3421992063522339,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.78 | loss:  0.75
-----------------------------------------------------------------------------------------
[2025-02-26 05:48:49,112][absl][INFO] - Saving checkpoint at step: 47160
[2025-02-26 05:48:49,113][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 05:48:49,113][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 05:48:49,115][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_47160.
[2025-02-26 05:48:49,117][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 05:48:49,118][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_47160.orbax-checkpoint-tmp-27
[2025-02-26 05:48:49,125][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 05:48:49,152][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 05:48:49,186][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 152.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 59 milliseconds) (per-host)
[2025-02-26 05:48:49,420][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-26 05:48:49,420][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 294 milliseconds) (per-host)
[2025-02-26 05:48:49,426][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 05:48:49,456][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_47160.orbax-checkpoint-tmp-27 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_47160
[2025-02-26 05:48:49,463][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_47160`.
[2025-02-26 05:48:49,463][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 05:48:49,464][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_43623
| epoch 41 | 1000/1179 batches | ms/batch 777.64 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.28
-----------------------------------------------------------------------------------------
| end of epoch  41 | time per epoch: 929.65s |
| Train Metrics | accuracy:  0.67 | loss:  1.28
| Eval  Metrics | accuracy:  0.76 | loss:  0.78
-----------------------------------------------------------------------------------------
| epoch 42 | 1000/1179 batches | ms/batch 795.76 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.27
-----------------------------------------------------------------------------------------
| end of epoch  42 | time per epoch: 944.48s |
| Train Metrics | accuracy:  0.68 | loss:  1.27
| Eval  Metrics | accuracy:  0.77 | loss:  0.78
-----------------------------------------------------------------------------------------
| epoch 43 | 1000/1179 batches | ms/batch 854.77 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.24
-----------------------------------------------------------------------------------------
| end of epoch  43 | time per epoch: 1003.03s |
| Train Metrics | accuracy:  0.68 | loss:  1.24
| Eval  Metrics | accuracy:  0.77 | loss:  0.79
-----------------------------------------------------------------------------------------
| epoch 44 | 1000/1179 batches | ms/batch 814.20 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.26
-----------------------------------------------------------------------------------------
| end of epoch  44 | time per epoch: 948.12s |
| Train Metrics | accuracy:  0.68 | loss:  1.26
| Eval  Metrics | accuracy:  0.79 | loss:  0.74
-----------------------------------------------------------------------------------------
[2025-02-26 06:58:39,931][absl][INFO] - Saving checkpoint at step: 51876
[2025-02-26 06:58:39,933][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 06:58:39,933][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 06:58:39,935][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_51876.
[2025-02-26 06:58:39,938][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 06:58:39,939][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_51876.orbax-checkpoint-tmp-28
[2025-02-26 06:58:39,948][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 06:58:39,975][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 06:58:40,009][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 151.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 60 milliseconds) (per-host)
[2025-02-26 06:58:40,232][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-26 06:58:40,232][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 283 milliseconds) (per-host)
[2025-02-26 06:58:40,238][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 06:58:40,269][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_51876.orbax-checkpoint-tmp-28 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_51876
[2025-02-26 06:58:40,275][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_51876`.
[2025-02-26 06:58:40,275][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 06:58:40,277][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_47160
| epoch 45 | 1000/1179 batches | ms/batch 860.62 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.24
-----------------------------------------------------------------------------------------
| end of epoch  45 | time per epoch: 1041.00s |
| Train Metrics | accuracy:  0.68 | loss:  1.25
| Eval  Metrics | accuracy:  0.79 | loss:  0.75
-----------------------------------------------------------------------------------------
| epoch 46 | 1000/1179 batches | ms/batch 810.15 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.28
-----------------------------------------------------------------------------------------
| end of epoch  46 | time per epoch: 992.65s |
| Train Metrics | accuracy:  0.68 | loss:  1.27
| Eval  Metrics | accuracy:  0.77 | loss:  0.80
-----------------------------------------------------------------------------------------
| epoch 47 | 1000/1179 batches | ms/batch 849.96 | Performance/Training accuracy:  0.67 | Performance/Training loss:  1.29
-----------------------------------------------------------------------------------------
| end of epoch  47 | time per epoch: 952.11s |
| Train Metrics | accuracy:  0.68 | loss:  1.28
| Eval  Metrics | accuracy:  0.78 | loss:  0.76
-----------------------------------------------------------------------------------------
| epoch 48 | 1000/1179 batches | ms/batch 678.37 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.23
-----------------------------------------------------------------------------------------
| end of epoch  48 | time per epoch: 814.35s |
| Train Metrics | accuracy:  0.69 | loss:  1.24
| Eval  Metrics | accuracy:  0.79 | loss:  0.75
-----------------------------------------------------------------------------------------
| epoch 49 | 1000/1179 batches | ms/batch 799.29 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.22
-----------------------------------------------------------------------------------------
| end of epoch  49 | time per epoch: 932.71s |
| Train Metrics | accuracy:  0.69 | loss:  1.22
| Eval  Metrics | accuracy:  0.79 | loss:  0.72
-----------------------------------------------------------------------------------------
[2025-02-26 08:24:37,980][absl][INFO] - Saving checkpoint at step: 57771
[2025-02-26 08:24:37,981][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 08:24:37,981][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 08:24:37,983][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_57771.
[2025-02-26 08:24:37,985][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 08:24:37,986][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_57771.orbax-checkpoint-tmp-29
[2025-02-26 08:24:37,993][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 08:24:38,020][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 08:24:38,042][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 190.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 47 milliseconds) (per-host)
[2025-02-26 08:24:38,338][absl][INFO] - ChainedFuture completed 1/1 futures in 0.29 seconds.
[2025-02-26 08:24:38,338][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 26.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 344 milliseconds) (per-host)
[2025-02-26 08:24:38,345][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 08:24:38,377][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_57771.orbax-checkpoint-tmp-29 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_57771
[2025-02-26 08:24:38,384][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_57771`.
[2025-02-26 08:24:38,384][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 08:24:38,386][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_51876
| epoch 50 | 1000/1179 batches | ms/batch 838.71 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.26
-----------------------------------------------------------------------------------------
| end of epoch  50 | time per epoch: 977.95s |
| Train Metrics | accuracy:  0.68 | loss:  1.25
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.15051615238189697,
    "std": 0.27236464619636536,
    "var": 0.07418250292539597,
    "min": -0.2573660910129547,
    "max": 0.9051361083984375,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.2683965861797333,
    "std": 0.1346762478351593,
    "var": 0.018137693405151367,
    "min": 0.05420283228158951,
    "max": 0.7535098195075989,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.00019700065604411066,
    "std": 0.10475153475999832,
    "var": 0.010972883552312851,
    "min": -0.5473386645317078,
    "max": 0.4513162076473236,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.23776398599147797,
    "std": 0.1765100657939911,
    "var": 0.031155802309513092,
    "min": -0.05722280219197273,
    "max": 0.8839360475540161,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.3597812056541443,
    "std": 0.20852994918823242,
    "var": 0.04348473995923996,
    "min": 0.06754170358181,
    "max": 1.268969178199768,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 3.690167795866728e-05,
    "std": 0.10632283985614777,
    "var": 0.011304546147584915,
    "min": -0.4795182943344116,
    "max": 0.38050177693367004,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2562529444694519,
    "std": 0.18807436525821686,
    "var": 0.035371970385313034,
    "min": -0.036388929933309555,
    "max": 0.8399609923362732,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.38593387603759766,
    "std": 0.2778834402561188,
    "var": 0.07721921056509018,
    "min": 0.06998105347156525,
    "max": 1.6704825162887573,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00045877939555794,
    "std": 0.10689003020524979,
    "var": 0.011425478383898735,
    "min": -0.5605683922767639,
    "max": 0.5456534028053284,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.1528901606798172,
    "std": 0.21289394795894623,
    "var": 0.04532383009791374,
    "min": -0.2959441840648651,
    "max": 0.999326765537262,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6347745060920715,
    "std": 0.2512471675872803,
    "var": 0.06312514841556549,
    "min": 0.06919007003307343,
    "max": 1.8811603784561157,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.000749991915654391,
    "std": 0.06347431987524033,
    "var": 0.0040289899334311485,
    "min": -0.5115723013877869,
    "max": 0.5513108372688293,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.1421276032924652,
    "std": 0.24237340688705444,
    "var": 0.058744870126247406,
    "min": -0.48405373096466064,
    "max": 1.058760166168213,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.7151063680648804,
    "std": 0.2712664008140564,
    "var": 0.07358546555042267,
    "min": 0.15344460308551788,
    "max": 1.8412429094314575,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0001258114934898913,
    "std": 0.05986069142818451,
    "var": 0.0035833022557199,
    "min": -0.425567090511322,
    "max": 0.3544462323188782,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.04619435966014862,
    "std": 0.10244937241077423,
    "var": 0.010495874099433422,
    "min": -0.6084619760513306,
    "max": 0.2369878590106964,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.0192210674285889,
    "std": 0.25283700227737427,
    "var": 0.06392654776573181,
    "min": 0.5155943036079407,
    "max": 2.2494354248046875,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0004791265237145126,
    "std": 0.07535986602306366,
    "var": 0.005679109133780003,
    "min": -0.46809038519859314,
    "max": 0.41275179386138916,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -5.9379672165960073e-05,
    "std": 0.11397708207368851,
    "var": 0.012990775518119335,
    "min": -0.5994707345962524,
    "max": 0.7116366028785706,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0010431780247017741,
    "std": 0.12065700441598892,
    "var": 0.014558114111423492,
    "min": -0.5678125023841858,
    "max": 0.6631236672401428,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.000707255385350436,
    "std": 0.11890897899866104,
    "var": 0.014139345847070217,
    "min": -0.7867454290390015,
    "max": 0.8191710710525513,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": 7.63900316087529e-05,
    "std": 0.09640268236398697,
    "var": 0.009293477982282639,
    "min": -0.7572311758995056,
    "max": 0.8690050840377808,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0003575567970983684,
    "std": 0.10197386890649796,
    "var": 0.01039867103099823,
    "min": -0.7223232388496399,
    "max": 0.8180603981018066,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0006301387911662459,
    "std": 0.11230428516864777,
    "var": 0.012612253427505493,
    "min": -0.6998882293701172,
    "max": 0.6826865077018738,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.46326857805252075,
    "std": 0.15284611284732819,
    "var": 0.023361936211586,
    "min": -0.8269649147987366,
    "max": -0.11629367619752884,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07448112964630127,
    "std": 0.32192814350128174,
    "var": 0.10363773256540298,
    "min": -1.354594111442566,
    "max": 1.508047342300415,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.9769588708877563,
    "std": 1.042880654335022,
    "var": 1.0875999927520752,
    "min": -1.609992265701294,
    "max": 4.044459819793701,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.316535085439682,
    "std": 0.14235633611679077,
    "var": 0.020265327766537666,
    "min": -0.5918261408805847,
    "max": 0.056475672870874405,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.1955447942018509,
    "std": 0.2071855217218399,
    "var": 0.042925842106342316,
    "min": -1.3289071321487427,
    "max": 0.6228070855140686,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.1708672046661377,
    "std": 1.0631582736968994,
    "var": 1.130305528640747,
    "min": -1.2293643951416016,
    "max": 4.126297950744629,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.29840296506881714,
    "std": 0.15956367552280426,
    "var": 0.02546056918799877,
    "min": -0.6701852679252625,
    "max": 0.08630448579788208,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.17386041581630707,
    "std": 0.22110669314861298,
    "var": 0.04888817295432091,
    "min": -1.5485444068908691,
    "max": 0.7971518039703369,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.8702329397201538,
    "std": 0.8951348066329956,
    "var": 0.8012663722038269,
    "min": -0.773668110370636,
    "max": 3.35733962059021,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.11333340406417847,
    "std": 0.09785106778144836,
    "var": 0.009574832394719124,
    "min": -0.4345085024833679,
    "max": 0.11468536406755447,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.09256958216428757,
    "std": 0.16862793266773224,
    "var": 0.02843537926673889,
    "min": -1.1086597442626953,
    "max": 0.5856558084487915,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0013436500448733568,
    "std": 0.006876918487250805,
    "var": 4.729200736619532e-05,
    "min": -0.023165710270404816,
    "max": 0.01978417858481407,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.0003457974235061556,
    "std": 0.11072985827922821,
    "var": 0.01226110104471445,
    "min": -0.8448970317840576,
    "max": 0.784603476524353,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.025887910276651382,
    "std": 0.3852904140949249,
    "var": 0.14844870567321777,
    "min": -3.6401004791259766,
    "max": 2.42215633392334,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.16869410872459412,
    "std": 0.11281342059373856,
    "var": 0.012726868502795696,
    "min": -0.5113863348960876,
    "max": 0.13915963470935822,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07775191217660904,
    "std": 0.16800764203071594,
    "var": 0.028226571157574654,
    "min": -1.2611868381500244,
    "max": 0.6484647989273071,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.14433354139328003,
    "std": 1.0727430582046509,
    "var": 1.1507775783538818,
    "min": -2.983280897140503,
    "max": 2.586761236190796,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.021824052557349205,
    "std": 0.13578306138515472,
    "var": 0.018437039107084274,
    "min": -0.41010206937789917,
    "max": 0.3228309452533722,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.047492966055870056,
    "std": 0.16694141924381256,
    "var": 0.027869436889886856,
    "min": -1.0018130540847778,
    "max": 0.5568975806236267,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.3991479277610779,
    "std": 0.7534807324409485,
    "var": 0.5677332282066345,
    "min": -2.168301820755005,
    "max": 2.42866849899292,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.012650185264647007,
    "std": 0.08211726695299149,
    "var": 0.006743245292454958,
    "min": -0.1936212033033371,
    "max": 0.11745213717222214,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.002458942588418722,
    "std": 0.2062520831823349,
    "var": 0.04253992438316345,
    "min": -0.9468263387680054,
    "max": 0.9336579442024231,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.004776144400238991,
    "std": 0.3009047210216522,
    "var": 0.09054365009069443,
    "min": -1.3339118957519531,
    "max": 1.8537015914916992,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.7241002917289734,
    "std": 0.49153175950050354,
    "var": 0.24160346388816833,
    "min": -1.9356485605239868,
    "max": 0.4941299855709076,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.7777937054634094,
    "std": 0.5025149583816528,
    "var": 0.2525213062763214,
    "min": -2.2919514179229736,
    "max": 0.23794375360012054,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.956618070602417,
    "std": 0.5465375781059265,
    "var": 0.2987033426761627,
    "min": -2.7476038932800293,
    "max": 0.19459863007068634,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.4056657552719116,
    "std": 0.5005272030830383,
    "var": 0.2505274713039398,
    "min": -3.2148547172546387,
    "max": 0.059666719287633896,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.4107904434204102,
    "std": 0.4459645748138428,
    "var": 0.19888439774513245,
    "min": -2.724696636199951,
    "max": 0.0443706288933754,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.458038568496704,
    "std": 0.6056278944015503,
    "var": 0.3667851686477661,
    "min": -2.8812472820281982,
    "max": -0.13662494719028473,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.78 | loss:  0.76
-----------------------------------------------------------------------------------------
| epoch 51 | 1000/1179 batches | ms/batch 792.22 | Performance/Training accuracy:  0.68 | Performance/Training loss:  1.25
-----------------------------------------------------------------------------------------
| end of epoch  51 | time per epoch: 930.30s |
| Train Metrics | accuracy:  0.69 | loss:  1.24
| Eval  Metrics | accuracy:  0.78 | loss:  0.75
-----------------------------------------------------------------------------------------
| epoch 52 | 1000/1179 batches | ms/batch 832.03 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.22
-----------------------------------------------------------------------------------------
| end of epoch  52 | time per epoch: 987.39s |
| Train Metrics | accuracy:  0.69 | loss:  1.22
| Eval  Metrics | accuracy:  0.78 | loss:  0.76
-----------------------------------------------------------------------------------------
| epoch 53 | 1000/1179 batches | ms/batch 708.83 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.20
-----------------------------------------------------------------------------------------
| end of epoch  53 | time per epoch: 840.64s |
| Train Metrics | accuracy:  0.69 | loss:  1.20
| Eval  Metrics | accuracy:  0.79 | loss:  0.71
-----------------------------------------------------------------------------------------
[2025-02-26 09:32:04,859][absl][INFO] - Saving checkpoint at step: 62487
[2025-02-26 09:32:04,861][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 09:32:04,861][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 09:32:04,862][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_62487.
[2025-02-26 09:32:04,865][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 09:32:04,867][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_62487.orbax-checkpoint-tmp-30
[2025-02-26 09:32:04,874][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 09:32:04,901][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 09:32:04,933][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 156.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 58 milliseconds) (per-host)
[2025-02-26 09:32:05,186][absl][INFO] - ChainedFuture completed 1/1 futures in 0.25 seconds.
[2025-02-26 09:32:05,186][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 29.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 310 milliseconds) (per-host)
[2025-02-26 09:32:05,192][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 09:32:05,227][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_62487.orbax-checkpoint-tmp-30 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_62487
[2025-02-26 09:32:05,236][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_62487`.
[2025-02-26 09:32:05,236][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 09:32:05,238][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_57771
| epoch 54 | 1000/1179 batches | ms/batch 810.71 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.22
-----------------------------------------------------------------------------------------
| end of epoch  54 | time per epoch: 977.82s |
| Train Metrics | accuracy:  0.69 | loss:  1.22
| Eval  Metrics | accuracy:  0.80 | loss:  0.67
-----------------------------------------------------------------------------------------
[2025-02-26 09:49:40,295][absl][INFO] - Saving checkpoint at step: 63666
[2025-02-26 09:49:40,296][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 09:49:40,296][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 09:49:40,297][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_63666.
[2025-02-26 09:49:40,300][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 09:49:40,301][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_63666.orbax-checkpoint-tmp-31
[2025-02-26 09:49:40,308][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 09:49:40,335][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 09:49:40,361][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 174.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 52 milliseconds) (per-host)
[2025-02-26 09:49:40,653][absl][INFO] - ChainedFuture completed 1/1 futures in 0.29 seconds.
[2025-02-26 09:49:40,653][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 26.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 344 milliseconds) (per-host)
[2025-02-26 09:49:40,659][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 09:49:40,690][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_63666.orbax-checkpoint-tmp-31 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_63666
[2025-02-26 09:49:40,696][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_63666`.
[2025-02-26 09:49:40,696][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 09:49:40,697][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_62487
| epoch 55 | 1000/1179 batches | ms/batch 824.15 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.23
-----------------------------------------------------------------------------------------
| end of epoch  55 | time per epoch: 968.57s |
| Train Metrics | accuracy:  0.69 | loss:  1.22
| Eval  Metrics | accuracy:  0.78 | loss:  0.74
-----------------------------------------------------------------------------------------
| epoch 56 | 1000/1179 batches | ms/batch 863.48 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.17
-----------------------------------------------------------------------------------------
| end of epoch  56 | time per epoch: 977.75s |
| Train Metrics | accuracy:  0.70 | loss:  1.18
| Eval  Metrics | accuracy:  0.79 | loss:  0.75
-----------------------------------------------------------------------------------------
| epoch 57 | 1000/1179 batches | ms/batch 723.05 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.24
-----------------------------------------------------------------------------------------
| end of epoch  57 | time per epoch: 889.88s |
| Train Metrics | accuracy:  0.69 | loss:  1.23
| Eval  Metrics | accuracy:  0.79 | loss:  0.73
-----------------------------------------------------------------------------------------
| epoch 58 | 1000/1179 batches | ms/batch 818.11 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.21
-----------------------------------------------------------------------------------------
| end of epoch  58 | time per epoch: 967.97s |
| Train Metrics | accuracy:  0.69 | loss:  1.21
| Eval  Metrics | accuracy:  0.78 | loss:  0.74
-----------------------------------------------------------------------------------------
| epoch 59 | 1000/1179 batches | ms/batch 827.00 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.22
-----------------------------------------------------------------------------------------
| end of epoch  59 | time per epoch: 993.66s |
| Train Metrics | accuracy:  0.69 | loss:  1.22
| Eval  Metrics | accuracy:  0.79 | loss:  0.73
-----------------------------------------------------------------------------------------
| epoch 60 | 1000/1179 batches | ms/batch 915.23 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.22
-----------------------------------------------------------------------------------------
| end of epoch  60 | time per epoch: 1098.56s |
| Train Metrics | accuracy:  0.69 | loss:  1.22
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.17476192116737366,
    "std": 0.2874690294265747,
    "var": 0.0826384425163269,
    "min": -0.21022313833236694,
    "max": 0.92167067527771,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.2824699282646179,
    "std": 0.16685174405574799,
    "var": 0.027839507907629013,
    "min": 0.05523911863565445,
    "max": 0.8573135137557983,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.00024971767561510205,
    "std": 0.10710828006267548,
    "var": 0.011472183279693127,
    "min": -0.5994529128074646,
    "max": 0.5420312881469727,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.23406986892223358,
    "std": 0.18056119978427887,
    "var": 0.03260234370827675,
    "min": -0.0602789930999279,
    "max": 0.922921359539032,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.34865278005599976,
    "std": 0.21402257680892944,
    "var": 0.045805662870407104,
    "min": 0.07774064689874649,
    "max": 1.282623529434204,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00012198451440781355,
    "std": 0.11028876155614853,
    "var": 0.012163612060248852,
    "min": -0.5590553283691406,
    "max": 0.4194640517234802,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2565903663635254,
    "std": 0.17699281871318817,
    "var": 0.03132645785808563,
    "min": -0.09495232999324799,
    "max": 0.8216621279716492,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.39506444334983826,
    "std": 0.3018536865711212,
    "var": 0.09111564606428146,
    "min": 0.08322569727897644,
    "max": 1.8375790119171143,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0004842476628255099,
    "std": 0.1101359948515892,
    "var": 0.01212993822991848,
    "min": -0.6121717691421509,
    "max": 0.5962982773780823,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.15346954762935638,
    "std": 0.21989697217941284,
    "var": 0.048354677855968475,
    "min": -0.3536272644996643,
    "max": 0.998708188533783,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6407139301300049,
    "std": 0.2530355751514435,
    "var": 0.06402699649333954,
    "min": 0.08574002236127853,
    "max": 2.2119789123535156,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0007201064145192504,
    "std": 0.06147697940468788,
    "var": 0.003779419232159853,
    "min": -0.5750120282173157,
    "max": 0.6502519249916077,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.1449788510799408,
    "std": 0.2523706257343292,
    "var": 0.06369093060493469,
    "min": -0.4704902172088623,
    "max": 1.1030309200286865,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.7012250423431396,
    "std": 0.26195311546325684,
    "var": 0.06861944496631622,
    "min": 0.1401723325252533,
    "max": 1.6325851678848267,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00022982269001659006,
    "std": 0.05986728519201279,
    "var": 0.003584092017263174,
    "min": -0.4705943465232849,
    "max": 0.4375210404396057,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.05289822816848755,
    "std": 0.10332252085208893,
    "var": 0.010675543919205666,
    "min": -0.5319318771362305,
    "max": 0.22655311226844788,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.040194034576416,
    "std": 0.259408563375473,
    "var": 0.06729279458522797,
    "min": 0.5400176048278809,
    "max": 2.183480739593506,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00036725177778862417,
    "std": 0.0784664899110794,
    "var": 0.006156989838927984,
    "min": -0.5280312895774841,
    "max": 0.4489423632621765,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0001600943214725703,
    "std": 0.11210320889949799,
    "var": 0.012567128986120224,
    "min": -0.5142142176628113,
    "max": 0.642339289188385,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0014367946423590183,
    "std": 0.11729619652032852,
    "var": 0.013758397661149502,
    "min": -0.506051242351532,
    "max": 0.6091892123222351,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0016484204679727554,
    "std": 0.11472728103399277,
    "var": 0.013162348419427872,
    "min": -0.7598766088485718,
    "max": 0.7266262173652649,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0003443563764449209,
    "std": 0.08900652825832367,
    "var": 0.007922162301838398,
    "min": -0.6807101964950562,
    "max": 0.858272135257721,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00019855797290802002,
    "std": 0.09870843589305878,
    "var": 0.009743355214595795,
    "min": -0.6242766976356506,
    "max": 0.6293783783912659,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0007084963726811111,
    "std": 0.10885326564311981,
    "var": 0.011849033646285534,
    "min": -0.6962329745292664,
    "max": 0.7178492546081543,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.4331287741661072,
    "std": 0.13664914667606354,
    "var": 0.018672991544008255,
    "min": -0.7770598530769348,
    "max": -0.15144257247447968,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07759638875722885,
    "std": 0.3118482530117035,
    "var": 0.097249336540699,
    "min": -1.637223482131958,
    "max": 1.4793342351913452,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.9518200755119324,
    "std": 1.0946067571640015,
    "var": 1.1981639862060547,
    "min": -1.7601174116134644,
    "max": 3.7776541709899902,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.32157814502716064,
    "std": 0.14638054370880127,
    "var": 0.02142726257443428,
    "min": -0.6380631923675537,
    "max": 0.08046189695596695,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.20383594930171967,
    "std": 0.2140095978975296,
    "var": 0.0458001084625721,
    "min": -1.476891040802002,
    "max": 0.782250165939331,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.1399509906768799,
    "std": 1.0420351028442383,
    "var": 1.0858371257781982,
    "min": -1.4447553157806396,
    "max": 3.62135648727417,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.28814375400543213,
    "std": 0.16200295090675354,
    "var": 0.026244958862662315,
    "min": -0.6792172789573669,
    "max": 0.08383134752511978,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.18266677856445312,
    "std": 0.22460292279720306,
    "var": 0.05044647678732872,
    "min": -1.7857774496078491,
    "max": 0.7570686936378479,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.8914713859558105,
    "std": 0.8850536942481995,
    "var": 0.7833200693130493,
    "min": -1.025899887084961,
    "max": 3.4960134029388428,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.11314453929662704,
    "std": 0.09763263911008835,
    "var": 0.009532133117318153,
    "min": -0.44650784134864807,
    "max": 0.09534496068954468,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08904051035642624,
    "std": 0.16967670619487762,
    "var": 0.028790183365345,
    "min": -1.1367794275283813,
    "max": 0.5538643598556519,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0007916290778666735,
    "std": 0.007269269786775112,
    "var": 5.284228245727718e-05,
    "min": -0.03235805779695511,
    "max": 0.015221265144646168,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.00015306232671719044,
    "std": 0.10970192402601242,
    "var": 0.012034513056278229,
    "min": -0.8855271339416504,
    "max": 0.7511176466941833,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.0214844923466444,
    "std": 0.37876445055007935,
    "var": 0.14346250891685486,
    "min": -3.707152843475342,
    "max": 2.2395668029785156,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.1660843789577484,
    "std": 0.1075449287891388,
    "var": 0.011565911583602428,
    "min": -0.47406598925590515,
    "max": 0.11665280908346176,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07710208743810654,
    "std": 0.16787593066692352,
    "var": 0.02818232774734497,
    "min": -1.2543048858642578,
    "max": 0.592692494392395,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.16460543870925903,
    "std": 1.0371925830841064,
    "var": 1.0757684707641602,
    "min": -2.8197810649871826,
    "max": 2.4484751224517822,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.027124203741550446,
    "std": 0.1374277025461197,
    "var": 0.018886376172304153,
    "min": -0.3348906636238098,
    "max": 0.36458712816238403,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.0461701899766922,
    "std": 0.16434615850448608,
    "var": 0.027009660378098488,
    "min": -1.0152878761291504,
    "max": 0.5730158090591431,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.4012056291103363,
    "std": 0.6929817795753479,
    "var": 0.48022374510765076,
    "min": -1.9118282794952393,
    "max": 2.197071075439453,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.011560708284378052,
    "std": 0.07650535553693771,
    "var": 0.005853069014847279,
    "min": -0.18353278934955597,
    "max": 0.12268153578042984,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.002845184179022908,
    "std": 0.20949824154376984,
    "var": 0.04388951137661934,
    "min": -0.9013470411300659,
    "max": 0.8114360570907593,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.0044455998577177525,
    "std": 0.29440179467201233,
    "var": 0.08667241781949997,
    "min": -1.2742424011230469,
    "max": 1.7534316778182983,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.5829327702522278,
    "std": 0.4685872495174408,
    "var": 0.21957403421401978,
    "min": -1.5919610261917114,
    "max": 0.5772996544837952,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.6706164479255676,
    "std": 0.4736073911190033,
    "var": 0.2243039458990097,
    "min": -1.9993586540222168,
    "max": 0.34237247705459595,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.8543621897697449,
    "std": 0.5153168439865112,
    "var": 0.26555144786834717,
    "min": -2.623382091522217,
    "max": 0.2746049463748932,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.4031038284301758,
    "std": 0.4954645037651062,
    "var": 0.2454850673675537,
    "min": -3.0966172218322754,
    "max": 0.1311408132314682,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.3263765573501587,
    "std": 0.43453076481819153,
    "var": 0.18881699442863464,
    "min": -2.5257084369659424,
    "max": 0.09160201251506805,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.3672442436218262,
    "std": 0.6016888618469238,
    "var": 0.362029492855072,
    "min": -2.8527421951293945,
    "max": 0.02302207611501217,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.78 | loss:  0.78
-----------------------------------------------------------------------------------------
| epoch 61 | 1000/1179 batches | ms/batch 843.18 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.19
-----------------------------------------------------------------------------------------
| end of epoch  61 | time per epoch: 971.14s |
| Train Metrics | accuracy:  0.70 | loss:  1.19
| Eval  Metrics | accuracy:  0.79 | loss:  0.73
-----------------------------------------------------------------------------------------
| epoch 62 | 1000/1179 batches | ms/batch 852.78 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.22
-----------------------------------------------------------------------------------------
| end of epoch  62 | time per epoch: 985.20s |
| Train Metrics | accuracy:  0.69 | loss:  1.21
| Eval  Metrics | accuracy:  0.80 | loss:  0.71
-----------------------------------------------------------------------------------------
[2025-02-26 12:12:52,563][absl][INFO] - Saving checkpoint at step: 73098
[2025-02-26 12:12:52,565][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 12:12:52,565][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 12:12:52,567][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_73098.
[2025-02-26 12:12:52,569][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 12:12:52,570][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_73098.orbax-checkpoint-tmp-32
[2025-02-26 12:12:52,578][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 12:12:52,604][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 12:12:52,639][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 149.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 60 milliseconds) (per-host)
[2025-02-26 12:12:52,878][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-26 12:12:52,879][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 300 milliseconds) (per-host)
[2025-02-26 12:12:52,885][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 12:12:52,914][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_73098.orbax-checkpoint-tmp-32 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_73098
[2025-02-26 12:12:52,920][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_73098`.
[2025-02-26 12:12:52,920][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 12:12:52,922][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_63666
| epoch 63 | 1000/1179 batches | ms/batch 743.91 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.20
-----------------------------------------------------------------------------------------
| end of epoch  63 | time per epoch: 901.68s |
| Train Metrics | accuracy:  0.70 | loss:  1.19
| Eval  Metrics | accuracy:  0.80 | loss:  0.71
-----------------------------------------------------------------------------------------
| epoch 64 | 1000/1179 batches | ms/batch 846.87 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.23
-----------------------------------------------------------------------------------------
| end of epoch  64 | time per epoch: 1007.84s |
| Train Metrics | accuracy:  0.69 | loss:  1.23
| Eval  Metrics | accuracy:  0.80 | loss:  0.71
-----------------------------------------------------------------------------------------
| epoch 65 | 1000/1179 batches | ms/batch 758.84 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.20
-----------------------------------------------------------------------------------------
| end of epoch  65 | time per epoch: 889.55s |
| Train Metrics | accuracy:  0.70 | loss:  1.21
| Eval  Metrics | accuracy:  0.79 | loss:  0.73
-----------------------------------------------------------------------------------------
| epoch 66 | 1000/1179 batches | ms/batch 716.42 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.22
-----------------------------------------------------------------------------------------
| end of epoch  66 | time per epoch: 862.59s |
| Train Metrics | accuracy:  0.69 | loss:  1.21
| Eval  Metrics | accuracy:  0.79 | loss:  0.74
-----------------------------------------------------------------------------------------
| epoch 67 | 1000/1179 batches | ms/batch 815.93 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.18
-----------------------------------------------------------------------------------------
| end of epoch  67 | time per epoch: 953.09s |
| Train Metrics | accuracy:  0.70 | loss:  1.19
| Eval  Metrics | accuracy:  0.79 | loss:  0.72
-----------------------------------------------------------------------------------------
| epoch 68 | 1000/1179 batches | ms/batch 843.77 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.18
-----------------------------------------------------------------------------------------
| end of epoch  68 | time per epoch: 983.38s |
| Train Metrics | accuracy:  0.70 | loss:  1.19
| Eval  Metrics | accuracy:  0.78 | loss:  0.74
-----------------------------------------------------------------------------------------
| epoch 69 | 1000/1179 batches | ms/batch 876.53 | Performance/Training accuracy:  0.69 | Performance/Training loss:  1.20
-----------------------------------------------------------------------------------------
| end of epoch  69 | time per epoch: 1021.76s |
| Train Metrics | accuracy:  0.69 | loss:  1.20
| Eval  Metrics | accuracy:  0.79 | loss:  0.73
-----------------------------------------------------------------------------------------
| epoch 70 | 1000/1179 batches | ms/batch 872.72 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.18
-----------------------------------------------------------------------------------------
| end of epoch  70 | time per epoch: 1034.75s |
| Train Metrics | accuracy:  0.70 | loss:  1.18
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.20155000686645508,
    "std": 0.3159330189228058,
    "var": 0.09981368482112885,
    "min": -0.20853006839752197,
    "max": 1.017651915550232,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.2758609652519226,
    "std": 0.16496503353118896,
    "var": 0.027213461697101593,
    "min": 0.06060263514518738,
    "max": 0.7779355049133301,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.00039792212191969156,
    "std": 0.10926947742700577,
    "var": 0.01193981897085905,
    "min": -0.6239348649978638,
    "max": 0.6028816103935242,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.23982875049114227,
    "std": 0.1862488090991974,
    "var": 0.03468862175941467,
    "min": -0.057355303317308426,
    "max": 0.929463267326355,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.34471794962882996,
    "std": 0.22741098701953888,
    "var": 0.051715753972530365,
    "min": 0.08129138499498367,
    "max": 1.3249942064285278,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00033069978235289454,
    "std": 0.11382123082876205,
    "var": 0.012955273501574993,
    "min": -0.6109597086906433,
    "max": 0.45703864097595215,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2571398615837097,
    "std": 0.16977249085903168,
    "var": 0.028822701424360275,
    "min": -0.09674358367919922,
    "max": 0.818798303604126,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.3998830318450928,
    "std": 0.3188779056072235,
    "var": 0.1016831323504448,
    "min": 0.06974337995052338,
    "max": 1.880082607269287,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0006758867530152202,
    "std": 0.1131395697593689,
    "var": 0.012800563126802444,
    "min": -0.642839789390564,
    "max": 0.6920531988143921,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.15498140454292297,
    "std": 0.22672563791275024,
    "var": 0.05140451714396477,
    "min": -0.38002583384513855,
    "max": 1.0051158666610718,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6436573266983032,
    "std": 0.25258636474609375,
    "var": 0.06379988044500351,
    "min": 0.07760383188724518,
    "max": 2.2992935180664062,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0006314568454399705,
    "std": 0.05935100466012955,
    "var": 0.0035225420724600554,
    "min": -0.6285204291343689,
    "max": 0.7882251143455505,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.14581298828125,
    "std": 0.24921227991580963,
    "var": 0.06210675835609436,
    "min": -0.47502198815345764,
    "max": 1.0754510164260864,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6964046359062195,
    "std": 0.26396045088768005,
    "var": 0.06967511773109436,
    "min": 0.12686049938201904,
    "max": 1.5530133247375488,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00018907818594016135,
    "std": 0.059738464653491974,
    "var": 0.0035686842165887356,
    "min": -0.5245955586433411,
    "max": 0.46308934688568115,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.05536171421408653,
    "std": 0.10214920341968536,
    "var": 0.010434459894895554,
    "min": -0.5117064118385315,
    "max": 0.24099545180797577,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.0635392665863037,
    "std": 0.2566608786582947,
    "var": 0.06587481498718262,
    "min": 0.5184083580970764,
    "max": 2.1748507022857666,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0004068443668074906,
    "std": 0.08102232962846756,
    "var": 0.006564618553966284,
    "min": -0.5746715664863586,
    "max": 0.5029885768890381,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00027244578814134,
    "std": 0.10746200382709503,
    "var": 0.011548083275556564,
    "min": -0.5053362250328064,
    "max": 0.5614054799079895,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0010051531717181206,
    "std": 0.11318030208349228,
    "var": 0.012809781357645988,
    "min": -0.48061972856521606,
    "max": 0.561237633228302,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.002532403916120529,
    "std": 0.11048634350299835,
    "var": 0.012207232415676117,
    "min": -0.6318805813789368,
    "max": 0.7094040513038635,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00012725716806016862,
    "std": 0.08223307132720947,
    "var": 0.0067622787319123745,
    "min": -0.6083298325538635,
    "max": 0.8372467756271362,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00018863059813156724,
    "std": 0.09461209177970886,
    "var": 0.008951447904109955,
    "min": -0.5107167959213257,
    "max": 0.5734633207321167,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0007407626835629344,
    "std": 0.10457845777273178,
    "var": 0.010936654172837734,
    "min": -0.7284227013587952,
    "max": 0.6298828125,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.4105357527732849,
    "std": 0.12628507614135742,
    "var": 0.015947921201586723,
    "min": -0.7214369773864746,
    "max": -0.1400749236345291,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07764575630426407,
    "std": 0.29795894026756287,
    "var": 0.08877953141927719,
    "min": -1.5153285264968872,
    "max": 1.2938117980957031,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.8707510232925415,
    "std": 1.0873537063598633,
    "var": 1.182337999343872,
    "min": -1.9306772947311401,
    "max": 3.6116714477539062,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.31803756952285767,
    "std": 0.1374696046113968,
    "var": 0.01889789290726185,
    "min": -0.6818035840988159,
    "max": 0.04165515676140785,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.2035428285598755,
    "std": 0.21315115690231323,
    "var": 0.045433420687913895,
    "min": -1.3357681035995483,
    "max": 0.7403590679168701,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.0622490644454956,
    "std": 1.0092912912368774,
    "var": 1.0186688899993896,
    "min": -1.3046759366989136,
    "max": 3.281691312789917,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.28289246559143066,
    "std": 0.15655232965946198,
    "var": 0.024508632719516754,
    "min": -0.644214928150177,
    "max": 0.02918827347457409,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.18855448067188263,
    "std": 0.22407880425453186,
    "var": 0.050211310386657715,
    "min": -1.6839309930801392,
    "max": 0.6979040503501892,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.9203993678092957,
    "std": 0.882215142250061,
    "var": 0.7783036231994629,
    "min": -1.4171364307403564,
    "max": 3.59808611869812,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.11341498792171478,
    "std": 0.09732526540756226,
    "var": 0.009472208097577095,
    "min": -0.4193589687347412,
    "max": 0.1281803697347641,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.087517648935318,
    "std": 0.16826564073562622,
    "var": 0.028313325718045235,
    "min": -1.3984853029251099,
    "max": 0.49057698249816895,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0013653765199705958,
    "std": 0.006636588368564844,
    "var": 4.404430364957079e-05,
    "min": -0.030850401148200035,
    "max": 0.014919531531631947,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.0004588871088344604,
    "std": 0.10835637152194977,
    "var": 0.01174110360443592,
    "min": -0.8939208984375,
    "max": 0.7439538836479187,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.018251949921250343,
    "std": 0.36674803495407104,
    "var": 0.13450410962104797,
    "min": -3.37296462059021,
    "max": 2.0993568897247314,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.16427065432071686,
    "std": 0.0989057719707489,
    "var": 0.009782351553440094,
    "min": -0.4611598253250122,
    "max": 0.08749714493751526,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07523226737976074,
    "std": 0.16660356521606445,
    "var": 0.027756748721003532,
    "min": -1.3323355913162231,
    "max": 0.6556006669998169,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.18024758994579315,
    "std": 1.023030400276184,
    "var": 1.0465911626815796,
    "min": -2.639148473739624,
    "max": 2.456782817840576,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.03929382562637329,
    "std": 0.14057976007461548,
    "var": 0.019762666895985603,
    "min": -0.30935224890708923,
    "max": 0.34404265880584717,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.045370638370513916,
    "std": 0.16145199537277222,
    "var": 0.026066744700074196,
    "min": -1.004435658454895,
    "max": 0.708707869052887,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.39575815200805664,
    "std": 0.6476167440414429,
    "var": 0.4194074869155884,
    "min": -1.804477334022522,
    "max": 2.073518991470337,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.01100192777812481,
    "std": 0.0743752121925354,
    "var": 0.0055316719226539135,
    "min": -0.18997922539710999,
    "max": 0.12968477606773376,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.003326288890093565,
    "std": 0.21108239889144897,
    "var": 0.04455577954649925,
    "min": -0.8928263783454895,
    "max": 0.8370693922042847,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.00555382389575243,
    "std": 0.2895704507827759,
    "var": 0.08385105431079865,
    "min": -1.1691149473190308,
    "max": 1.8474668264389038,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.46084779500961304,
    "std": 0.4397740364074707,
    "var": 0.19340121746063232,
    "min": -1.4113904237747192,
    "max": 0.5965213775634766,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.5588698387145996,
    "std": 0.45355117321014404,
    "var": 0.20570868253707886,
    "min": -1.8178696632385254,
    "max": 0.45516347885131836,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.7764066457748413,
    "std": 0.490476131439209,
    "var": 0.24056684970855713,
    "min": -2.4722139835357666,
    "max": 0.284864604473114,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.45219087600708,
    "std": 0.5148864388465881,
    "var": 0.26510801911354065,
    "min": -3.020432472229004,
    "max": 0.10393473505973816,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.2932978868484497,
    "std": 0.41945767402648926,
    "var": 0.1759447455406189,
    "min": -2.4389595985412598,
    "max": 0.10326090455055237,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.3048678636550903,
    "std": 0.594059944152832,
    "var": 0.3529072105884552,
    "min": -2.861698627471924,
    "max": 0.10433487594127655,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.80 | loss:  0.69
-----------------------------------------------------------------------------------------
[2025-02-26 14:31:11,864][absl][INFO] - Saving checkpoint at step: 82530
[2025-02-26 14:31:11,866][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 14:31:11,866][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 14:31:11,868][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_82530.
[2025-02-26 14:31:11,870][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 14:31:11,871][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_82530.orbax-checkpoint-tmp-33
[2025-02-26 14:31:11,878][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 14:31:12,373][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 14:31:12,404][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 17.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 525 milliseconds) (per-host)
[2025-02-26 14:31:12,636][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-26 14:31:12,636][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 12.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 756 milliseconds) (per-host)
[2025-02-26 14:31:12,642][absl][INFO] - Wrote Metadata={'item_handlers': 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler', 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1740598271874569534, 'commit_timestamp_nsecs': None, 'custom': {}}, json={"item_handlers": "orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler", "metrics": {}, "performance_metrics": {}, "init_timestamp_nsecs": 1740598271874569534, "commit_timestamp_nsecs": null, "custom": {}} to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_82530.orbax-checkpoint-tmp-33/_CHECKPOINT_METADATA
[2025-02-26 14:31:12,642][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 14:31:12,673][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_82530.orbax-checkpoint-tmp-33 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_82530
[2025-02-26 14:31:12,679][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_82530`.
[2025-02-26 14:31:12,679][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 14:31:12,681][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_73098
| epoch 71 | 1000/1179 batches | ms/batch 812.67 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.19
-----------------------------------------------------------------------------------------
| end of epoch  71 | time per epoch: 990.71s |
| Train Metrics | accuracy:  0.70 | loss:  1.19
| Eval  Metrics | accuracy:  0.79 | loss:  0.75
-----------------------------------------------------------------------------------------
| epoch 72 | 1000/1179 batches | ms/batch 742.89 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.15
-----------------------------------------------------------------------------------------
| end of epoch  72 | time per epoch: 898.16s |
| Train Metrics | accuracy:  0.70 | loss:  1.17
| Eval  Metrics | accuracy:  0.80 | loss:  0.71
-----------------------------------------------------------------------------------------
| epoch 73 | 1000/1179 batches | ms/batch 796.84 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.17
-----------------------------------------------------------------------------------------
| end of epoch  73 | time per epoch: 959.00s |
| Train Metrics | accuracy:  0.70 | loss:  1.18
| Eval  Metrics | accuracy:  0.80 | loss:  0.68
-----------------------------------------------------------------------------------------
[2025-02-26 15:22:46,398][absl][INFO] - Saving checkpoint at step: 86067
[2025-02-26 15:22:46,400][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 15:22:46,400][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 15:22:46,401][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_86067.
[2025-02-26 15:22:46,404][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 15:22:46,405][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_86067.orbax-checkpoint-tmp-34
[2025-02-26 15:22:46,413][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 15:22:46,443][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 15:22:46,463][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 184.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 49 milliseconds) (per-host)
[2025-02-26 15:22:46,718][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-26 15:22:46,719][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 29.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 304 milliseconds) (per-host)
[2025-02-26 15:22:46,726][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 15:22:46,759][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_86067.orbax-checkpoint-tmp-34 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_86067
[2025-02-26 15:22:46,765][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_86067`.
[2025-02-26 15:22:46,765][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 15:22:46,767][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_82530
| epoch 74 | 1000/1179 batches | ms/batch 843.52 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.18
-----------------------------------------------------------------------------------------
| end of epoch  74 | time per epoch: 1018.14s |
| Train Metrics | accuracy:  0.70 | loss:  1.19
| Eval  Metrics | accuracy:  0.80 | loss:  0.70
-----------------------------------------------------------------------------------------
[2025-02-26 15:42:03,673][absl][INFO] - Saving checkpoint at step: 87246
[2025-02-26 15:42:03,674][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 15:42:03,674][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 15:42:03,676][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_87246.
[2025-02-26 15:42:03,678][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 15:42:03,679][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_87246.orbax-checkpoint-tmp-35
[2025-02-26 15:42:03,686][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 15:42:03,715][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 15:42:03,749][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 147.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 61 milliseconds) (per-host)
[2025-02-26 15:42:03,991][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-26 15:42:03,991][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 304 milliseconds) (per-host)
[2025-02-26 15:42:03,998][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 15:42:04,033][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_87246.orbax-checkpoint-tmp-35 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_87246
[2025-02-26 15:42:04,040][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_87246`.
[2025-02-26 15:42:04,040][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 15:42:04,041][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_86067
| epoch 75 | 1000/1179 batches | ms/batch 916.74 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.17
-----------------------------------------------------------------------------------------
| end of epoch  75 | time per epoch: 1113.41s |
| Train Metrics | accuracy:  0.70 | loss:  1.17
| Eval  Metrics | accuracy:  0.79 | loss:  0.73
-----------------------------------------------------------------------------------------
| epoch 76 | 1000/1179 batches | ms/batch 930.62 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.17
-----------------------------------------------------------------------------------------
| end of epoch  76 | time per epoch: 1133.58s |
| Train Metrics | accuracy:  0.71 | loss:  1.17
| Eval  Metrics | accuracy:  0.81 | loss:  0.65
-----------------------------------------------------------------------------------------
[2025-02-26 16:23:03,981][absl][INFO] - Saving checkpoint at step: 89604
[2025-02-26 16:23:03,983][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 16:23:03,983][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 16:23:03,985][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_89604.
[2025-02-26 16:23:03,987][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 16:23:03,989][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_89604.orbax-checkpoint-tmp-36
[2025-02-26 16:23:03,997][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 16:23:04,025][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 16:23:04,059][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 148.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 61 milliseconds) (per-host)
[2025-02-26 16:23:04,326][absl][INFO] - ChainedFuture completed 1/1 futures in 0.27 seconds.
[2025-02-26 16:23:04,326][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 27.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 328 milliseconds) (per-host)
[2025-02-26 16:23:04,333][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 16:23:04,369][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_89604.orbax-checkpoint-tmp-36 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_89604
[2025-02-26 16:23:04,379][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_89604`.
[2025-02-26 16:23:04,379][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 16:23:04,381][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_87246
| epoch 77 | 1000/1179 batches | ms/batch 885.28 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.14
-----------------------------------------------------------------------------------------
| end of epoch  77 | time per epoch: 1069.60s |
| Train Metrics | accuracy:  0.71 | loss:  1.14
| Eval  Metrics | accuracy:  0.79 | loss:  0.70
-----------------------------------------------------------------------------------------
| epoch 78 | 1000/1179 batches | ms/batch 976.46 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.15
-----------------------------------------------------------------------------------------
| end of epoch  78 | time per epoch: 1154.80s |
| Train Metrics | accuracy:  0.70 | loss:  1.17
| Eval  Metrics | accuracy:  0.81 | loss:  0.68
-----------------------------------------------------------------------------------------
| epoch 79 | 1000/1179 batches | ms/batch 937.02 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.21
-----------------------------------------------------------------------------------------
| end of epoch  79 | time per epoch: 1102.72s |
| Train Metrics | accuracy:  0.70 | loss:  1.21
| Eval  Metrics | accuracy:  0.81 | loss:  0.65
-----------------------------------------------------------------------------------------
[2025-02-26 17:24:48,934][absl][INFO] - Saving checkpoint at step: 93141
[2025-02-26 17:24:48,935][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 17:24:48,935][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 17:24:48,937][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_93141.
[2025-02-26 17:24:48,939][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 17:24:48,940][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_93141.orbax-checkpoint-tmp-37
[2025-02-26 17:24:48,947][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 17:24:48,974][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 17:24:49,006][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 155.4 MiB/s (total bytes: 9.1 MiB) (time elapsed: 58 milliseconds) (per-host)
[2025-02-26 17:24:49,239][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-26 17:24:49,239][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 291 milliseconds) (per-host)
[2025-02-26 17:24:49,245][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 17:24:49,278][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_93141.orbax-checkpoint-tmp-37 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_93141
[2025-02-26 17:24:49,285][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_93141`.
[2025-02-26 17:24:49,285][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 17:24:49,287][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_89604
| epoch 80 | 1000/1179 batches | ms/batch 886.69 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.17
-----------------------------------------------------------------------------------------
| end of epoch  80 | time per epoch: 1044.98s |
| Train Metrics | accuracy:  0.70 | loss:  1.17
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.22021451592445374,
    "std": 0.3270179331302643,
    "var": 0.10694073140621185,
    "min": -0.2140486091375351,
    "max": 1.0337276458740234,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.28034093976020813,
    "std": 0.17522858083248138,
    "var": 0.030705055221915245,
    "min": 0.04076694697141647,
    "max": 0.7932009100914001,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0004685100575443357,
    "std": 0.11087782680988312,
    "var": 0.012293892912566662,
    "min": -0.6404256820678711,
    "max": 0.6694096326828003,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.24078485369682312,
    "std": 0.19455641508102417,
    "var": 0.037852201610803604,
    "min": -0.0515994057059288,
    "max": 0.9989492297172546,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.35079139471054077,
    "std": 0.24609948694705963,
    "var": 0.06056496128439903,
    "min": 0.07729848474264145,
    "max": 1.2878618240356445,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0005312844295985997,
    "std": 0.11644601821899414,
    "var": 0.013559674844145775,
    "min": -0.6599575281143188,
    "max": 0.49557211995124817,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2573208808898926,
    "std": 0.16132137179374695,
    "var": 0.026024585589766502,
    "min": -0.061864111572504044,
    "max": 0.7676648497581482,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.40496188402175903,
    "std": 0.3334676921367645,
    "var": 0.11120070517063141,
    "min": 0.07756572961807251,
    "max": 2.082977771759033,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0006769417668692768,
    "std": 0.11554984003305435,
    "var": 0.013351766392588615,
    "min": -0.6567559838294983,
    "max": 0.7585965394973755,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.15817081928253174,
    "std": 0.22950442135334015,
    "var": 0.05267227813601494,
    "min": -0.3615911304950714,
    "max": 1.0479401350021362,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6459376811981201,
    "std": 0.2575992941856384,
    "var": 0.06635738909244537,
    "min": 0.0853503942489624,
    "max": 2.426076889038086,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0006520933238789439,
    "std": 0.05718131735920906,
    "var": 0.0032697031274437904,
    "min": -0.6583712697029114,
    "max": 0.8825306296348572,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.14866064488887787,
    "std": 0.2514570355415344,
    "var": 0.06323064863681793,
    "min": -0.4739658236503601,
    "max": 1.0524836778640747,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6869772672653198,
    "std": 0.2604210376739502,
    "var": 0.06781912595033646,
    "min": 0.12362930923700333,
    "max": 1.5671181678771973,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00021947907225694507,
    "std": 0.059617023915052414,
    "var": 0.0035541895776987076,
    "min": -0.5579842329025269,
    "max": 0.4966796040534973,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.05158408731222153,
    "std": 0.1019723191857338,
    "var": 0.01039835438132286,
    "min": -0.5280440449714661,
    "max": 0.2480674535036087,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.0872184038162231,
    "std": 0.2609970271587372,
    "var": 0.06811944395303726,
    "min": 0.6268297433853149,
    "max": 2.191652536392212,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00045639381278306246,
    "std": 0.08313068002462387,
    "var": 0.006910709664225578,
    "min": -0.6006014943122864,
    "max": 0.5599997043609619,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0018179439939558506,
    "std": 0.10456996411085129,
    "var": 0.010934877209365368,
    "min": -0.7291826605796814,
    "max": 0.5440071225166321,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0013251862255856395,
    "std": 0.10926339775323868,
    "var": 0.011938489973545074,
    "min": -0.4668242931365967,
    "max": 0.5833021402359009,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.00211492832750082,
    "std": 0.10595040023326874,
    "var": 0.011225487105548382,
    "min": -0.6164332628250122,
    "max": 0.6531366109848022,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00015211889694910496,
    "std": 0.07532305270433426,
    "var": 0.00567356264218688,
    "min": -0.6200176477432251,
    "max": 0.7438697218894958,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00047800439642742276,
    "std": 0.09033837169408798,
    "var": 0.008161021396517754,
    "min": -0.5094408392906189,
    "max": 0.5237593054771423,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0011440578382462263,
    "std": 0.10013506561517715,
    "var": 0.010027031414210796,
    "min": -0.7125451564788818,
    "max": 0.6237815618515015,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.39620059728622437,
    "std": 0.1124793067574501,
    "var": 0.012651595287024975,
    "min": -0.7256961464881897,
    "max": -0.15175668895244598,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08072657883167267,
    "std": 0.2908545136451721,
    "var": 0.08459634333848953,
    "min": -1.1846543550491333,
    "max": 1.2268702983856201,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.7767667770385742,
    "std": 1.0629314184188843,
    "var": 1.1298232078552246,
    "min": -2.116494655609131,
    "max": 3.478430986404419,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.3171757459640503,
    "std": 0.13574588298797607,
    "var": 0.018426945433020592,
    "min": -0.690097987651825,
    "max": 0.003848223015666008,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.20589865744113922,
    "std": 0.21176262199878693,
    "var": 0.0448434054851532,
    "min": -1.595650553703308,
    "max": 0.6473129987716675,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 1.0140889883041382,
    "std": 0.9916325807571411,
    "var": 0.9833351373672485,
    "min": -1.311553716659546,
    "max": 3.156935453414917,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.2838914394378662,
    "std": 0.15126122534275055,
    "var": 0.022879956290125847,
    "min": -0.6288100481033325,
    "max": 0.00951982382684946,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.19330890476703644,
    "std": 0.22349858283996582,
    "var": 0.049951616674661636,
    "min": -1.8084819316864014,
    "max": 0.626251757144928,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.9281317591667175,
    "std": 0.8913995623588562,
    "var": 0.7945932149887085,
    "min": -1.8229395151138306,
    "max": 3.6510560512542725,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.11484962701797485,
    "std": 0.09748239815235138,
    "var": 0.009502818807959557,
    "min": -0.39047378301620483,
    "max": 0.11251823604106903,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08618943393230438,
    "std": 0.16613595187664032,
    "var": 0.027601156383752823,
    "min": -1.2729887962341309,
    "max": 0.5963586568832397,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0011854572221636772,
    "std": 0.005964374635368586,
    "var": 3.5573764762375504e-05,
    "min": -0.016454482451081276,
    "max": 0.013827583752572536,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.00045641776523552835,
    "std": 0.10786080360412598,
    "var": 0.01163395307958126,
    "min": -0.9502350687980652,
    "max": 0.7604103684425354,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.015170878730714321,
    "std": 0.35007524490356445,
    "var": 0.12255268543958664,
    "min": -2.951253652572632,
    "max": 2.075676441192627,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.16306814551353455,
    "std": 0.09522159397602081,
    "var": 0.009067152626812458,
    "min": -0.44571876525878906,
    "max": 0.08497653156518936,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07480156421661377,
    "std": 0.16355301439762115,
    "var": 0.026749586686491966,
    "min": -1.670257329940796,
    "max": 0.5908699035644531,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.19182710349559784,
    "std": 0.9845414757728577,
    "var": 0.9693219065666199,
    "min": -2.5135979652404785,
    "max": 2.4146060943603516,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.042853742837905884,
    "std": 0.1388552486896515,
    "var": 0.019280780106782913,
    "min": -0.3035389482975006,
    "max": 0.3775199055671692,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.04343646019697189,
    "std": 0.15813398361206055,
    "var": 0.025006357580423355,
    "min": -0.9260104894638062,
    "max": 0.6916489005088806,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.38291820883750916,
    "std": 0.6062480807304382,
    "var": 0.367536723613739,
    "min": -1.5000700950622559,
    "max": 2.0602221488952637,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.010229332372546196,
    "std": 0.07043566554784775,
    "var": 0.0049611832946538925,
    "min": -0.18845878541469574,
    "max": 0.11504053324460983,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0037405083421617746,
    "std": 0.21228352189064026,
    "var": 0.0450642928481102,
    "min": -0.8844450116157532,
    "max": 0.8353487253189087,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.006799838040024042,
    "std": 0.2770010232925415,
    "var": 0.07672957330942154,
    "min": -1.1588715314865112,
    "max": 1.685604214668274,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.39327549934387207,
    "std": 0.43364956974983215,
    "var": 0.1880519688129425,
    "min": -1.3156689405441284,
    "max": 0.8459802269935608,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.500510573387146,
    "std": 0.42862892150878906,
    "var": 0.18372274935245514,
    "min": -1.6937869787216187,
    "max": 0.5518522262573242,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.7195793390274048,
    "std": 0.47779399156570435,
    "var": 0.22828710079193115,
    "min": -2.341188430786133,
    "max": 0.3034663498401642,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.539607048034668,
    "std": 0.574834406375885,
    "var": 0.3304346203804016,
    "min": -2.948910713195801,
    "max": 0.1104666143655777,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.255028247833252,
    "std": 0.4177381992340088,
    "var": 0.17450520396232605,
    "min": -2.3810575008392334,
    "max": 0.16169117391109467,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.2561050653457642,
    "std": 0.5913799405097961,
    "var": 0.3497302532196045,
    "min": -2.8395674228668213,
    "max": 0.16186746954917908,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.81 | loss:  0.68
-----------------------------------------------------------------------------------------
| epoch 81 | 1000/1179 batches | ms/batch 856.05 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.19
-----------------------------------------------------------------------------------------
| end of epoch  81 | time per epoch: 999.62s |
| Train Metrics | accuracy:  0.70 | loss:  1.20
| Eval  Metrics | accuracy:  0.78 | loss:  0.75
-----------------------------------------------------------------------------------------
| epoch 82 | 1000/1179 batches | ms/batch 885.01 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.17
-----------------------------------------------------------------------------------------
| end of epoch  82 | time per epoch: 1040.08s |
| Train Metrics | accuracy:  0.70 | loss:  1.18
| Eval  Metrics | accuracy:  0.80 | loss:  0.71
-----------------------------------------------------------------------------------------
| epoch 83 | 1000/1179 batches | ms/batch 751.12 | Performance/Training accuracy:  0.70 | Performance/Training loss:  1.19
-----------------------------------------------------------------------------------------
| end of epoch  83 | time per epoch: 925.07s |
| Train Metrics | accuracy:  0.71 | loss:  1.18
| Eval  Metrics | accuracy:  0.79 | loss:  0.70
-----------------------------------------------------------------------------------------
| epoch 84 | 1000/1179 batches | ms/batch 738.59 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.15
-----------------------------------------------------------------------------------------
| end of epoch  84 | time per epoch: 877.95s |
| Train Metrics | accuracy:  0.71 | loss:  1.14
| Eval  Metrics | accuracy:  0.80 | loss:  0.67
-----------------------------------------------------------------------------------------
| epoch 85 | 1000/1179 batches | ms/batch 786.83 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.13
-----------------------------------------------------------------------------------------
| end of epoch  85 | time per epoch: 964.57s |
| Train Metrics | accuracy:  0.71 | loss:  1.14
| Eval  Metrics | accuracy:  0.80 | loss:  0.70
-----------------------------------------------------------------------------------------
| epoch 86 | 1000/1179 batches | ms/batch 731.57 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.13
-----------------------------------------------------------------------------------------
| end of epoch  86 | time per epoch: 870.00s |
| Train Metrics | accuracy:  0.71 | loss:  1.15
| Eval  Metrics | accuracy:  0.79 | loss:  0.74
-----------------------------------------------------------------------------------------
| epoch 87 | 1000/1179 batches | ms/batch 820.45 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.19
-----------------------------------------------------------------------------------------
| end of epoch  87 | time per epoch: 993.33s |
| Train Metrics | accuracy:  0.71 | loss:  1.18
| Eval  Metrics | accuracy:  0.80 | loss:  0.68
-----------------------------------------------------------------------------------------
| epoch 88 | 1000/1179 batches | ms/batch 793.93 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.16
-----------------------------------------------------------------------------------------
| end of epoch  88 | time per epoch: 920.93s |
| Train Metrics | accuracy:  0.71 | loss:  1.15
| Eval  Metrics | accuracy:  0.81 | loss:  0.65
-----------------------------------------------------------------------------------------
| epoch 89 | 1000/1179 batches | ms/batch 800.19 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.15
-----------------------------------------------------------------------------------------
| end of epoch  89 | time per epoch: 976.54s |
| Train Metrics | accuracy:  0.71 | loss:  1.16
| Eval  Metrics | accuracy:  0.81 | loss:  0.66
-----------------------------------------------------------------------------------------
| epoch 90 | 1000/1179 batches | ms/batch 842.46 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.16
-----------------------------------------------------------------------------------------
| end of epoch  90 | time per epoch: 1011.12s |
| Train Metrics | accuracy:  0.71 | loss:  1.14
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.22904369235038757,
    "std": 0.3386506140232086,
    "var": 0.11468424648046494,
    "min": -0.18172018229961395,
    "max": 1.0876601934432983,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.2823331356048584,
    "std": 0.18354256451129913,
    "var": 0.03368787467479706,
    "min": 0.05381685122847557,
    "max": 0.8715973496437073,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0004666414752136916,
    "std": 0.11248807609081268,
    "var": 0.012653566896915436,
    "min": -0.6694573760032654,
    "max": 0.707590639591217,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.24977324903011322,
    "std": 0.20886944234371185,
    "var": 0.043626442551612854,
    "min": -0.051822010427713394,
    "max": 1.0084553956985474,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.34886109828948975,
    "std": 0.25696760416030884,
    "var": 0.06603235006332397,
    "min": 0.07804611325263977,
    "max": 1.3096427917480469,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0008065368747338653,
    "std": 0.11837036162614822,
    "var": 0.014011542312800884,
    "min": -0.701747477054596,
    "max": 0.5340678095817566,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.26066404581069946,
    "std": 0.16038472950458527,
    "var": 0.025723259896039963,
    "min": -0.07582737505435944,
    "max": 0.7561706304550171,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.40639790892601013,
    "std": 0.3379926383495331,
    "var": 0.11423902958631516,
    "min": 0.06345944106578827,
    "max": 2.0671486854553223,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00046003726311028004,
    "std": 0.11739528924226761,
    "var": 0.013781653717160225,
    "min": -0.678533673286438,
    "max": 0.8176472187042236,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.16304054856300354,
    "std": 0.22820726037025452,
    "var": 0.052078552544116974,
    "min": -0.3670724034309387,
    "max": 1.0287021398544312,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6469799876213074,
    "std": 0.2565750479698181,
    "var": 0.06583075225353241,
    "min": 0.04796619340777397,
    "max": 2.384828567504883,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0006277408101595938,
    "std": 0.0553511381149292,
    "var": 0.0030637483578175306,
    "min": -0.6672189831733704,
    "max": 0.9392188191413879,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.15688347816467285,
    "std": 0.25178149342536926,
    "var": 0.06339392811059952,
    "min": -0.4556870460510254,
    "max": 1.0889232158660889,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6810671091079712,
    "std": 0.261902391910553,
    "var": 0.0685928612947464,
    "min": 0.12809725105762482,
    "max": 1.6664495468139648,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00026812590658664703,
    "std": 0.05947791039943695,
    "var": 0.003537622047588229,
    "min": -0.571651816368103,
    "max": 0.5309249758720398,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.051807135343551636,
    "std": 0.10008525848388672,
    "var": 0.010017059743404388,
    "min": -0.48360320925712585,
    "max": 0.2293117344379425,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.108087182044983,
    "std": 0.2618162930011749,
    "var": 0.06854777038097382,
    "min": 0.6675662398338318,
    "max": 2.153319835662842,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00035516099887900054,
    "std": 0.08481831103563309,
    "var": 0.007194146513938904,
    "min": -0.6489009261131287,
    "max": 0.5893028974533081,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00042463428690098226,
    "std": 0.09946031123399734,
    "var": 0.009892353788018227,
    "min": -0.7316359281539917,
    "max": 0.546843409538269,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.0005860445089638233,
    "std": 0.10360860079526901,
    "var": 0.010734742507338524,
    "min": -0.5446842312812805,
    "max": 0.49801358580589294,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0017806347459554672,
    "std": 0.10008864104747772,
    "var": 0.01001773588359356,
    "min": -0.6178706288337708,
    "max": 0.5436688661575317,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00011810373689513654,
    "std": 0.07052826136350632,
    "var": 0.0049742357805371284,
    "min": -0.6170467734336853,
    "max": 0.7195103764533997,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00016765002510510385,
    "std": 0.08640556782484055,
    "var": 0.007465922739356756,
    "min": -0.4956633746623993,
    "max": 0.4872267544269562,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0011525312438607216,
    "std": 0.09532752633094788,
    "var": 0.0090873371809721,
    "min": -0.7303747534751892,
    "max": 0.6221252083778381,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3815976083278656,
    "std": 0.10256560891866684,
    "var": 0.010519703850150108,
    "min": -0.6512750387191772,
    "max": -0.19550172984600067,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08240082859992981,
    "std": 0.2829625904560089,
    "var": 0.08006783574819565,
    "min": -1.15048348903656,
    "max": 1.1457306146621704,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.712613046169281,
    "std": 1.0205172300338745,
    "var": 1.0414553880691528,
    "min": -2.2688469886779785,
    "max": 3.1657772064208984,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.31074780225753784,
    "std": 0.13616512715816498,
    "var": 0.018540939316153526,
    "min": -0.6592347025871277,
    "max": 0.014509730041027069,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.2019767314195633,
    "std": 0.21260808408260345,
    "var": 0.04520219564437866,
    "min": -1.6264511346817017,
    "max": 0.5655861496925354,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.9224085211753845,
    "std": 0.9517925381660461,
    "var": 0.9059090614318848,
    "min": -1.2454843521118164,
    "max": 2.968069553375244,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.2870975732803345,
    "std": 0.15396150946617126,
    "var": 0.023704146966338158,
    "min": -0.6435285210609436,
    "max": 0.014340003952383995,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.1970248818397522,
    "std": 0.2229493111371994,
    "var": 0.04970639571547508,
    "min": -1.6130050420761108,
    "max": 0.6719491481781006,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.9063763618469238,
    "std": 0.9024415612220764,
    "var": 0.8144007921218872,
    "min": -2.111135482788086,
    "max": 3.5706710815429688,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.11821775138378143,
    "std": 0.09244079142808914,
    "var": 0.008545300923287868,
    "min": -0.3425021171569824,
    "max": 0.10692164301872253,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.0842563658952713,
    "std": 0.1636146456003189,
    "var": 0.02676975168287754,
    "min": -1.2423182725906372,
    "max": 0.6524211168289185,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0006895264377817512,
    "std": 0.00552059430629015,
    "var": 3.0476963729597628e-05,
    "min": -0.025622155517339706,
    "max": 0.0170854814350605,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.0008747572428546846,
    "std": 0.10607807338237762,
    "var": 0.011252558790147305,
    "min": -0.8880655169487,
    "max": 0.8941759467124939,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.013301127590239048,
    "std": 0.3298064172267914,
    "var": 0.10877227783203125,
    "min": -2.6611928939819336,
    "max": 1.9258869886398315,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.16116076707839966,
    "std": 0.09006056934595108,
    "var": 0.00811090599745512,
    "min": -0.4278736412525177,
    "max": 0.05959918722510338,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07430888712406158,
    "std": 0.16079744696617126,
    "var": 0.025855818763375282,
    "min": -1.584778904914856,
    "max": 0.5713616609573364,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.1918773502111435,
    "std": 0.9373725652694702,
    "var": 0.8786673545837402,
    "min": -2.438014507293701,
    "max": 2.359342575073242,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.0498233400285244,
    "std": 0.13703285157680511,
    "var": 0.018778003752231598,
    "min": -0.2794990837574005,
    "max": 0.3786284923553467,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.04157160967588425,
    "std": 0.1541469693183899,
    "var": 0.023761287331581116,
    "min": -1.0003796815872192,
    "max": 0.6499363780021667,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.373950332403183,
    "std": 0.5574494004249573,
    "var": 0.3107498586177826,
    "min": -1.2731525897979736,
    "max": 2.001990556716919,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.009647080674767494,
    "std": 0.06716735661029816,
    "var": 0.004511453676968813,
    "min": -0.18928825855255127,
    "max": 0.10306570678949356,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.0038714800029993057,
    "std": 0.21290628612041473,
    "var": 0.04532908648252487,
    "min": -0.8643791079521179,
    "max": 0.9033632874488831,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.008097009733319283,
    "std": 0.2640155553817749,
    "var": 0.06970421224832535,
    "min": -1.1491310596466064,
    "max": 1.497904896736145,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.3335370719432831,
    "std": 0.41593658924102783,
    "var": 0.17300325632095337,
    "min": -1.246372103691101,
    "max": 0.9699161052703857,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.4406459927558899,
    "std": 0.42884671688079834,
    "var": 0.18390950560569763,
    "min": -1.5831438302993774,
    "max": 0.668067216873169,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.674839198589325,
    "std": 0.4748142957687378,
    "var": 0.2254486382007599,
    "min": -2.2606797218322754,
    "max": 0.4252239763736725,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.6078245639801025,
    "std": 0.6288251280784607,
    "var": 0.3954210579395294,
    "min": -3.0132453441619873,
    "max": 0.14691555500030518,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.2133841514587402,
    "std": 0.41845229268074036,
    "var": 0.1751023232936859,
    "min": -2.3250820636749268,
    "max": 0.21511679887771606,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.2087454795837402,
    "std": 0.5919861197471619,
    "var": 0.35044753551483154,
    "min": -2.8200414180755615,
    "max": 0.22243452072143555,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.81 | loss:  0.65
-----------------------------------------------------------------------------------------
| epoch 91 | 1000/1179 batches | ms/batch 808.69 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.14
-----------------------------------------------------------------------------------------
| end of epoch  91 | time per epoch: 937.43s |
| Train Metrics | accuracy:  0.71 | loss:  1.14
| Eval  Metrics | accuracy:  0.80 | loss:  0.70
-----------------------------------------------------------------------------------------
| epoch 92 | 1000/1179 batches | ms/batch 805.34 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.16
-----------------------------------------------------------------------------------------
| end of epoch  92 | time per epoch: 903.61s |
| Train Metrics | accuracy:  0.71 | loss:  1.15
| Eval  Metrics | accuracy:  0.80 | loss:  0.69
-----------------------------------------------------------------------------------------
| epoch 93 | 1000/1179 batches | ms/batch 862.74 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.16
-----------------------------------------------------------------------------------------
| end of epoch  93 | time per epoch: 1008.33s |
| Train Metrics | accuracy:  0.71 | loss:  1.15
| Eval  Metrics | accuracy:  0.80 | loss:  0.68
-----------------------------------------------------------------------------------------
| epoch 94 | 1000/1179 batches | ms/batch 819.98 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.11
-----------------------------------------------------------------------------------------
| end of epoch  94 | time per epoch: 938.74s |
| Train Metrics | accuracy:  0.72 | loss:  1.11
| Eval  Metrics | accuracy:  0.81 | loss:  0.67
-----------------------------------------------------------------------------------------
| epoch 95 | 1000/1179 batches | ms/batch 754.62 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.17
-----------------------------------------------------------------------------------------
| end of epoch  95 | time per epoch: 872.82s |
| Train Metrics | accuracy:  0.71 | loss:  1.16
| Eval  Metrics | accuracy:  0.81 | loss:  0.63
-----------------------------------------------------------------------------------------
[2025-02-26 22:03:19,486][absl][INFO] - Saving checkpoint at step: 112005
[2025-02-26 22:03:19,488][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 22:03:19,488][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 22:03:19,489][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_112005.
[2025-02-26 22:03:19,491][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 22:03:19,492][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_112005.orbax-checkpoint-tmp-38
[2025-02-26 22:03:19,501][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 22:03:19,527][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 22:03:19,559][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 159.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 57 milliseconds) (per-host)
[2025-02-26 22:03:19,785][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-26 22:03:19,785][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 283 milliseconds) (per-host)
[2025-02-26 22:03:19,790][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 22:03:19,822][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_112005.orbax-checkpoint-tmp-38 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_112005
[2025-02-26 22:03:19,828][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_112005`.
[2025-02-26 22:03:19,828][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 22:03:19,830][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_93141
| epoch 96 | 1000/1179 batches | ms/batch 772.54 | Performance/Training accuracy:  0.71 | Performance/Training loss:  1.15
-----------------------------------------------------------------------------------------
| end of epoch  96 | time per epoch: 937.79s |
| Train Metrics | accuracy:  0.71 | loss:  1.15
| Eval  Metrics | accuracy:  0.82 | loss:  0.63
-----------------------------------------------------------------------------------------
[2025-02-26 22:20:16,674][absl][INFO] - Saving checkpoint at step: 113184
[2025-02-26 22:20:16,675][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-26 22:20:16,675][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-26 22:20:16,676][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_113184.
[2025-02-26 22:20:16,679][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-26 22:20:16,680][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_113184.orbax-checkpoint-tmp-39
[2025-02-26 22:20:16,686][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-26 22:20:16,712][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-26 22:20:16,745][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 156.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 58 milliseconds) (per-host)
[2025-02-26 22:20:17,342][absl][INFO] - ChainedFuture completed 1/1 futures in 0.60 seconds.
[2025-02-26 22:20:17,343][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 13.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 655 milliseconds) (per-host)
[2025-02-26 22:20:17,353][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-26 22:20:17,385][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_113184.orbax-checkpoint-tmp-39 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_113184
[2025-02-26 22:20:17,397][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_113184`.
[2025-02-26 22:20:17,397][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-26 22:20:17,398][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_112005
| epoch 97 | 1000/1179 batches | ms/batch 789.78 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.13
-----------------------------------------------------------------------------------------
| end of epoch  97 | time per epoch: 941.41s |
| Train Metrics | accuracy:  0.72 | loss:  1.12
| Eval  Metrics | accuracy:  0.81 | loss:  0.65
-----------------------------------------------------------------------------------------
| epoch 98 | 1000/1179 batches | ms/batch 827.03 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.12
-----------------------------------------------------------------------------------------
| end of epoch  98 | time per epoch: 950.01s |
| Train Metrics | accuracy:  0.72 | loss:  1.13
| Eval  Metrics | accuracy:  0.82 | loss:  0.64
-----------------------------------------------------------------------------------------
| epoch 99 | 1000/1179 batches | ms/batch 810.62 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.14
-----------------------------------------------------------------------------------------
| end of epoch  99 | time per epoch: 963.55s |
| Train Metrics | accuracy:  0.72 | loss:  1.14
| Eval  Metrics | accuracy:  0.82 | loss:  0.62
-----------------------------------------------------------------------------------------
| epoch 100 | 1000/1179 batches | ms/batch 783.76 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.10
-----------------------------------------------------------------------------------------
| end of epoch 100 | time per epoch: 895.37s |
| Train Metrics | accuracy:  0.72 | loss:  1.11
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.24052512645721436,
    "std": 0.35517576336860657,
    "var": 0.12614981830120087,
    "min": -0.20805573463439941,
    "max": 1.1098508834838867,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.28533071279525757,
    "std": 0.19426751136779785,
    "var": 0.037739869207143784,
    "min": 0.04854903742671013,
    "max": 0.8929778337478638,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0005769996205344796,
    "std": 0.1135164424777031,
    "var": 0.012885983102023602,
    "min": -0.685219407081604,
    "max": 0.74395751953125,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.2561497092247009,
    "std": 0.21576620638370514,
    "var": 0.0465550534427166,
    "min": -0.06318251043558121,
    "max": 1.0547008514404297,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.35016879439353943,
    "std": 0.27156129479408264,
    "var": 0.07374553382396698,
    "min": 0.07172208279371262,
    "max": 1.3647220134735107,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0009555978467687964,
    "std": 0.11982017010450363,
    "var": 0.01435687392950058,
    "min": -0.7291316986083984,
    "max": 0.5662879347801208,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2621341347694397,
    "std": 0.16020087897777557,
    "var": 0.025664320215582848,
    "min": -0.07428755611181259,
    "max": 0.7059215307235718,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.4044837951660156,
    "std": 0.35027074813842773,
    "var": 0.12268960475921631,
    "min": 0.07795028388500214,
    "max": 2.102633237838745,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.000593316915910691,
    "std": 0.11883803457021713,
    "var": 0.014122478663921356,
    "min": -0.6768243908882141,
    "max": 0.8620864152908325,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.16714653372764587,
    "std": 0.2312197983264923,
    "var": 0.053462594747543335,
    "min": -0.3601771593093872,
    "max": 1.080626368522644,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6496296525001526,
    "std": 0.2579834759235382,
    "var": 0.06655548512935638,
    "min": 0.06469599157571793,
    "max": 2.4024102687835693,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0006852126098237932,
    "std": 0.05382952839136124,
    "var": 0.0028976178728044033,
    "min": -0.6788233518600464,
    "max": 0.9854724407196045,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.16217952966690063,
    "std": 0.250326931476593,
    "var": 0.06266357749700546,
    "min": -0.4258546531200409,
    "max": 1.0911318063735962,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6737319827079773,
    "std": 0.25967156887054443,
    "var": 0.0674293264746666,
    "min": 0.11683674901723862,
    "max": 1.737869381904602,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00030857534147799015,
    "std": 0.059344612061977386,
    "var": 0.0035217832773923874,
    "min": -0.5817601680755615,
    "max": 0.5660315752029419,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.04898282140493393,
    "std": 0.09837653487920761,
    "var": 0.009677942842245102,
    "min": -0.48506852984428406,
    "max": 0.2295326590538025,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.1303751468658447,
    "std": 0.26345568895339966,
    "var": 0.06940890103578568,
    "min": 0.653083086013794,
    "max": 2.2209296226501465,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00037366471951827407,
    "std": 0.08612308651208878,
    "var": 0.007417186163365841,
    "min": -0.6893997192382812,
    "max": 0.6122503280639648,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0012933894759044051,
    "std": 0.09514093399047852,
    "var": 0.009051797911524773,
    "min": -0.6073492765426636,
    "max": 0.5032901167869568,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.000528119970113039,
    "std": 0.09890727698802948,
    "var": 0.009782649576663971,
    "min": -0.5485232472419739,
    "max": 0.47831079363822937,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.001450965995900333,
    "std": 0.09491697698831558,
    "var": 0.009009232744574547,
    "min": -0.630017876625061,
    "max": 0.5124244689941406,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00024313453468494117,
    "std": 0.06636442989110947,
    "var": 0.0044042374938726425,
    "min": -0.5054700970649719,
    "max": 0.6083168387413025,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00032210556673817337,
    "std": 0.08235543966293335,
    "var": 0.006782418116927147,
    "min": -0.515355110168457,
    "max": 0.48587995767593384,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0011580241844058037,
    "std": 0.09032466262578964,
    "var": 0.008158545009791851,
    "min": -0.7225591540336609,
    "max": 0.5450032353401184,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3753282427787781,
    "std": 0.10216572880744934,
    "var": 0.01043783687055111,
    "min": -0.6746214032173157,
    "max": -0.20410001277923584,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08382059633731842,
    "std": 0.278824120759964,
    "var": 0.07774288952350616,
    "min": -1.041276216506958,
    "max": 1.1729443073272705,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.655885636806488,
    "std": 0.982366681098938,
    "var": 0.965044379234314,
    "min": -2.3212809562683105,
    "max": 2.920356035232544,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.30735552310943604,
    "std": 0.13339540362358093,
    "var": 0.017794333398342133,
    "min": -0.6907958388328552,
    "max": -0.01335648912936449,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.20201046764850616,
    "std": 0.21110999584197998,
    "var": 0.04456743225455284,
    "min": -1.6245410442352295,
    "max": 0.6384631395339966,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.8400375247001648,
    "std": 0.9000815153121948,
    "var": 0.810146689414978,
    "min": -1.13655424118042,
    "max": 2.779696226119995,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.28824013471603394,
    "std": 0.148695170879364,
    "var": 0.02211025357246399,
    "min": -0.6333271861076355,
    "max": -0.0006556306616403162,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.19788138568401337,
    "std": 0.21984635293483734,
    "var": 0.04833241552114487,
    "min": -1.5436521768569946,
    "max": 0.6008134484291077,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.8640643954277039,
    "std": 0.8929364681243896,
    "var": 0.7973355650901794,
    "min": -2.2659218311309814,
    "max": 3.622183084487915,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.12108279764652252,
    "std": 0.09023184329271317,
    "var": 0.008141785860061646,
    "min": -0.3344157338142395,
    "max": 0.08908066898584366,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08319379389286041,
    "std": 0.160012885928154,
    "var": 0.02560412511229515,
    "min": -1.1928648948669434,
    "max": 0.620585560798645,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0009181865025311708,
    "std": 0.004891603719443083,
    "var": 2.3927786969579756e-05,
    "min": -0.016223780810832977,
    "max": 0.012485559098422527,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.00028437472064979374,
    "std": 0.10457589477300644,
    "var": 0.01093611866235733,
    "min": -0.9050964713096619,
    "max": 1.0245088338851929,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.012022229842841625,
    "std": 0.3087918758392334,
    "var": 0.0953524187207222,
    "min": -2.468597412109375,
    "max": 1.8727842569351196,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15867403149604797,
    "std": 0.08819808810949326,
    "var": 0.007778902538120747,
    "min": -0.42278531193733215,
    "max": 0.053273048251867294,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.0726444199681282,
    "std": 0.15738852322101593,
    "var": 0.02477114647626877,
    "min": -1.4967063665390015,
    "max": 0.528227686882019,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.18891839683055878,
    "std": 0.8934038877487183,
    "var": 0.7981705665588379,
    "min": -2.3935718536376953,
    "max": 2.3646507263183594,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.05529890954494476,
    "std": 0.1357799768447876,
    "var": 0.01843620464205742,
    "min": -0.30404236912727356,
    "max": 0.39480525255203247,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.04040307179093361,
    "std": 0.14966341853141785,
    "var": 0.022399140521883965,
    "min": -0.8827292323112488,
    "max": 0.6094658970832825,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.3596975803375244,
    "std": 0.5257384777069092,
    "var": 0.27640095353126526,
    "min": -1.0829753875732422,
    "max": 2.0333409309387207,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.00924614630639553,
    "std": 0.06464871019124985,
    "var": 0.004179455805569887,
    "min": -0.17396873235702515,
    "max": 0.10706261545419693,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.004103226587176323,
    "std": 0.21325863897800446,
    "var": 0.04547924920916557,
    "min": -0.8891299366950989,
    "max": 0.8703542947769165,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.009235873818397522,
    "std": 0.2518429756164551,
    "var": 0.06342489272356033,
    "min": -1.065053105354309,
    "max": 1.4024643898010254,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.2880781590938568,
    "std": 0.4041309356689453,
    "var": 0.16332180798053741,
    "min": -1.187303066253662,
    "max": 1.1039644479751587,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.3944154381752014,
    "std": 0.42573514580726624,
    "var": 0.1812504231929779,
    "min": -1.5431125164031982,
    "max": 0.6919792890548706,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.6366667747497559,
    "std": 0.47294148802757263,
    "var": 0.22367364168167114,
    "min": -2.149050235748291,
    "max": 0.42272019386291504,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.6419161558151245,
    "std": 0.6480721235275269,
    "var": 0.41999751329421997,
    "min": -3.2695810794830322,
    "max": 0.1626630574464798,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.1750141382217407,
    "std": 0.4151383936405182,
    "var": 0.17233988642692566,
    "min": -2.2571725845336914,
    "max": 0.23120245337486267,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.1714060306549072,
    "std": 0.5865883827209473,
    "var": 0.3440859317779541,
    "min": -2.783975124359131,
    "max": 0.2742714285850525,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.81 | loss:  0.67
-----------------------------------------------------------------------------------------
| epoch 101 | 1000/1179 batches | ms/batch 840.92 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.10
-----------------------------------------------------------------------------------------
| end of epoch 101 | time per epoch: 975.69s |
| Train Metrics | accuracy:  0.72 | loss:  1.10
| Eval  Metrics | accuracy:  0.82 | loss:  0.63
-----------------------------------------------------------------------------------------
| epoch 102 | 1000/1179 batches | ms/batch 812.07 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.08
-----------------------------------------------------------------------------------------
| end of epoch 102 | time per epoch: 976.45s |
| Train Metrics | accuracy:  0.73 | loss:  1.08
| Eval  Metrics | accuracy:  0.81 | loss:  0.67
-----------------------------------------------------------------------------------------
| epoch 103 | 1000/1179 batches | ms/batch 808.77 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.09
-----------------------------------------------------------------------------------------
| end of epoch 103 | time per epoch: 954.43s |
| Train Metrics | accuracy:  0.73 | loss:  1.09
| Eval  Metrics | accuracy:  0.81 | loss:  0.67
-----------------------------------------------------------------------------------------
| epoch 104 | 1000/1179 batches | ms/batch 790.02 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.12
-----------------------------------------------------------------------------------------
| end of epoch 104 | time per epoch: 956.07s |
| Train Metrics | accuracy:  0.72 | loss:  1.12
| Eval  Metrics | accuracy:  0.83 | loss:  0.63
-----------------------------------------------------------------------------------------
[2025-02-27 00:38:39,390][absl][INFO] - Saving checkpoint at step: 122616
[2025-02-27 00:38:39,391][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 00:38:39,391][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 00:38:39,393][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_122616.
[2025-02-27 00:38:39,395][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 00:38:39,396][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_122616.orbax-checkpoint-tmp-40
[2025-02-27 00:38:39,406][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 00:38:39,433][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 00:38:39,465][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 157.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 58 milliseconds) (per-host)
[2025-02-27 00:38:39,692][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-27 00:38:39,692][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 284 milliseconds) (per-host)
[2025-02-27 00:38:39,698][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 00:38:39,729][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_122616.orbax-checkpoint-tmp-40 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_122616
[2025-02-27 00:38:39,735][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_122616`.
[2025-02-27 00:38:39,735][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 00:38:39,737][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_113184
| epoch 105 | 1000/1179 batches | ms/batch 771.38 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.13
-----------------------------------------------------------------------------------------
| end of epoch 105 | time per epoch: 934.43s |
| Train Metrics | accuracy:  0.72 | loss:  1.12
| Eval  Metrics | accuracy:  0.82 | loss:  0.65
-----------------------------------------------------------------------------------------
| epoch 106 | 1000/1179 batches | ms/batch 870.84 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.09
-----------------------------------------------------------------------------------------
| end of epoch 106 | time per epoch: 1025.15s |
| Train Metrics | accuracy:  0.72 | loss:  1.10
| Eval  Metrics | accuracy:  0.81 | loss:  0.68
-----------------------------------------------------------------------------------------
| epoch 107 | 1000/1179 batches | ms/batch 781.56 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.11
-----------------------------------------------------------------------------------------
| end of epoch 107 | time per epoch: 912.61s |
| Train Metrics | accuracy:  0.72 | loss:  1.12
| Eval  Metrics | accuracy:  0.81 | loss:  0.65
-----------------------------------------------------------------------------------------
| epoch 108 | 1000/1179 batches | ms/batch 879.55 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.09
-----------------------------------------------------------------------------------------
| end of epoch 108 | time per epoch: 1034.42s |
| Train Metrics | accuracy:  0.73 | loss:  1.08
| Eval  Metrics | accuracy:  0.82 | loss:  0.62
-----------------------------------------------------------------------------------------
| epoch 109 | 1000/1179 batches | ms/batch 909.86 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.10
-----------------------------------------------------------------------------------------
| end of epoch 109 | time per epoch: 1068.32s |
| Train Metrics | accuracy:  0.73 | loss:  1.10
| Eval  Metrics | accuracy:  0.82 | loss:  0.67
-----------------------------------------------------------------------------------------
| epoch 110 | 1000/1179 batches | ms/batch 859.49 | Performance/Training accuracy:  0.72 | Performance/Training loss:  1.10
-----------------------------------------------------------------------------------------
| end of epoch 110 | time per epoch: 1025.29s |
| Train Metrics | accuracy:  0.72 | loss:  1.10
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.25050219893455505,
    "std": 0.3657524287700653,
    "var": 0.13377484679222107,
    "min": -0.23072940111160278,
    "max": 1.1383545398712158,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.28606510162353516,
    "std": 0.20688600838184357,
    "var": 0.04280181974172592,
    "min": 0.03331151604652405,
    "max": 1.0193191766738892,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0005876586656086147,
    "std": 0.11437015235424042,
    "var": 0.013080531731247902,
    "min": -0.7127671241760254,
    "max": 0.7642631530761719,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.26185140013694763,
    "std": 0.22405236959457397,
    "var": 0.050199463963508606,
    "min": -0.05361892655491829,
    "max": 1.0836938619613647,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.35552510619163513,
    "std": 0.2865876853466034,
    "var": 0.08213251084089279,
    "min": 0.06249343976378441,
    "max": 1.408919334411621,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0010693817166611552,
    "std": 0.1209571585059166,
    "var": 0.01463063433766365,
    "min": -0.7541957497596741,
    "max": 0.5892714262008667,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.26463207602500916,
    "std": 0.1619141548871994,
    "var": 0.02621619403362274,
    "min": -0.06463067978620529,
    "max": 0.7299389839172363,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.41269809007644653,
    "std": 0.36178159713745117,
    "var": 0.13088592886924744,
    "min": 0.06150619685649872,
    "max": 2.1423733234405518,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0006653566379100084,
    "std": 0.11986247450113297,
    "var": 0.014367012307047844,
    "min": -0.7010653018951416,
    "max": 0.8899474143981934,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.1758008897304535,
    "std": 0.22945082187652588,
    "var": 0.052647676318883896,
    "min": -0.35677918791770935,
    "max": 1.0564181804656982,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6534256935119629,
    "std": 0.2627946734428406,
    "var": 0.0690610408782959,
    "min": 0.06813303381204605,
    "max": 2.4851391315460205,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0006387970643118024,
    "std": 0.05251641571521759,
    "var": 0.0027579739689826965,
    "min": -0.6718377470970154,
    "max": 1.0124086141586304,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.16745005548000336,
    "std": 0.2500108480453491,
    "var": 0.06250542402267456,
    "min": -0.4253831207752228,
    "max": 1.1250734329223633,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6683117747306824,
    "std": 0.2577708065509796,
    "var": 0.06644579768180847,
    "min": 0.12042458355426788,
    "max": 1.7670502662658691,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0003194326418451965,
    "std": 0.059242185205221176,
    "var": 0.003509636502712965,
    "min": -0.5874689817428589,
    "max": 0.5948948860168457,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.04502780735492706,
    "std": 0.09564828127622604,
    "var": 0.009148593991994858,
    "min": -0.4827573597431183,
    "max": 0.22909195721149445,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.1515393257141113,
    "std": 0.260398268699646,
    "var": 0.06780725717544556,
    "min": 0.6896612048149109,
    "max": 2.2415771484375,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00033016069210134447,
    "std": 0.08709955215454102,
    "var": 0.0075863320380449295,
    "min": -0.7127609252929688,
    "max": 0.628132700920105,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0013318064156919718,
    "std": 0.0905519425868988,
    "var": 0.008199654519557953,
    "min": -0.5399820804595947,
    "max": 0.5044856667518616,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00036915671080350876,
    "std": 0.09319239854812622,
    "var": 0.008684824220836163,
    "min": -0.4518335461616516,
    "max": 0.476949006319046,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0011608970817178488,
    "std": 0.08996980637311935,
    "var": 0.008094565942883492,
    "min": -0.5695180296897888,
    "max": 0.48321279883384705,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00020241807214915752,
    "std": 0.06186990812420845,
    "var": 0.003827885491773486,
    "min": -0.508671224117279,
    "max": 0.5647814869880676,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00035135107464157045,
    "std": 0.07779059559106827,
    "var": 0.006051377393305302,
    "min": -0.4842987358570099,
    "max": 0.4505111277103424,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0012855753302574158,
    "std": 0.08516152203083038,
    "var": 0.007252485491335392,
    "min": -0.6371584534645081,
    "max": 0.49496588110923767,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3667881190776825,
    "std": 0.10112737864255905,
    "var": 0.010226747021079063,
    "min": -0.6572363376617432,
    "max": -0.194668248295784,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08607842773199081,
    "std": 0.27105942368507385,
    "var": 0.07347321510314941,
    "min": -0.985583484172821,
    "max": 1.1394400596618652,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.6149405241012573,
    "std": 0.9551942944526672,
    "var": 0.9123961329460144,
    "min": -2.3419370651245117,
    "max": 2.5497536659240723,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.30492839217185974,
    "std": 0.13105551898479462,
    "var": 0.017175551503896713,
    "min": -0.6612314581871033,
    "max": -0.028994332998991013,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.20035652816295624,
    "std": 0.20949241518974304,
    "var": 0.043887075036764145,
    "min": -1.6182115077972412,
    "max": 0.7339023947715759,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.7793887853622437,
    "std": 0.854786217212677,
    "var": 0.7306594848632812,
    "min": -0.8921248912811279,
    "max": 2.61553955078125,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.2895408868789673,
    "std": 0.14597268402576447,
    "var": 0.02130802720785141,
    "min": -0.6356163620948792,
    "max": 0.020065737888216972,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.19983334839344025,
    "std": 0.21746467053890228,
    "var": 0.04729088395833969,
    "min": -1.5197324752807617,
    "max": 0.5960805416107178,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.8298344016075134,
    "std": 0.8822410702705383,
    "var": 0.7783492803573608,
    "min": -2.339700937271118,
    "max": 3.6052887439727783,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.1245318204164505,
    "std": 0.0860210508108139,
    "var": 0.00739962188526988,
    "min": -0.34335437417030334,
    "max": 0.08158319443464279,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08189084380865097,
    "std": 0.15680043399333954,
    "var": 0.024586377665400505,
    "min": -1.2359150648117065,
    "max": 0.5858811736106873,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0009884824976325035,
    "std": 0.004717845004051924,
    "var": 2.2258063836488873e-05,
    "min": -0.022798381745815277,
    "max": 0.010609735734760761,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.0007517152698710561,
    "std": 0.10225443542003632,
    "var": 0.010455969721078873,
    "min": -0.9551140666007996,
    "max": 1.003357172012329,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.010701545514166355,
    "std": 0.2880769371986389,
    "var": 0.08298832923173904,
    "min": -2.293797254562378,
    "max": 1.7946701049804688,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.1557588279247284,
    "std": 0.08426539599895477,
    "var": 0.007100657559931278,
    "min": -0.3956640958786011,
    "max": 0.0587906576693058,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07155834883451462,
    "std": 0.15332771837711334,
    "var": 0.023509390652179718,
    "min": -1.3687880039215088,
    "max": 0.532379686832428,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.1887456178665161,
    "std": 0.833714485168457,
    "var": 0.6950798034667969,
    "min": -2.184019088745117,
    "max": 2.2164413928985596,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.0641179233789444,
    "std": 0.13382987678050995,
    "var": 0.017910435795783997,
    "min": -0.29145577549934387,
    "max": 0.3869158625602722,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.037601981312036514,
    "std": 0.144663006067276,
    "var": 0.020927386358380318,
    "min": -0.8603223562240601,
    "max": 0.5371738076210022,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.3465195298194885,
    "std": 0.4960052967071533,
    "var": 0.24602125585079193,
    "min": -0.9209283590316772,
    "max": 1.9713646173477173,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.009295286610722542,
    "std": 0.06453777104616165,
    "var": 0.004165124148130417,
    "min": -0.1858202964067459,
    "max": 0.10433024913072586,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.004015136510133743,
    "std": 0.21317307651042938,
    "var": 0.04544275999069214,
    "min": -0.8765119314193726,
    "max": 0.9007461667060852,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.008773625828325748,
    "std": 0.2405579388141632,
    "var": 0.05786812677979469,
    "min": -1.04080331325531,
    "max": 1.2900375127792358,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.2391895353794098,
    "std": 0.39280709624290466,
    "var": 0.15429742634296417,
    "min": -1.1699777841567993,
    "max": 1.1084891557693481,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.3583664894104004,
    "std": 0.4206107258796692,
    "var": 0.17691339552402496,
    "min": -1.4395698308944702,
    "max": 0.7298148274421692,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.5937153697013855,
    "std": 0.46593108773231506,
    "var": 0.21709179878234863,
    "min": -2.0035817623138428,
    "max": 0.45768776535987854,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.6476209163665771,
    "std": 0.6560224890708923,
    "var": 0.43036556243896484,
    "min": -3.0518107414245605,
    "max": 0.25498950481414795,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.132598876953125,
    "std": 0.41478878259658813,
    "var": 0.17204973101615906,
    "min": -2.185333013534546,
    "max": 0.25855618715286255,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.1344711780548096,
    "std": 0.5846742987632751,
    "var": 0.34184402227401733,
    "min": -2.760755777359009,
    "max": 0.2701862156391144,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.82 | loss:  0.63
-----------------------------------------------------------------------------------------
| epoch 111 | 1000/1179 batches | ms/batch 888.85 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.11
-----------------------------------------------------------------------------------------
| end of epoch 111 | time per epoch: 1043.62s |
| Train Metrics | accuracy:  0.73 | loss:  1.10
| Eval  Metrics | accuracy:  0.82 | loss:  0.65
-----------------------------------------------------------------------------------------
| epoch 112 | 1000/1179 batches | ms/batch 853.68 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.08
-----------------------------------------------------------------------------------------
| end of epoch 112 | time per epoch: 987.77s |
| Train Metrics | accuracy:  0.73 | loss:  1.08
| Eval  Metrics | accuracy:  0.82 | loss:  0.64
-----------------------------------------------------------------------------------------
| epoch 113 | 1000/1179 batches | ms/batch 775.89 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.04
-----------------------------------------------------------------------------------------
| end of epoch 113 | time per epoch: 943.89s |
| Train Metrics | accuracy:  0.74 | loss:  1.05
| Eval  Metrics | accuracy:  0.82 | loss:  0.60
-----------------------------------------------------------------------------------------
| epoch 114 | 1000/1179 batches | ms/batch 825.92 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.05
-----------------------------------------------------------------------------------------
| end of epoch 114 | time per epoch: 991.72s |
| Train Metrics | accuracy:  0.74 | loss:  1.06
| Eval  Metrics | accuracy:  0.82 | loss:  0.61
-----------------------------------------------------------------------------------------
| epoch 115 | 1000/1179 batches | ms/batch 847.37 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.10
-----------------------------------------------------------------------------------------
| end of epoch 115 | time per epoch: 1014.64s |
| Train Metrics | accuracy:  0.73 | loss:  1.10
| Eval  Metrics | accuracy:  0.82 | loss:  0.64
-----------------------------------------------------------------------------------------
| epoch 116 | 1000/1179 batches | ms/batch 748.73 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.06
-----------------------------------------------------------------------------------------
| end of epoch 116 | time per epoch: 884.28s |
| Train Metrics | accuracy:  0.73 | loss:  1.07
| Eval  Metrics | accuracy:  0.81 | loss:  0.67
-----------------------------------------------------------------------------------------
| epoch 117 | 1000/1179 batches | ms/batch 836.83 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.07
-----------------------------------------------------------------------------------------
| end of epoch 117 | time per epoch: 1040.98s |
| Train Metrics | accuracy:  0.73 | loss:  1.06
| Eval  Metrics | accuracy:  0.82 | loss:  0.59
-----------------------------------------------------------------------------------------
| epoch 118 | 1000/1179 batches | ms/batch 828.76 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.05
-----------------------------------------------------------------------------------------
| end of epoch 118 | time per epoch: 979.84s |
| Train Metrics | accuracy:  0.74 | loss:  1.05
| Eval  Metrics | accuracy:  0.83 | loss:  0.59
-----------------------------------------------------------------------------------------
[2025-02-27 04:50:27,091][absl][INFO] - Saving checkpoint at step: 139122
[2025-02-27 04:50:27,093][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 04:50:27,093][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 04:50:27,094][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_139122.
[2025-02-27 04:50:27,096][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 04:50:27,097][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_139122.orbax-checkpoint-tmp-41
[2025-02-27 04:50:27,110][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 04:50:27,137][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 04:50:27,168][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 159.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 57 milliseconds) (per-host)
[2025-02-27 04:50:27,401][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-27 04:50:27,401][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 289 milliseconds) (per-host)
[2025-02-27 04:50:27,406][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 04:50:27,436][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_139122.orbax-checkpoint-tmp-41 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_139122
[2025-02-27 04:50:27,442][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_139122`.
[2025-02-27 04:50:27,442][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 04:50:27,444][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_122616
| epoch 119 | 1000/1179 batches | ms/batch 862.93 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.05
-----------------------------------------------------------------------------------------
| end of epoch 119 | time per epoch: 1018.72s |
| Train Metrics | accuracy:  0.74 | loss:  1.06
| Eval  Metrics | accuracy:  0.83 | loss:  0.58
-----------------------------------------------------------------------------------------
[2025-02-27 05:08:31,305][absl][INFO] - Saving checkpoint at step: 140301
[2025-02-27 05:08:31,306][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 05:08:31,307][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 05:08:31,310][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_140301.
[2025-02-27 05:08:31,313][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 05:08:31,316][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_140301.orbax-checkpoint-tmp-42
[2025-02-27 05:08:31,326][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 05:08:31,355][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 05:08:31,387][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 151.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 60 milliseconds) (per-host)
[2025-02-27 05:08:31,632][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-27 05:08:31,632][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 29.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 305 milliseconds) (per-host)
[2025-02-27 05:08:31,638][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 05:08:31,685][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_140301.orbax-checkpoint-tmp-42 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_140301
[2025-02-27 05:08:31,692][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_140301`.
[2025-02-27 05:08:31,692][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 05:08:31,693][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_139122
| epoch 120 | 1000/1179 batches | ms/batch 779.73 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.08
-----------------------------------------------------------------------------------------
| end of epoch 120 | time per epoch: 937.53s |
| Train Metrics | accuracy:  0.74 | loss:  1.07
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.25618016719818115,
    "std": 0.3745723068714142,
    "var": 0.14030441641807556,
    "min": -0.24164323508739471,
    "max": 1.1279091835021973,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.2866426706314087,
    "std": 0.22219188511371613,
    "var": 0.04936923831701279,
    "min": 0.03373109549283981,
    "max": 1.0421857833862305,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0005019882810302079,
    "std": 0.11501713842153549,
    "var": 0.013228941708803177,
    "min": -0.7265931367874146,
    "max": 0.7731093168258667,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.26994818449020386,
    "std": 0.23380057513713837,
    "var": 0.054662711918354034,
    "min": -0.04454505071043968,
    "max": 1.104133129119873,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.3607777953147888,
    "std": 0.30238962173461914,
    "var": 0.09143947809934616,
    "min": 0.05717870965600014,
    "max": 1.4350372552871704,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0011342378566041589,
    "std": 0.12161087989807129,
    "var": 0.01478920690715313,
    "min": -0.7706347703933716,
    "max": 0.607561469078064,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2681245803833008,
    "std": 0.16382436454296112,
    "var": 0.02683842182159424,
    "min": -0.06026141345500946,
    "max": 0.7446897625923157,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.41673439741134644,
    "std": 0.3709993362426758,
    "var": 0.13764050602912903,
    "min": 0.0629647746682167,
    "max": 2.138195276260376,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0006837797118350863,
    "std": 0.12049990147352219,
    "var": 0.01452022697776556,
    "min": -0.7386398911476135,
    "max": 0.9042918086051941,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.17917528748512268,
    "std": 0.22789862751960754,
    "var": 0.05193778872489929,
    "min": -0.3596620559692383,
    "max": 1.0566205978393555,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6543758511543274,
    "std": 0.26084914803504944,
    "var": 0.06804227828979492,
    "min": 0.05691855400800705,
    "max": 2.4851605892181396,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0006345607107505202,
    "std": 0.05142030492424965,
    "var": 0.0026440478395670652,
    "min": -0.6713141202926636,
    "max": 1.0175690650939941,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.1750096082687378,
    "std": 0.24658755958080292,
    "var": 0.06080542504787445,
    "min": -0.3819960355758667,
    "max": 1.135439395904541,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6610971689224243,
    "std": 0.25348442792892456,
    "var": 0.06425435096025467,
    "min": 0.11793079227209091,
    "max": 1.7795634269714355,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00036164303310215473,
    "std": 0.059207599610090256,
    "var": 0.003505539847537875,
    "min": -0.5891252756118774,
    "max": 0.6191205978393555,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.03961009532213211,
    "std": 0.09193329513072968,
    "var": 0.008451730944216251,
    "min": -0.42455005645751953,
    "max": 0.1944582760334015,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.175243854522705,
    "std": 0.26152878999710083,
    "var": 0.06839731335639954,
    "min": 0.6841670870780945,
    "max": 2.336075782775879,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0003457923303358257,
    "std": 0.08777282387018204,
    "var": 0.007704068906605244,
    "min": -0.7433883547782898,
    "max": 0.6378663182258606,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0012802204582840204,
    "std": 0.08358125388622284,
    "var": 0.006985826417803764,
    "min": -0.46865537762641907,
    "max": 0.4535946249961853,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -9.73045825958252e-06,
    "std": 0.08700557053089142,
    "var": 0.00756996963173151,
    "min": -0.4577561616897583,
    "max": 0.4874701201915741,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0012451796792447567,
    "std": 0.0836486741900444,
    "var": 0.006997101008892059,
    "min": -0.5859072804450989,
    "max": 0.42386096715927124,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00040527209057472646,
    "std": 0.05698644369840622,
    "var": 0.0032474547624588013,
    "min": -0.4518030881881714,
    "max": 0.5261565446853638,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00013818219304084778,
    "std": 0.07340940833091736,
    "var": 0.005388941615819931,
    "min": -0.48122885823249817,
    "max": 0.46615251898765564,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0010429619578644633,
    "std": 0.07963629066944122,
    "var": 0.006341937929391861,
    "min": -0.5741363763809204,
    "max": 0.44964367151260376,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.36174246668815613,
    "std": 0.09932612627744675,
    "var": 0.009865679778158665,
    "min": -0.6723305583000183,
    "max": -0.1684468537569046,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08689317852258682,
    "std": 0.26736295223236084,
    "var": 0.07148295640945435,
    "min": -1.0101710557937622,
    "max": 1.247178316116333,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.5774791836738586,
    "std": 0.9216221570968628,
    "var": 0.8493874073028564,
    "min": -2.2884459495544434,
    "max": 2.3668742179870605,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.30119022727012634,
    "std": 0.1314423531293869,
    "var": 0.01727709174156189,
    "min": -0.6345781087875366,
    "max": 0.008299208246171474,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.20050236582756042,
    "std": 0.20691020786762238,
    "var": 0.04281183332204819,
    "min": -1.5063544511795044,
    "max": 0.807200014591217,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.7155095338821411,
    "std": 0.8195562958717346,
    "var": 0.671672523021698,
    "min": -0.8349067568778992,
    "max": 2.5064339637756348,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.29004570841789246,
    "std": 0.1433558166027069,
    "var": 0.020550893619656563,
    "min": -0.614901602268219,
    "max": 0.010804961435496807,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.1997005045413971,
    "std": 0.21551717817783356,
    "var": 0.04644765704870224,
    "min": -1.4842714071273804,
    "max": 0.6104555130004883,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.7877695560455322,
    "std": 0.8531950116157532,
    "var": 0.7279417514801025,
    "min": -2.322715997695923,
    "max": 3.4091591835021973,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.12875643372535706,
    "std": 0.08160252124071121,
    "var": 0.00665897224098444,
    "min": -0.35056161880493164,
    "max": 0.0644666850566864,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07969348877668381,
    "std": 0.15336565673351288,
    "var": 0.023521024733781815,
    "min": -1.1598803997039795,
    "max": 0.5846793055534363,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.000764534343034029,
    "std": 0.004100012127310038,
    "var": 1.6810097804409452e-05,
    "min": -0.0174007136374712,
    "max": 0.010221489705145359,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.00040060069295577705,
    "std": 0.10020019114017487,
    "var": 0.010040078312158585,
    "min": -0.9002243876457214,
    "max": 0.9797977209091187,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.008530941791832447,
    "std": 0.2679487466812134,
    "var": 0.07179653644561768,
    "min": -2.1690680980682373,
    "max": 1.71498441696167,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.1552276611328125,
    "std": 0.08169079571962357,
    "var": 0.006673385854810476,
    "min": -0.38198933005332947,
    "max": 0.06086674705147743,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07088640332221985,
    "std": 0.1490800827741623,
    "var": 0.022224873304367065,
    "min": -1.2341755628585815,
    "max": 0.5142835974693298,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.18206781148910522,
    "std": 0.7779131531715393,
    "var": 0.6051489114761353,
    "min": -2.1478095054626465,
    "max": 2.0811607837677,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.06454356014728546,
    "std": 0.12822498381137848,
    "var": 0.016441646963357925,
    "min": -0.307417631149292,
    "max": 0.3863508999347687,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.03590357303619385,
    "std": 0.13943691551685333,
    "var": 0.01944265142083168,
    "min": -0.963227391242981,
    "max": 0.5537022948265076,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.3320657014846802,
    "std": 0.46338018774986267,
    "var": 0.2147212028503418,
    "min": -0.8297052979469299,
    "max": 1.8276218175888062,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.00911560095846653,
    "std": 0.06328676640987396,
    "var": 0.004005215130746365,
    "min": -0.18561871349811554,
    "max": 0.10238200426101685,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.003934352193027735,
    "std": 0.21361729502677917,
    "var": 0.04563235118985176,
    "min": -0.9114221930503845,
    "max": 0.9416170716285706,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.008660282008349895,
    "std": 0.22771193087100983,
    "var": 0.05185272544622421,
    "min": -0.9569826126098633,
    "max": 1.147841453552246,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.20479433238506317,
    "std": 0.3730761706829071,
    "var": 0.1391858458518982,
    "min": -1.1044594049453735,
    "max": 1.172417163848877,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.32102715969085693,
    "std": 0.40706300735473633,
    "var": 0.1657002866268158,
    "min": -1.3782563209533691,
    "max": 0.813086211681366,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.5597009658813477,
    "std": 0.46118301153182983,
    "var": 0.21268975734710693,
    "min": -1.9368469715118408,
    "max": 0.4691486358642578,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.6231989860534668,
    "std": 0.653659999370575,
    "var": 0.42727142572402954,
    "min": -2.896207332611084,
    "max": 0.37643295526504517,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.0790119171142578,
    "std": 0.4164161682128906,
    "var": 0.17340242862701416,
    "min": -2.120373010635376,
    "max": 0.25500646233558655,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.1051909923553467,
    "std": 0.5778706669807434,
    "var": 0.3339345455169678,
    "min": -2.7222163677215576,
    "max": 0.25167927145957947,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.82 | loss:  0.61
-----------------------------------------------------------------------------------------
| epoch 121 | 1000/1179 batches | ms/batch 778.77 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.03
-----------------------------------------------------------------------------------------
| end of epoch 121 | time per epoch: 914.35s |
| Train Metrics | accuracy:  0.74 | loss:  1.04
| Eval  Metrics | accuracy:  0.82 | loss:  0.62
-----------------------------------------------------------------------------------------
| epoch 122 | 1000/1179 batches | ms/batch 862.44 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.05
-----------------------------------------------------------------------------------------
| end of epoch 122 | time per epoch: 1002.20s |
| Train Metrics | accuracy:  0.74 | loss:  1.06
| Eval  Metrics | accuracy:  0.83 | loss:  0.59
-----------------------------------------------------------------------------------------
[2025-02-27 06:00:42,349][absl][INFO] - Saving checkpoint at step: 143838
[2025-02-27 06:00:42,350][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 06:00:42,350][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 06:00:42,351][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_143838.
[2025-02-27 06:00:42,353][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 06:00:42,354][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_143838.orbax-checkpoint-tmp-43
[2025-02-27 06:00:42,362][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 06:00:42,389][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 06:00:42,423][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 150.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 60 milliseconds) (per-host)
[2025-02-27 06:00:42,657][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-27 06:00:42,657][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 294 milliseconds) (per-host)
[2025-02-27 06:00:42,665][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 06:00:42,697][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_143838.orbax-checkpoint-tmp-43 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_143838
[2025-02-27 06:00:42,703][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_143838`.
[2025-02-27 06:00:42,703][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 06:00:42,705][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_140301
| epoch 123 | 1000/1179 batches | ms/batch 818.68 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.03
-----------------------------------------------------------------------------------------
| end of epoch 123 | time per epoch: 956.12s |
| Train Metrics | accuracy:  0.74 | loss:  1.05
| Eval  Metrics | accuracy:  0.82 | loss:  0.62
-----------------------------------------------------------------------------------------
| epoch 124 | 1000/1179 batches | ms/batch 783.45 | Performance/Training accuracy:  0.73 | Performance/Training loss:  1.09
-----------------------------------------------------------------------------------------
| end of epoch 124 | time per epoch: 948.16s |
| Train Metrics | accuracy:  0.73 | loss:  1.08
| Eval  Metrics | accuracy:  0.83 | loss:  0.61
-----------------------------------------------------------------------------------------
| epoch 125 | 1000/1179 batches | ms/batch 917.90 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.04
-----------------------------------------------------------------------------------------
| end of epoch 125 | time per epoch: 1084.90s |
| Train Metrics | accuracy:  0.74 | loss:  1.04
| Eval  Metrics | accuracy:  0.83 | loss:  0.58
-----------------------------------------------------------------------------------------
[2025-02-27 06:54:23,595][absl][INFO] - Saving checkpoint at step: 147375
[2025-02-27 06:54:23,596][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 06:54:23,596][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 06:54:23,597][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_147375.
[2025-02-27 06:54:23,599][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 06:54:23,600][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_147375.orbax-checkpoint-tmp-44
[2025-02-27 06:54:23,607][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 06:54:23,633][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 06:54:23,666][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 158.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 57 milliseconds) (per-host)
[2025-02-27 06:54:23,905][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-27 06:54:23,906][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 297 milliseconds) (per-host)
[2025-02-27 06:54:23,911][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 06:54:23,939][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_147375.orbax-checkpoint-tmp-44 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_147375
[2025-02-27 06:54:23,945][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_147375`.
[2025-02-27 06:54:23,945][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 06:54:23,947][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_143838
| epoch 126 | 1000/1179 batches | ms/batch 759.02 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.08
-----------------------------------------------------------------------------------------
| end of epoch 126 | time per epoch: 916.96s |
| Train Metrics | accuracy:  0.74 | loss:  1.08
| Eval  Metrics | accuracy:  0.83 | loss:  0.58
-----------------------------------------------------------------------------------------
| epoch 127 | 1000/1179 batches | ms/batch 745.73 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 127 | time per epoch: 923.65s |
| Train Metrics | accuracy:  0.75 | loss:  1.00
| Eval  Metrics | accuracy:  0.82 | loss:  0.59
-----------------------------------------------------------------------------------------
| epoch 128 | 1000/1179 batches | ms/batch 862.18 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.02
-----------------------------------------------------------------------------------------
| end of epoch 128 | time per epoch: 969.16s |
| Train Metrics | accuracy:  0.74 | loss:  1.03
| Eval  Metrics | accuracy:  0.82 | loss:  0.63
-----------------------------------------------------------------------------------------
| epoch 129 | 1000/1179 batches | ms/batch 785.67 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 129 | time per epoch: 897.18s |
| Train Metrics | accuracy:  0.75 | loss:  1.00
| Eval  Metrics | accuracy:  0.83 | loss:  0.56
-----------------------------------------------------------------------------------------
| epoch 130 | 1000/1179 batches | ms/batch 841.62 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.03
-----------------------------------------------------------------------------------------
| end of epoch 130 | time per epoch: 1004.79s |
| Train Metrics | accuracy:  0.75 | loss:  1.03
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.2598370313644409,
    "std": 0.3789556920528412,
    "var": 0.14360740780830383,
    "min": -0.2140381932258606,
    "max": 1.1225517988204956,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.28581011295318604,
    "std": 0.22854115068912506,
    "var": 0.05223105475306511,
    "min": 0.03235040232539177,
    "max": 1.098659873008728,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0005451900651678443,
    "std": 0.11537984013557434,
    "var": 0.013312507420778275,
    "min": -0.7354600429534912,
    "max": 0.778058648109436,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.2760183811187744,
    "std": 0.24463021755218506,
    "var": 0.059843942523002625,
    "min": -0.05188075453042984,
    "max": 1.1213712692260742,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.36403870582580566,
    "std": 0.31576913595199585,
    "var": 0.09971015155315399,
    "min": 0.05046934634447098,
    "max": 1.47292160987854,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0011930131586268544,
    "std": 0.1220637634396553,
    "var": 0.014899562112987041,
    "min": -0.7774059176445007,
    "max": 0.6206750869750977,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2700999677181244,
    "std": 0.16778331995010376,
    "var": 0.028151242062449455,
    "min": -0.02946959249675274,
    "max": 0.7953963875770569,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.422097772359848,
    "std": 0.38536301255226135,
    "var": 0.14850465953350067,
    "min": 0.05641104653477669,
    "max": 2.1277334690093994,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0006727561703883111,
    "std": 0.12097219377756119,
    "var": 0.014634272083640099,
    "min": -0.757937490940094,
    "max": 0.9110797643661499,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.1891748607158661,
    "std": 0.2268676608800888,
    "var": 0.05146893858909607,
    "min": -0.37829214334487915,
    "max": 1.0773063898086548,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6529239416122437,
    "std": 0.26056697964668274,
    "var": 0.06789515912532806,
    "min": 0.054878171533346176,
    "max": 2.5441336631774902,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0005590445944108069,
    "std": 0.050588417798280716,
    "var": 0.0025591878220438957,
    "min": -0.6691034436225891,
    "max": 1.026865005493164,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.18288955092430115,
    "std": 0.244020015001297,
    "var": 0.059545766562223434,
    "min": -0.36380863189697266,
    "max": 1.1364811658859253,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6595619916915894,
    "std": 0.24919986724853516,
    "var": 0.062100574374198914,
    "min": 0.13523852825164795,
    "max": 1.8225524425506592,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0003707380674313754,
    "std": 0.059165943413972855,
    "var": 0.00350060872733593,
    "min": -0.5859001874923706,
    "max": 0.6298795342445374,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.03415711224079132,
    "std": 0.08940759301185608,
    "var": 0.007993718609213829,
    "min": -0.4005403518676758,
    "max": 0.21213068068027496,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.19987952709198,
    "std": 0.26294079422950745,
    "var": 0.06913786381483078,
    "min": 0.7081611752510071,
    "max": 2.362837314605713,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0003393040969967842,
    "std": 0.08820885419845581,
    "var": 0.007780801504850388,
    "min": -0.7635507583618164,
    "max": 0.6484150886535645,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.000290009134914726,
    "std": 0.07800032943487167,
    "var": 0.0060840509831905365,
    "min": -0.4432179927825928,
    "max": 0.4057059586048126,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 0.00010505047248443589,
    "std": 0.0809035450220108,
    "var": 0.006545383483171463,
    "min": -0.4317009747028351,
    "max": 0.4726443588733673,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0011947262100875378,
    "std": 0.07793594151735306,
    "var": 0.006074011325836182,
    "min": -0.5195629596710205,
    "max": 0.4076189696788788,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0001357492001261562,
    "std": 0.05279218778014183,
    "var": 0.0027870151679962873,
    "min": -0.40089428424835205,
    "max": 0.4645041823387146,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.0001958040811587125,
    "std": 0.06883209198713303,
    "var": 0.004737856797873974,
    "min": -0.4765135645866394,
    "max": 0.4051954448223114,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0009817993268370628,
    "std": 0.07423097640275955,
    "var": 0.005510238464921713,
    "min": -0.5284981727600098,
    "max": 0.4165748655796051,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3566255569458008,
    "std": 0.10034772008657455,
    "var": 0.010069665499031544,
    "min": -0.642545223236084,
    "max": -0.1827246993780136,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.0866735652089119,
    "std": 0.2659795582294464,
    "var": 0.07074513286352158,
    "min": -1.0006067752838135,
    "max": 1.1911207437515259,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.5433059334754944,
    "std": 0.9003086090087891,
    "var": 0.8105555772781372,
    "min": -2.252931833267212,
    "max": 2.2346909046173096,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.2982766628265381,
    "std": 0.13014453649520874,
    "var": 0.016937600448727608,
    "min": -0.6298419833183289,
    "max": -0.003977649845182896,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19865404069423676,
    "std": 0.20474682748317719,
    "var": 0.04192126542329788,
    "min": -1.3917014598846436,
    "max": 0.8373531699180603,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.6713604927062988,
    "std": 0.7821276187896729,
    "var": 0.6117236018180847,
    "min": -0.791733980178833,
    "max": 2.3495194911956787,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.29152190685272217,
    "std": 0.13913679122924805,
    "var": 0.019359048455953598,
    "min": -0.6009789705276489,
    "max": -0.0056160008534789085,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.19907550513744354,
    "std": 0.21275198459625244,
    "var": 0.04526340961456299,
    "min": -1.450516939163208,
    "max": 0.6282705068588257,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.7453842163085938,
    "std": 0.832217276096344,
    "var": 0.6925856471061707,
    "min": -2.294051170349121,
    "max": 3.2845847606658936,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.13261878490447998,
    "std": 0.07898040860891342,
    "var": 0.0062379054725170135,
    "min": -0.35891374945640564,
    "max": 0.0490088127553463,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07860499620437622,
    "std": 0.14967775344848633,
    "var": 0.022403430193662643,
    "min": -1.117140769958496,
    "max": 0.6407127380371094,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0010320035507902503,
    "std": 0.003611650550737977,
    "var": 1.3044020306551829e-05,
    "min": -0.014829606749117374,
    "max": 0.00930597260594368,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.0004113033937755972,
    "std": 0.09712181985378265,
    "var": 0.009432648308575153,
    "min": -0.9009541869163513,
    "max": 0.973694384098053,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.008382427506148815,
    "std": 0.24926994740962982,
    "var": 0.06213551014661789,
    "min": -2.0786561965942383,
    "max": 1.657970666885376,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.1538202166557312,
    "std": 0.07721737027168274,
    "var": 0.005962522234767675,
    "min": -0.3830467760562897,
    "max": 0.04242904856801033,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.07022591680288315,
    "std": 0.1452750414609909,
    "var": 0.02110484056174755,
    "min": -1.2405439615249634,
    "max": 0.5384316444396973,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.17265409231185913,
    "std": 0.7202249765396118,
    "var": 0.5187240242958069,
    "min": -2.037302017211914,
    "max": 1.959581971168518,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.06605824083089828,
    "std": 0.12436939775943756,
    "var": 0.015467748045921326,
    "min": -0.28730425238609314,
    "max": 0.3683375120162964,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.03358173742890358,
    "std": 0.13452409207820892,
    "var": 0.01809673197567463,
    "min": -0.9802848100662231,
    "max": 0.5749427080154419,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.3188985288143158,
    "std": 0.426233172416687,
    "var": 0.18167471885681152,
    "min": -0.6968145966529846,
    "max": 1.6944655179977417,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.00903837475925684,
    "std": 0.061872195452451706,
    "var": 0.003828168846666813,
    "min": -0.17536021769046783,
    "max": 0.10668479651212692,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.003945097327232361,
    "std": 0.21368764340877533,
    "var": 0.04566241055727005,
    "min": -0.9315517544746399,
    "max": 0.9437417984008789,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.008371477015316486,
    "std": 0.21568860113620758,
    "var": 0.04652157053351402,
    "min": -0.9314838647842407,
    "max": 1.1450612545013428,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.17231792211532593,
    "std": 0.36250975728034973,
    "var": 0.13141334056854248,
    "min": -1.0203545093536377,
    "max": 1.1955883502960205,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.2858715057373047,
    "std": 0.4054561257362366,
    "var": 0.16439467668533325,
    "min": -1.3645806312561035,
    "max": 0.853129506111145,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.5264784097671509,
    "std": 0.4584898352622986,
    "var": 0.21021294593811035,
    "min": -1.840045690536499,
    "max": 0.5028654932975769,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.590296745300293,
    "std": 0.6498585343360901,
    "var": 0.42231613397598267,
    "min": -2.791782855987549,
    "max": 0.46235010027885437,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -1.027601718902588,
    "std": 0.41731441020965576,
    "var": 0.17415133118629456,
    "min": -2.0912725925445557,
    "max": 0.2697283625602722,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.06805419921875,
    "std": 0.575680136680603,
    "var": 0.3314076066017151,
    "min": -2.6675426959991455,
    "max": 0.2538633346557617,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.83 | loss:  0.61
-----------------------------------------------------------------------------------------
| epoch 131 | 1000/1179 batches | ms/batch 772.35 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.05
-----------------------------------------------------------------------------------------
| end of epoch 131 | time per epoch: 936.18s |
| Train Metrics | accuracy:  0.74 | loss:  1.05
| Eval  Metrics | accuracy:  0.82 | loss:  0.62
-----------------------------------------------------------------------------------------
| epoch 132 | 1000/1179 batches | ms/batch 844.35 | Performance/Training accuracy:  0.74 | Performance/Training loss:  1.05
-----------------------------------------------------------------------------------------
| end of epoch 132 | time per epoch: 990.26s |
| Train Metrics | accuracy:  0.74 | loss:  1.07
| Eval  Metrics | accuracy:  0.83 | loss:  0.60
-----------------------------------------------------------------------------------------
| epoch 133 | 1000/1179 batches | ms/batch 863.80 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.02
-----------------------------------------------------------------------------------------
| end of epoch 133 | time per epoch: 1004.83s |
| Train Metrics | accuracy:  0.75 | loss:  1.04
| Eval  Metrics | accuracy:  0.83 | loss:  0.60
-----------------------------------------------------------------------------------------
| epoch 134 | 1000/1179 batches | ms/batch 757.55 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.02
-----------------------------------------------------------------------------------------
| end of epoch 134 | time per epoch: 917.44s |
| Train Metrics | accuracy:  0.75 | loss:  1.03
| Eval  Metrics | accuracy:  0.84 | loss:  0.56
-----------------------------------------------------------------------------------------
[2025-02-27 09:30:42,809][absl][INFO] - Saving checkpoint at step: 157986
[2025-02-27 09:30:42,813][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 09:30:42,813][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 09:30:42,815][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_157986.
[2025-02-27 09:30:42,817][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 09:30:42,818][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_157986.orbax-checkpoint-tmp-45
[2025-02-27 09:30:42,827][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 09:30:42,854][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 09:30:42,885][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 157.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 57 milliseconds) (per-host)
[2025-02-27 09:30:43,122][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-27 09:30:43,123][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 30.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 294 milliseconds) (per-host)
[2025-02-27 09:30:43,128][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 09:30:43,162][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_157986.orbax-checkpoint-tmp-45 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_157986
[2025-02-27 09:30:43,168][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_157986`.
[2025-02-27 09:30:43,168][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 09:30:43,170][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_147375
| epoch 135 | 1000/1179 batches | ms/batch 871.00 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.02
-----------------------------------------------------------------------------------------
| end of epoch 135 | time per epoch: 1068.34s |
| Train Metrics | accuracy:  0.75 | loss:  1.01
| Eval  Metrics | accuracy:  0.83 | loss:  0.58
-----------------------------------------------------------------------------------------
| epoch 136 | 1000/1179 batches | ms/batch 838.93 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 136 | time per epoch: 963.55s |
| Train Metrics | accuracy:  0.75 | loss:  1.01
| Eval  Metrics | accuracy:  0.83 | loss:  0.57
-----------------------------------------------------------------------------------------
| epoch 137 | 1000/1179 batches | ms/batch 850.59 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.03
-----------------------------------------------------------------------------------------
| end of epoch 137 | time per epoch: 1023.58s |
| Train Metrics | accuracy:  0.75 | loss:  1.04
| Eval  Metrics | accuracy:  0.83 | loss:  0.57
-----------------------------------------------------------------------------------------
| epoch 138 | 1000/1179 batches | ms/batch 722.38 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.02
-----------------------------------------------------------------------------------------
| end of epoch 138 | time per epoch: 867.12s |
| Train Metrics | accuracy:  0.75 | loss:  1.02
| Eval  Metrics | accuracy:  0.83 | loss:  0.55
-----------------------------------------------------------------------------------------
| epoch 139 | 1000/1179 batches | ms/batch 846.01 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.02
-----------------------------------------------------------------------------------------
| end of epoch 139 | time per epoch: 983.45s |
| Train Metrics | accuracy:  0.75 | loss:  1.01
| Eval  Metrics | accuracy:  0.84 | loss:  0.54
-----------------------------------------------------------------------------------------
[2025-02-27 11:00:16,130][absl][INFO] - Saving checkpoint at step: 163881
[2025-02-27 11:00:16,132][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 11:00:16,132][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 11:00:16,134][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_163881.
[2025-02-27 11:00:16,142][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 11:00:16,143][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_163881.orbax-checkpoint-tmp-46
[2025-02-27 11:00:16,150][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 11:00:16,179][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 11:00:16,212][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 149.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 61 milliseconds) (per-host)
[2025-02-27 11:00:16,456][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-27 11:00:16,456][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 29.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 305 milliseconds) (per-host)
[2025-02-27 11:00:16,462][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 11:00:16,493][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_163881.orbax-checkpoint-tmp-46 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_163881
[2025-02-27 11:00:16,499][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_163881`.
[2025-02-27 11:00:16,499][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 11:00:16,501][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_157986
| epoch 140 | 1000/1179 batches | ms/batch 895.38 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.01
-----------------------------------------------------------------------------------------
| end of epoch 140 | time per epoch: 1075.85s |
| Train Metrics | accuracy:  0.75 | loss:  1.02
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.26906538009643555,
    "std": 0.38990822434425354,
    "var": 0.152028426527977,
    "min": -0.21129196882247925,
    "max": 1.1373246908187866,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.2848723530769348,
    "std": 0.2402486503124237,
    "var": 0.05771941691637039,
    "min": 0.027145814150571823,
    "max": 1.1079356670379639,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0005690829129889607,
    "std": 0.1156662330031395,
    "var": 0.013378677889704704,
    "min": -0.7383620738983154,
    "max": 0.7743340134620667,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.2801598310470581,
    "std": 0.2521146833896637,
    "var": 0.0635618194937706,
    "min": -0.04476586729288101,
    "max": 1.1342781782150269,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.36484867334365845,
    "std": 0.3232974410057068,
    "var": 0.1045212373137474,
    "min": 0.034632522612810135,
    "max": 1.5002561807632446,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0013424244243651628,
    "std": 0.12224520742893219,
    "var": 0.014943890273571014,
    "min": -0.7850437164306641,
    "max": 0.6284938454627991,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2731654644012451,
    "std": 0.17109791934490204,
    "var": 0.02927449904382229,
    "min": -0.010679306462407112,
    "max": 0.8617643713951111,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.4266136586666107,
    "std": 0.3971917927265167,
    "var": 0.1577613204717636,
    "min": 0.04819473251700401,
    "max": 2.2209279537200928,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.000750666600652039,
    "std": 0.12124598771333694,
    "var": 0.014700589701533318,
    "min": -0.7708735466003418,
    "max": 0.9189770221710205,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.19675278663635254,
    "std": 0.2259516566991806,
    "var": 0.051054149866104126,
    "min": -0.33991339802742004,
    "max": 1.0914721488952637,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6500393152236938,
    "std": 0.25659042596817017,
    "var": 0.06583865731954575,
    "min": 0.059289295226335526,
    "max": 2.5058517456054688,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0005515195662155747,
    "std": 0.050025660544633865,
    "var": 0.0025025666691362858,
    "min": -0.6650485992431641,
    "max": 1.0268843173980713,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.190855473279953,
    "std": 0.2419513612985611,
    "var": 0.0585404634475708,
    "min": -0.3467561602592468,
    "max": 1.1223773956298828,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6536394357681274,
    "std": 0.24446333944797516,
    "var": 0.05976232886314392,
    "min": 0.12177947163581848,
    "max": 1.8112457990646362,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0003578214382287115,
    "std": 0.05912140756845474,
    "var": 0.0034953407011926174,
    "min": -0.5853483080863953,
    "max": 0.6484101414680481,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.02891397848725319,
    "std": 0.08783169090747833,
    "var": 0.007714405655860901,
    "min": -0.37961912155151367,
    "max": 0.22929294407367706,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.2223541736602783,
    "std": 0.26061028242111206,
    "var": 0.06791772693395615,
    "min": 0.7610675692558289,
    "max": 2.3661296367645264,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0002775945467874408,
    "std": 0.0884629637002945,
    "var": 0.007825695909559727,
    "min": -0.7730180025100708,
    "max": 0.6502887606620789,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0003793034702539444,
    "std": 0.07235874980688095,
    "var": 0.005235788878053427,
    "min": -0.3949931263923645,
    "max": 0.35199424624443054,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": -8.925252586777788e-06,
    "std": 0.07487688958644867,
    "var": 0.005606548860669136,
    "min": -0.3931726813316345,
    "max": 0.45061495900154114,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0011686603538691998,
    "std": 0.07246458530426025,
    "var": 0.005251116119325161,
    "min": -0.4656859040260315,
    "max": 0.36942413449287415,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -5.781869913334958e-05,
    "std": 0.0487276166677475,
    "var": 0.0023743808269500732,
    "min": -0.35168248414993286,
    "max": 0.41792866587638855,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.0001211112248711288,
    "std": 0.06427976489067078,
    "var": 0.004131888039410114,
    "min": -0.47672736644744873,
    "max": 0.41147705912590027,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0009301933459937572,
    "std": 0.06879943609237671,
    "var": 0.0047333622351288795,
    "min": -0.4945244789123535,
    "max": 0.3758290112018585,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3535662889480591,
    "std": 0.10041419416666031,
    "var": 0.010083010420203209,
    "min": -0.6301002502441406,
    "max": -0.17514999210834503,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.0867239311337471,
    "std": 0.2639292776584625,
    "var": 0.06965865939855576,
    "min": -1.012248158454895,
    "max": 1.2020306587219238,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.5130661725997925,
    "std": 0.8748531341552734,
    "var": 0.7653679847717285,
    "min": -2.2256717681884766,
    "max": 2.1747372150421143,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.2959883213043213,
    "std": 0.1295340210199356,
    "var": 0.016779063269495964,
    "min": -0.6467116475105286,
    "max": -0.007112549152225256,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19729763269424438,
    "std": 0.20187562704086304,
    "var": 0.040753770619630814,
    "min": -1.3514933586120605,
    "max": 0.8476216793060303,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.628076434135437,
    "std": 0.7463452816009521,
    "var": 0.5570312738418579,
    "min": -0.8480883836746216,
    "max": 2.2173056602478027,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.29323524236679077,
    "std": 0.1347702294588089,
    "var": 0.018163016065955162,
    "min": -0.6189748048782349,
    "max": -0.0077366516925394535,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.19893816113471985,
    "std": 0.20989878475666046,
    "var": 0.04405749961733818,
    "min": -1.4370375871658325,
    "max": 0.6160575747489929,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.7001891136169434,
    "std": 0.8092969655990601,
    "var": 0.6549615263938904,
    "min": -2.3269340991973877,
    "max": 3.1674463748931885,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.1363096982240677,
    "std": 0.07601961493492126,
    "var": 0.005778982304036617,
    "min": -0.35628631711006165,
    "max": 0.03876292705535889,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07791466265916824,
    "std": 0.1457052379846573,
    "var": 0.021230017766356468,
    "min": -1.127292513847351,
    "max": 0.6714295148849487,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0008627744391560555,
    "std": 0.0030104080215096474,
    "var": 9.062557182915043e-06,
    "min": -0.012054848484694958,
    "max": 0.0067094857804477215,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.0005380770890042186,
    "std": 0.09414050728082657,
    "var": 0.008862434886395931,
    "min": -0.8738662600517273,
    "max": 0.9171773195266724,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.007709393743425608,
    "std": 0.22990752756595612,
    "var": 0.052857473492622375,
    "min": -1.902022361755371,
    "max": 1.5072340965270996,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15313473343849182,
    "std": 0.07274246960878372,
    "var": 0.0052914670668542385,
    "min": -0.3531648516654968,
    "max": 0.030237732455134392,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.06931903958320618,
    "std": 0.14133775234222412,
    "var": 0.019976360723376274,
    "min": -1.2279835939407349,
    "max": 0.5548394918441772,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.1620093584060669,
    "std": 0.6633567810058594,
    "var": 0.4400421977043152,
    "min": -1.9012064933776855,
    "max": 1.822865605354309,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.06994901597499847,
    "std": 0.11957018822431564,
    "var": 0.014297029934823513,
    "min": -0.2571994662284851,
    "max": 0.35495638847351074,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.031630177050828934,
    "std": 0.12992848455905914,
    "var": 0.016881413757801056,
    "min": -0.9836171269416809,
    "max": 0.5353853702545166,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.3001258671283722,
    "std": 0.3962959349155426,
    "var": 0.1570504754781723,
    "min": -0.6200196743011475,
    "max": 1.5798909664154053,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.008608462288975716,
    "std": 0.05889880657196045,
    "var": 0.0034690694883465767,
    "min": -0.16242101788520813,
    "max": 0.09936586767435074,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.004157694987952709,
    "std": 0.2131887674331665,
    "var": 0.045449450612068176,
    "min": -0.9253937005996704,
    "max": 0.9490017294883728,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.008453421294689178,
    "std": 0.202985480427742,
    "var": 0.04120310768485069,
    "min": -0.8603940606117249,
    "max": 1.0534287691116333,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.13400432467460632,
    "std": 0.35278981924057007,
    "var": 0.12446065247058868,
    "min": -0.9776208996772766,
    "max": 1.2399160861968994,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.2591972351074219,
    "std": 0.4035208821296692,
    "var": 0.16282910108566284,
    "min": -1.3141844272613525,
    "max": 0.8851672410964966,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.49167653918266296,
    "std": 0.45774340629577637,
    "var": 0.20952904224395752,
    "min": -1.8008173704147339,
    "max": 0.5331072211265564,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.5390901565551758,
    "std": 0.6370142698287964,
    "var": 0.4057871699333191,
    "min": -2.763472318649292,
    "max": 0.5538628101348877,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.9740301966667175,
    "std": 0.415534645318985,
    "var": 0.17266905307769775,
    "min": -2.0222089290618896,
    "max": 0.27203628420829773,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.0361390113830566,
    "std": 0.572455883026123,
    "var": 0.3277057409286499,
    "min": -2.668126344680786,
    "max": 0.25953808426856995,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.83 | loss:  0.58
-----------------------------------------------------------------------------------------
| epoch 141 | 1000/1179 batches | ms/batch 893.69 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.03
-----------------------------------------------------------------------------------------
| end of epoch 141 | time per epoch: 1050.00s |
| Train Metrics | accuracy:  0.75 | loss:  1.03
| Eval  Metrics | accuracy:  0.83 | loss:  0.57
-----------------------------------------------------------------------------------------
| epoch 142 | 1000/1179 batches | ms/batch 869.30 | Performance/Training accuracy:  0.76 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 142 | time per epoch: 1023.66s |
| Train Metrics | accuracy:  0.75 | loss:  1.01
| Eval  Metrics | accuracy:  0.84 | loss:  0.56
-----------------------------------------------------------------------------------------
| epoch 143 | 1000/1179 batches | ms/batch 995.69 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.97
-----------------------------------------------------------------------------------------
| end of epoch 143 | time per epoch: 1159.62s |
| Train Metrics | accuracy:  0.76 | loss:  0.98
| Eval  Metrics | accuracy:  0.84 | loss:  0.58
-----------------------------------------------------------------------------------------
| epoch 144 | 1000/1179 batches | ms/batch 873.70 | Performance/Training accuracy:  0.75 | Performance/Training loss:  1.02
-----------------------------------------------------------------------------------------
| end of epoch 144 | time per epoch: 1026.93s |
| Train Metrics | accuracy:  0.75 | loss:  1.02
| Eval  Metrics | accuracy:  0.83 | loss:  0.57
-----------------------------------------------------------------------------------------
| epoch 145 | 1000/1179 batches | ms/batch 800.84 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.98
-----------------------------------------------------------------------------------------
| end of epoch 145 | time per epoch: 944.66s |
| Train Metrics | accuracy:  0.76 | loss:  0.98
| Eval  Metrics | accuracy:  0.84 | loss:  0.58
-----------------------------------------------------------------------------------------
| epoch 146 | 1000/1179 batches | ms/batch 797.66 | Performance/Training accuracy:  0.76 | Performance/Training loss:  1.01
-----------------------------------------------------------------------------------------
| end of epoch 146 | time per epoch: 921.88s |
| Train Metrics | accuracy:  0.75 | loss:  1.01
| Eval  Metrics | accuracy:  0.83 | loss:  0.58
-----------------------------------------------------------------------------------------
| epoch 147 | 1000/1179 batches | ms/batch 774.58 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.98
-----------------------------------------------------------------------------------------
| end of epoch 147 | time per epoch: 882.22s |
| Train Metrics | accuracy:  0.76 | loss:  0.98
| Eval  Metrics | accuracy:  0.84 | loss:  0.56
-----------------------------------------------------------------------------------------
| epoch 148 | 1000/1179 batches | ms/batch 773.57 | Performance/Training accuracy:  0.76 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 148 | time per epoch: 909.02s |
| Train Metrics | accuracy:  0.76 | loss:  1.01
| Eval  Metrics | accuracy:  0.84 | loss:  0.57
-----------------------------------------------------------------------------------------
| epoch 149 | 1000/1179 batches | ms/batch 834.72 | Performance/Training accuracy:  0.76 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 149 | time per epoch: 993.30s |
| Train Metrics | accuracy:  0.76 | loss:  0.99
| Eval  Metrics | accuracy:  0.84 | loss:  0.58
-----------------------------------------------------------------------------------------
[2025-02-27 14:02:09,991][absl][INFO] - Saving checkpoint at step: 175671
[2025-02-27 14:02:09,993][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 14:02:09,993][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 14:02:09,994][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_175671.
[2025-02-27 14:02:09,997][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 14:02:09,999][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_175671.orbax-checkpoint-tmp-47
[2025-02-27 14:02:10,008][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 14:02:10,445][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 14:02:10,475][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 19.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 466 milliseconds) (per-host)
[2025-02-27 14:02:10,727][absl][INFO] - ChainedFuture completed 1/1 futures in 0.25 seconds.
[2025-02-27 14:02:10,728][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 12.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 718 milliseconds) (per-host)
[2025-02-27 14:02:10,734][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 14:02:10,769][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_175671.orbax-checkpoint-tmp-47 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_175671
[2025-02-27 14:02:10,776][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_175671`.
[2025-02-27 14:02:10,776][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 14:02:10,778][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_163881
| epoch 150 | 1000/1179 batches | ms/batch 815.05 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.99
-----------------------------------------------------------------------------------------
| end of epoch 150 | time per epoch: 967.00s |
| Train Metrics | accuracy:  0.76 | loss:  0.98
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.27342191338539124,
    "std": 0.39339154958724976,
    "var": 0.15475690364837646,
    "min": -0.19584554433822632,
    "max": 1.1345241069793701,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.2869020402431488,
    "std": 0.25226956605911255,
    "var": 0.06363993883132935,
    "min": 0.016049399971961975,
    "max": 1.1810792684555054,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0005715106963180006,
    "std": 0.11576856672763824,
    "var": 0.013402360491454601,
    "min": -0.7407659888267517,
    "max": 0.7734982967376709,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.28523555397987366,
    "std": 0.26115527749061584,
    "var": 0.06820208579301834,
    "min": -0.049729425460100174,
    "max": 1.1639658212661743,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.3637995421886444,
    "std": 0.3313710391521454,
    "var": 0.10980676114559174,
    "min": 0.03735656291246414,
    "max": 1.5301754474639893,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0013580527156591415,
    "std": 0.12242565304040909,
    "var": 0.014988040551543236,
    "min": -0.7896540760993958,
    "max": 0.6349917054176331,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.275499165058136,
    "std": 0.1725640892982483,
    "var": 0.029778361320495605,
    "min": -0.008317236788570881,
    "max": 0.8899226188659668,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.42680495977401733,
    "std": 0.40541332960128784,
    "var": 0.16435997188091278,
    "min": 0.041781146079301834,
    "max": 2.2695984840393066,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0007652537315152586,
    "std": 0.12138354778289795,
    "var": 0.014733965508639812,
    "min": -0.7772486209869385,
    "max": 0.9218248724937439,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.2037186324596405,
    "std": 0.2242518663406372,
    "var": 0.05028889700770378,
    "min": -0.3287794888019562,
    "max": 1.0884032249450684,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6454359292984009,
    "std": 0.25814300775527954,
    "var": 0.06663782149553299,
    "min": 0.05161942541599274,
    "max": 2.5568315982818604,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0005543499137274921,
    "std": 0.04966311901807785,
    "var": 0.002466425532475114,
    "min": -0.6659113764762878,
    "max": 1.024554967880249,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.1965237855911255,
    "std": 0.23822467029094696,
    "var": 0.05675099417567253,
    "min": -0.3155321478843689,
    "max": 1.0919528007507324,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.650097131729126,
    "std": 0.24129123985767365,
    "var": 0.05822146683931351,
    "min": 0.12211766839027405,
    "max": 1.8611855506896973,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00037209870060905814,
    "std": 0.059085819870233536,
    "var": 0.0034911343827843666,
    "min": -0.5949118733406067,
    "max": 0.6465352177619934,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.023631885647773743,
    "std": 0.08521553874015808,
    "var": 0.00726168742403388,
    "min": -0.33654066920280457,
    "max": 0.23933929204940796,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.2428500652313232,
    "std": 0.2608969509601593,
    "var": 0.06806721538305283,
    "min": 0.7829861640930176,
    "max": 2.387758731842041,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0003103907802142203,
    "std": 0.08860547095537186,
    "var": 0.007850930094718933,
    "min": -0.7801430225372314,
    "max": 0.6547660231590271,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0002573729434516281,
    "std": 0.06713857501745224,
    "var": 0.004507588222622871,
    "min": -0.34811869263648987,
    "max": 0.32521525025367737,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 4.113838076591492e-05,
    "std": 0.06952255964279175,
    "var": 0.004833386745303869,
    "min": -0.3664466142654419,
    "max": 0.4328141510486603,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0012306941207498312,
    "std": 0.06723658740520477,
    "var": 0.0045207589864730835,
    "min": -0.4391504228115082,
    "max": 0.3394463360309601,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -1.1922165867872536e-05,
    "std": 0.04531755670905113,
    "var": 0.0020536810625344515,
    "min": -0.32039955258369446,
    "max": 0.3596053421497345,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.00018588174134492874,
    "std": 0.06005670502781868,
    "var": 0.003606808139011264,
    "min": -0.44923529028892517,
    "max": 0.3626340329647064,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0007096321205608547,
    "std": 0.06396810710430145,
    "var": 0.004091918934136629,
    "min": -0.4528910219669342,
    "max": 0.34044674038887024,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3483657240867615,
    "std": 0.10091781616210938,
    "var": 0.01018440630286932,
    "min": -0.6462110877037048,
    "max": -0.1725517362356186,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08635435253381729,
    "std": 0.26200804114341736,
    "var": 0.06864821910858154,
    "min": -0.9762183427810669,
    "max": 1.1669150590896606,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.4903373122215271,
    "std": 0.8572160005569458,
    "var": 0.7348192930221558,
    "min": -2.155410051345825,
    "max": 2.0650250911712646,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.2938308119773865,
    "std": 0.12773756682872772,
    "var": 0.016316886991262436,
    "min": -0.6336479783058167,
    "max": 0.005673499777913094,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19602079689502716,
    "std": 0.1988084763288498,
    "var": 0.03952481225132942,
    "min": -1.3526543378829956,
    "max": 0.7797131538391113,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.5945145487785339,
    "std": 0.7075491547584534,
    "var": 0.5006258487701416,
    "min": -0.8089203238487244,
    "max": 2.1327502727508545,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.29547107219696045,
    "std": 0.1313844621181488,
    "var": 0.017261875793337822,
    "min": -0.6239033341407776,
    "max": -0.025519030168652534,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.19844622910022736,
    "std": 0.20666275918483734,
    "var": 0.04270949587225914,
    "min": -1.412222981452942,
    "max": 0.6399443745613098,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.656262218952179,
    "std": 0.7813467383384705,
    "var": 0.6105027794837952,
    "min": -2.314229726791382,
    "max": 3.012014389038086,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.1395556777715683,
    "std": 0.072310671210289,
    "var": 0.005228833295404911,
    "min": -0.3483102321624756,
    "max": 0.02005624584853649,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07748281955718994,
    "std": 0.14211080968379974,
    "var": 0.020195480436086655,
    "min": -1.176626205444336,
    "max": 0.6589229106903076,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0009404250304214656,
    "std": 0.002851491328328848,
    "var": 8.131002687150612e-06,
    "min": -0.009844266809523106,
    "max": 0.00556916231289506,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.0007154751801863313,
    "std": 0.09098716080188751,
    "var": 0.008278663270175457,
    "min": -0.8330923318862915,
    "max": 0.8797575831413269,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.007083574775606394,
    "std": 0.2135668843984604,
    "var": 0.04561081528663635,
    "min": -1.7903151512145996,
    "max": 1.4138740301132202,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15251579880714417,
    "std": 0.07124834507703781,
    "var": 0.005076327361166477,
    "min": -0.35506200790405273,
    "max": 0.025419455021619797,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.06850879639387131,
    "std": 0.1379898339509964,
    "var": 0.019041195511817932,
    "min": -1.2381644248962402,
    "max": 0.5753660202026367,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.15045340359210968,
    "std": 0.61610347032547,
    "var": 0.379583477973938,
    "min": -1.7748427391052246,
    "max": 1.7025896310806274,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.07398814707994461,
    "std": 0.11828567087650299,
    "var": 0.01399150025099516,
    "min": -0.2627440392971039,
    "max": 0.36532703042030334,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.030032554641366005,
    "std": 0.12601760029792786,
    "var": 0.015880435705184937,
    "min": -0.9525525569915771,
    "max": 0.5062901973724365,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.281282901763916,
    "std": 0.37153932452201843,
    "var": 0.13804146647453308,
    "min": -0.5523141026496887,
    "max": 1.4596105813980103,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.008819201961159706,
    "std": 0.0595872662961483,
    "var": 0.0035506426356732845,
    "min": -0.15669076144695282,
    "max": 0.11048641800880432,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.00398960430175066,
    "std": 0.21311606466770172,
    "var": 0.04541845992207527,
    "min": -0.9163878560066223,
    "max": 0.9367477893829346,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.008274804800748825,
    "std": 0.19196170568466187,
    "var": 0.03684929385781288,
    "min": -0.8203210830688477,
    "max": 0.9899783730506897,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.10001854598522186,
    "std": 0.3411826193332672,
    "var": 0.11640559136867523,
    "min": -0.9188635349273682,
    "max": 1.220727562904358,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.23822125792503357,
    "std": 0.395279198884964,
    "var": 0.1562456488609314,
    "min": -1.2927905321121216,
    "max": 0.8734116554260254,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.4629930257797241,
    "std": 0.44883501529693604,
    "var": 0.20145288109779358,
    "min": -1.7481385469436646,
    "max": 0.547392725944519,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.4823622703552246,
    "std": 0.6220415830612183,
    "var": 0.3869357109069824,
    "min": -2.6985321044921875,
    "max": 0.5852084755897522,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.929681658744812,
    "std": 0.4127398729324341,
    "var": 0.1703542172908783,
    "min": -1.9783084392547607,
    "max": 0.26033979654312134,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -1.0089805126190186,
    "std": 0.5668158531188965,
    "var": 0.32128024101257324,
    "min": -2.6211414337158203,
    "max": 0.26006877422332764,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.84 | loss:  0.54
-----------------------------------------------------------------------------------------
[2025-02-27 14:19:53,213][absl][INFO] - Saving checkpoint at step: 176850
[2025-02-27 14:19:53,215][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 14:19:53,215][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 14:19:53,217][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_176850.
[2025-02-27 14:19:53,219][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 14:19:53,220][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_176850.orbax-checkpoint-tmp-48
[2025-02-27 14:19:53,226][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 14:19:53,253][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 14:19:53,284][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 159.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 57 milliseconds) (per-host)
[2025-02-27 14:19:53,521][absl][INFO] - ChainedFuture completed 1/1 futures in 0.24 seconds.
[2025-02-27 14:19:53,521][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 293 milliseconds) (per-host)
[2025-02-27 14:19:53,527][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 14:19:53,560][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_176850.orbax-checkpoint-tmp-48 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_176850
[2025-02-27 14:19:53,566][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_176850`.
[2025-02-27 14:19:53,566][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 14:19:53,568][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_175671
| epoch 151 | 1000/1179 batches | ms/batch 848.13 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.95
-----------------------------------------------------------------------------------------
| end of epoch 151 | time per epoch: 1004.42s |
| Train Metrics | accuracy:  0.77 | loss:  0.95
| Eval  Metrics | accuracy:  0.84 | loss:  0.54
-----------------------------------------------------------------------------------------
| epoch 152 | 1000/1179 batches | ms/batch 796.58 | Performance/Training accuracy:  0.76 | Performance/Training loss:  1.00
-----------------------------------------------------------------------------------------
| end of epoch 152 | time per epoch: 920.38s |
| Train Metrics | accuracy:  0.76 | loss:  0.99
| Eval  Metrics | accuracy:  0.84 | loss:  0.55
-----------------------------------------------------------------------------------------
| epoch 153 | 1000/1179 batches | ms/batch 837.16 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.95
-----------------------------------------------------------------------------------------
| end of epoch 153 | time per epoch: 976.15s |
| Train Metrics | accuracy:  0.77 | loss:  0.95
| Eval  Metrics | accuracy:  0.84 | loss:  0.57
-----------------------------------------------------------------------------------------
| epoch 154 | 1000/1179 batches | ms/batch 744.33 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.99
-----------------------------------------------------------------------------------------
| end of epoch 154 | time per epoch: 880.41s |
| Train Metrics | accuracy:  0.76 | loss:  1.00
| Eval  Metrics | accuracy:  0.84 | loss:  0.57
-----------------------------------------------------------------------------------------
| epoch 155 | 1000/1179 batches | ms/batch 731.68 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.96
-----------------------------------------------------------------------------------------
| end of epoch 155 | time per epoch: 881.05s |
| Train Metrics | accuracy:  0.77 | loss:  0.96
| Eval  Metrics | accuracy:  0.84 | loss:  0.57
-----------------------------------------------------------------------------------------
| epoch 156 | 1000/1179 batches | ms/batch 836.86 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.93
-----------------------------------------------------------------------------------------
| end of epoch 156 | time per epoch: 992.90s |
| Train Metrics | accuracy:  0.77 | loss:  0.94
| Eval  Metrics | accuracy:  0.84 | loss:  0.54
-----------------------------------------------------------------------------------------
| epoch 157 | 1000/1179 batches | ms/batch 835.60 | Performance/Training accuracy:  0.76 | Performance/Training loss:  0.98
-----------------------------------------------------------------------------------------
| end of epoch 157 | time per epoch: 963.34s |
| Train Metrics | accuracy:  0.76 | loss:  0.99
| Eval  Metrics | accuracy:  0.84 | loss:  0.58
-----------------------------------------------------------------------------------------
| epoch 158 | 1000/1179 batches | ms/batch 894.56 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.96
-----------------------------------------------------------------------------------------
| end of epoch 158 | time per epoch: 1067.33s |
| Train Metrics | accuracy:  0.77 | loss:  0.97
| Eval  Metrics | accuracy:  0.84 | loss:  0.54
-----------------------------------------------------------------------------------------
[2025-02-27 16:38:23,807][absl][INFO] - Saving checkpoint at step: 186282
[2025-02-27 16:38:23,809][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 16:38:23,809][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 16:38:23,810][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_186282.
[2025-02-27 16:38:23,813][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 16:38:23,814][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_186282.orbax-checkpoint-tmp-49
[2025-02-27 16:38:23,822][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 16:38:23,849][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 16:38:23,879][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 161.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 56 milliseconds) (per-host)
[2025-02-27 16:38:24,101][absl][INFO] - ChainedFuture completed 1/1 futures in 0.22 seconds.
[2025-02-27 16:38:24,101][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 32.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 278 milliseconds) (per-host)
[2025-02-27 16:38:24,107][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 16:38:24,140][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_186282.orbax-checkpoint-tmp-49 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_186282
[2025-02-27 16:38:24,147][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_186282`.
[2025-02-27 16:38:24,147][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 16:38:24,149][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_176850
| epoch 159 | 1000/1179 batches | ms/batch 768.82 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.92
-----------------------------------------------------------------------------------------
| end of epoch 159 | time per epoch: 919.82s |
| Train Metrics | accuracy:  0.77 | loss:  0.92
| Eval  Metrics | accuracy:  0.84 | loss:  0.55
-----------------------------------------------------------------------------------------
| epoch 160 | 1000/1179 batches | ms/batch 864.40 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.96
-----------------------------------------------------------------------------------------
| end of epoch 160 | time per epoch: 1041.54s |
| Train Metrics | accuracy:  0.77 | loss:  0.96
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.27720552682876587,
    "std": 0.3996625244617462,
    "var": 0.15973013639450073,
    "min": -0.19046540558338165,
    "max": 1.171730875968933,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.28835567831993103,
    "std": 0.26232051849365234,
    "var": 0.0688120499253273,
    "min": 0.011606545187532902,
    "max": 1.2148654460906982,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0005828438443131745,
    "std": 0.11581166833639145,
    "var": 0.013412343338131905,
    "min": -0.7385866045951843,
    "max": 0.7729188203811646,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.28965601325035095,
    "std": 0.26825979351997375,
    "var": 0.07196332514286041,
    "min": -0.04905247688293457,
    "max": 1.1728790998458862,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.36607760190963745,
    "std": 0.3414510488510132,
    "var": 0.11658883094787598,
    "min": 0.030415480956435204,
    "max": 1.5765864849090576,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0013460395857691765,
    "std": 0.12251900881528854,
    "var": 0.01501090731471777,
    "min": -0.7922918200492859,
    "max": 0.6367810964584351,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2789815664291382,
    "std": 0.17641648650169373,
    "var": 0.031122779473662376,
    "min": -0.010499217547476292,
    "max": 0.9201102256774902,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.4284553527832031,
    "std": 0.4157731235027313,
    "var": 0.1728672981262207,
    "min": 0.03287804499268532,
    "max": 2.3192319869995117,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0007480253698304296,
    "std": 0.12143278121948242,
    "var": 0.014745920896530151,
    "min": -0.7799627780914307,
    "max": 0.9223428964614868,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.21106182038784027,
    "std": 0.2231222540140152,
    "var": 0.04978353902697563,
    "min": -0.3211420178413391,
    "max": 1.0856889486312866,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.639487624168396,
    "std": 0.25647881627082825,
    "var": 0.06578138470649719,
    "min": 0.04514576122164726,
    "max": 2.556023359298706,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0005355344037525356,
    "std": 0.049469538033008575,
    "var": 0.0024472353979945183,
    "min": -0.6636888384819031,
    "max": 1.0216915607452393,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.203698992729187,
    "std": 0.2374943345785141,
    "var": 0.05640355870127678,
    "min": -0.3074907064437866,
    "max": 1.0827265977859497,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6458937525749207,
    "std": 0.23916271328926086,
    "var": 0.05719880387187004,
    "min": 0.11979887634515762,
    "max": 1.871111512184143,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0003728244628291577,
    "std": 0.059075549244880676,
    "var": 0.0034899204038083553,
    "min": -0.5954505801200867,
    "max": 0.6474388837814331,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.01912562921643257,
    "std": 0.08434674143791199,
    "var": 0.007114372681826353,
    "min": -0.3210252821445465,
    "max": 0.23344603180885315,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.261979341506958,
    "std": 0.2608926594257355,
    "var": 0.06806498765945435,
    "min": 0.8265566825866699,
    "max": 2.4188802242279053,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00030161929316818714,
    "std": 0.08867326378822327,
    "var": 0.007862947881221771,
    "min": -0.7843125462532043,
    "max": 0.6578300595283508,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00040140311466529965,
    "std": 0.06251844763755798,
    "var": 0.003908556420356035,
    "min": -0.3390916585922241,
    "max": 0.2905796468257904,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 9.637877519708127e-05,
    "std": 0.06500696390867233,
    "var": 0.004225905518978834,
    "min": -0.33461910486221313,
    "max": 0.3991936445236206,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0010003054048866034,
    "std": 0.06266969442367554,
    "var": 0.0039274911396205425,
    "min": -0.41016101837158203,
    "max": 0.31125813722610474,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -5.825807966175489e-05,
    "std": 0.0424947664141655,
    "var": 0.001805805368348956,
    "min": -0.2934407591819763,
    "max": 0.32218489050865173,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.00014193417155183852,
    "std": 0.056476153433322906,
    "var": 0.0031895560678094625,
    "min": -0.43270251154899597,
    "max": 0.3376108407974243,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0006523019401356578,
    "std": 0.059799935668706894,
    "var": 0.0035760323517024517,
    "min": -0.42374369502067566,
    "max": 0.325044721364975,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.34651994705200195,
    "std": 0.10060624033212662,
    "var": 0.01012161560356617,
    "min": -0.6193872690200806,
    "max": -0.16864287853240967,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.086729034781456,
    "std": 0.2608564496040344,
    "var": 0.06804609298706055,
    "min": -0.9647319912910461,
    "max": 1.1225794553756714,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.47477003931999207,
    "std": 0.8431624174118042,
    "var": 0.71092289686203,
    "min": -2.134120464324951,
    "max": 2.016009569168091,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.29271212220191956,
    "std": 0.1276230812072754,
    "var": 0.016287652775645256,
    "min": -0.6421738266944885,
    "max": 0.0031887271907180548,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19512934982776642,
    "std": 0.19679227471351624,
    "var": 0.03872719779610634,
    "min": -1.338098406791687,
    "max": 0.7456359267234802,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.5638394355773926,
    "std": 0.6778365969657898,
    "var": 0.4594624936580658,
    "min": -0.7653384804725647,
    "max": 2.04951810836792,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.29739969968795776,
    "std": 0.12957827746868134,
    "var": 0.01679052971303463,
    "min": -0.6253364682197571,
    "max": -0.04117157310247421,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.19881783425807953,
    "std": 0.20437410473823547,
    "var": 0.04176877811551094,
    "min": -1.350836157798767,
    "max": 0.6633217930793762,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.6211236119270325,
    "std": 0.7557843327522278,
    "var": 0.5712099671363831,
    "min": -2.284297227859497,
    "max": 2.8920154571533203,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.14291580021381378,
    "std": 0.07010295987129211,
    "var": 0.004914425313472748,
    "min": -0.3523314893245697,
    "max": 0.013911730609834194,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.077101930975914,
    "std": 0.13911792635917664,
    "var": 0.019353797659277916,
    "min": -1.1356080770492554,
    "max": 0.7026179432868958,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0007561427773907781,
    "std": 0.0025376565754413605,
    "var": 6.4397008827654645e-06,
    "min": -0.011782054789364338,
    "max": 0.005780510138720274,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.0007078739581629634,
    "std": 0.08835425972938538,
    "var": 0.0078064757399261,
    "min": -0.8130683302879333,
    "max": 0.8341744542121887,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.006333961151540279,
    "std": 0.19969604909420013,
    "var": 0.03987850993871689,
    "min": -1.6675766706466675,
    "max": 1.337228536605835,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15332850813865662,
    "std": 0.06968216598033905,
    "var": 0.004855604376643896,
    "min": -0.3414385914802551,
    "max": 0.016574012115597725,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.06824280321598053,
    "std": 0.13507454097270966,
    "var": 0.01824513077735901,
    "min": -1.2559598684310913,
    "max": 0.5957956314086914,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.13866713643074036,
    "std": 0.5752023458480835,
    "var": 0.3308577537536621,
    "min": -1.653914213180542,
    "max": 1.5921905040740967,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.07794220745563507,
    "std": 0.11668626964092255,
    "var": 0.013615685515105724,
    "min": -0.25045499205589294,
    "max": 0.36236992478370667,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.02824164740741253,
    "std": 0.12272115051746368,
    "var": 0.015060481615364552,
    "min": -0.9343293905258179,
    "max": 0.5366197824478149,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.2665780484676361,
    "std": 0.34828081727027893,
    "var": 0.12129953503608704,
    "min": -0.4949129521846771,
    "max": 1.3592838048934937,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.008953271433711052,
    "std": 0.06009865179657936,
    "var": 0.003611848223954439,
    "min": -0.14982321858406067,
    "max": 0.10137148946523666,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.00401652604341507,
    "std": 0.21324697136878967,
    "var": 0.045474275946617126,
    "min": -0.9156118035316467,
    "max": 0.945966362953186,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.008262483403086662,
    "std": 0.1828128546476364,
    "var": 0.033420540392398834,
    "min": -0.8350100517272949,
    "max": 0.9123514890670776,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.07385377585887909,
    "std": 0.33591631054878235,
    "var": 0.11283978074789047,
    "min": -0.8749344944953918,
    "max": 1.2495518922805786,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.22016604244709015,
    "std": 0.3901727795600891,
    "var": 0.15223479270935059,
    "min": -1.2630269527435303,
    "max": 0.8709222078323364,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.4423811137676239,
    "std": 0.443853497505188,
    "var": 0.19700594246387482,
    "min": -1.7148268222808838,
    "max": 0.5448330044746399,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.4258573055267334,
    "std": 0.6068239808082581,
    "var": 0.36823534965515137,
    "min": -2.631680727005005,
    "max": 0.6261329054832458,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.8897757530212402,
    "std": 0.4092743992805481,
    "var": 0.16750553250312805,
    "min": -1.933278203010559,
    "max": 0.25730466842651367,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.9854371547698975,
    "std": 0.5615782141685486,
    "var": 0.3153700828552246,
    "min": -2.5762505531311035,
    "max": 0.24699938297271729,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
[2025-02-27 17:13:50,026][absl][INFO] - Saving checkpoint at step: 188640
[2025-02-27 17:13:50,027][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 17:13:50,028][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 17:13:50,029][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_188640.
[2025-02-27 17:13:50,031][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 17:13:50,032][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_188640.orbax-checkpoint-tmp-50
[2025-02-27 17:13:50,038][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 17:13:50,065][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 17:13:50,095][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 162.2 MiB/s (total bytes: 9.1 MiB) (time elapsed: 56 milliseconds) (per-host)
[2025-02-27 17:13:50,331][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-27 17:13:50,331][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 31.3 MiB/s (total bytes: 9.1 MiB) (time elapsed: 291 milliseconds) (per-host)
[2025-02-27 17:13:50,337][absl][INFO] - Updated Metadata={'item_handlers': 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler', 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1740694430034909294, 'commit_timestamp_nsecs': None, 'custom': {}} to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_188640.orbax-checkpoint-tmp-50/_CHECKPOINT_METADATA
[2025-02-27 17:13:50,337][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 17:13:50,373][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_188640.orbax-checkpoint-tmp-50 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_188640
[2025-02-27 17:13:50,380][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_188640`.
[2025-02-27 17:13:50,380][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 17:13:50,381][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_186282
| epoch 161 | 1000/1179 batches | ms/batch 1013.48 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.93
-----------------------------------------------------------------------------------------
| end of epoch 161 | time per epoch: 1121.32s |
| Train Metrics | accuracy:  0.77 | loss:  0.94
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 162 | 1000/1179 batches | ms/batch 901.30 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.96
-----------------------------------------------------------------------------------------
| end of epoch 162 | time per epoch: 1054.13s |
| Train Metrics | accuracy:  0.77 | loss:  0.96
| Eval  Metrics | accuracy:  0.84 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 163 | 1000/1179 batches | ms/batch 793.35 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.94
-----------------------------------------------------------------------------------------
| end of epoch 163 | time per epoch: 952.20s |
| Train Metrics | accuracy:  0.77 | loss:  0.93
| Eval  Metrics | accuracy:  0.85 | loss:  0.54
-----------------------------------------------------------------------------------------
| epoch 164 | 1000/1179 batches | ms/batch 868.34 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.94
-----------------------------------------------------------------------------------------
| end of epoch 164 | time per epoch: 1028.46s |
| Train Metrics | accuracy:  0.77 | loss:  0.95
| Eval  Metrics | accuracy:  0.84 | loss:  0.56
-----------------------------------------------------------------------------------------
| epoch 165 | 1000/1179 batches | ms/batch 792.28 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.94
-----------------------------------------------------------------------------------------
| end of epoch 165 | time per epoch: 967.81s |
| Train Metrics | accuracy:  0.77 | loss:  0.95
| Eval  Metrics | accuracy:  0.84 | loss:  0.55
-----------------------------------------------------------------------------------------
| epoch 166 | 1000/1179 batches | ms/batch 840.87 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.93
-----------------------------------------------------------------------------------------
| end of epoch 166 | time per epoch: 1029.18s |
| Train Metrics | accuracy:  0.77 | loss:  0.94
| Eval  Metrics | accuracy:  0.85 | loss:  0.56
-----------------------------------------------------------------------------------------
| epoch 167 | 1000/1179 batches | ms/batch 779.96 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.92
-----------------------------------------------------------------------------------------
| end of epoch 167 | time per epoch: 943.47s |
| Train Metrics | accuracy:  0.78 | loss:  0.91
| Eval  Metrics | accuracy:  0.85 | loss:  0.51
-----------------------------------------------------------------------------------------
[2025-02-27 19:21:43,135][absl][INFO] - Saving checkpoint at step: 196893
[2025-02-27 19:21:43,136][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 19:21:43,136][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 19:21:43,138][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_196893.
[2025-02-27 19:21:43,140][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 19:21:43,141][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_196893.orbax-checkpoint-tmp-51
[2025-02-27 19:21:43,149][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 19:21:43,176][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 19:21:43,206][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 161.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 56 milliseconds) (per-host)
[2025-02-27 19:21:43,464][absl][INFO] - ChainedFuture completed 1/1 futures in 0.26 seconds.
[2025-02-27 19:21:43,464][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 29.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 313 milliseconds) (per-host)
[2025-02-27 19:21:43,470][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 19:21:43,501][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_196893.orbax-checkpoint-tmp-51 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_196893
[2025-02-27 19:21:43,508][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_196893`.
[2025-02-27 19:21:43,508][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 19:21:43,510][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_188640
| epoch 168 | 1000/1179 batches | ms/batch 844.01 | Performance/Training accuracy:  0.77 | Performance/Training loss:  0.98
-----------------------------------------------------------------------------------------
| end of epoch 168 | time per epoch: 985.33s |
| Train Metrics | accuracy:  0.77 | loss:  0.97
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 169 | 1000/1179 batches | ms/batch 858.17 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.91
-----------------------------------------------------------------------------------------
| end of epoch 169 | time per epoch: 1011.86s |
| Train Metrics | accuracy:  0.78 | loss:  0.91
| Eval  Metrics | accuracy:  0.85 | loss:  0.53
-----------------------------------------------------------------------------------------
| epoch 170 | 1000/1179 batches | ms/batch 854.13 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.94
-----------------------------------------------------------------------------------------
| end of epoch 170 | time per epoch: 998.54s |
| Train Metrics | accuracy:  0.78 | loss:  0.95
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.27778252959251404,
    "std": 0.40105298161506653,
    "var": 0.16084349155426025,
    "min": -0.18535594642162323,
    "max": 1.1742085218429565,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.2878274619579315,
    "std": 0.2686694860458374,
    "var": 0.07218329608440399,
    "min": 0.013580462895333767,
    "max": 1.2626581192016602,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0005903507699258626,
    "std": 0.11583001166582108,
    "var": 0.013416591100394726,
    "min": -0.7371800541877747,
    "max": 0.7715381383895874,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.29255911707878113,
    "std": 0.2736382782459259,
    "var": 0.07487790286540985,
    "min": -0.050422925502061844,
    "max": 1.1831282377243042,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.3665105700492859,
    "std": 0.34668177366256714,
    "var": 0.12018825858831406,
    "min": 0.027487115934491158,
    "max": 1.5956580638885498,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0013718684203922749,
    "std": 0.12253785878419876,
    "var": 0.015015526674687862,
    "min": -0.7914355993270874,
    "max": 0.6374292969703674,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.27890822291374207,
    "std": 0.17802360653877258,
    "var": 0.03169240429997444,
    "min": -0.0077618868090212345,
    "max": 0.9361083507537842,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.4291638731956482,
    "std": 0.4215281307697296,
    "var": 0.17768597602844238,
    "min": 0.03144349902868271,
    "max": 2.358081102371216,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0007546046981588006,
    "std": 0.12146803736686707,
    "var": 0.01475448440760374,
    "min": -0.7804445624351501,
    "max": 0.9225888848304749,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.21433638036251068,
    "std": 0.2219637632369995,
    "var": 0.04926791414618492,
    "min": -0.31581056118011475,
    "max": 1.0955108404159546,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6348922252655029,
    "std": 0.2550758719444275,
    "var": 0.06506370007991791,
    "min": 0.041004348546266556,
    "max": 2.558499813079834,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0005419058143161237,
    "std": 0.049395136535167694,
    "var": 0.0024398795794695616,
    "min": -0.6649158000946045,
    "max": 1.0176303386688232,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.20833733677864075,
    "std": 0.23535975813865662,
    "var": 0.05539421737194061,
    "min": -0.29003050923347473,
    "max": 1.0801481008529663,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6427488327026367,
    "std": 0.2376900017261505,
    "var": 0.05649654194712639,
    "min": 0.11396923661231995,
    "max": 1.89398992061615,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.00037466990761458874,
    "std": 0.0590716116130352,
    "var": 0.003489455208182335,
    "min": -0.5978813767433167,
    "max": 0.648734986782074,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.015679001808166504,
    "std": 0.08374478667974472,
    "var": 0.007013189606368542,
    "min": -0.30600255727767944,
    "max": 0.23597949743270874,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.275957465171814,
    "std": 0.2612704336643219,
    "var": 0.0682622417807579,
    "min": 0.836249828338623,
    "max": 2.41709303855896,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0003026007325388491,
    "std": 0.08870337158441544,
    "var": 0.007868289016187191,
    "min": -0.7849507927894592,
    "max": 0.6591649055480957,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0003261215169914067,
    "std": 0.05934307724237442,
    "var": 0.0035216007381677628,
    "min": -0.3228450417518616,
    "max": 0.26561957597732544,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 5.89722185395658e-05,
    "std": 0.06140248477458954,
    "var": 0.0037702652625739574,
    "min": -0.3163292109966278,
    "max": 0.388237863779068,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0009987265802919865,
    "std": 0.05935291200876236,
    "var": 0.0035227681510150433,
    "min": -0.3736574947834015,
    "max": 0.2894918918609619,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -6.023760579410009e-05,
    "std": 0.04055393487215042,
    "var": 0.001644621603190899,
    "min": -0.27509254217147827,
    "max": 0.3051283657550812,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": -6.762459815945476e-05,
    "std": 0.05374618247151375,
    "var": 0.00288865203037858,
    "min": -0.4197710156440735,
    "max": 0.3333055078983307,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0005579099524766207,
    "std": 0.056688420474529266,
    "var": 0.0032135769724845886,
    "min": -0.3971005082130432,
    "max": 0.30145806074142456,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3426765203475952,
    "std": 0.10222765058279037,
    "var": 0.010450492613017559,
    "min": -0.6342737078666687,
    "max": -0.1538819968700409,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08587078005075455,
    "std": 0.25889384746551514,
    "var": 0.06702601909637451,
    "min": -0.990900456905365,
    "max": 1.1036632061004639,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.46155476570129395,
    "std": 0.8323434591293335,
    "var": 0.6927956342697144,
    "min": -2.086668014526367,
    "max": 1.9556869268417358,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.2919548451900482,
    "std": 0.12706226110458374,
    "var": 0.01614481955766678,
    "min": -0.6346081495285034,
    "max": 0.008245758712291718,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19429104030132294,
    "std": 0.19486747682094574,
    "var": 0.03797333315014839,
    "min": -1.3260914087295532,
    "max": 0.7584480047225952,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.5415182709693909,
    "std": 0.6570813059806824,
    "var": 0.43175584077835083,
    "min": -0.751224935054779,
    "max": 1.9775428771972656,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.2983173727989197,
    "std": 0.12754704058170319,
    "var": 0.016268249601125717,
    "min": -0.6282665133476257,
    "max": -0.044041410088539124,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.19794991612434387,
    "std": 0.20184825360774994,
    "var": 0.040742721408605576,
    "min": -1.3181276321411133,
    "max": 0.642909049987793,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.593508243560791,
    "std": 0.7337685227394104,
    "var": 0.5384162664413452,
    "min": -2.2624075412750244,
    "max": 2.7907652854919434,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.14492322504520416,
    "std": 0.06874758005142212,
    "var": 0.004726230166852474,
    "min": -0.3550299108028412,
    "max": 0.011740141548216343,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07679736614227295,
    "std": 0.13683249056339264,
    "var": 0.018723130226135254,
    "min": -1.0949655771255493,
    "max": 0.7012013792991638,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0007935863686725497,
    "std": 0.0022493277210742235,
    "var": 5.059475370217115e-06,
    "min": -0.0103968670591712,
    "max": 0.005405955482274294,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.0005851405439898372,
    "std": 0.08586812019348145,
    "var": 0.0073733339086174965,
    "min": -0.7878807187080383,
    "max": 0.8000422716140747,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.0060856956988573074,
    "std": 0.18926051259040833,
    "var": 0.03581954538822174,
    "min": -1.5672270059585571,
    "max": 1.2721480131149292,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.154457688331604,
    "std": 0.06857500225305557,
    "var": 0.004702531732618809,
    "min": -0.3402417302131653,
    "max": 0.013582882471382618,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.06828538328409195,
    "std": 0.13274912536144257,
    "var": 0.017622333019971848,
    "min": -1.2627652883529663,
    "max": 0.5995292663574219,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.12933579087257385,
    "std": 0.5438718795776367,
    "var": 0.29579660296440125,
    "min": -1.5886356830596924,
    "max": 1.5050041675567627,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.08074995875358582,
    "std": 0.11565054953098297,
    "var": 0.013375049456954002,
    "min": -0.24407032132148743,
    "max": 0.36410433053970337,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.027184195816516876,
    "std": 0.12031318247318268,
    "var": 0.014475262723863125,
    "min": -0.9309816956520081,
    "max": 0.5115593075752258,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.25659286975860596,
    "std": 0.33125877380371094,
    "var": 0.10973238199949265,
    "min": -0.479133278131485,
    "max": 1.2804285287857056,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.008923256769776344,
    "std": 0.058623895049095154,
    "var": 0.0034367612097412348,
    "min": -0.14778603613376617,
    "max": 0.09819178283214569,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.003991908393800259,
    "std": 0.21349041163921356,
    "var": 0.045578159391880035,
    "min": -0.92217618227005,
    "max": 0.9649412631988525,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.008161735720932484,
    "std": 0.17547693848609924,
    "var": 0.030792156234383583,
    "min": -0.816733717918396,
    "max": 0.8853753805160522,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.04784957692027092,
    "std": 0.32661715149879456,
    "var": 0.10667876899242401,
    "min": -0.8541174530982971,
    "max": 1.2373679876327515,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.20936140418052673,
    "std": 0.3843953013420105,
    "var": 0.14775973558425903,
    "min": -1.2251471281051636,
    "max": 0.8742161989212036,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.4274948239326477,
    "std": 0.4369543194770813,
    "var": 0.19092907011508942,
    "min": -1.6828093528747559,
    "max": 0.5550049543380737,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.3804757595062256,
    "std": 0.5925769209861755,
    "var": 0.3511474132537842,
    "min": -2.5925283432006836,
    "max": 0.6234835982322693,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.8584527373313904,
    "std": 0.4068180322647095,
    "var": 0.1655009239912033,
    "min": -1.9001350402832031,
    "max": 0.2579587399959564,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.9692577719688416,
    "std": 0.5575149655342102,
    "var": 0.3108229637145996,
    "min": -2.5446372032165527,
    "max": 0.23470810055732727,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.85 | loss:  0.53
-----------------------------------------------------------------------------------------
| epoch 171 | 1000/1179 batches | ms/batch 863.22 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.92
-----------------------------------------------------------------------------------------
| end of epoch 171 | time per epoch: 995.60s |
| Train Metrics | accuracy:  0.78 | loss:  0.93
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 172 | 1000/1179 batches | ms/batch 766.99 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.95
-----------------------------------------------------------------------------------------
| end of epoch 172 | time per epoch: 904.31s |
| Train Metrics | accuracy:  0.78 | loss:  0.93
| Eval  Metrics | accuracy:  0.85 | loss:  0.53
-----------------------------------------------------------------------------------------
| epoch 173 | 1000/1179 batches | ms/batch 794.23 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.92
-----------------------------------------------------------------------------------------
| end of epoch 173 | time per epoch: 941.61s |
| Train Metrics | accuracy:  0.78 | loss:  0.92
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 174 | 1000/1179 batches | ms/batch 812.80 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.91
-----------------------------------------------------------------------------------------
| end of epoch 174 | time per epoch: 982.27s |
| Train Metrics | accuracy:  0.78 | loss:  0.92
| Eval  Metrics | accuracy:  0.85 | loss:  0.53
-----------------------------------------------------------------------------------------
| epoch 175 | 1000/1179 batches | ms/batch 765.35 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.95
-----------------------------------------------------------------------------------------
| end of epoch 175 | time per epoch: 915.31s |
| Train Metrics | accuracy:  0.78 | loss:  0.93
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 176 | 1000/1179 batches | ms/batch 819.20 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.94
-----------------------------------------------------------------------------------------
| end of epoch 176 | time per epoch: 952.67s |
| Train Metrics | accuracy:  0.78 | loss:  0.93
| Eval  Metrics | accuracy:  0.85 | loss:  0.50
-----------------------------------------------------------------------------------------
[2025-02-27 21:57:40,142][absl][INFO] - Saving checkpoint at step: 207504
[2025-02-27 21:57:40,144][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 21:57:40,144][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 21:57:40,146][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_207504.
[2025-02-27 21:57:40,148][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 21:57:40,149][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_207504.orbax-checkpoint-tmp-52
[2025-02-27 21:57:40,162][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 21:57:40,188][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 21:57:40,223][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 150.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 60 milliseconds) (per-host)
[2025-02-27 21:57:40,469][absl][INFO] - ChainedFuture completed 1/1 futures in 0.25 seconds.
[2025-02-27 21:57:40,470][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 29.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 306 milliseconds) (per-host)
[2025-02-27 21:57:40,482][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 21:57:40,511][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_207504.orbax-checkpoint-tmp-52 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_207504
[2025-02-27 21:57:40,517][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_207504`.
[2025-02-27 21:57:40,517][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 21:57:40,519][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_196893
| epoch 177 | 1000/1179 batches | ms/batch 847.72 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.92
-----------------------------------------------------------------------------------------
| end of epoch 177 | time per epoch: 988.58s |
| Train Metrics | accuracy:  0.78 | loss:  0.91
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 178 | 1000/1179 batches | ms/batch 754.79 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.88
-----------------------------------------------------------------------------------------
| end of epoch 178 | time per epoch: 907.62s |
| Train Metrics | accuracy:  0.79 | loss:  0.89
| Eval  Metrics | accuracy:  0.85 | loss:  0.54
-----------------------------------------------------------------------------------------
| epoch 179 | 1000/1179 batches | ms/batch 811.52 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.90
-----------------------------------------------------------------------------------------
| end of epoch 179 | time per epoch: 951.69s |
| Train Metrics | accuracy:  0.79 | loss:  0.90
| Eval  Metrics | accuracy:  0.85 | loss:  0.53
-----------------------------------------------------------------------------------------
| epoch 180 | 1000/1179 batches | ms/batch 786.03 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.90
-----------------------------------------------------------------------------------------
| end of epoch 180 | time per epoch: 929.20s |
| Train Metrics | accuracy:  0.79 | loss:  0.90
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.2791748046875,
    "std": 0.4035555124282837,
    "var": 0.1628570556640625,
    "min": -0.18075880408287048,
    "max": 1.175418496131897,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.28792837262153625,
    "std": 0.27260372042655945,
    "var": 0.07431278377771378,
    "min": 0.01183003094047308,
    "max": 1.2812793254852295,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.000597176025621593,
    "std": 0.11583959311246872,
    "var": 0.013418811373412609,
    "min": -0.7363699078559875,
    "max": 0.7706671953201294,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.29472848773002625,
    "std": 0.277821809053421,
    "var": 0.07718496024608612,
    "min": -0.043662894517183304,
    "max": 1.1927837133407593,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.36694392561912537,
    "std": 0.3500601649284363,
    "var": 0.1225421279668808,
    "min": 0.020816728472709656,
    "max": 1.6124767065048218,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.001353436498902738,
    "std": 0.12256559729576111,
    "var": 0.01502232626080513,
    "min": -0.7920207977294922,
    "max": 0.6377110481262207,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.27986183762550354,
    "std": 0.1795719563961029,
    "var": 0.03224609047174454,
    "min": -0.009281344711780548,
    "max": 0.9445019960403442,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.4290394186973572,
    "std": 0.42426934838294983,
    "var": 0.18000447750091553,
    "min": 0.026162486523389816,
    "max": 2.3734793663024902,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0007598515367135406,
    "std": 0.12147367000579834,
    "var": 0.01475585252046585,
    "min": -0.7811022996902466,
    "max": 0.922224760055542,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.21685342490673065,
    "std": 0.2215372622013092,
    "var": 0.04907875880599022,
    "min": -0.30856770277023315,
    "max": 1.1024158000946045,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6320478320121765,
    "std": 0.2545487582683563,
    "var": 0.06479507684707642,
    "min": 0.03967294842004776,
    "max": 2.559494733810425,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0005298343021422625,
    "std": 0.04938487336039543,
    "var": 0.002438865602016449,
    "min": -0.6644608974456787,
    "max": 1.0180832147598267,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.21163535118103027,
    "std": 0.2353098839521408,
    "var": 0.055370740592479706,
    "min": -0.2840375304222107,
    "max": 1.0833903551101685,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6401036977767944,
    "std": 0.23605579137802124,
    "var": 0.05572233721613884,
    "min": 0.11395130306482315,
    "max": 1.8917802572250366,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0003728428855538368,
    "std": 0.059080448001623154,
    "var": 0.003490499220788479,
    "min": -0.5970987677574158,
    "max": 0.6485123038291931,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.013637850992381573,
    "std": 0.08350436389446259,
    "var": 0.006972978822886944,
    "min": -0.29650506377220154,
    "max": 0.2362605184316635,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.2850143909454346,
    "std": 0.2620510756969452,
    "var": 0.06867077201604843,
    "min": 0.845561683177948,
    "max": 2.4296557903289795,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00029605469899252057,
    "std": 0.0887165367603302,
    "var": 0.007870624773204327,
    "min": -0.7839358448982239,
    "max": 0.6620058417320251,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0003110997495241463,
    "std": 0.057388633489608765,
    "var": 0.00329345534555614,
    "min": -0.3056262135505676,
    "max": 0.24542944133281708,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 8.348825940629467e-05,
    "std": 0.059351325035095215,
    "var": 0.003522580023854971,
    "min": -0.29556891322135925,
    "max": 0.3690923750400543,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0009854782838374376,
    "std": 0.05738448724150658,
    "var": 0.0032929794397205114,
    "min": -0.3580888509750366,
    "max": 0.2820892333984375,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -4.182437260169536e-05,
    "std": 0.03952454775571823,
    "var": 0.0015621900092810392,
    "min": -0.26066142320632935,
    "max": 0.28746452927589417,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.0001419863401679322,
    "std": 0.052130818367004395,
    "var": 0.002717622322961688,
    "min": -0.4117279350757599,
    "max": 0.33148616552352905,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0005682036862708628,
    "std": 0.054823704063892365,
    "var": 0.003005638485774398,
    "min": -0.37204453349113464,
    "max": 0.2878691554069519,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3416033983230591,
    "std": 0.10249977558851242,
    "var": 0.010506204329431057,
    "min": -0.6364779472351074,
    "max": -0.1530746966600418,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08568909764289856,
    "std": 0.25834569334983826,
    "var": 0.06674250215291977,
    "min": -1.0070369243621826,
    "max": 1.1059894561767578,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.4527181088924408,
    "std": 0.8244982361793518,
    "var": 0.679797351360321,
    "min": -2.068474531173706,
    "max": 1.9153002500534058,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.2920578122138977,
    "std": 0.12711471319198608,
    "var": 0.016158150508999825,
    "min": -0.6212716698646545,
    "max": 0.002478147391229868,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19399423897266388,
    "std": 0.193772554397583,
    "var": 0.037547800689935684,
    "min": -1.3172916173934937,
    "max": 0.753358006477356,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.52848219871521,
    "std": 0.6442487835884094,
    "var": 0.4150565266609192,
    "min": -0.7348881959915161,
    "max": 1.937881588935852,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.2991974949836731,
    "std": 0.1269192397594452,
    "var": 0.016108494251966476,
    "min": -0.629840075969696,
    "max": -0.048705458641052246,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.1976615935564041,
    "std": 0.2005395144224167,
    "var": 0.04021609574556351,
    "min": -1.2968380451202393,
    "max": 0.6455138325691223,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.5770831108093262,
    "std": 0.7202091217041016,
    "var": 0.5187011957168579,
    "min": -2.2283623218536377,
    "max": 2.733538866043091,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.14672547578811646,
    "std": 0.0679301768541336,
    "var": 0.004614508710801601,
    "min": -0.3541446030139923,
    "max": 0.008330226875841618,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07687254995107651,
    "std": 0.13531436026096344,
    "var": 0.018309975042939186,
    "min": -1.0895001888275146,
    "max": 0.7025286555290222,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0008265635697171092,
    "std": 0.00207170145586133,
    "var": 4.29194733442273e-06,
    "min": -0.0111860241740942,
    "max": 0.003976292908191681,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.0006208944832906127,
    "std": 0.08426506817340851,
    "var": 0.007100602146238089,
    "min": -0.774050235748291,
    "max": 0.776538074016571,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.005826601758599281,
    "std": 0.18299810588359833,
    "var": 0.033488307148218155,
    "min": -1.5137261152267456,
    "max": 1.228635311126709,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15505170822143555,
    "std": 0.06771962344646454,
    "var": 0.0045859478414058685,
    "min": -0.3356376588344574,
    "max": 0.009942261502146721,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.0681651160120964,
    "std": 0.13142196834087372,
    "var": 0.0172717347741127,
    "min": -1.2705624103546143,
    "max": 0.5997857451438904,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.12395551055669785,
    "std": 0.5247652530670166,
    "var": 0.27537858486175537,
    "min": -1.5338538885116577,
    "max": 1.452212929725647,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.08200046420097351,
    "std": 0.11491573601961136,
    "var": 0.013205626979470253,
    "min": -0.23997725546360016,
    "max": 0.36548084020614624,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.02643027901649475,
    "std": 0.11892981827259064,
    "var": 0.014144301414489746,
    "min": -0.9268365502357483,
    "max": 0.5107776522636414,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.2494528591632843,
    "std": 0.3207372725009918,
    "var": 0.10287240147590637,
    "min": -0.46968743205070496,
    "max": 1.2342503070831299,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.0090120704844594,
    "std": 0.05880090594291687,
    "var": 0.003457546466961503,
    "min": -0.1482892483472824,
    "max": 0.0972374901175499,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.004028592724353075,
    "std": 0.21371711790561676,
    "var": 0.04567500576376915,
    "min": -0.9148050546646118,
    "max": 0.9721187353134155,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.008061086758971214,
    "std": 0.17108158767223358,
    "var": 0.029268909245729446,
    "min": -0.8186356425285339,
    "max": 0.8591787815093994,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.032521359622478485,
    "std": 0.3212375044822693,
    "var": 0.10319352895021439,
    "min": -0.8330584764480591,
    "max": 1.2192933559417725,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.20115645229816437,
    "std": 0.37991464138031006,
    "var": 0.14433512091636658,
    "min": -1.2063184976577759,
    "max": 0.8668984770774841,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.41789358854293823,
    "std": 0.4322431683540344,
    "var": 0.1868341565132141,
    "min": -1.6601790189743042,
    "max": 0.5452587008476257,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.3504505157470703,
    "std": 0.5821109414100647,
    "var": 0.3388531506061554,
    "min": -2.5651440620422363,
    "max": 0.6293402314186096,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.8376457095146179,
    "std": 0.40459778904914856,
    "var": 0.16369937360286713,
    "min": -1.8774436712265015,
    "max": 0.24973131716251373,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.9592458009719849,
    "std": 0.5539791584014893,
    "var": 0.30689293146133423,
    "min": -2.517287492752075,
    "max": 0.22739703953266144,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.85 | loss:  0.50
-----------------------------------------------------------------------------------------
[2025-02-27 23:06:33,647][absl][INFO] - Saving checkpoint at step: 212220
[2025-02-27 23:06:33,649][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-27 23:06:33,649][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-27 23:06:33,650][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_212220.
[2025-02-27 23:06:33,652][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-27 23:06:33,653][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_212220.orbax-checkpoint-tmp-53
[2025-02-27 23:06:33,661][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-27 23:06:33,688][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-27 23:06:33,721][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 153.5 MiB/s (total bytes: 9.1 MiB) (time elapsed: 59 milliseconds) (per-host)
[2025-02-27 23:06:33,986][absl][INFO] - ChainedFuture completed 1/1 futures in 0.26 seconds.
[2025-02-27 23:06:33,986][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 28.1 MiB/s (total bytes: 9.1 MiB) (time elapsed: 324 milliseconds) (per-host)
[2025-02-27 23:06:33,993][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-27 23:06:34,025][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_212220.orbax-checkpoint-tmp-53 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_212220
[2025-02-27 23:06:34,032][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_212220`.
[2025-02-27 23:06:34,032][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-27 23:06:34,034][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_207504
| epoch 181 | 1000/1179 batches | ms/batch 747.42 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.90
-----------------------------------------------------------------------------------------
| end of epoch 181 | time per epoch: 918.03s |
| Train Metrics | accuracy:  0.79 | loss:  0.91
| Eval  Metrics | accuracy:  0.85 | loss:  0.50
-----------------------------------------------------------------------------------------
| epoch 182 | 1000/1179 batches | ms/batch 854.18 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.90
-----------------------------------------------------------------------------------------
| end of epoch 182 | time per epoch: 1008.33s |
| Train Metrics | accuracy:  0.79 | loss:  0.90
| Eval  Metrics | accuracy:  0.85 | loss:  0.49
-----------------------------------------------------------------------------------------
| epoch 183 | 1000/1179 batches | ms/batch 850.85 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.89
-----------------------------------------------------------------------------------------
| end of epoch 183 | time per epoch: 978.56s |
| Train Metrics | accuracy:  0.79 | loss:  0.90
| Eval  Metrics | accuracy:  0.85 | loss:  0.54
-----------------------------------------------------------------------------------------
| epoch 184 | 1000/1179 batches | ms/batch 809.15 | Performance/Training accuracy:  0.78 | Performance/Training loss:  0.92
-----------------------------------------------------------------------------------------
| end of epoch 184 | time per epoch: 954.85s |
| Train Metrics | accuracy:  0.78 | loss:  0.92
| Eval  Metrics | accuracy:  0.85 | loss:  0.51
-----------------------------------------------------------------------------------------
| epoch 185 | 1000/1179 batches | ms/batch 794.39 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.90
-----------------------------------------------------------------------------------------
| end of epoch 185 | time per epoch: 936.39s |
| Train Metrics | accuracy:  0.79 | loss:  0.92
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 186 | 1000/1179 batches | ms/batch 810.87 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.88
-----------------------------------------------------------------------------------------
| end of epoch 186 | time per epoch: 929.86s |
| Train Metrics | accuracy:  0.79 | loss:  0.88
| Eval  Metrics | accuracy:  0.85 | loss:  0.50
-----------------------------------------------------------------------------------------
[2025-02-28 00:50:20,212][absl][INFO] - Saving checkpoint at step: 219294
[2025-02-28 00:50:20,214][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-28 00:50:20,214][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-28 00:50:20,215][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_219294.
[2025-02-28 00:50:20,218][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-28 00:50:20,219][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_219294.orbax-checkpoint-tmp-54
[2025-02-28 00:50:20,227][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-28 00:50:20,674][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-28 00:50:20,711][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 18.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 482 milliseconds) (per-host)
[2025-02-28 00:50:20,944][absl][INFO] - ChainedFuture completed 1/1 futures in 0.23 seconds.
[2025-02-28 00:50:20,944][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 12.7 MiB/s (total bytes: 9.1 MiB) (time elapsed: 716 milliseconds) (per-host)
[2025-02-28 00:50:20,950][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-28 00:50:20,980][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_219294.orbax-checkpoint-tmp-54 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_219294
[2025-02-28 00:50:20,986][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_219294`.
[2025-02-28 00:50:20,986][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-28 00:50:20,988][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_212220
| epoch 187 | 1000/1179 batches | ms/batch 756.47 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.87
-----------------------------------------------------------------------------------------
| end of epoch 187 | time per epoch: 916.36s |
| Train Metrics | accuracy:  0.79 | loss:  0.88
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 188 | 1000/1179 batches | ms/batch 756.24 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.91
-----------------------------------------------------------------------------------------
| end of epoch 188 | time per epoch: 923.58s |
| Train Metrics | accuracy:  0.79 | loss:  0.89
| Eval  Metrics | accuracy:  0.86 | loss:  0.49
-----------------------------------------------------------------------------------------
[2025-02-28 01:23:16,340][absl][INFO] - Saving checkpoint at step: 221652
[2025-02-28 01:23:16,342][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-28 01:23:16,342][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-28 01:23:16,343][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_221652.
[2025-02-28 01:23:16,346][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-28 01:23:16,347][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_221652.orbax-checkpoint-tmp-55
[2025-02-28 01:23:16,354][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-28 01:23:16,380][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-28 01:23:16,421][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 137.9 MiB/s (total bytes: 9.1 MiB) (time elapsed: 66 milliseconds) (per-host)
[2025-02-28 01:23:16,672][absl][INFO] - ChainedFuture completed 1/1 futures in 0.25 seconds.
[2025-02-28 01:23:16,672][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 28.8 MiB/s (total bytes: 9.1 MiB) (time elapsed: 317 milliseconds) (per-host)
[2025-02-28 01:23:16,678][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-28 01:23:16,709][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_221652.orbax-checkpoint-tmp-55 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_221652
[2025-02-28 01:23:16,715][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_221652`.
[2025-02-28 01:23:16,715][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-28 01:23:16,717][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_219294
| epoch 189 | 1000/1179 batches | ms/batch 842.31 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.91
-----------------------------------------------------------------------------------------
| end of epoch 189 | time per epoch: 996.47s |
| Train Metrics | accuracy:  0.79 | loss:  0.91
| Eval  Metrics | accuracy:  0.85 | loss:  0.53
-----------------------------------------------------------------------------------------
| epoch 190 | 1000/1179 batches | ms/batch 781.70 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.90
-----------------------------------------------------------------------------------------
| end of epoch 190 | time per epoch: 944.68s |
| Train Metrics | accuracy:  0.79 | loss:  0.90
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.27926361560821533,
    "std": 0.4039228856563568,
    "var": 0.16315369307994843,
    "min": -0.17988331615924835,
    "max": 1.1758366823196411,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.2878393232822418,
    "std": 0.27426764369010925,
    "var": 0.07522275298833847,
    "min": 0.009587784297764301,
    "max": 1.2875959873199463,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.000605525157880038,
    "std": 0.11584903299808502,
    "var": 0.01342099905014038,
    "min": -0.7359742522239685,
    "max": 0.7706321477890015,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.29534730315208435,
    "std": 0.2789298892021179,
    "var": 0.07780188322067261,
    "min": -0.0403791218996048,
    "max": 1.1968073844909668,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.3668818473815918,
    "std": 0.3513351082801819,
    "var": 0.1234363541007042,
    "min": 0.01977895013988018,
    "max": 1.6145343780517578,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0013465085066854954,
    "std": 0.12256428599357605,
    "var": 0.015022004954516888,
    "min": -0.7920131683349609,
    "max": 0.6378510594367981,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.2800248861312866,
    "std": 0.1800065040588379,
    "var": 0.032402344048023224,
    "min": -0.008481602184474468,
    "max": 0.9466875195503235,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.42921656370162964,
    "std": 0.4257567226886749,
    "var": 0.18126878142356873,
    "min": 0.02265945076942444,
    "max": 2.3847875595092773,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0007678712718188763,
    "std": 0.12147178500890732,
    "var": 0.01475539430975914,
    "min": -0.7810361385345459,
    "max": 0.9217292070388794,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.21783733367919922,
    "std": 0.22166649997234344,
    "var": 0.04913603514432907,
    "min": -0.30703043937683105,
    "max": 1.1028271913528442,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.6305420398712158,
    "std": 0.254361093044281,
    "var": 0.06469956785440445,
    "min": 0.03938734158873558,
    "max": 2.5560519695281982,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0005266068619675934,
    "std": 0.04938748851418495,
    "var": 0.0024391240440309048,
    "min": -0.6640854477882385,
    "max": 1.016774296760559,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.21310476958751678,
    "std": 0.2349853664636612,
    "var": 0.05521812289953232,
    "min": -0.2814731299877167,
    "max": 1.0828068256378174,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6392841339111328,
    "std": 0.23587986826896667,
    "var": 0.05563931167125702,
    "min": 0.11348255723714828,
    "max": 1.8952256441116333,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0003732991754077375,
    "std": 0.059084612876176834,
    "var": 0.003490991424769163,
    "min": -0.5966178774833679,
    "max": 0.6485060453414917,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.012784110382199287,
    "std": 0.08351916074752808,
    "var": 0.006975450552999973,
    "min": -0.295492023229599,
    "max": 0.239291712641716,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.2891178131103516,
    "std": 0.26211535930633545,
    "var": 0.06870447099208832,
    "min": 0.8516170978546143,
    "max": 2.431941270828247,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0002958747500088066,
    "std": 0.08871931582689285,
    "var": 0.007871117442846298,
    "min": -0.7838899493217468,
    "max": 0.6624971628189087,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.00032157672103494406,
    "std": 0.056620750576257706,
    "var": 0.0032059093937277794,
    "min": -0.2972071170806885,
    "max": 0.24188165366649628,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 7.948881102493033e-05,
    "std": 0.05851604789495468,
    "var": 0.0034241280518472195,
    "min": -0.29637888073921204,
    "max": 0.36104539036750793,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0009782483102753758,
    "std": 0.05653996765613556,
    "var": 0.003196767996996641,
    "min": -0.35278084874153137,
    "max": 0.27674585580825806,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -4.430769331520423e-05,
    "std": 0.03912241756916046,
    "var": 0.0015305634588003159,
    "min": -0.2586291432380676,
    "max": 0.28445515036582947,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.0001517349446658045,
    "std": 0.05142419785261154,
    "var": 0.0026444480754435062,
    "min": -0.40727362036705017,
    "max": 0.32717040181159973,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0005366390687413514,
    "std": 0.0540182925760746,
    "var": 0.0029179761186242104,
    "min": -0.36769431829452515,
    "max": 0.2852940261363983,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.341028094291687,
    "std": 0.10291516780853271,
    "var": 0.010591531172394753,
    "min": -0.6372629404067993,
    "max": -0.15320439636707306,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.0856163427233696,
    "std": 0.2578279972076416,
    "var": 0.0664752870798111,
    "min": -1.004919171333313,
    "max": 1.104777455329895,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.4489745497703552,
    "std": 0.8211711049079895,
    "var": 0.6743220090866089,
    "min": -2.0637948513031006,
    "max": 1.895939826965332,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.2918686270713806,
    "std": 0.12737742066383362,
    "var": 0.01622501015663147,
    "min": -0.6208310127258301,
    "max": 0.0049143582582473755,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.19371367990970612,
    "std": 0.1932106763124466,
    "var": 0.03733036294579506,
    "min": -1.3118951320648193,
    "max": 0.7463557124137878,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.5228601694107056,
    "std": 0.638985276222229,
    "var": 0.4083021879196167,
    "min": -0.7343524098396301,
    "max": 1.9211093187332153,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.2995818555355072,
    "std": 0.12625141441822052,
    "var": 0.015939421951770782,
    "min": -0.6289563179016113,
    "max": -0.04772729054093361,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.19758279621601105,
    "std": 0.20000505447387695,
    "var": 0.04000202193856239,
    "min": -1.292217493057251,
    "max": 0.6459960341453552,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.5699080228805542,
    "std": 0.7149083018302917,
    "var": 0.5110939145088196,
    "min": -2.216336965560913,
    "max": 2.7094788551330566,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.14754021167755127,
    "std": 0.06783130019903183,
    "var": 0.0046010855585336685,
    "min": -0.3570387363433838,
    "max": 0.00625436007976532,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07695432752370834,
    "std": 0.13465382158756256,
    "var": 0.018131650984287262,
    "min": -1.0830856561660767,
    "max": 0.70027095079422,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0007829621317796409,
    "std": 0.001970417331904173,
    "var": 3.882544660882559e-06,
    "min": -0.010271442122757435,
    "max": 0.003037781221792102,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.0005902466364204884,
    "std": 0.08356117457151413,
    "var": 0.0069824703969061375,
    "min": -0.7671788334846497,
    "max": 0.7670920491218567,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.005665835924446583,
    "std": 0.1803768426179886,
    "var": 0.03253580257296562,
    "min": -1.487202525138855,
    "max": 1.2087346315383911,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.15547005832195282,
    "std": 0.06739477813243866,
    "var": 0.00454205647110939,
    "min": -0.3365868031978607,
    "max": 0.0045344289392232895,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.06817977875471115,
    "std": 0.13086342811584473,
    "var": 0.017125239595770836,
    "min": -1.2738813161849976,
    "max": 0.599712610244751,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.12161052227020264,
    "std": 0.5165504217147827,
    "var": 0.2668243646621704,
    "min": -1.5094958543777466,
    "max": 1.4296740293502808,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.08270372450351715,
    "std": 0.11492739617824554,
    "var": 0.013208307325839996,
    "min": -0.23876741528511047,
    "max": 0.36944741010665894,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.026088450103998184,
    "std": 0.11840172857046127,
    "var": 0.014018969610333443,
    "min": -0.9251151084899902,
    "max": 0.5076980590820312,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.24651741981506348,
    "std": 0.3160429298877716,
    "var": 0.09988313168287277,
    "min": -0.46528834104537964,
    "max": 1.2169663906097412,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.009060333482921124,
    "std": 0.05883745104074478,
    "var": 0.0034618456847965717,
    "min": -0.14878998696804047,
    "max": 0.09564398974180222,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.004035217687487602,
    "std": 0.2138500213623047,
    "var": 0.045731835067272186,
    "min": -0.9153186678886414,
    "max": 0.9728116393089294,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.008097079582512379,
    "std": 0.16922593116760254,
    "var": 0.028637418523430824,
    "min": -0.8158597350120544,
    "max": 0.8521021008491516,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.02561287395656109,
    "std": 0.3185313642024994,
    "var": 0.1014622300863266,
    "min": -0.8226835131645203,
    "max": 1.2196147441864014,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.19704028964042664,
    "std": 0.37797755002975464,
    "var": 0.14286702871322632,
    "min": -1.1997321844100952,
    "max": 0.8626654744148254,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.4137060046195984,
    "std": 0.43003368377685547,
    "var": 0.1849289834499359,
    "min": -1.6462266445159912,
    "max": 0.5433737635612488,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.3367125988006592,
    "std": 0.5775132775306702,
    "var": 0.3335215747356415,
    "min": -2.554549217224121,
    "max": 0.6274271607398987,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.8296408653259277,
    "std": 0.4035189151763916,
    "var": 0.1628275215625763,
    "min": -1.869445562362671,
    "max": 0.24885345995426178,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.9550456404685974,
    "std": 0.5525221824645996,
    "var": 0.30528080463409424,
    "min": -2.508639097213745,
    "max": 0.2276056557893753,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.86 | loss:  0.49
-----------------------------------------------------------------------------------------
[2025-02-28 01:58:19,614][absl][INFO] - Saving checkpoint at step: 224010
[2025-02-28 01:58:19,615][absl][INFO] - Using Orbax as backend to save Flax checkpoints. For potential troubleshooting see: https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting
[2025-02-28 01:58:19,615][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-28 01:58:19,616][absl][INFO] - [process=0] Started saving checkpoint to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_224010.
[2025-02-28 01:58:19,618][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:pre
[2025-02-28 01:58:19,619][absl][INFO] - Creating tmp directory /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_224010.orbax-checkpoint-tmp-56
[2025-02-28 01:58:19,627][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: create_tmp_directory:post
[2025-02-28 01:58:19,654][absl][INFO] - Transferring arrays to host memory with options: use_replica_parallel=False, enable_pinned_host_transfer=False
[2025-02-28 01:58:19,684][absl][INFO] - [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 163.0 MiB/s (total bytes: 9.1 MiB) (time elapsed: 55 milliseconds) (per-host)
[2025-02-28 01:58:20,030][absl][INFO] - ChainedFuture completed 1/1 futures in 0.34 seconds.
[2025-02-28 01:58:20,031][absl][INFO] - [process=0] /jax/checkpoint/write/bytes_per_sec: 22.6 MiB/s (total bytes: 9.1 MiB) (time elapsed: 403 milliseconds) (per-host)
[2025-02-28 01:58:20,036][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:save
[2025-02-28 01:58:20,067][absl][INFO] - Renaming /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_224010.orbax-checkpoint-tmp-56 to /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_224010
[2025-02-28 01:58:20,073][absl][INFO] - [process=0][thread=MainThread] Finished saving checkpoint (finalized tmp dir) to `/nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_224010`.
[2025-02-28 01:58:20,073][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:finalize
[2025-02-28 01:58:20,075][absl][INFO] - Removing checkpoint at /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_221652
| epoch 191 | 1000/1179 batches | ms/batch 849.10 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.89
-----------------------------------------------------------------------------------------
| end of epoch 191 | time per epoch: 983.99s |
| Train Metrics | accuracy:  0.79 | loss:  0.89
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 192 | 1000/1179 batches | ms/batch 847.20 | Performance/Training accuracy:  0.80 | Performance/Training loss:  0.86
-----------------------------------------------------------------------------------------
| end of epoch 192 | time per epoch: 985.33s |
| Train Metrics | accuracy:  0.80 | loss:  0.86
| Eval  Metrics | accuracy:  0.85 | loss:  0.51
-----------------------------------------------------------------------------------------
| epoch 193 | 1000/1179 batches | ms/batch 838.29 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.89
-----------------------------------------------------------------------------------------
| end of epoch 193 | time per epoch: 953.68s |
| Train Metrics | accuracy:  0.79 | loss:  0.89
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 194 | 1000/1179 batches | ms/batch 870.92 | Performance/Training accuracy:  0.80 | Performance/Training loss:  0.86
-----------------------------------------------------------------------------------------
| end of epoch 194 | time per epoch: 1031.78s |
| Train Metrics | accuracy:  0.79 | loss:  0.87
| Eval  Metrics | accuracy:  0.86 | loss:  0.50
-----------------------------------------------------------------------------------------
| epoch 195 | 1000/1179 batches | ms/batch 792.88 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.88
-----------------------------------------------------------------------------------------
| end of epoch 195 | time per epoch: 936.74s |
| Train Metrics | accuracy:  0.79 | loss:  0.89
| Eval  Metrics | accuracy:  0.85 | loss:  0.52
-----------------------------------------------------------------------------------------
| epoch 196 | 1000/1179 batches | ms/batch 773.73 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.88
-----------------------------------------------------------------------------------------
| end of epoch 196 | time per epoch: 902.78s |
| Train Metrics | accuracy:  0.79 | loss:  0.87
| Eval  Metrics | accuracy:  0.86 | loss:  0.50
-----------------------------------------------------------------------------------------
| epoch 197 | 1000/1179 batches | ms/batch 796.58 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.90
-----------------------------------------------------------------------------------------
| end of epoch 197 | time per epoch: 933.27s |
| Train Metrics | accuracy:  0.79 | loss:  0.90
| Eval  Metrics | accuracy:  0.86 | loss:  0.50
-----------------------------------------------------------------------------------------
| epoch 198 | 1000/1179 batches | ms/batch 792.15 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.90
-----------------------------------------------------------------------------------------
| end of epoch 198 | time per epoch: 932.15s |
| Train Metrics | accuracy:  0.79 | loss:  0.90
| Eval  Metrics | accuracy:  0.86 | loss:  0.50
-----------------------------------------------------------------------------------------
| epoch 199 | 1000/1179 batches | ms/batch 764.49 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.91
-----------------------------------------------------------------------------------------
| end of epoch 199 | time per epoch: 906.03s |
| Train Metrics | accuracy:  0.79 | loss:  0.90
| Eval  Metrics | accuracy:  0.85 | loss:  0.50
-----------------------------------------------------------------------------------------
| epoch 200 | 1000/1179 batches | ms/batch 764.95 | Performance/Training accuracy:  0.79 | Performance/Training loss:  0.89
-----------------------------------------------------------------------------------------
| end of epoch 200 | time per epoch: 889.37s |
| Train Metrics | accuracy:  0.79 | loss:  0.90
==== Parameter Statistics: Lambda ====
{}
==== Parameter Statistics: B Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.2793593406677246,
    "std": 0.4041275084018707,
    "var": 0.16331903636455536,
    "min": -0.18085019290447235,
    "max": 1.176914095878601,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.2877606153488159,
    "std": 0.2745046317577362,
    "var": 0.07535280287265778,
    "min": 0.009490299969911575,
    "max": 1.2885136604309082,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/B": {
    "mean": -0.0006053012912161648,
    "std": 0.11584968864917755,
    "var": 0.013421150855720043,
    "min": -0.7359151840209961,
    "max": 0.7706435322761536,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.2954576015472412,
    "std": 0.2792151868343353,
    "var": 0.07796111702919006,
    "min": -0.03998621180653572,
    "max": 1.1972979307174683,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.3668750524520874,
    "std": 0.3515136241912842,
    "var": 0.12356182187795639,
    "min": 0.019046751782298088,
    "max": 1.6152397394180298,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0013451778795570135,
    "std": 0.12256483733654022,
    "var": 0.015022139996290207,
    "min": -0.7919872403144836,
    "max": 0.6378834247589111,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": 0.28008875250816345,
    "std": 0.18004260957241058,
    "var": 0.03241534158587456,
    "min": -0.008528796955943108,
    "max": 0.9471060633659363,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 0.4292389750480652,
    "std": 0.42593833804130554,
    "var": 0.18142347037792206,
    "min": 0.022902650758624077,
    "max": 2.385867118835449,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.0007658569957129657,
    "std": 0.12147345393896103,
    "var": 0.014755800366401672,
    "min": -0.78099524974823,
    "max": 0.9218493103981018,
    "shape": [
      128,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/bias": {
    "mean": 0.21799854934215546,
    "std": 0.22162418067455292,
    "var": 0.049117278307676315,
    "min": -0.3066598176956177,
    "max": 1.10311758518219,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/BatchNorm_0/scale": {
    "mean": 0.630306601524353,
    "std": 0.2543317973613739,
    "var": 0.0646846741437912,
    "min": 0.03921329975128174,
    "max": 2.555741310119629,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/B": {
    "mean": 0.0005260019097477198,
    "std": 0.04938831552863121,
    "var": 0.0024392057675868273,
    "min": -0.6641446948051453,
    "max": 1.0166738033294678,
    "shape": [
      256,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/bias": {
    "mean": 0.2132384032011032,
    "std": 0.2349143922328949,
    "var": 0.05518477410078049,
    "min": -0.28123587369918823,
    "max": 1.0833702087402344,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/BatchNorm_0/scale": {
    "mean": 0.6391351819038391,
    "std": 0.23577067255973816,
    "var": 0.05558780953288078,
    "min": 0.11342771351337433,
    "max": 1.8954192399978638,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/B": {
    "mean": 0.0003730931493919343,
    "std": 0.05908547341823578,
    "var": 0.0034910934045910835,
    "min": -0.5967220664024353,
    "max": 0.6484273672103882,
    "shape": [
      256,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/bias": {
    "mean": -0.012636695057153702,
    "std": 0.08350876718759537,
    "var": 0.006973715033382177,
    "min": -0.2945004999637604,
    "max": 0.23939405381679535,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/BatchNorm_0/scale": {
    "mean": 1.289775013923645,
    "std": 0.26228630542755127,
    "var": 0.06879410147666931,
    "min": 0.8523873090744019,
    "max": 2.4325554370880127,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/B": {
    "mean": 0.00029571718187071383,
    "std": 0.08871957659721375,
    "var": 0.007871164008975029,
    "min": -0.7839819192886353,
    "max": 0.6626065373420715,
    "shape": [
      256,
      192
    ]
  }
}
==== Parameter Statistics: C Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/C": {
    "mean": -0.0003198926569893956,
    "std": 0.05648670718073845,
    "var": 0.0031907479278743267,
    "min": -0.295788049697876,
    "max": 0.24161094427108765,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/C": {
    "mean": 8.005699783097953e-05,
    "std": 0.05838741362094879,
    "var": 0.003409090219065547,
    "min": -0.29665595293045044,
    "max": 0.36014604568481445,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/C": {
    "mean": 0.0009752946789376438,
    "std": 0.056415025144815445,
    "var": 0.0031826552003622055,
    "min": -0.35179731249809265,
    "max": 0.27578437328338623,
    "shape": [
      96,
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/C": {
    "mean": -4.659401020035148e-05,
    "std": 0.039065055549144745,
    "var": 0.0015260785585269332,
    "min": -0.2580941319465637,
    "max": 0.28391212224960327,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/C": {
    "mean": -0.00015287616406567395,
    "std": 0.05131925642490387,
    "var": 0.002633666153997183,
    "min": -0.4064857065677643,
    "max": 0.32667097449302673,
    "shape": [
      192,
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/C": {
    "mean": -0.0005363377276808023,
    "std": 0.05389730632305145,
    "var": 0.0029049196746200323,
    "min": -0.36687976121902466,
    "max": 0.28389298915863037,
    "shape": [
      192,
      256
    ]
  }
}
==== Parameter Statistics: D Matrices ====
{
  "encoder/stages_0/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.3409954905509949,
    "std": 0.10298426449298859,
    "var": 0.010605758987367153,
    "min": -0.636743426322937,
    "max": -0.15348999202251434,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.08561781048774719,
    "std": 0.257743775844574,
    "var": 0.06643185764551163,
    "min": -1.00432550907135,
    "max": 1.1045573949813843,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/D": {
    "mean": 0.4483683109283447,
    "std": 0.8206484913825989,
    "var": 0.6734639406204224,
    "min": -2.062350034713745,
    "max": 1.8938337564468384,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.291904091835022,
    "std": 0.1272924840450287,
    "var": 0.01620337925851345,
    "min": -0.6213027834892273,
    "max": 0.00457576010376215,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.1936987340450287,
    "std": 0.1931239664554596,
    "var": 0.03729686886072159,
    "min": -1.3112062215805054,
    "max": 0.7459467053413391,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.5220159292221069,
    "std": 0.6382498145103455,
    "var": 0.4073628783226013,
    "min": -0.7334259152412415,
    "max": 1.9185079336166382,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/bias": {
    "mean": -0.29963821172714233,
    "std": 0.12616319954395294,
    "var": 0.015917152166366577,
    "min": -0.629395067691803,
    "max": -0.048013750463724136,
    "shape": [
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.19756817817687988,
    "std": 0.19991923868656158,
    "var": 0.03996770456433296,
    "min": -1.2916359901428223,
    "max": 0.6453400254249573,
    "shape": [
      96,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.5687627792358398,
    "std": 0.714086651802063,
    "var": 0.5099197626113892,
    "min": -2.214210271835327,
    "max": 2.7059497833251953,
    "shape": [
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/bias": {
    "mean": -0.14766104519367218,
    "std": 0.06773997843265533,
    "var": 0.004588705487549305,
    "min": -0.3559674620628357,
    "max": 0.0063393451273441315,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_0/kernel": {
    "mean": -0.07695551961660385,
    "std": 0.1345517635345459,
    "var": 0.018104176968336105,
    "min": -1.0824322700500488,
    "max": 0.7012924551963806,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/bias": {
    "mean": -0.0007916956092230976,
    "std": 0.001953920815140009,
    "var": 3.817806373263011e-06,
    "min": -0.01014379970729351,
    "max": 0.003222648287191987,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/Dense_1/kernel": {
    "mean": -0.0005892146145924926,
    "std": 0.08344874531030655,
    "var": 0.0069636935368180275,
    "min": -0.7658591866493225,
    "max": 0.765600323677063,
    "shape": [
      96,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/D": {
    "mean": -0.0056440155021846294,
    "std": 0.17997103929519653,
    "var": 0.032389573752880096,
    "min": -1.4836790561676025,
    "max": 1.2059712409973145,
    "shape": [
      192,
      96
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/bias": {
    "mean": -0.1555115282535553,
    "std": 0.0674097016453743,
    "var": 0.004544067662209272,
    "min": -0.33622801303863525,
    "max": 0.004874470643699169,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/Dense_0/kernel": {
    "mean": -0.06818237155675888,
    "std": 0.13077139854431152,
    "var": 0.017101159319281578,
    "min": -1.2732429504394531,
    "max": 0.5995798110961914,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/D": {
    "mean": 0.12128272652626038,
    "std": 0.5152877569198608,
    "var": 0.26552149653434753,
    "min": -1.5055997371673584,
    "max": 1.4260988235473633,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/bias": {
    "mean": 0.08285877108573914,
    "std": 0.1148643046617508,
    "var": 0.013193808495998383,
    "min": -0.23776796460151672,
    "max": 0.36866897344589233,
    "shape": [
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/Dense_0/kernel": {
    "mean": -0.026006130501627922,
    "std": 0.11832191050052643,
    "var": 0.014000074937939644,
    "min": -0.9254503846168518,
    "max": 0.5071507096290588,
    "shape": [
      192,
      192
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/D": {
    "mean": 0.24603943526744843,
    "std": 0.315325528383255,
    "var": 0.09943018853664398,
    "min": -0.4643693268299103,
    "max": 1.2138938903808594,
    "shape": [
      192
    ]
  }
}
==== Parameter Statistics: Other ====
{
  "decoder/bias": {
    "mean": -0.00906611792743206,
    "std": 0.058799970895051956,
    "var": 0.003457436803728342,
    "min": -0.14832226932048798,
    "max": 0.09604736417531967,
    "shape": [
      35
    ]
  },
  "decoder/kernel": {
    "mean": -0.004034398589283228,
    "std": 0.21388578414916992,
    "var": 0.04574713110923767,
    "min": -0.9148371815681458,
    "max": 0.9733748435974121,
    "shape": [
      192,
      35
    ]
  },
  "encoder/encoder/embedding": {
    "mean": -0.008095786906778812,
    "std": 0.1689525842666626,
    "var": 0.02854497730731964,
    "min": -0.8146129250526428,
    "max": 0.8504936695098877,
    "shape": [
      700,
      96
    ]
  },
  "encoder/stages_0/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -0.024619553238153458,
    "std": 0.3182109594345093,
    "var": 0.10125820338726044,
    "min": -0.8204959034919739,
    "max": 1.2195662260055542,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.19649656116962433,
    "std": 0.3777119815349579,
    "var": 0.14266633987426758,
    "min": -1.1977578401565552,
    "max": 0.8621614575386047,
    "shape": [
      128
    ]
  },
  "encoder/stages_0/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.4131110906600952,
    "std": 0.42959895730018616,
    "var": 0.1845552772283554,
    "min": -1.644742727279663,
    "max": 0.5431074500083923,
    "shape": [
      128
    ]
  },
  "encoder/stages_1/SequenceLayer_0/S5SSM_0/log_step": {
    "mean": -1.334586501121521,
    "std": 0.5767629742622375,
    "var": 0.33265551924705505,
    "min": -2.552666664123535,
    "max": 0.6268550157546997,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_1/S5SSM_0/log_step": {
    "mean": -0.8283050060272217,
    "std": 0.4033276438713074,
    "var": 0.1626731902360916,
    "min": -1.8679203987121582,
    "max": 0.24827028810977936,
    "shape": [
      256
    ]
  },
  "encoder/stages_1/SequenceLayer_2/S5SSM_0/log_step": {
    "mean": -0.9544371366500854,
    "std": 0.5523151755332947,
    "var": 0.3050520420074463,
    "min": -2.506883144378662,
    "max": 0.2270902693271637,
    "shape": [
      256
    ]
  }
}
| Eval  Metrics | accuracy:  0.85 | loss:  0.51
-----------------------------------------------------------------------------------------
[2025-02-28 04:50:01,480][absl][INFO] - Restoring orbax checkpoint from /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_224010
[2025-02-28 04:50:01,481][absl][INFO] - Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None
[2025-02-28 04:50:01,488][absl][INFO] - Restoring checkpoint from /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_224010.
[2025-02-28 04:50:01,790][absl][WARNING] - The transformations API will eventually be replaced by an upgraded design. The current API will not be removed until this point, but it will no longer be actively worked on.
[2025-02-28 04:50:01,797][absl][INFO] - Finished restoring checkpoint from /nfs/turbo/coe-wluee/zxygo/event-ssm_ver2/outputs/2025-02-25-17-52-09/checkpoints/checkpoint_224010.
[2025-02-28 04:50:01,797][absl][INFO] - [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:restore
[SequenceLayer] Layer 0: using manual_lambda = -0.3
SSM: 96 -> 128 -> 96 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 2: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 0: using manual_lambda = -0.2
SSM: 96 -> 256 -> 192 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.2
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 2: using manual_lambda = -0.2
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 0: using manual_lambda = -0.3
SSM: 96 -> 128 -> 96 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 2: using manual_lambda = -0.2
SSM: 96 -> 128 -> 96
[SequenceLayer] Layer 0: using manual_lambda = -0.2
SSM: 96 -> 256 -> 192 (stride 8 with pooling mode avgpool)
[SequenceLayer] Layer 1: using manual_lambda = -0.2
SSM: 192 -> 256 -> 192
[SequenceLayer] Layer 2: using manual_lambda = -0.2
SSM: 192 -> 256 -> 192
-----------------------------------------------------------------------------------------
| End of Training |
| Test  Metrics |  accuracy:  0.85 |  loss:  0.54
-----------------------------------------------------------------------------------------
